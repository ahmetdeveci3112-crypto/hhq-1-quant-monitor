"""
HHQ-1 Quant Monitor - Python Backend v2.0
==========================================
FastAPI WebSocket server for real-time algorithmic trading analysis.

Features:
- Binance WebSocket data streaming via CCXT
- Hurst Exponent calculation (R/S Analysis)
- Z-Score calculation for pairs trading
- ATR calculation for volatility-based risk management
- Order Book imbalance analysis
- Liquidation cascade detection
- 4-Layer signal generation
"""

import asyncio
import json
import logging
import math
import os
import time
import websockets
from collections import deque
from datetime import datetime, timedelta
from typing import Optional, Dict, Any

import ccxt.async_support as ccxt_async
import ccxt as ccxt_sync
import numpy as np
import pandas as pd
import pytz
from contextlib import asynccontextmanager
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Phase 193: pandas-ta for enhanced technical indicators
try:
    import pandas_ta as pta
    PANDAS_TA_AVAILABLE = True
    logger.info("‚úÖ pandas-ta loaded successfully")
except ImportError:
    PANDAS_TA_AVAILABLE = False
    logger.warning("‚ö†Ô∏è pandas-ta not installed, using manual TA calculations")

# Phase 193: Import new modules (graceful fallback)
try:
    from ccxt_ws_manager import ccxt_ws_manager
    logger.info("‚úÖ ccxt_ws_manager loaded")
except ImportError:
    ccxt_ws_manager = None
    logger.warning("‚ö†Ô∏è ccxt_ws_manager not available")

try:
    from freqai_adapter import freqai_model
    logger.info("‚úÖ freqai_adapter loaded")
except ImportError:
    freqai_model = None
    logger.warning("‚ö†Ô∏è freqai_adapter not available")

try:
    from hyperopt import hhq_hyperoptimizer
    logger.info("‚úÖ hyperopt loaded")
except ImportError:
    hhq_hyperoptimizer = None
    logger.warning("‚ö†Ô∏è hyperopt not available")

# ============================================================================
# SQLITE DATABASE MANAGER
# ============================================================================
import aiosqlite

class SQLiteManager:
    """
    Async SQLite database manager for persistent storage.
    Stores trades, settings, and logs in a SQLite database.
    """
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            if os.path.exists("/data"):
                db_path = "/data/trading.db"
                logger.info("üìÅ Using persistent SQLite: /data/trading.db")
            else:
                db_path = "trading.db"
                logger.info("üìÅ Using local SQLite: trading.db")
        self.db_path = db_path
        self._initialized = False
    
    async def init_db(self):
        """Initialize database tables."""
        if self._initialized:
            return
        
        async with aiosqlite.connect(self.db_path) as db:
            # Trades table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS trades (
                    id TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    exit_price REAL,
                    size REAL NOT NULL,
                    size_usd REAL NOT NULL,
                    pnl REAL,
                    pnl_percent REAL,
                    open_time INTEGER NOT NULL,
                    close_time INTEGER,
                    close_reason TEXT,
                    leverage INTEGER DEFAULT 10,
                    signal_score INTEGER DEFAULT 0,
                    mtf_score INTEGER DEFAULT 0,
                    z_score REAL DEFAULT 0,
                    spread_level TEXT DEFAULT 'unknown',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Settings table (key-value)
            await db.execute('''
                CREATE TABLE IF NOT EXISTS settings (
                    key TEXT PRIMARY KEY,
                    value TEXT NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Logs table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    time TEXT NOT NULL,
                    message TEXT NOT NULL,
                    ts INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Equity curve table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS equity_curve (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    time INTEGER NOT NULL,
                    balance REAL NOT NULL,
                    drawdown REAL NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Coin stats table (for blacklist system)
            await db.execute('''
                CREATE TABLE IF NOT EXISTS coin_stats (
                    symbol TEXT PRIMARY KEY,
                    wins INTEGER DEFAULT 0,
                    losses INTEGER DEFAULT 0,
                    consecutive_losses INTEGER DEFAULT 0,
                    consecutive_wins INTEGER DEFAULT 0,
                    total_pnl REAL DEFAULT 0,
                    last_trade_time REAL DEFAULT 0,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Signals table - ALL signals (accepted AND rejected) for performance analysis
            await db.execute('''
                CREATE TABLE IF NOT EXISTS signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    action TEXT NOT NULL,
                    price REAL NOT NULL,
                    zscore REAL,
                    hurst REAL,
                    atr REAL,
                    signal_score INTEGER,
                    htf_trend TEXT,
                    mtf_confirmed INTEGER,
                    mtf_reason TEXT,
                    blacklisted INTEGER DEFAULT 0,
                    accepted INTEGER DEFAULT 0,
                    reject_reason TEXT,
                    z_threshold REAL,
                    min_confidence REAL,
                    entry_tightness REAL,
                    exit_tightness REAL,
                    timestamp INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Open positions table - tracks positions while open
            await db.execute('''
                CREATE TABLE IF NOT EXISTS positions (
                    id TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    size REAL NOT NULL,
                    size_usd REAL NOT NULL,
                    stop_loss REAL,
                    take_profit REAL,
                    leverage INTEGER,
                    open_time INTEGER NOT NULL,
                    signal_score INTEGER,
                    zscore REAL,
                    hurst REAL,
                    atr REAL,
                    htf_trend TEXT,
                    status TEXT DEFAULT 'OPEN',
                    close_time INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Migrate: add close_time column if missing
            try:
                await db.execute('ALTER TABLE positions ADD COLUMN close_time INTEGER')
                logger.info("üìÇ Added close_time column to positions table")
            except:
                pass  # Column already exists
            
            # Binance trade history - her realized PnL income kaydƒ±
            await db.execute('''
                CREATE TABLE IF NOT EXISTS binance_trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    income_id TEXT UNIQUE,
                    symbol TEXT NOT NULL,
                    side TEXT,
                    entry_price REAL,
                    exit_price REAL,
                    pnl REAL NOT NULL,
                    pnl_percent REAL,
                    margin REAL,
                    leverage INTEGER,
                    size_usd REAL,
                    close_reason TEXT,
                    close_time INTEGER NOT NULL,
                    raw_data TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Position close events - her pozisyon kapatma kaydƒ±
            await db.execute('''
                CREATE TABLE IF NOT EXISTS position_closes (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    reason TEXT NOT NULL,
                    original_reason TEXT,
                    entry_price REAL,
                    exit_price REAL,
                    pnl REAL,
                    leverage INTEGER,
                    size_usd REAL,
                    margin REAL,
                    roi REAL,
                    timestamp INTEGER NOT NULL,
                    matched_to_income INTEGER DEFAULT 0,
                    mae_pct REAL DEFAULT 0,
                    mfe_pct REAL DEFAULT 0,
                    decision_trace TEXT DEFAULT '[]',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Leverage cache - pozisyon leverage bilgilerini sakla
            await db.execute('''
                CREATE TABLE IF NOT EXISTS leverage_cache (
                    symbol TEXT PRIMARY KEY,
                    leverage INTEGER NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Phase 154: Breakeven states - survive deploy/restart
            await db.execute('''
                CREATE TABLE IF NOT EXISTS breakeven_states (
                    state_key TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    activation_price REAL NOT NULL,
                    activation_time TEXT NOT NULL,
                    spread_level TEXT DEFAULT 'Normal',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await db.commit()
            
            # Phase 49: Migration - Add new columns to trades table if they don't exist
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN signal_score INTEGER DEFAULT 0')
            except:
                pass  # Column already exists
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN mtf_score INTEGER DEFAULT 0')
            except:
                pass
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN z_score REAL DEFAULT 0')
            except:
                pass
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN spread_level TEXT DEFAULT "unknown"')
            except:
                pass
            # Phase 155: AI Optimizer ‚Äî settings snapshot per trade
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN settings_snapshot TEXT DEFAULT "{}"')
            except:
                pass
            
            # Phase 186: Comprehensive trade data persistence ‚Äî all missing columns
            migration_columns = [
                ('stop_loss', 'REAL DEFAULT 0'),
                ('take_profit', 'REAL DEFAULT 0'),
                ('atr', 'REAL DEFAULT 0'),
                ('trailing_stop', 'REAL DEFAULT 0'),
                ('trail_activation', 'REAL DEFAULT 0'),
                ('is_trailing_active', 'INTEGER DEFAULT 0'),
                ('margin', 'REAL DEFAULT 0'),
                ('roi', 'REAL DEFAULT 0'),
                ('is_live', 'INTEGER DEFAULT 0'),
                ('entry_method', 'TEXT DEFAULT "MARKET"'),
                ('entry_slippage', 'REAL DEFAULT 0'),
                ('entry_spread', 'REAL DEFAULT 0'),
                ('binance_fill_price', 'REAL DEFAULT 0'),
                ('binance_order_id', 'TEXT'),
                ('hurst', 'REAL DEFAULT 0.5'),
                ('adx', 'REAL DEFAULT 0'),
                ('pullback_pct', 'REAL DEFAULT 0'),
                # Phase 232: Close metrics snapshot
                ('close_metrics_json', 'TEXT DEFAULT "{}"'),
            ]
            for col_name, col_type in migration_columns:
                try:
                    await db.execute(f'ALTER TABLE trades ADD COLUMN {col_name} {col_type}')
                except:
                    pass  # Column already exists
            
            # Phase 187: position_closes needs settings data too
            pc_migration_columns = [
                ('stop_loss', 'REAL DEFAULT 0'),
                ('take_profit', 'REAL DEFAULT 0'),
                ('atr', 'REAL DEFAULT 0'),
                ('trailing_stop', 'REAL DEFAULT 0'),
                ('trail_activation', 'REAL DEFAULT 0'),
                ('settings_snapshot', 'TEXT DEFAULT "{}"'),
                ('entry_method', 'TEXT DEFAULT "MARKET"'),
                ('entry_slippage', 'REAL DEFAULT 0'),
                ('entry_spread', 'REAL DEFAULT 0'),
                ('signal_score', 'INTEGER DEFAULT 0'),
                ('spread_level', 'TEXT DEFAULT "unknown"'),
                ('binance_fill_price', 'REAL DEFAULT 0'),
                ('hurst', 'REAL DEFAULT 0.5'),
                ('trade_id', 'TEXT'),
                # Phase 224A: Diagnostics columns
                ('mae_pct', 'REAL DEFAULT 0'),
                ('mfe_pct', 'REAL DEFAULT 0'),
                ('decision_trace', 'TEXT DEFAULT \"[]\"'),
                # Phase 229: Order ID-based trade matching
                ('entry_order_id', 'TEXT'),
                ('close_order_id', 'TEXT'),
            ]
            for col_name, col_type in pc_migration_columns:
                try:
                    await db.execute(f'ALTER TABLE position_closes ADD COLUMN {col_name} {col_type}')
                except:
                    pass
            
            # Phase 211: OBI depth filter columns
            obi_migration_columns = [
                ('obi_value', 'REAL DEFAULT 0'),  # signals table
            ]
            for col_name, col_type in obi_migration_columns:
                try:
                    await db.execute(f'ALTER TABLE signals ADD COLUMN {col_name} {col_type}')
                except:
                    pass
            # OBI value for trades table (saved in settings_snapshot JSON, but also as direct column)
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN obi_value REAL DEFAULT 0')
            except:
                pass
            await db.commit()
            
            self._initialized = True
            logger.info("‚úÖ SQLite database initialized with all tables")
    
    async def save_setting(self, key: str, value: any):
        """Save a setting to database."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO settings (key, value, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
            ''', (key, json.dumps(value)))
            await db.commit()
    
    async def get_setting(self, key: str, default: any = None) -> any:
        """Get a setting from database."""
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute('SELECT value FROM settings WHERE key = ?', (key,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return json.loads(row[0])
                return default
    
    async def save_trade(self, trade: dict):
        """Save a completed trade ‚Äî Phase 186: ALL fields persisted."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO trades 
                (id, symbol, side, entry_price, exit_price, size, size_usd, pnl, pnl_percent, 
                 open_time, close_time, close_reason, leverage, signal_score, mtf_score, z_score, 
                 spread_level, settings_snapshot,
                 stop_loss, take_profit, atr, trailing_stop, trail_activation, is_trailing_active,
                 margin, roi, is_live, entry_method, entry_slippage, entry_spread, 
                 binance_fill_price, binance_order_id, hurst, adx, pullback_pct, close_metrics_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                trade.get('id'),
                trade.get('symbol'),
                trade.get('side'),
                trade.get('entryPrice'),
                trade.get('exitPrice'),
                trade.get('size', 0),
                trade.get('sizeUsd', 0),
                trade.get('pnl'),
                trade.get('pnlPercent', 0),
                trade.get('openTime', 0),
                trade.get('closeTime'),
                trade.get('reason', trade.get('closeReason')),
                trade.get('leverage', 10),
                trade.get('signalScore', 0),
                trade.get('mtfScore', 0),
                trade.get('zScore', 0),
                trade.get('spreadLevel', 'unknown'),
                json.dumps(trade.get('settingsSnapshot', {})),
                # Phase 186: New fields
                trade.get('stopLoss', 0),
                trade.get('takeProfit', 0),
                trade.get('atr', 0),
                trade.get('trailingStop', 0),
                trade.get('trailActivation', 0),
                1 if trade.get('isTrailingActive', False) else 0,
                trade.get('margin', 0),
                trade.get('roi', 0),
                1 if trade.get('isLive', False) else 0,
                trade.get('entry_method', 'MARKET'),
                trade.get('entry_slippage', 0),
                trade.get('entry_spread', 0),
                trade.get('binance_fill_price', 0),
                trade.get('binance_order_id', ''),
                trade.get('hurst', 0.5),
                trade.get('adx', 0),
                trade.get('pullbackPct', 0),
                trade.get('close_metrics_json', '{}'),
            ))
            await db.commit()
    
    async def get_recent_trades(self, limit: int = 50) -> list:
        """Get recent trades."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT * FROM trades ORDER BY close_time DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [dict(row) for row in rows]
    
    async def get_full_trade_history(self, limit: int = 0) -> list:
        """
        Phase 187b: Get ALL trades from SQLite with full data.
        Returns frontend-compatible format with all 35 fields.
        limit=0 means no limit (all trades).
        """
        try:
            async with aiosqlite.connect(self.db_path) as db:
                db.row_factory = aiosqlite.Row
                if limit > 0:
                    query = 'SELECT * FROM trades ORDER BY close_time DESC LIMIT ?'
                    params = (limit,)
                else:
                    query = 'SELECT * FROM trades ORDER BY close_time DESC'
                    params = ()
                
                async with db.execute(query, params) as cursor:
                    rows = await cursor.fetchall()
                    trades = []
                    for row in rows:
                        d = dict(row)
                        # Parse settings_snapshot from JSON string
                        try:
                            if d.get('settings_snapshot') and isinstance(d['settings_snapshot'], str):
                                d['settings_snapshot'] = json.loads(d['settings_snapshot'])
                        except:
                            d['settings_snapshot'] = {}
                        
                        # Frontend-compatible format
                        turkey_tz = pytz.timezone('Europe/Istanbul')
                        close_ts = d.get('close_time', 0)
                        if close_ts and close_ts > 0:
                            close_dt = datetime.fromtimestamp(close_ts / 1000, tz=turkey_tz)
                            time_str = close_dt.strftime('%H:%M')
                            date_str = close_dt.strftime('%d/%m')
                        else:
                            time_str = ''
                            date_str = ''
                        
                        pnl = d.get('pnl', 0) or 0
                        margin = d.get('margin', 0) or 0
                        roi = d.get('roi', 0) or 0
                        
                        trade = {
                            'id': d.get('id', ''),
                            'symbol': (d.get('symbol', '') or '').replace('USDT', ''),
                            'symbolFull': d.get('symbol', ''),
                            'side': d.get('side', 'LONG'),
                            'entryPrice': d.get('entry_price', 0) or 0,
                            'exitPrice': d.get('exit_price', 0) or 0,
                            'pnl': round(pnl, 4),
                            'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                            'pnlPercent': d.get('pnl_percent', 0) or 0,
                            'roi': round(roi, 2),
                            'margin': round(margin, 4),
                            'leverage': d.get('leverage', 10) or 10,
                            'sizeUsd': round(d.get('size_usd', 0) or 0, 2),
                            'closeTime': close_ts,
                            'openTime': d.get('open_time', 0) or 0,
                            'time': time_str,
                            'date': date_str,
                            'timestamp': close_ts,
                            'closeReason': d.get('close_reason', 'Closed') or 'Closed',
                            'reason': d.get('close_reason', 'Closed') or 'Closed',
                            'type': 'CLOSE',
                            # Phase 187b: Full data
                            'stopLoss': d.get('stop_loss', 0) or 0,
                            'takeProfit': d.get('take_profit', 0) or 0,
                            'atr': d.get('atr', 0) or 0,
                            'trailingStop': d.get('trailing_stop', 0) or 0,
                            'trailActivation': d.get('trail_activation', 0) or 0,
                            'isTrailingActive': bool(d.get('is_trailing_active', 0)),
                            'spreadLevel': d.get('spread_level', 'unknown'),
                            'signalScore': d.get('signal_score', 0) or 0,
                            'mtfScore': d.get('mtf_score', 0) or 0,
                            'zScore': d.get('z_score', 0) or 0,
                            'entryMethod': d.get('entry_method', 'MARKET'),
                            'entrySlippage': d.get('entry_slippage', 0) or 0,
                            'entrySpread': d.get('entry_spread', 0) or 0,
                            'binanceFillPrice': d.get('binance_fill_price', 0) or 0,
                            'isLive': bool(d.get('is_live', 0)),
                            'hurst': d.get('hurst', 0.5) or 0.5,
                            'settingsSnapshot': d.get('settings_snapshot', {}),
                            # Phase 232: Close metrics snapshot
                            'close_metrics_json': d.get('close_metrics_json', '{}'),
                        }
                        trades.append(trade)
                    
                    logger.info(f"üìä SQLite trade history: returning {len(trades)} trades")
                    return trades
        except Exception as e:
            logger.error(f"get_full_trade_history error: {e}")
            return []
    
    async def add_log(self, time: str, message: str, ts: int):
        """Add a log entry."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO logs (time, message, ts) VALUES (?, ?, ?)
            ''', (time, message, ts))
            # Keep only last 500 logs
            await db.execute('''
                DELETE FROM logs WHERE id NOT IN (
                    SELECT id FROM logs ORDER BY id DESC LIMIT 500
                )
            ''')
            await db.commit()
    
    async def get_recent_logs(self, limit: int = 100) -> list:
        """Get recent logs."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT time, message, ts FROM logs ORDER BY id DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [{"time": row["time"], "message": row["message"], "ts": row["ts"]} for row in rows]
    
    async def save_equity_point(self, time: int, balance: float, drawdown: float):
        """Save an equity curve point."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO equity_curve (time, balance, drawdown) VALUES (?, ?, ?)
            ''', (time, balance, drawdown))
            # Keep only last 1000 points
            await db.execute('''
                DELETE FROM equity_curve WHERE id NOT IN (
                    SELECT id FROM equity_curve ORDER BY id DESC LIMIT 1000
                )
            ''')
            await db.commit()
    
    async def get_equity_curve(self, limit: int = 500) -> list:
        """Get equity curve data."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT time, balance, drawdown FROM equity_curve ORDER BY id DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [{"time": row["time"], "balance": row["balance"], "drawdown": row["drawdown"]} for row in reversed(rows)]
    
    async def save_signal(self, signal_data: dict):
        """Save a signal (accepted or rejected) for performance analysis."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO signals (
                    symbol, action, price, zscore, hurst, atr, signal_score,
                    htf_trend, mtf_confirmed, mtf_reason, blacklisted, accepted,
                    reject_reason, z_threshold, min_confidence, entry_tightness,
                    exit_tightness, timestamp, obi_value
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                signal_data.get('symbol'),
                signal_data.get('action'),
                signal_data.get('price', 0),
                signal_data.get('zscore', 0),
                signal_data.get('hurst', 0),
                signal_data.get('atr', 0),
                signal_data.get('signal_score', 0),
                signal_data.get('htf_trend', 'NEUTRAL'),
                1 if signal_data.get('mtf_confirmed', False) else 0,
                signal_data.get('mtf_reason', ''),
                1 if signal_data.get('blacklisted', False) else 0,
                1 if signal_data.get('accepted', False) else 0,
                signal_data.get('reject_reason', ''),
                signal_data.get('z_threshold', 0),
                signal_data.get('min_confidence', 0),
                signal_data.get('entry_tightness', 1.0),
                signal_data.get('exit_tightness', 1.0),
                signal_data.get('timestamp', int(datetime.now().timestamp() * 1000)),
                signal_data.get('obi_value', 0),  # Phase 211: OBI depth value
            ))
            await db.commit()
    
    async def save_open_position(self, pos: dict):
        """Save an open position to database."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO positions (
                    id, symbol, side, entry_price, size, size_usd,
                    stop_loss, take_profit, leverage, open_time,
                    signal_score, zscore, hurst, atr, htf_trend, status
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                pos.get('id'),
                pos.get('symbol'),
                pos.get('side'),
                pos.get('entryPrice'),
                pos.get('size', 0),
                pos.get('sizeUsd', 0),
                pos.get('stopLoss', 0),
                pos.get('takeProfit', 0),
                pos.get('leverage', 10),
                pos.get('openTime', 0),
                pos.get('signalScore', 0),
                pos.get('zscore', 0),
                pos.get('hurst', 0),
                pos.get('atr', 0),
                pos.get('htfTrend', 'NEUTRAL'),
                'OPEN'
            ))
            await db.commit()
    
    async def close_position_in_db(self, position_id: str, symbol: str = None):
        """Mark a position as closed in database with close_time."""
        close_time = int(datetime.now().timestamp() * 1000)
        async with aiosqlite.connect(self.db_path) as db:
            if position_id:
                await db.execute('''
                    UPDATE positions SET status = 'CLOSED', close_time = ? WHERE id = ?
                ''', (close_time, position_id))
            elif symbol:
                await db.execute('''
                    UPDATE positions SET status = 'CLOSED', close_time = ? 
                    WHERE symbol = ? AND status = 'OPEN'
                ''', (close_time, symbol))
            await db.commit()
            logger.info(f"üìÇ Position closed in DB: id={position_id} symbol={symbol}")
    
    async def get_position_open_time(self, symbol: str) -> int:
        """Get open_time for an active position by symbol from SQLite."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute(
                    "SELECT open_time FROM positions WHERE symbol=? AND status='OPEN' ORDER BY open_time DESC LIMIT 1",
                    (symbol,)
                )
                row = await cursor.fetchone()
                return row[0] if row else None
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è get_position_open_time error for {symbol}: {e}")
            return None
    
    async def get_all_open_times(self) -> dict:
        """Get open_times for ALL active positions in one query. Returns {symbol: open_time_ms}."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute(
                    "SELECT symbol, open_time FROM positions WHERE status='OPEN'"
                )
                rows = await cursor.fetchall()
                return {row[0]: row[1] for row in rows}
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è get_all_open_times error: {e}")
            return {}
    
    async def get_all_settings(self) -> dict:
        """Get all settings from database."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('SELECT key, value FROM settings') as cursor:
                rows = await cursor.fetchall()
                return {row['key']: json.loads(row['value']) for row in rows}
    
    async def save_all_settings(self, settings: dict):
        """Save all settings to database."""
        async with aiosqlite.connect(self.db_path) as db:
            for key, value in settings.items():
                await db.execute('''
                    INSERT OR REPLACE INTO settings (key, value, updated_at)
                    VALUES (?, ?, CURRENT_TIMESTAMP)
                ''', (key, json.dumps(value)))
            await db.commit()
    
    async def save_position_close(self, close_data: dict):
        """Phase 187: Save position close with ALL trade data + settings."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO position_closes (
                    symbol, side, reason, original_reason, entry_price, exit_price,
                    pnl, leverage, size_usd, margin, roi, timestamp,
                    stop_loss, take_profit, atr, trailing_stop, trail_activation,
                    settings_snapshot, entry_method, entry_slippage, entry_spread,
                    signal_score, spread_level, binance_fill_price, hurst, trade_id,
                    mae_pct, mfe_pct, decision_trace,
                    entry_order_id, close_order_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                close_data.get('symbol'),
                close_data.get('side'),
                close_data.get('reason', 'Closed'),
                close_data.get('original_reason', 'Closed'),
                close_data.get('entryPrice', 0),
                close_data.get('exitPrice', 0),
                close_data.get('pnl', 0),
                close_data.get('leverage', 10),
                close_data.get('sizeUsd', 0),
                close_data.get('margin', 0),
                close_data.get('roi', 0),
                close_data.get('timestamp', int(datetime.now().timestamp() * 1000)),
                # Phase 187: Settings + execution data
                close_data.get('stopLoss', 0),
                close_data.get('takeProfit', 0),
                close_data.get('atr', 0),
                close_data.get('trailingStop', 0),
                close_data.get('trailActivation', 0),
                json.dumps(close_data.get('settingsSnapshot', {})),
                close_data.get('entry_method', 'MARKET'),
                close_data.get('entry_slippage', 0),
                close_data.get('entry_spread', 0),
                close_data.get('signalScore', 0),
                close_data.get('spreadLevel', 'unknown'),
                close_data.get('binance_fill_price', 0),
                close_data.get('hurst', 0.5),
                close_data.get('trade_id', ''),
                close_data.get('mae_pct', 0),
                close_data.get('mfe_pct', 0),
                close_data.get('decision_trace', '[]'),
                close_data.get('entry_order_id', ''),
                close_data.get('close_order_id', ''),
            ))
            await db.commit()
            logger.info(f"üíæ Position close saved to SQLite: {close_data.get('symbol')} - {close_data.get('reason')} | entry_oid={close_data.get('entry_order_id', '')[:12]} close_oid={close_data.get('close_order_id', '')[:12]}")
    
    async def get_pending_close_reason(self, symbol: str, close_time: int, window_minutes: int = 30, close_order_id: str = None) -> dict:
        """Phase 229: Get pending close reason ‚Äî order ID match first, timestamp fallback."""
        window_ms = window_minutes * 60 * 1000
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            
            # Step 0: Exact match by close_order_id (Phase 229)
            # Phase 229b: Added symbol filter to prevent cross-symbol mismatches
            if close_order_id:
                async with db.execute('''
                    SELECT * FROM position_closes 
                    WHERE symbol = ? AND close_order_id = ? AND close_order_id != ''
                    LIMIT 1
                ''', (symbol, close_order_id)) as cursor:
                    row = await cursor.fetchone()
                    if row:
                        logger.info(f"üÜî ORDER ID MATCH: {symbol} close_oid={close_order_id[:12]}")
                        return dict(row)
            
            # Step 1: Try unmatched records by timestamp
            async with db.execute('''
                SELECT * FROM position_closes 
                WHERE symbol = ? AND matched_to_income = 0
                AND ABS(timestamp - ?) < ?
                ORDER BY ABS(timestamp - ?) ASC
                LIMIT 1
            ''', (symbol, close_time, window_ms, close_time)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return dict(row)
            
            # Step 2: Fallback ‚Äî check ALL records (even matched ones)
            async with db.execute('''
                SELECT * FROM position_closes 
                WHERE symbol = ? AND ABS(timestamp - ?) < ?
                ORDER BY ABS(timestamp - ?) ASC
                LIMIT 1
            ''', (symbol, close_time, window_ms, close_time)) as cursor:
                row = await cursor.fetchone()
                if row:
                    logger.debug(f"üìã Fallback match for {symbol}: reason={dict(row).get('reason')}")
                    return dict(row)
            return None
    
    async def mark_close_matched(self, close_id: int):
        """Mark a position close as matched to Binance income."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                UPDATE position_closes SET matched_to_income = 1 WHERE id = ?
            ''', (close_id,))
            await db.commit()
    
    async def update_close_order_id(self, symbol: str, close_order_id: str):
        """Phase 229b: Update the most recent position_close with Binance close order ID.
        Uses timestamp window (last 5 min) to prevent wrong-row updates on rapid consecutive closes."""
        try:
            now_ms = int(datetime.now().timestamp() * 1000)
            window_ms = 5 * 60 * 1000  # 5 minutes
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute('''
                    UPDATE position_closes SET close_order_id = ?
                    WHERE symbol = ? AND (close_order_id IS NULL OR close_order_id = '')
                    AND timestamp > ? - ?
                    ORDER BY timestamp DESC LIMIT 1
                ''', (close_order_id, symbol, now_ms, window_ms))
                await db.commit()
                if cursor.rowcount > 0:
                    logger.info(f"üÜî Close order ID saved: {symbol} = {close_order_id[:12]}")
                else:
                    logger.debug(f"üÜî Close order ID no matching row: {symbol} = {close_order_id[:12]}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è update_close_order_id error: {e}")
    
    async def save_binance_trade(self, trade_data: dict):
        """
        Phase 152: Save Binance trade with enrichment from position_closes.
        Before saving, try to match with position_closes for better close reason.
        """
        async with aiosqlite.connect(self.db_path) as db:
            symbol = trade_data.get('symbol')
            close_time = trade_data.get('closeTime', 0)
            close_reason = trade_data.get('closeReason', 'Closed')
            entry_price = trade_data.get('entryPrice', 0)
            exit_price = trade_data.get('exitPrice', 0)
            side = trade_data.get('side', 'LONG')
            leverage = trade_data.get('leverage', 1)
            size_usd = trade_data.get('sizeUsd', 0)
            
            # Phase 152: Enrich from position_closes if close_reason is generic
            if close_reason in ('Closed', 'Position closed on Binance', 'Historical (from Binance)'):
                try:
                    db.row_factory = aiosqlite.Row
                    async with db.execute('''
                        SELECT * FROM position_closes 
                        WHERE symbol = ? AND ABS(timestamp - ?) < 3600000
                        ORDER BY ABS(timestamp - ?) ASC LIMIT 1
                    ''', (symbol, close_time, close_time)) as cursor:
                        pc = await cursor.fetchone()
                        if pc:
                            close_reason = pc['original_reason'] or pc['reason'] or close_reason
                            if pc['entry_price'] and pc['entry_price'] > 0:
                                entry_price = pc['entry_price']
                            if pc['exit_price'] and pc['exit_price'] > 0:
                                exit_price = pc['exit_price']
                            if pc['side']:
                                side = pc['side']
                            if pc['leverage'] and pc['leverage'] > 0:
                                leverage = pc['leverage']
                            if pc['size_usd'] and pc['size_usd'] > 0:
                                size_usd = pc['size_usd']
                            logger.info(f"üìã Enriched trade {symbol} with close reason: {close_reason}")
                except Exception as e:
                    logger.debug(f"Enrichment lookup failed: {e}")
            
            await db.execute('''
                INSERT OR REPLACE INTO binance_trades (
                    income_id, symbol, side, entry_price, exit_price, pnl, pnl_percent,
                    margin, leverage, size_usd, close_reason, close_time, raw_data
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                trade_data.get('incomeId', str(close_time)),
                symbol,
                side,
                entry_price,
                exit_price,
                trade_data.get('pnl', 0),
                trade_data.get('roi', 0),
                trade_data.get('margin', 0),
                leverage,
                size_usd,
                close_reason,
                close_time,
                json.dumps(trade_data)
            ))
            await db.commit()
    
    async def get_binance_trades(self, limit: int = 200) -> list:
        """
        Phase 152: Get trades from SQLite with position_closes JOIN for enriched data.
        Reads directly from binance_trades columns + enriches with position_closes.
        """
        try:
            async with aiosqlite.connect(self.db_path) as db:
                db.row_factory = aiosqlite.Row
                
                # LEFT JOIN position_closes to get proper close reasons
                # Match by symbol + timestamp within 5 minute window
                async with db.execute('''
                    SELECT 
                        bt.symbol, bt.side, bt.entry_price, bt.exit_price, 
                        bt.pnl, bt.pnl_percent, bt.margin, bt.leverage, 
                        bt.size_usd, bt.close_reason, bt.close_time,
                        pc.reason AS pc_reason, pc.original_reason AS pc_original_reason,
                        pc.entry_price AS pc_entry, pc.exit_price AS pc_exit,
                        pc.side AS pc_side, pc.leverage AS pc_leverage,
                        pc.size_usd AS pc_size_usd, pc.margin AS pc_margin,
                        pc.roi AS pc_roi
                    FROM binance_trades bt
                    LEFT JOIN position_closes pc 
                        ON bt.symbol = pc.symbol 
                        AND ABS(bt.close_time - pc.timestamp) < 300000
                    ORDER BY bt.close_time DESC 
                    LIMIT ?
                ''', (limit,)) as cursor:
                    rows = await cursor.fetchall()
                    
                    trades = []
                    seen = set()  # Dedup by symbol+close_time
                    
                    for row in rows:
                        dedup_key = f"{row['symbol']}_{row['close_time']}"
                        if dedup_key in seen:
                            continue
                        seen.add(dedup_key)
                        
                        # Use position_closes data for enrichment (priority)
                        close_reason = row['close_reason'] or 'Closed'
                        reason_detail = close_reason
                        entry_price = row['entry_price'] or 0
                        exit_price = row['exit_price'] or 0
                        side = row['side'] or 'LONG'
                        leverage = row['leverage'] or 10
                        size_usd = row['size_usd'] or 0
                        margin = row['margin'] or 0
                        pnl = row['pnl'] or 0
                        roi = row['pnl_percent'] or 0
                        
                        # Enrich from position_closes if available
                        if row['pc_reason'] and row['pc_reason'] != 'Closed':
                            close_reason = row['pc_reason']
                            reason_detail = row['pc_original_reason'] or row['pc_reason']
                        if row['pc_entry'] and row['pc_entry'] > 0:
                            entry_price = row['pc_entry']
                        if row['pc_exit'] and row['pc_exit'] > 0:
                            exit_price = row['pc_exit']
                        if row['pc_side']:
                            side = row['pc_side']
                        if row['pc_leverage'] and row['pc_leverage'] > 0:
                            leverage = row['pc_leverage']
                        if row['pc_size_usd'] and row['pc_size_usd'] > 0:
                            size_usd = row['pc_size_usd']
                        if row['pc_margin'] and row['pc_margin'] > 0:
                            margin = row['pc_margin']
                        if row['pc_roi'] and row['pc_roi'] != 0:
                            roi = row['pc_roi']
                        
                        # Recalculate margin/roi if needed
                        if margin == 0 and size_usd > 0 and leverage > 0:
                            margin = size_usd / leverage
                        if roi == 0 and margin > 0 and pnl != 0:
                            roi = (pnl / margin * 100)
                        
                        close_time_ms = row['close_time'] or 0
                        try:
                            turkey_tz = pytz.timezone('Europe/Istanbul')
                            ct = datetime.fromtimestamp(close_time_ms / 1000, turkey_tz)
                            time_str = ct.strftime('%H:%M:%S')
                            date_str = ct.strftime('%m/%d')
                        except:
                            time_str = ''
                            date_str = ''
                        
                        trades.append({
                            'symbol': row['symbol'],
                            'side': side,
                            'entryPrice': round(entry_price, 8) if entry_price else 0,
                            'exitPrice': round(exit_price, 8) if exit_price else 0,
                            'pnl': round(pnl, 4),
                            'closeTime': close_time_ms,
                            'closeReason': close_reason,
                            'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                            'timestamp': close_time_ms,
                            'time': time_str,
                            'date': date_str,
                            'type': 'CLOSE',
                            'margin': round(margin, 4),
                            'leverage': leverage,
                            'sizeUsd': round(size_usd, 2),
                            'roi': round(roi, 2),
                            'reason': reason_detail
                        })
                    
                    return trades
        except Exception as e:
            logger.error(f"get_binance_trades error: {e}")
            return []
    
    async def save_leverage(self, symbol: str, leverage: int):
        """Cache leverage for a symbol."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO leverage_cache (symbol, leverage, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
            ''', (symbol, leverage))
            await db.commit()
    
    async def get_leverage(self, symbol: str) -> int:
        """Get cached leverage for a symbol."""
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute('''
                SELECT leverage FROM leverage_cache WHERE symbol = ?
            ''', (symbol,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return row[0]
                return 10  # Default leverage
    
    # ================================================================
    # Phase 154: Breakeven State Persistence
    # ================================================================
    async def save_breakeven_state(self, state_key: str, symbol: str, side: str, 
                                    entry_price: float, activation_price: float,
                                    activation_time: str, spread_level: str = 'Normal'):
        """Save breakeven state to SQLite."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO breakeven_states 
                (state_key, symbol, side, entry_price, activation_price, activation_time, spread_level)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (state_key, symbol, side, entry_price, activation_price, activation_time, spread_level))
            await db.commit()
        logger.info(f"üíæ Breakeven state saved: {state_key}")
    
    async def delete_breakeven_state(self, state_key: str):
        """Delete breakeven state from SQLite."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('DELETE FROM breakeven_states WHERE state_key = ?', (state_key,))
            await db.commit()
        logger.info(f"üóëÔ∏è Breakeven state deleted: {state_key}")
    
    async def load_breakeven_states(self) -> dict:
        """Load all breakeven states from SQLite."""
        states = {}
        try:
            async with aiosqlite.connect(self.db_path) as db:
                async with db.execute('SELECT state_key, symbol, side, entry_price, activation_price, activation_time, spread_level FROM breakeven_states') as cursor:
                    async for row in cursor:
                        states[row[0]] = {
                            'active': True,
                            'entry_price': row[3],
                            'activation_price': row[4],
                            'activation_time': row[5],
                            'spread_level': row[6]
                        }
            if states:
                logger.info(f"üìÇ Loaded {len(states)} breakeven states from SQLite: {list(states.keys())}")
        except Exception as e:
            logger.error(f"Failed to load breakeven states: {e}")
        return states

# Global SQLite manager
sqlite_manager = SQLiteManager()


def safe_create_task(coro, name="unnamed"):
    """Create an asyncio task with exception logging instead of silent swallowing."""
    task = asyncio.create_task(coro)
    def _handle_exception(t):
        if t.cancelled():
            return
        exc = t.exception()
        if exc:
            logger.error(f"üî• Background task '{name}' failed: {exc}")
    task.add_done_callback(_handle_exception)
    return task


# ============================================================================
# UI WEBSOCKET MANAGER - Real-time updates to UI clients
# ============================================================================

class UIWebSocketManager:
    """
    Manages WebSocket connections to UI clients.
    Broadcasts real-time events: signals, positions, prices, logs.
    """
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.last_broadcast = 0
        self.broadcast_interval = 0.5  # Min 500ms between price broadcasts
        logger.info("üîå UIWebSocketManager initialized")
    
    async def connect(self, websocket: WebSocket):
        """Accept new WebSocket connection."""
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"üîå UI WebSocket connected. Total clients: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        """Remove disconnected WebSocket."""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info(f"üîå UI WebSocket disconnected. Total clients: {len(self.active_connections)}")
    
    async def broadcast(self, event_type: str, data: dict):
        """Broadcast event to all connected UI clients."""
        if not self.active_connections:
            return
        
        message = {
            "type": event_type,
            "data": data,
            "timestamp": int(datetime.now().timestamp() * 1000)
        }
        
        # Remove dead connections
        dead = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception:
                dead.append(connection)
        
        for d in dead:
            self.disconnect(d)
    
    async def broadcast_signal(self, signal: dict):
        """Broadcast new signal event."""
        await self.broadcast("SIGNAL", signal)
    
    async def broadcast_position_opened(self, position: dict):
        """Broadcast position opened event."""
        await self.broadcast("POSITION_OPENED", position)
    
    async def broadcast_position_closed(self, trade: dict):
        """Broadcast position closed event."""
        await self.broadcast("POSITION_CLOSED", trade)
    
    async def broadcast_pending_order(self, order: dict):
        """Broadcast new pending order event."""
        await self.broadcast("PENDING_ORDER", order)
    
    async def broadcast_price_update(self, positions: list):
        """Broadcast position price updates (throttled)."""
        now = datetime.now().timestamp()
        if now - self.last_broadcast < self.broadcast_interval:
            return  # Throttle
        self.last_broadcast = now
        await self.broadcast("PRICE_UPDATE", {"positions": positions})
    
    async def broadcast_log(self, log: str):
        """Broadcast log message."""
        await self.broadcast("LOG", {"message": log})
    
    async def broadcast_kill_switch(self, actions: dict):
        """Broadcast kill switch event."""
        await self.broadcast("KILL_SWITCH", actions)



# Global UI WebSocket manager
ui_ws_manager = UIWebSocketManager()


# ============================================================================
# LIVE BINANCE TRADER - Real Order Execution
# ============================================================================

class LiveBinanceTrader:
    """
    Binance Futures ger√ßek emir ve pozisyon y√∂netimi.
    Pozisyonlar, bakiye, PnL Binance'den okunur - backend hesaplamaz.
    Backend sadece AL/SAT emirleri g√∂nderir.
    """
    
    def __init__(self):
        self.exchange = None
        self.enabled = False
        self.initialized = False
        self.last_balance = 0.0
        self.last_positions = []
        self.last_sync_time = 0
        self.trading_mode = os.environ.get('TRADING_MODE', 'paper')  # paper, live
         # Phase 146: Persistent trailing state for live positions
        # Key: symbol, Value: {isActive: bool, trailingStop: float, peakPrice: float}
        self.trailing_state = {}
        logger.info(f"üìä LiveBinanceTrader initialized | Mode: {self.trading_mode}")
    
    async def initialize(self):
        """Binance baƒülantƒ±sƒ±nƒ± ba≈ülat."""
        self.last_error = None  # Reset error
        
        if self.trading_mode == 'paper':
            self.last_error = "trading_mode is paper, not live"
            logger.info("üìÑ PAPER MODE: Binance connection skipped")
            return False
            
        api_key = os.environ.get('BINANCE_API_KEY')
        api_secret = os.environ.get('BINANCE_SECRET')
        
        if not api_key or not api_secret:
            self.last_error = f"Missing credentials: api_key={bool(api_key)}, secret={bool(api_secret)}"
            logger.error("‚ùå BINANCE_API_KEY ve BINANCE_SECRET tanƒ±mlƒ± deƒüil!")
            return False
        
        try:
            self.exchange = ccxt_async.binance({
                'apiKey': api_key,
                'secret': api_secret,
                'options': {'defaultType': 'future'},
                'enableRateLimit': True,
            })
            
            # Baƒülantƒ± testi - bakiye √ßek
            balance = await self.exchange.fetch_balance()
            self.last_balance = float(balance.get('USDT', {}).get('free', 0))
            
            logger.info(f"‚úÖ Binance Futures baƒülantƒ±sƒ± ba≈üarƒ±lƒ±!")
            logger.info(f"üí∞ Kullanƒ±labilir Bakiye: ${self.last_balance:.2f} USDT")
            
            self.enabled = True
            self.initialized = True
            
            return True
            
        except Exception as e:
            self.last_error = f"Binance connection error: {str(e)}"
            logger.error(f"‚ùå Binance baƒülantƒ± hatasƒ±: {e}")
            self.exchange = None  # Reset exchange on error to allow retry
            self.enabled = False
            return False
    
    async def get_balance(self) -> dict:
        """Binance'den bakiye √ßek - Futures account i√ßin doƒüru alanlar."""
        if not self.enabled or not self.exchange:
            return {'walletBalance': 0, 'marginBalance': 0, 'availableBalance': 0, 'unrealizedPnl': 0, 'free': 0, 'used': 0, 'total': 0}
            
        try:
            balance = await self.exchange.fetch_balance()
            
            # Get raw Binance info for accurate Futures balance fields
            info = balance.get('info', {})
            
            # Binance Futures returns these in 'info':
            # totalWalletBalance: Wallet Balance (without unrealized PnL)
            # totalMarginBalance: Margin Balance (wallet + unrealized PnL)
            # totalUnrealizedProfit: Unrealized PnL
            # availableBalance: Available Balance for trading
            
            wallet_balance = float(info.get('totalWalletBalance', 0) or 0)
            margin_balance = float(info.get('totalMarginBalance', 0) or 0)
            unrealized_pnl = float(info.get('totalUnrealizedProfit', 0) or 0)
            available_balance = float(info.get('availableBalance', 0) or 0)
            
            # Fallback to USDT if raw info not available
            usdt = balance.get('USDT', {})
            if wallet_balance == 0:
                wallet_balance = float(usdt.get('total', 0))
            if available_balance == 0:
                available_balance = float(usdt.get('free', 0))
            
            result = {
                # Correct Binance Futures fields
                'walletBalance': wallet_balance,      # "Balance" in Binance UI
                'marginBalance': margin_balance,      # "Margin Balance" in Binance UI
                'availableBalance': available_balance, # Available for trading
                'unrealizedPnl': unrealized_pnl,      # "Unrealized PNL" in Binance UI
                # Legacy fields for compatibility
                'free': available_balance,
                'used': margin_balance - available_balance,
                'total': margin_balance
            }
            
            self.last_balance = margin_balance  # Use margin balance as total
            logger.info(f"Balance: wallet={wallet_balance:.2f}, margin={margin_balance:.2f}, available={available_balance:.2f}, unrealizedPnl={unrealized_pnl:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"Balance fetch error: {e}")
            return {'walletBalance': 0, 'marginBalance': 0, 'availableBalance': 0, 'unrealizedPnl': 0, 'free': 0, 'used': 0, 'total': self.last_balance}
    
    async def get_positions(self, fast: bool = False) -> list:
        """Binance'den a√ßƒ±k pozisyonlarƒ± √ßek. fast=True skips expensive openTime lookup."""
        logger.info(f"get_positions called: enabled={self.enabled}, exchange={self.exchange is not None}")
        
        if not self.enabled or not self.exchange:
            logger.warning(f"get_positions early return: enabled={self.enabled}, exchange={self.exchange is not None}")
            return []
            
        try:
            # Use Binance fapiPrivateV2GetPositionRisk directly - fapiPrivateGetAccount returns 404
            raw_positions = None
            try:
                raw_positions = await self.exchange.fapiPrivateV2GetPositionRisk()
                logger.info(f"Binance API returned {len(raw_positions)} position entries")
            except Exception as e:
                logger.warning(f"Direct API failed ({e}), using CCXT fetch_positions")
                raw_positions = None
            
            if raw_positions:
                # Process direct Binance API response
                result = []
                skipped_symbols = []
                for p in raw_positions:
                    position_amt = float(p.get('positionAmt', 0) or 0)
                    symbol = p.get('symbol', '')
                    if abs(position_amt) > 0:
                        symbol = p.get('symbol', '')
                        side = 'LONG' if position_amt > 0 else 'SHORT'
                        entry_price = float(p.get('entryPrice', 0) or 0)
                        unrealized_pnl = float(p.get('unRealizedProfit', 0) or 0)
                        notional = abs(float(p.get('notional', 0) or 0))
                        leverage = int(p.get('leverage', 1) or 1)
                        position_margin = float(p.get('isolatedMargin', 0) or p.get('initialMargin', 0) or 0)
                        if position_margin == 0 and notional > 0 and leverage > 0:
                            position_margin = notional / leverage
                        
                        # Calculate PnL percentage
                        pnl_percent = (unrealized_pnl / position_margin * 100) if position_margin > 0 else 0
                        
                        # Read openTime from SQLite (single source of truth)
                        try:
                            db_ot = await db_manager.get_position_open_time(symbol)
                            open_time_val = db_ot if db_ot else int(p.get('updateTime', datetime.now().timestamp() * 1000))
                        except:
                            open_time_val = int(p.get('updateTime', datetime.now().timestamp() * 1000))
                        result.append({
                            'symbol': symbol,
                            'side': side,
                            'entryPrice': entry_price,
                            'sizeUsd': notional,
                            'unrealizedPnl': unrealized_pnl,
                            'pnlPercent': pnl_percent,
                            'leverage': leverage,
                            'initialMargin': position_margin,
                            'size': abs(position_amt),           # Phase 149: Fix missing size field
                            'contracts': abs(position_amt),
                            'markPrice': float(p.get('markPrice', entry_price) or entry_price),  # Phase 149: Add markPrice
                            'openTime': open_time_val
                        })
                    else:
                        # Track symbols with 0 positionAmt
                        if symbol.endswith('USDT'):
                            skipped_symbols.append(f"{symbol}:{position_amt}")
                            # Log detailed info for suspected missing positions
                            if any(x in symbol for x in ['HANA', 'BUSDT', 'FLOKI', 'PORTAL', 'MEGA']):
                                notional = float(p.get('notional', 0) or 0)
                                entry = float(p.get('entryPrice', 0) or 0)
                                pnl = float(p.get('unRealizedProfit', 0) or 0)
                                logger.warning(f"üîç Suspected missing: {symbol} posAmt={position_amt} notional={notional} entry={entry} pnl={pnl}")
                
                # Log any skipped USDT symbols (these might be the missing ones)
                if skipped_symbols:
                    logger.info(f"‚ö†Ô∏è Skipped {len(skipped_symbols)} positions with positionAmt=0")
                
                # Log ALL active position symbols for debugging
                active_symbols = sorted([r['symbol'] for r in result])
                logger.info(f"üìã Active positions ({len(result)}): {', '.join(active_symbols)}")
                
                logger.info(f"get_positions returning {len(result)} active positions (direct API)")
                return sorted(result, key=lambda x: x.get('openTime', 0), reverse=True)
            
            # Fallback to CCXT if direct API failed
            positions = await self.exchange.fetch_positions()
            logger.info(f"fetch_positions returned {len(positions)} items from CCXT")
            result = []
            skipped_count = 0
            
            for p in positions:
                contracts = float(p.get('contracts') or 0)
                notional = float(p.get('notional') or 0)
                raw_info = p.get('info', {})
                raw_position_amt = float(raw_info.get('positionAmt', 0) or 0)
                
                # Check if position is active using multiple indicators
                # Some CCXT versions may not populate 'contracts' correctly
                is_active = abs(contracts) > 0 or abs(notional) > 0 or abs(raw_position_amt) > 0
                
                if is_active:
                    # CCXT symbol format: BTC/USDT:USDT -> BTCUSDT
                    symbol = p.get('symbol', '').replace('/USDT:USDT', 'USDT')
                    
                    
                    # Determine side correctly:
                    # 1. Check CCXT side field first
                    # 2. Fall back to raw Binance positionAmt (negative = SHORT)
                    ccxt_side = p.get('side', '').upper()
                    
                    if ccxt_side in ['LONG', 'SHORT']:
                        side = ccxt_side
                    elif raw_position_amt < 0:
                        side = 'SHORT'
                    elif raw_position_amt > 0:
                        side = 'LONG'
                    else:
                        # Fallback to contracts sign
                        side = 'LONG' if contracts > 0 else 'SHORT'
                    
                    logger.info(f"Found active position: {symbol} side={side} contracts={contracts} raw_amt={raw_position_amt}")
                    
                    notional = abs(float(p.get('notional') or 0))
                    position_margin = float(raw_info.get('positionInitialMargin', 0) or raw_info.get('initialMargin', 0) or 0)
                    
                    # Get raw leverage from Binance directly
                    raw_leverage = int(p.get('leverage') or raw_info.get('leverage') or 1)
                    
                    # Calculate leverage from notional/margin (for verification)
                    if position_margin > 0:
                        calculated_leverage = int(round(notional / position_margin))
                    else:
                        calculated_leverage = raw_leverage
                    
                    # Use raw Binance leverage instead of calculated (more accurate)
                    final_leverage = raw_leverage
                    
                    logger.info(f"  üìä {symbol}: raw_lev={raw_leverage}x, calc_lev={calculated_leverage}x, margin=${position_margin:.2f}, notional=${notional:.2f}")
                    
                    # Calculate PnL percentage based on margin (ROI)
                    unrealized_pnl = float(p.get('unrealizedPnl') or 0)
                    if position_margin > 0:
                        pnl_percent = (unrealized_pnl / position_margin) * 100
                    else:
                        pnl_percent = float(p.get('percentage') or 0)
                    
                    # Get position open time from SQLite
                    open_time = int(datetime.now().timestamp() * 1000)  # Default to now
                    
                    # Read from SQLite positions table (single source of truth)
                    try:
                        db_open_time = await db_manager.get_position_open_time(symbol)
                        if db_open_time:
                            open_time = db_open_time
                    except Exception as e:
                        logger.warning(f"Could not get openTime from SQLite for {symbol}: {e}")
                    
                    # Phase 232: Use raw_position_amt when contracts==0
                    position_amount = abs(contracts) if abs(contracts) > 0 else abs(raw_position_amt)
                    entry_price = float(p.get('entryPrice') or 0)
                    mark_price = float(p.get('markPrice') or 0)
                    
                    # Phase 204: Use currentPrice from engine position (scanner/WS close price)
                    # instead of markPrice for exit decisions ‚Äî markPrice can spike with wicks
                    engine_pos = None
                    if global_paper_trader:
                        for ep in global_paper_trader.positions:
                            if ep.get('symbol') == symbol:
                                engine_pos = ep
                                break
                    current_price = float(engine_pos.get('currentPrice', 0)) if engine_pos else 0
                    if current_price <= 0:
                        current_price = mark_price  # Fallback to markPrice if no engine price
                    
                    # ================================================================
                    # Phase 145: Calculate dynamic TP/SL/Trail for live positions
                    # ================================================================
                    # Use same formulas as paper trading
                    # Phase 221: Use same formula as open_position for consistency
                    sl_atr_mult = (global_paper_trader.sl_atr / 10) if global_paper_trader else 1.5
                    tp_atr_mult = (global_paper_trader.tp_atr / 10) if global_paper_trader else 3.0
                    trail_activation_atr = 1.5
                    trail_distance_atr = 1.0
                    exit_tightness = global_paper_trader.exit_tightness if global_paper_trader else 1.0
                    
                    # Estimate ATR as ~1.5% of price (typical for crypto)
                    estimated_atr = entry_price * 0.015
                    
                    # Phase 221: Apply exit_tightness + dynamic_atr_mult (was missing)
                    dyn_mult = global_paper_trader.calculate_dynamic_atr_multiplier(estimated_atr, entry_price) if global_paper_trader else 1.0
                    adjusted_sl_atr = sl_atr_mult * exit_tightness * dyn_mult
                    adjusted_tp_atr = tp_atr_mult * exit_tightness * dyn_mult
                    adjusted_trail_activation = trail_activation_atr * exit_tightness * dyn_mult
                    adjusted_trail_distance = trail_distance_atr * exit_tightness * dyn_mult
                    
                    # Calculate TP/SL based on side
                    if side == 'LONG':
                        sl = entry_price - (estimated_atr * adjusted_sl_atr)
                        tp = entry_price + (estimated_atr * adjusted_tp_atr)
                        trail_activation = entry_price + (estimated_atr * adjusted_trail_activation)
                    else:  # SHORT
                        sl = entry_price + (estimated_atr * adjusted_sl_atr)
                        tp = entry_price - (estimated_atr * adjusted_tp_atr)
                        trail_activation = entry_price - (estimated_atr * adjusted_trail_activation)
                    
                    trailing_stop = sl  # Initial trailing stop = SL
                    trail_distance = estimated_atr * adjusted_trail_distance
                    
                    # ================================================================
                    # Phase 146: Persistent Trailing State (server-side)
                    # ================================================================
                    # Get or create trailing state for this symbol
                    if symbol not in self.trailing_state:
                        self.trailing_state[symbol] = {
                            'isActive': False,
                            'trailingStop': sl,
                            'peakPrice': current_price,
                            'activatedAt': None,
                            'openTime': open_time  # Phase 232: for hold-time guard
                        }
                    
                    # Phase 205: Use candle close price for trail decisions
                    candle_close_price = last_candle_close.get(symbol, current_price)
                    
                    trail_state = self.trailing_state[symbol]
                    roi_pct = pnl_percent
                    # Phase 231j: Dual-condition ‚Äî aligned with scanner/WS/backup/sync
                    # Phase 231l: Side-aware (not abs) ‚Äî same as other paths
                    if side == 'LONG':
                        fb_price_move = ((current_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                    else:
                        fb_price_move = ((entry_price - current_price) / entry_price) * 100 if entry_price > 0 else 0
                    
                    # Phase 231h: Breakeven prices
                    be_long = entry_price * 1.001
                    be_short = entry_price * 0.999
                    
                    # Phase 231j: price_move >= 0.75 OR roi >= 5.0
                    if not trail_state['isActive'] and (fb_price_move >= 0.75 or roi_pct >= 5.0):
                        trail_state['isActive'] = True
                        trail_state['activatedAt'] = datetime.now().isoformat()
                        trail_state['peakPrice'] = current_price
                        logger.info(f"üîÑ TRAIL+BE(fallback): {symbol} pm={fb_price_move:.2f}% roi={roi_pct:.1f}%")
                    
                    is_trailing_active = trail_state['isActive']
                    
                    # Update trailing stop if active
                    if is_trailing_active:
                        if side == 'LONG':
                            # Track peak price using candle close (Phase 205)
                            if candle_close_price > trail_state['peakPrice']:
                                trail_state['peakPrice'] = candle_close_price
                            trailing_stop = trail_state['peakPrice'] - trail_distance
                            # Phase 231h: Clamp ‚Äî never below breakeven
                            trailing_stop = max(trailing_stop, be_long)
                            # Keep the highest trailing stop
                            if trailing_stop > trail_state['trailingStop']:
                                trail_state['trailingStop'] = trailing_stop
                                logger.debug(f"  üìà {symbol} LONG trailing stop raised to ${trailing_stop:.6f}")
                        else:  # SHORT
                            # Track lowest price using candle close (Phase 205)
                            if candle_close_price < trail_state['peakPrice']:
                                trail_state['peakPrice'] = candle_close_price
                            trailing_stop = trail_state['peakPrice'] + trail_distance
                            # Phase 231h: Clamp ‚Äî never above breakeven
                            trailing_stop = min(trailing_stop, be_short)
                            # Keep the lowest trailing stop for shorts
                            if trailing_stop < trail_state['trailingStop'] or trail_state['trailingStop'] == sl:
                                trail_state['trailingStop'] = trailing_stop
                                logger.debug(f"  üìâ {symbol} SHORT trailing stop lowered to ${trailing_stop:.6f}")
                        
                        trailing_stop = trail_state['trailingStop']
                        
                        # ================================================================
                        # Phase 147: Check if trailing stop is HIT and close position
                        # ================================================================
                        # Phase 212: Emergency SL runs BEFORE Flash Trade Guard
                        # Flash crash korumasƒ± ilk 60 saniyede de aktif olmalƒ±
                        if engine_pos and check_emergency_sl_static(engine_pos, current_price, trailing_stop):
                            excess_pct = abs(current_price - trailing_stop) / entry_price * 100
                            close_reason = f"EMERGENCY_SL: price ${current_price:.6f} exceeded trail ${trailing_stop:.6f} by {excess_pct:.2f}%"
                            logger.warning(f"üö® EMERGENCY SL (pre-guard): {symbol} {side} | {close_reason}")
                            should_close = True
                        else:
                            should_close = False
                            close_reason = ""
                        
                        if should_close:
                            # Emergency ‚Äî skip Flash Trade Guard, close immediately
                            logger.warning(f"üî¥ LIVE TRAIL EXIT: {symbol} {side} | {close_reason}")
                            if not hasattr(self, 'pending_closes'):
                                self.pending_closes = []
                            self.pending_closes.append({
                                'symbol': symbol,
                                'side': side,
                                'reason': close_reason,
                                'amount': position_amount,
                                'pnl_percent': pnl_percent,
                                # Phase 232b: Position snapshot for trade_data + DB persist
                                'pos_snapshot': {
                                    'entryPrice': entry_price,
                                    'exitPrice': current_price,
                                    'unrealizedPnl': unrealized_pnl,
                                    'leverage': calculated_leverage,
                                    'sizeUsd': notional,
                                    'margin': position_margin,
                                    'stopLoss': sl,
                                    'takeProfit': tp,
                                    'trailActivation': trail_activation,
                                    'trailingStop': trailing_stop,
                                    'isTrailingActive': is_trailing_active,
                                    'atr': estimated_atr,
                                    'spreadLevel': engine_pos.get('spreadLevel', 'unknown') if engine_pos else 'unknown',
                                    'signalScore': engine_pos.get('signalScore', 0) if engine_pos else 0,
                                    'openTime': engine_pos.get('openTime', 0) if engine_pos else 0,
                                    'binance_order_id': engine_pos.get('binance_order_id', '') if engine_pos else '',
                                    'hurst': engine_pos.get('hurst', 0.5) if engine_pos else 0.5,
                                },
                            })
                            continue
                        
                        # Phase 210: Flash Trade Guard ‚Äî minimum 60s hold time
                        MIN_HOLD_SECONDS = 60
                        open_time_ms = trail_state.get('openTime', 0)
                        if open_time_ms > 0:
                            hold_duration = datetime.now().timestamp() - (open_time_ms / 1000)
                            if hold_duration < MIN_HOLD_SECONDS:
                                continue  # Skip trail exit check ‚Äî too early
                        
                        should_close = False
                        close_reason = ""
                        
                        if side == 'LONG':
                            # LONG: candle close drops below trailing stop
                            if candle_close_price <= trailing_stop:
                                should_close = True
                                close_reason = f"TRAIL_EXIT: close ${candle_close_price:.6f} <= trail ${trailing_stop:.6f}"
                        else:  # SHORT
                            # SHORT: candle close rises above trailing stop
                            if candle_close_price >= trailing_stop:
                                should_close = True
                                close_reason = f"TRAIL_EXIT: close ${candle_close_price:.6f} >= trail ${trailing_stop:.6f}"
                        
                        # Phase 212: Duplicate Emergency SL removed ‚Äî pre-guard version handles this
                        # (See L1527-1557 above)
                        if should_close:
                            logger.warning(f"üî¥ LIVE TRAIL EXIT: {symbol} {side} | {close_reason}")
                            logger.warning(f"   üìä ROI: {pnl_percent:.1f}% | PnL: ${unrealized_pnl:.2f}")
                            
                            # Queue for closing - don't close directly in get_positions to avoid blocking
                            if not hasattr(self, 'pending_closes'):
                                self.pending_closes = []
                            
                            self.pending_closes.append({
                                'symbol': symbol,
                                'side': side,
                                'amount': position_amount,
                                'reason': close_reason,
                                'timestamp': datetime.now().isoformat(),
                                # Phase 232b: Position snapshot for trade_data + DB persist
                                'pos_snapshot': {
                                    'entryPrice': entry_price,
                                    'exitPrice': candle_close_price,
                                    'unrealizedPnl': unrealized_pnl,
                                    'leverage': calculated_leverage,
                                    'sizeUsd': notional,
                                    'margin': position_margin,
                                    'stopLoss': sl,
                                    'takeProfit': tp,
                                    'trailActivation': trail_activation,
                                    'trailingStop': trailing_stop,
                                    'isTrailingActive': is_trailing_active,
                                    'atr': estimated_atr,
                                    'spreadLevel': engine_pos.get('spreadLevel', 'unknown') if engine_pos else 'unknown',
                                    'signalScore': engine_pos.get('signalScore', 0) if engine_pos else 0,
                                    'openTime': engine_pos.get('openTime', 0) if engine_pos else 0,
                                    'binance_order_id': engine_pos.get('binance_order_id', '') if engine_pos else '',
                                    'hurst': engine_pos.get('hurst', 0.5) if engine_pos else 0.5,
                                },
                            })
                            
                            # Clear trailing state after close triggered
                            del self.trailing_state[symbol]
                    
                    result.append({
                        'id': f"BIN_{symbol}_{int(datetime.now().timestamp())}",
                        'symbol': symbol,
                        'side': side,  # Use calculated side from CCXT/raw info
                        'size': position_amount,        # Internal usage
                        'contracts': position_amount,   # Phase 141: Binance-compatible field
                        'sizeUsd': notional,
                        'entryPrice': entry_price,
                        'markPrice': mark_price,
                        'unrealizedPnl': unrealized_pnl,
                        'unrealizedPnlPercent': pnl_percent,
                        'leverage': calculated_leverage,  # notional/margin - accurate for cross margin
                        'margin': position_margin,  # Add margin for UI
                        'liquidationPrice': float(p.get('liquidationPrice') or 0),
                        'marginType': p.get('marginMode', 'cross'),
                        'openTime': open_time,  # Actual position open time from trade history
                        'isLive': True,  # Mark as live position
                        # Phase 145: Dynamic TP/SL/Trail values
                        'stopLoss': sl,
                        'takeProfit': tp,
                        'trailActivation': trail_activation,
                        'trailingStop': trailing_stop,
                        'trailDistance': trail_distance,
                        'isTrailingActive': is_trailing_active,
                        'atr': estimated_atr
                    })
            
            # Phase 147: Process pending closes
            if hasattr(self, 'pending_closes') and self.pending_closes:
                for close_order in self.pending_closes:
                    logger.info(f"üîÑ Processing pending close: {close_order['symbol']}")
                    # Note: This will be executed on next tick - positions will close async
                    asyncio.create_task(self._execute_pending_close(close_order))
                self.pending_closes = []
            
            logger.info(f"get_positions returning {len(result)} active positions")
            self.last_positions = result
            return result
            
        except Exception as e:
            logger.error(f"Positions fetch error: {e}")
            return self.last_positions
    
    async def set_leverage(self, symbol: str, leverage: int) -> bool:
        """Kaldƒ±ra√ß ayarla."""
        if not self.enabled or not self.exchange:
            return False
            
        try:
            ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
            await self.exchange.set_leverage(leverage, ccxt_symbol)
            logger.info(f"‚öôÔ∏è Leverage set: {symbol} -> {leverage}x")
            return True
        except Exception as e:
            err_str = str(e).lower()
            # "already set" / "No need to change" is benign ‚Äî Binance returns error if same leverage
            if 'already' in err_str or 'no need' in err_str or 'not modified' in err_str:
                logger.info(f"‚öôÔ∏è Leverage already {leverage}x for {symbol} (OK)")
                return True
            logger.error(f"‚ùå Leverage set FAILED for {symbol} -> {leverage}x: {e}")
            return False  # Real error ‚Äî caller should abort order
    
    async def place_market_order(self, symbol: str, side: str, size_usd: float, leverage: int) -> dict:
        """Market emir g√∂nder ‚Äî Phase 186: with execution quality logging."""
        if not self.enabled or not self.exchange:
            logger.error("‚ùå LiveBinanceTrader not enabled, order rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            # Kaldƒ±ra√ß ayarla ‚Äî abort if real failure
            set_ok = await self.set_leverage(symbol, leverage)
            if not set_ok:
                logger.error(f"‚ùå Aborting market order {symbol}: leverage set to {leverage}x failed")
                return None
            
            # Phase 186: Capture pre-order book state
            ticker = await self.exchange.fetch_ticker(ccxt_symbol)
            price = ticker['last']
            best_bid = ticker.get('bid', price)
            best_ask = ticker.get('ask', price)
            mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else price
            spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0
            
            amount = size_usd / price
            
            # Minimum lot size kontrol√º
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            if market:
                min_amount = market.get('limits', {}).get('amount', {}).get('min', 0)
                if amount < min_amount:
                    logger.warning(f"‚ö†Ô∏è Amount {amount} below minimum {min_amount}, adjusting...")
                    amount = min_amount
            
            send_time = datetime.now().timestamp()
            
            # Emir g√∂nder
            order_side = 'buy' if side == 'LONG' else 'sell'
            order = await self.exchange.create_market_order(
                ccxt_symbol,
                order_side,
                amount,
                params={'reduceOnly': False}
            )
            
            fill_time = datetime.now().timestamp()
            avg_fill = float(order.get('average', price))
            fee_cost = float(order.get('fee', {}).get('cost', 0))
            
            # Phase 186: Calculate slippage
            if side == 'LONG':
                reference = best_ask if best_ask else price
                slippage_pct = (avg_fill - reference) / reference * 100 if reference > 0 else 0
            else:
                reference = best_bid if best_bid else price
                slippage_pct = (reference - avg_fill) / reference * 100 if reference > 0 else 0
            
            latency_ms = (fill_time - send_time) * 1000
            
            logger.info(f"üì§ BINANCE ORDER SENT: {side} {symbol}")
            logger.info(f"   üíµ Size: ${size_usd:.2f} | Amount: {amount:.6f}")
            logger.info(f"   üìä Leverage: {leverage}x | Price: ${price:.4f}")
            logger.info(f"   üÜî Order ID: {order.get('id', 'N/A')}")
            logger.warning(f"üìä EXEC_QUALITY: {side} {symbol} MARKET | bid=${best_bid:.6f} ask=${best_ask:.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | fee=${fee_cost:.4f} | {latency_ms:.0f}ms")
            
            return {
                'id': order.get('id'),
                'symbol': symbol,
                'side': side,
                'amount': amount,
                'price': avg_fill,  # Use actual fill price
                'cost': size_usd,
                'status': order.get('status', 'filled'),
                'timestamp': int(datetime.now().timestamp() * 1000),
                'slippage_pct': slippage_pct,
                'spread_pct': spread_pct,
                'fee': fee_cost,
            }
            
        except Exception as e:
            logger.error(f"‚ùå BINANCE ORDER FAILED: {side} {symbol} | Error: {e}")
            return None
    
    async def place_limit_entry_order(self, symbol: str, side: str, size_usd: float, leverage: int) -> dict:
        """
        Phase 186: Limit entry with aggressive pricing + 3s timeout ‚Üí market fallback.
        LONG: limit at best_ask + 2 ticks (crosses spread slightly for fast fill)
        SHORT: limit at best_bid - 2 ticks
        """
        if not self.enabled or not self.exchange:
            logger.error("‚ùå LiveBinanceTrader not enabled, order rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            set_ok = await self.set_leverage(symbol, leverage)
            if not set_ok:
                logger.error(f"‚ùå Aborting limit entry {symbol}: leverage set to {leverage}x failed")
                return None
            
            # Fetch ticker for pricing
            ticker = await self.exchange.fetch_ticker(ccxt_symbol)
            price = ticker['last']
            best_bid = ticker.get('bid', price)
            best_ask = ticker.get('ask', price)
            mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else price
            spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0
            
            # ===== Phase 201: Order Book Depth Check =====
            try:
                orderbook = await self.exchange.fetch_order_book(ccxt_symbol, 10)
                relevant_levels = orderbook['asks'][:10] if side == 'LONG' else orderbook['bids'][:10]
                available_liquidity_usd = sum(level[0] * level[1] for level in relevant_levels)
                
                MAX_BOOK_IMPACT_PCT = 0.20  # Max 20% of visible liquidity
                if available_liquidity_usd > 0 and size_usd > available_liquidity_usd * MAX_BOOK_IMPACT_PCT:
                    adjusted_size = available_liquidity_usd * 0.10  # Reduce to 10% of book
                    logger.warning(f"üö´ LIQUIDITY_GUARD: {symbol} size ${size_usd:.2f} > {MAX_BOOK_IMPACT_PCT*100:.0f}% of book (${available_liquidity_usd:.0f}) ‚Üí adjusted to ${adjusted_size:.2f}")
                    size_usd = max(adjusted_size, 5.0)  # Min $5 notional floor
                elif available_liquidity_usd > 0:
                    logger.debug(f"üìä BOOK_DEPTH: {symbol} size=${size_usd:.2f} vs book=${available_liquidity_usd:.0f} ({size_usd/available_liquidity_usd*100:.1f}%)")
            except Exception as ob_err:
                logger.debug(f"Order book depth check error: {ob_err}")
            
            amount = size_usd / price
            
            # Minimum lot size
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            tick_size = 0.0001  # Default
            if market:
                min_amount = market.get('limits', {}).get('amount', {}).get('min', 0)
                if amount < min_amount:
                    amount = min_amount
                # Get price tick size
                tick_size = market.get('precision', {}).get('price', 0.0001)
                if isinstance(tick_size, int):
                    tick_size = 10 ** (-tick_size)  # ccxt sometimes returns precision as decimal places
            
            # Aggressive limit pricing: cross the spread slightly
            order_side = 'buy' if side == 'LONG' else 'sell'
            if side == 'LONG':
                limit_price = best_ask + (tick_size * 2)  # 2 ticks above ask
            else:
                limit_price = best_bid - (tick_size * 2)  # 2 ticks below bid
            
            limit_price = float(self.exchange.price_to_precision(ccxt_symbol, limit_price))
            amount = float(self.exchange.amount_to_precision(ccxt_symbol, amount))
            
            send_time = datetime.now().timestamp()
            
            # Send limit order (IOC would be better but GTC + cancel is more portable)
            order = await self.exchange.create_limit_order(
                ccxt_symbol,
                order_side,
                amount,
                limit_price,
                params={'reduceOnly': False, 'timeInForce': 'GTC'}
            )
            
            order_id = order.get('id')
            logger.info(f"üì§ LIMIT ENTRY: {side} {symbol} @ ${limit_price:.6f} | Amount: {amount}")
            
            # Wait 3 seconds for fill
            await asyncio.sleep(3)
            
            # Check fill status
            order_check = await self.exchange.fetch_order(order_id, ccxt_symbol)
            status = order_check.get('status', 'unknown')
            filled = float(order_check.get('filled', 0))
            remaining = float(order_check.get('remaining', 0))
            avg_fill = float(order_check.get('average', 0))
            
            fill_time = datetime.now().timestamp()
            latency_ms = (fill_time - send_time) * 1000
            
            if status == 'closed' and remaining <= 0:
                # Fully filled via limit! Best case ‚Äî reduced slippage
                fee_cost = float(order_check.get('fee', {}).get('cost', 0))
                
                if side == 'LONG':
                    slippage_pct = (avg_fill - best_ask) / best_ask * 100 if best_ask > 0 else 0
                else:
                    slippage_pct = (best_bid - avg_fill) / best_bid * 100 if best_bid > 0 else 0
                
                logger.warning(f"üìä EXEC_QUALITY: {side} {symbol} LIMIT_FILLED | bid=${best_bid:.6f} ask=${best_ask:.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | {latency_ms:.0f}ms")
                
                return {
                    'id': order_id,
                    'symbol': symbol,
                    'side': side,
                    'amount': filled,
                    'price': avg_fill,
                    'cost': size_usd,
                    'status': 'filled',
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    'slippage_pct': slippage_pct,
                    'spread_pct': spread_pct,
                    'fee': fee_cost,
                    'entry_method': 'LIMIT',
                }
            
            else:
                # Not fully filled ‚Äî cancel remainder and market fallback
                if filled > 0:
                    logger.warning(f"‚ö†Ô∏è LIMIT_PARTIAL_ENTRY: {side} {symbol} filled={filled:.4f} remaining={remaining:.4f}")
                
                # Cancel unfilled portion
                try:
                    await self.exchange.cancel_order(order_id, ccxt_symbol)
                except:
                    pass  # May already be filled/cancelled
                
                if remaining > 0:
                    # Market fallback for unfilled portion
                    logger.warning(f"üîÑ LIMIT‚ÜíMARKET FALLBACK: {side} {symbol} | {remaining:.4f} unfilled ‚Üí market")
                    try:
                        fallback_order = await self.exchange.create_market_order(
                            ccxt_symbol,
                            order_side,
                            remaining,
                            params={'reduceOnly': False}
                        )
                        fallback_fill = float(fallback_order.get('average', price))
                        
                        # Weighted average fill price
                        if filled > 0:
                            total_filled = filled + float(fallback_order.get('filled', remaining))
                            avg_fill = (avg_fill * filled + fallback_fill * float(fallback_order.get('filled', remaining))) / total_filled if total_filled > 0 else fallback_fill
                        else:
                            avg_fill = fallback_fill
                            
                    except Exception as fb_err:
                        logger.error(f"‚ùå MARKET FALLBACK FAILED: {side} {symbol} | {fb_err}")
                        if filled <= 0:
                            return None  # Total failure
                        # If partially filled via limit, continue with what we have
                
                if side == 'LONG':
                    slippage_pct = (avg_fill - best_ask) / best_ask * 100 if best_ask > 0 else 0
                else:
                    slippage_pct = (best_bid - avg_fill) / best_bid * 100 if best_bid > 0 else 0
                
                logger.warning(f"üìä EXEC_QUALITY: {side} {symbol} LIMIT‚ÜíMKT | bid=${best_bid:.6f} ask=${best_ask:.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | {latency_ms:.0f}ms")
                
                return {
                    'id': order_id,
                    'symbol': symbol,
                    'side': side,
                    'amount': filled + remaining,  # Total intended
                    'price': avg_fill,
                    'cost': size_usd,
                    'status': 'filled',
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    'slippage_pct': slippage_pct,
                    'spread_pct': spread_pct,
                    'entry_method': 'LIMIT_MKT_FALLBACK',
                }
                
        except Exception as e:
            logger.error(f"‚ùå LIMIT ENTRY FAILED: {side} {symbol} | {e} ‚Äî falling back to market")
            # Full market fallback on any error
            return await self.place_market_order(symbol, side, size_usd, leverage)
    
    async def close_position(self, symbol: str, side: str, amount: float) -> dict:
        """Pozisyon kapat (reduceOnly=True) ‚Äî Market order. Phase 186: with exec logging."""
        if not self.enabled or not self.exchange:
            logger.error("‚ùå LiveBinanceTrader not enabled, close rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            # Phase 186: Capture pre-close book state
            try:
                ticker = await self.exchange.fetch_ticker(ccxt_symbol)
                best_bid = ticker.get('bid', 0)
                best_ask = ticker.get('ask', 0)
                mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else ticker.get('last', 0)
                spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0
            except:
                best_bid = best_ask = mid_price = spread_pct = 0
            
            send_time = datetime.now().timestamp()
            
            # Kapanƒ±≈ü emri - ters y√∂nde reduceOnly
            close_side = 'sell' if side == 'LONG' else 'buy'
            order = await self.exchange.create_market_order(
                ccxt_symbol,
                close_side,
                amount,
                params={'reduceOnly': True}
            )
            
            fill_time = datetime.now().timestamp()
            avg_fill = float(order.get('average', 0))
            fee_cost = float(order.get('fee', {}).get('cost', 0))
            latency_ms = (fill_time - send_time) * 1000
            
            # Slippage: for CLOSE, selling LONG hits bid, buying SHORT hits ask
            if side == 'LONG':
                reference = best_bid if best_bid else avg_fill
                slippage_pct = (reference - avg_fill) / reference * 100 if reference > 0 else 0
            else:
                reference = best_ask if best_ask else avg_fill
                slippage_pct = (avg_fill - reference) / reference * 100 if reference > 0 else 0
            
            logger.info(f"üì§ BINANCE CLOSE: {side} {symbol} | Amount: {amount:.6f}")
            logger.info(f"   üÜî Order ID: {order.get('id', 'N/A')}")
            logger.warning(f"üìä EXEC_QUALITY_CLOSE: {side} {symbol} | bid=${best_bid:.6f} ask=${best_ask:.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | fee=${fee_cost:.4f} | {latency_ms:.0f}ms")
            
            return {
                'id': order.get('id'),
                'symbol': symbol,
                'side': side,
                'amount': amount,
                'status': order.get('status', 'filled'),
                'timestamp': int(datetime.now().timestamp() * 1000),
                'slippage_pct': slippage_pct,
                'fee': fee_cost,
            }
            
        except Exception as e:
            logger.error(f"‚ùå BINANCE CLOSE FAILED: {side} {symbol} | Error: {e}")
            # Phase 217: Retry with exponential backoff to prevent ghost positions
            for retry in range(3):
                try:
                    await asyncio.sleep(1 * (retry + 1))
                    logger.warning(f"üîÑ CLOSE RETRY {retry+1}/3: {side} {symbol}")
                    order = await self.exchange.create_market_order(
                        ccxt_symbol, close_side, amount,
                        params={'reduceOnly': True}
                    )
                    logger.info(f"‚úÖ CLOSE RETRY SUCCESS: {side} {symbol} | Order: {order.get('id', 'N/A')}")
                    return {
                        'id': order.get('id'),
                        'symbol': symbol,
                        'side': side,
                        'amount': amount,
                        'status': order.get('status', 'filled'),
                        'timestamp': int(datetime.now().timestamp() * 1000),
                    }
                except Exception as retry_err:
                    logger.error(f"‚ùå CLOSE RETRY {retry+1} FAILED: {retry_err}")
            
            # All retries failed ‚Äî mark as ghost position risk
            logger.critical(f"üö® GHOST POSITION RISK: {side} {symbol} close FAILED after 3 retries ‚Äî manual intervention needed")
            return None
    
    async def close_position_limit(self, symbol: str, side: str, amount: float, price: float) -> dict:
        """
        Phase 179: Place a LIMIT close order at exact price (no slippage).
        Used for breakeven close ‚Äî order sits on book until filled.
        """
        if not self.enabled or not self.exchange:
            logger.error("‚ùå LiveBinanceTrader not enabled, limit close rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            close_side = 'sell' if side == 'LONG' else 'buy'
            
            # Price precision: match market requirements
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            if market:
                price = self.exchange.price_to_precision(ccxt_symbol, price)
                amount = self.exchange.amount_to_precision(ccxt_symbol, amount)
            
            order = await self.exchange.create_limit_order(
                ccxt_symbol,
                close_side,
                float(amount),
                float(price),
                params={
                    'reduceOnly': True,
                    'timeInForce': 'GTC'  # Good-Till-Cancel
                }
            )
            
            order_id = order.get('id', 'N/A')
            logger.warning(f"üîí BREAKEVEN LIMIT ORDER: {side} {symbol} @ ${price} | Amount: {amount} | Order: {order_id}")
            
            return {
                'id': order_id,
                'symbol': symbol,
                'side': side,
                'amount': float(amount),
                'price': float(price),
                'status': order.get('status', 'open'),
                'timestamp': int(datetime.now().timestamp() * 1000)
            }
            
        except Exception as e:
            logger.error(f"‚ùå BREAKEVEN LIMIT ORDER FAILED: {side} {symbol} @ ${price} | Error: {e}")
            return None
    
    async def cancel_order(self, symbol: str, order_id: str) -> bool:
        """Phase 179: Cancel an open order."""
        if not self.enabled or not self.exchange:
            return False
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            await self.exchange.cancel_order(order_id, ccxt_symbol)
            logger.info(f"üóëÔ∏è Order cancelled: {symbol} #{order_id}")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Cancel order failed: {symbol} #{order_id} - {e}")
            return False
    
    async def check_order_status(self, symbol: str, order_id: str) -> dict:
        """Phase 179: Check if a limit order has been filled."""
        if not self.enabled or not self.exchange:
            return {'status': 'unknown'}
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            order = await self.exchange.fetch_order(order_id, ccxt_symbol)
            return {
                'status': order.get('status', 'unknown'),  # open, closed, canceled
                'filled': float(order.get('filled', 0)),
                'remaining': float(order.get('remaining', 0)),
                'average': float(order.get('average', 0)),  # Average fill price
                'price': float(order.get('price', 0)),
            }
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Check order status failed: {symbol} #{order_id} - {e}")
            return {'status': 'error', 'error': str(e)}
    
    async def _execute_pending_close(self, close_order: dict):
        """Execute a pending close order from trailing stop hit."""
        try:
            symbol = close_order['symbol']
            side = close_order['side']
            amount = close_order['amount']
            reason = close_order['reason']
            pos_snapshot = close_order.get('pos_snapshot', {})
            
            logger.info(f"üî¥ EXECUTING TRAIL CLOSE: {symbol} {side}")
            logger.info(f"   üìã Reason: {reason}")
            
            result = await self.close_position(symbol, side, amount)
            
            if result:
                logger.info(f"‚úÖ TRAIL CLOSE SUCCESS: {symbol} | Order ID: {result.get('id')}")
                
                now_ms = int(datetime.now().timestamp() * 1000)
                entry_price = pos_snapshot.get('entryPrice', 0)
                exit_price = pos_snapshot.get('exitPrice', 0)
                pnl = pos_snapshot.get('unrealizedPnl', 0)
                leverage = pos_snapshot.get('leverage', 10)
                size_usd = pos_snapshot.get('sizeUsd', 0)
                margin = pos_snapshot.get('margin', 0) or (size_usd / max(leverage, 1))
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Build trade_data for sync loop
                trade_data = {
                    'id': f"TRAIL_{symbol}_{now_ms}",
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': entry_price,
                    'exitPrice': exit_price,
                    'size': amount,
                    'sizeUsd': size_usd,
                    'pnl': round(pnl, 4),
                    'pnlPercent': close_order.get('pnl_percent', 0),
                    'margin': round(margin, 4),
                    'roi': round(roi, 2),
                    'openTime': pos_snapshot.get('openTime', 0),
                    'closeTime': now_ms,
                    'reason': reason,
                    'closeReason': reason,
                    'leverage': leverage,
                    'isLive': True,
                    'stopLoss': pos_snapshot.get('stopLoss', 0),
                    'takeProfit': pos_snapshot.get('takeProfit', 0),
                    'trailActivation': pos_snapshot.get('trailActivation', 0),
                    'trailingStop': pos_snapshot.get('trailingStop', 0),
                    'isTrailingActive': pos_snapshot.get('isTrailingActive', False),
                    'atr': pos_snapshot.get('atr', 0),
                    'spreadLevel': pos_snapshot.get('spreadLevel', 'unknown'),
                    'signalScore': pos_snapshot.get('signalScore', 0),
                    'hurst': pos_snapshot.get('hurst', 0.5),
                }
                
                # Phase 232b-P1: Write to GLOBAL pending_close_reasons WITH trade_data
                pending_close_reasons[symbol] = {
                    "reason": reason,
                    "original_reason": reason,
                    "timestamp": now_ms,
                    "trade_data": trade_data,
                    "entry_order_id": pos_snapshot.get('binance_order_id', ''),
                }
                
                # Phase 232b-P2: Persist to position_closes for restart safety
                try:
                    close_data = {
                        'symbol': symbol,
                        'side': side,
                        'reason': reason,
                        'original_reason': reason,
                        'entryPrice': entry_price,
                        'exitPrice': exit_price,
                        'pnl': pnl,
                        'leverage': leverage,
                        'sizeUsd': size_usd,
                        'margin': margin,
                        'roi': roi,
                        'timestamp': now_ms,
                        'stopLoss': pos_snapshot.get('stopLoss', 0),
                        'takeProfit': pos_snapshot.get('takeProfit', 0),
                        'atr': pos_snapshot.get('atr', 0),
                        'trailingStop': pos_snapshot.get('trailingStop', 0),
                        'trailActivation': pos_snapshot.get('trailActivation', 0),
                        'signalScore': pos_snapshot.get('signalScore', 0),
                        'spreadLevel': pos_snapshot.get('spreadLevel', 'unknown'),
                        'hurst': pos_snapshot.get('hurst', 0.5),
                        'entry_order_id': pos_snapshot.get('binance_order_id', ''),
                    }
                    safe_create_task(sqlite_manager.save_position_close(close_data))
                    logger.info(f"üíæ TRAIL CLOSE persisted to position_closes: {symbol}")
                except Exception as db_err:
                    logger.debug(f"SQLite position_close save error: {db_err}")
            else:
                logger.error(f"‚ùå TRAIL CLOSE FAILED: {symbol}")
                
            return result
            
        except Exception as e:
            logger.error(f"‚ùå _execute_pending_close error: {e}")
            return None
    
    async def close_all_positions(self) -> list:
        """T√ºm a√ßƒ±k pozisyonlarƒ± kapat (Emergency)."""
        if not self.enabled:
            return []
            
        closed = []
        positions = await self.get_positions()
        
        for pos in positions:
            result = await self.close_position(
                pos['symbol'], 
                pos['side'], 
                pos['size']
            )
            if result:
                closed.append(result)
                
        logger.warning(f"‚ö†Ô∏è EMERGENCY CLOSE: {len(closed)} positions closed")
        return closed
    
    async def get_pnl_from_binance(self) -> dict:
        """
        Binance Futures income history'den Today's PnL ve Total PnL hesapla.
        Returns: {todayPnl, todayPnlPercent, totalPnl, totalPnlPercent, todayTradesCount}
        """
        if not self.enabled or not self.exchange:
            return {
                'todayPnl': 0, 'todayPnlPercent': 0,
                'totalPnl': 0, 'totalPnlPercent': 0,
                'todayTradesCount': 0
            }
        
        try:
            # pytz imported globally
            
            # Turkey timezone (UTC+3)
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now_turkey = datetime.now(turkey_tz)
            
            # Start of today in Turkey time
            today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
            today_start_ms = int(today_start.timestamp() * 1000)
            
            # Fetch income history from Binance (all types for accurate Today's PnL)
            # Binance Today's PnL includes: REALIZED_PNL, FUNDING_FEE, COMMISSION, etc.
            # CCXT async uses camelCase: fapiPrivateGetIncome
            all_income = await self.exchange.fapiPrivateGetIncome({
                'limit': 1000  # All income types, max allowed
            })
            
            today_pnl = 0.0
            total_pnl = 0.0
            today_trades_count = 0
            
            logger.info(f"üìä Income history: {len(all_income)} entries, today_start_ms={today_start_ms}")
            
            for income in all_income:
                income_type = income.get('incomeType', '')
                pnl = float(income.get('income', 0))
                timestamp = int(income.get('time', 0))
                
                # Only count trading-related income (exclude transfers, deposits)
                if income_type in ['REALIZED_PNL', 'FUNDING_FEE', 'COMMISSION']:
                    total_pnl += pnl
                    
                    if timestamp >= today_start_ms:
                        today_pnl += pnl
                        today_trades_count += 1
                        # Removed noisy individual income logging (Phase 105)
            
            # Calculate percentages based on wallet balance
            wallet_balance = self.last_balance if self.last_balance > 0 else 100
            today_pnl_percent = (today_pnl / wallet_balance) * 100
            total_pnl_percent = (total_pnl / wallet_balance) * 100
            
            logger.info(f"üìä PnL from Binance: Today=${today_pnl:.2f} ({today_pnl_percent:.2f}%) | Total=${total_pnl:.2f}")
            
            return {
                'todayPnl': round(today_pnl, 2),
                'todayPnlPercent': round(today_pnl_percent, 2),
                'totalPnl': round(total_pnl, 2),
                'totalPnlPercent': round(total_pnl_percent, 2),
                'todayTradesCount': today_trades_count
            }
            
        except Exception as e:
            logger.error(f"PnL fetch error: {e}")
            return {
                'todayPnl': 0, 'todayPnlPercent': 0,
                'totalPnl': 0, 'totalPnlPercent': 0,
                'todayTradesCount': 0
            }

    async def get_trade_history(self, limit: int = 50, days_back: int = 7) -> list:
        """
        Binance Futures'dan trade history √ßek.
        Uses userTrades API to get entry/exit prices and combines with Income API for PnL.
        Returns list of trades in frontend-compatible format.
        """
        logger.info(f"get_trade_history called: enabled={self.enabled}, exchange={self.exchange is not None}")
        
        if not self.enabled or not self.exchange:
            logger.warning(f"get_trade_history: Early return - enabled={self.enabled}, exchange={self.exchange is not None}")
            return []
        
        try:
            # pytz imported globally
            from datetime import timedelta
            from collections import defaultdict
            
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now = datetime.now(turkey_tz)
            start_time = int((now - timedelta(days=days_back)).timestamp() * 1000)
            
            # Step 1: Get all Income records (REALIZED_PNL) - these represent closed positions
            logger.info(f"Fetching income history from {days_back} days back...")
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'startTime': start_time,
                'limit': min(limit * 2, 1000)  # Fetch more to ensure coverage
            })
            
            if not income_history:
                logger.warning("Trade history: No income history found")
                return []
            
            logger.info(f"Got {len(income_history)} income records")
            
            # Group income by symbol to get unique closed positions
            # Each income record represents a partial or full position close
            position_closes = []
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income', 0))
                timestamp = int(income.get('time', 0))
                
                if pnl == 0:
                    continue  # Skip zero PnL (partial fills without actual close)
                
                position_closes.append({
                    'symbol': symbol,
                    'pnl': pnl,
                    'timestamp': timestamp
                })
            
            logger.info(f"Found {len(position_closes)} position closes with non-zero PnL")
            
            # Phase 150: Aggregate partial fills ‚Äî same symbol within ¬±5 seconds = single trade
            aggregated_closes = []
            i = 0
            while i < len(position_closes):
                current = position_closes[i]
                agg_pnl = current['pnl']
                agg_timestamp = current['timestamp']
                j = i + 1
                while j < len(position_closes):
                    next_close = position_closes[j]
                    if (next_close['symbol'] == current['symbol'] and 
                        abs(next_close['timestamp'] - current['timestamp']) < 5000):  # ¬±5 seconds
                        agg_pnl += next_close['pnl']
                        agg_timestamp = max(agg_timestamp, next_close['timestamp'])  # Use latest
                        j += 1
                    else:
                        break
                aggregated_closes.append({
                    'symbol': current['symbol'],
                    'pnl': agg_pnl,
                    'timestamp': agg_timestamp,
                    'partial_count': j - i
                })
                i = j
            
            logger.info(f"Phase 150: Aggregated {len(position_closes)} fills ‚Üí {len(aggregated_closes)} trades")
            position_closes = aggregated_closes
            
            # Step 2: For each closed position, try to get trade details
            trades = []
            processed_symbols = set()
            
            for close_info in position_closes:
                symbol = close_info['symbol']
                pnl = close_info['pnl']
                timestamp = close_info['timestamp']
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Try to get user trades for this symbol to get entry/exit prices
                entry_price = 0.0
                exit_price = 0.0
                side = 'LONG'  # Phase 181: Default, will be corrected by actual trade data below
                leverage = 1
                size_usd = 0.0
                qty = 0.0
                close_order_id = ''  # Phase 229: Binance close order ID
                
                # Fetch trades for this symbol around the close time
                try:
                    # Phase 181: Get trades from wider window (7 days for entry, 1 min for close)
                    trade_start = timestamp - (7 * 24 * 60 * 60 * 1000)  # 7 days before (entry may be old)
                    trade_end = timestamp + (60 * 1000)  # 1 minute after
                    
                    user_trades = await self.exchange.fapiPrivateGetUserTrades({
                        'symbol': symbol,
                        'startTime': trade_start,
                        'endTime': trade_end,
                        'limit': 100
                    })
                    
                    if user_trades and len(user_trades) > 0:
                        # Find the closing trade (closest to timestamp, reducing position)
                        # Trades with 'SELL' for LONG positions or 'BUY' for SHORT positions
                        for t in user_trades:
                            t_time = int(t.get('time', 0))
                            t_side = t.get('side', '')
                            t_price = float(t.get('price', 0))
                            t_qty = float(t.get('qty', 0))
                            realized = float(t.get('realizedPnl', 0))
                            t_order_id = str(t.get('orderId', ''))  # Phase 229
                            
                            # If this trade has realized PnL matching our close, it's the exit
                            if abs(realized - pnl) < 0.01 and t_price > 0:
                                exit_price = t_price
                                qty = t_qty
                                close_order_id = t_order_id  # Phase 229
                                # If selling, was LONG. If buying, was SHORT
                                side = 'LONG' if t_side == 'SELL' else 'SHORT'
                                break
                            # Fallback: use the last trade before close time
                            elif t_time <= timestamp and t_price > 0:
                                exit_price = t_price
                                qty = t_qty
                                side = 'LONG' if t_side == 'SELL' else 'SHORT'
                        
                        # Try to find entry price from earlier trades
                        entry_side = 'BUY' if side == 'LONG' else 'SELL'
                        for t in reversed(user_trades):
                            if t.get('side') == entry_side and float(t.get('price', 0)) > 0:
                                entry_price = float(t.get('price', 0))
                                break
                        
                        # If we found exit but no entry, estimate from PnL
                        if exit_price > 0 and entry_price == 0 and qty > 0:
                            # PnL = (exit - entry) * qty for LONG, (entry - exit) * qty for SHORT
                            if side == 'LONG':
                                entry_price = exit_price - (pnl / qty) if qty > 0 else 0
                            else:
                                entry_price = exit_price + (pnl / qty) if qty > 0 else 0
                        
                        size_usd = exit_price * qty if exit_price > 0 and qty > 0 else 0
                
                except Exception as e:
                    logger.debug(f"Could not fetch trades for {symbol}: {e}")
                
                # Get close reason from pending_close_reasons if available
                close_reason = 'Closed'
                reason_detail = 'Position closed on Binance'
                matched_close_id = None
                
                # First try in-memory pending_close_reasons
                if symbol in pending_close_reasons:
                    reason_data = pending_close_reasons.get(symbol, {})
                    reason_timestamp = reason_data.get('timestamp', 0)
                    # Match if within 30 minutes of close (extended from 5 min)
                    if abs(timestamp - reason_timestamp) < 30 * 60 * 1000:
                        close_reason = reason_data.get('reason', close_reason)
                        reason_detail = reason_data.get('original_reason', reason_detail)
                        # Use trade data from our system if available
                        trade_data = reason_data.get('trade_data', {})
                        if trade_data:
                            if trade_data.get('entryPrice', 0) > 0:
                                entry_price = trade_data.get('entryPrice')
                            if trade_data.get('exitPrice', 0) > 0:
                                exit_price = trade_data.get('exitPrice')
                            if trade_data.get('side'):
                                side = trade_data.get('side')
                            if trade_data.get('leverage', 0) > 0:
                                leverage = trade_data.get('leverage')
                            if trade_data.get('sizeUsd', 0) > 0:
                                size_usd = trade_data.get('sizeUsd')
                            # Override PnL from trade_data if available (more accurate)
                            if trade_data.get('pnl') is not None:
                                pnl = trade_data.get('pnl')
                
                # If not found in memory, try SQLite (for persistence after restart)
                # Phase 229: Pass close_order_id from in-memory or UserTrades
                mem_close_oid = pending_close_reasons.get(symbol, {}).get('close_order_id', '') if symbol in pending_close_reasons else ''
                effective_close_oid = mem_close_oid or close_order_id
                if reason_detail == 'Position closed on Binance':
                    try:
                        sqlite_close = await sqlite_manager.get_pending_close_reason(symbol, timestamp, window_minutes=60, close_order_id=effective_close_oid)
                        if sqlite_close:
                            close_reason = sqlite_close.get('reason', close_reason)
                            reason_detail = sqlite_close.get('original_reason', reason_detail)
                            matched_close_id = sqlite_close.get('id')
                            # Use SQLite data
                            if sqlite_close.get('entry_price', 0) > 0:
                                entry_price = sqlite_close.get('entry_price')
                            if sqlite_close.get('exit_price', 0) > 0:
                                exit_price = sqlite_close.get('exit_price')
                            if sqlite_close.get('side'):
                                side = sqlite_close.get('side')
                            if sqlite_close.get('leverage', 0) > 0:
                                leverage = sqlite_close.get('leverage')
                            if sqlite_close.get('size_usd', 0) > 0:
                                size_usd = sqlite_close.get('size_usd')
                            if sqlite_close.get('pnl') is not None:
                                pnl = sqlite_close.get('pnl')
                            logger.info(f"üìã Matched trade with SQLite close reason: {symbol} - {reason_detail}")
                    except Exception as e:
                        logger.debug(f"SQLite close reason lookup failed: {e}")
                
                # Calculate margin and ROI (Binance style: ROI = PnL / Margin * 100)
                margin = size_usd / leverage if leverage > 0 and size_usd > 0 else 0
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Frontend-compatible format
                trade = {
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': round(entry_price, 8) if entry_price else 0,
                    'exitPrice': round(exit_price, 8) if exit_price else 0,
                    'pnl': round(pnl, 4),
                    'closeTime': timestamp,
                    'closeReason': close_reason,
                    'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                    'timestamp': timestamp,
                    'time': close_time.strftime('%H:%M:%S'),
                    'date': close_time.strftime('%Y-%m-%d'),
                    'type': 'CLOSE',
                    'margin': round(margin, 4),
                    'leverage': leverage,
                    'sizeUsd': round(size_usd, 2),
                    'roi': round(roi, 2),  # Pre-calculated ROI for frontend
                    'reason': reason_detail
                }
                trades.append(trade)
                
                # Save to SQLite for historical analysis
                try:
                    trade_for_sqlite = trade.copy()
                    trade_for_sqlite['incomeId'] = f"{symbol}_{timestamp}"
                    safe_create_task(sqlite_manager.save_binance_trade(trade_for_sqlite))
                    # Mark matched position close as matched
                    if matched_close_id:
                        safe_create_task(sqlite_manager.mark_close_matched(matched_close_id))
                except Exception as e:
                    logger.debug(f"SQLite trade save error: {e}")
            
            # Sort by timestamp descending (newest first)
            trades.sort(key=lambda x: x['timestamp'], reverse=True)
            
            logger.info(f"üìä Returning {len(trades)} trades from Binance (last {days_back} days)")
            return trades[:limit]
            
        except Exception as e:
            import traceback
            logger.error(f"Trade history fetch error: {e}")
            logger.error(f"Trade history traceback: {traceback.format_exc()}")
            return []
    
    async def sync_closed_trades_from_binance(self, hours_back: int = 24) -> int:
        """
        Phase 148: Sync closed trades from Binance to trade history.
        This captures trades that were missed (external closes, server restart).
        Returns number of new trades synced.
        """
        if not self.enabled or not self.exchange:
            return 0
        
        try:
            # pytz imported globally
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now = datetime.now(turkey_tz)
            start_time = int((now - timedelta(hours=hours_back)).timestamp() * 1000)
            
            # Fetch REALIZED_PNL entries from Binance
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'startTime': start_time,
                'limit': 500
            })
            
            if not income_history:
                return 0
            
            # Get existing trade IDs to avoid duplicates
            existing_ids = set()
            if global_paper_trader:
                for trade in global_paper_trader.trades:
                    # Create unique ID from symbol + closeTime
                    # Phase 188: Use symbolFull if available (get_full_trade_history strips USDT)
                    close_time = trade.get('closeTime', 0)
                    symbol = trade.get('symbolFull', trade.get('symbol', ''))
                    existing_ids.add(f"{symbol}_{close_time}")
            
            synced_count = 0
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income', 0))
                timestamp = int(income.get('time', 0))
                
                # Create unique ID
                trade_id = f"{symbol}_{timestamp}"
                
                if trade_id in existing_ids:
                    continue  # Already in trade history
                
                # Skip very small PnL (likely partial fills or dust)
                if abs(pnl) < 0.01:
                    continue
                
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Create trade record
                trade = {
                    'id': f"BINANCE_{symbol}_{timestamp}",
                    'symbol': symbol,
                    'side': 'LONG' if pnl > 0 else 'SHORT',  # Estimate
                    'entryPrice': 0,
                    'exitPrice': 0,
                    'size': 0,
                    'sizeUsd': 0,
                    'pnl': round(pnl, 4),
                    'pnlPercent': 0,
                    'openTime': timestamp - 3600000,  # Estimate: 1 hour before close
                    'closeTime': timestamp,
                    'reason': 'Synced from Binance',
                    'closeReason': 'Synced from Binance',
                    'leverage': 0,
                    'isLive': True,
                    'signalScore': 0,
                    'mtfScore': 0
                }
                
                if global_paper_trader:
                    global_paper_trader.trades.append(trade)
                    synced_count += 1
                    existing_ids.add(trade_id)
                    
                    # Save to SQLite
                    try:
                        safe_create_task(sqlite_manager.save_trade(trade))
                    except Exception as e:
                        logger.debug(f"SQLite sync save error: {e}")
            
            if synced_count > 0:
                logger.info(f"üì• BINANCE SYNC: Added {synced_count} missing trades from last {hours_back}h")
                if global_paper_trader:
                    global_paper_trader.save_state()
            
            return synced_count
            
        except Exception as e:
            logger.error(f"sync_closed_trades_from_binance error: {e}")
            return 0
    
    async def backfill_trade_history_to_sqlite(self, limit: int = 1000):
        """
        Backfill last N trades from Binance Income API to SQLite.
        Called once at startup to populate historical data.
        """
        if not self.enabled or not self.exchange:
            logger.info("Backfill skipped: Binance trader not enabled")
            return 0
        
        try:
            # pytz imported globally
            turkey_tz = pytz.timezone('Europe/Istanbul')
            
            # Fetch last 1000 REALIZED_PNL entries (max allowed by Binance)
            logger.info(f"üì• Starting Binance trade history backfill (limit={limit})...")
            
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'limit': limit
            })
            
            if not income_history:
                logger.warning("Backfill: No income history found")
                return 0
            
            saved_count = 0
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income', 0))
                timestamp = int(income.get('time', 0))
                
                # Skip very small PnL
                if abs(pnl) < 0.01:
                    continue
                
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Check if we have close reason from SQLite
                close_reason = 'Closed'
                reason_detail = 'Historical (from Binance)'
                entry_price = 0
                exit_price = 0
                side = 'LONG' if pnl > 0 else 'SHORT'
                leverage = await sqlite_manager.get_leverage(symbol)  # Get cached leverage or default
                size_usd = 0
                
                # Try to find matching close from position_closes table
                try:
                    sqlite_close = await sqlite_manager.get_pending_close_reason(symbol, timestamp, window_minutes=60)
                    if sqlite_close:
                        close_reason = sqlite_close.get('reason', close_reason)
                        reason_detail = sqlite_close.get('original_reason', reason_detail)
                        entry_price = sqlite_close.get('entry_price', 0)
                        exit_price = sqlite_close.get('exit_price', 0)
                        side = sqlite_close.get('side', side)
                        leverage = sqlite_close.get('leverage', leverage)
                        size_usd = sqlite_close.get('size_usd', 0)
                except:
                    pass
                
                # Calculate margin and ROI
                margin = size_usd / leverage if leverage > 0 and size_usd > 0 else abs(pnl) / 0.1  # Estimate
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Save to SQLite
                trade_data = {
                    'incomeId': f"{symbol}_{timestamp}",
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': entry_price,
                    'exitPrice': exit_price,
                    'pnl': round(pnl, 4),
                    'roi': round(roi, 2),
                    'margin': round(margin, 4),
                    'leverage': leverage,
                    'sizeUsd': round(size_usd, 2),
                    'closeReason': close_reason,
                    'closeTime': timestamp
                }
                
                try:
                    await sqlite_manager.save_binance_trade(trade_data)
                    saved_count += 1
                except Exception as e:
                    # Likely duplicate, skip
                    pass
            
            logger.info(f"üìä Binance backfill complete: {saved_count}/{len(income_history)} trades saved to SQLite")
            return saved_count
            
        except Exception as e:
            import traceback
            logger.error(f"backfill_trade_history_to_sqlite error: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return 0

    def get_status(self) -> dict:
        """Trader durumu."""
        return {
            'enabled': self.enabled,
            'initialized': self.initialized,
            'trading_mode': self.trading_mode,
            'last_balance': self.last_balance,
            'position_count': len(self.last_positions),
            'last_sync': self.last_sync_time
        }


# Global LiveBinanceTrader instance
live_binance_trader = LiveBinanceTrader()


# Forward declaration for background tasks
background_scanner_task = None
position_updater_task = None
binance_sync_task = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan: start background scanner and position updater on startup."""
    global background_scanner_task, position_updater_task, binance_sync_task
    
    # Initialize SQLite database
    logger.info("üìÅ Initializing SQLite database...")
    await sqlite_manager.init_db()
    
    # Phase 187b: Load ALL trades from SQLite into paper_trader.trades
    # This ensures WebSocket/REST endpoints serve complete historical data from the start
    try:
        sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
        if sqlite_trades:
            global_paper_trader.trades = sqlite_trades
            logger.info(f"üìä Phase 187b: Loaded {len(sqlite_trades)} trades from SQLite into memory")
        else:
            logger.info("üìä Phase 187b: No trades found in SQLite")
    except Exception as e:
        logger.error(f"üìä Phase 187b: Failed to load trades from SQLite: {e}")
    
    # Phase 154: Load persisted breakeven states
    await breakeven_stop_manager.load_from_sqlite()
    logger.info(f"üîí Breakeven states loaded: {len(breakeven_stop_manager.breakeven_state)} active")
    
    # Initialize LiveBinanceTrader (if TRADING_MODE is live)
    # Note: Read TRADING_MODE here (after secrets are loaded) and update the trader
    trading_mode = os.environ.get('TRADING_MODE', 'paper')
    live_binance_trader.trading_mode = trading_mode  # Update trading mode from env
    logger.info(f"üìä Trading Mode: {trading_mode.upper()}")
    
    if trading_mode == 'live':
        try:
            logger.info("üîå Initializing LiveBinanceTrader...")
            success = await live_binance_trader.initialize()
            if success:
                logger.info("‚úÖ LiveBinanceTrader ready for real trading!")
                
                # Backfill last 1000 trades to SQLite (one-time on startup)
                asyncio.create_task(live_binance_trader.backfill_trade_history_to_sqlite(1000))
            else:
                logger.error("‚ùå LiveBinanceTrader failed to initialize! Sync loop will retry...")
        except Exception as e:
            logger.error(f"‚ùå CRITICAL: LiveBinanceTrader initialization error: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        # Phase 189: ALWAYS start sync loop - it has auto-reconnect logic
        binance_sync_task = asyncio.create_task(binance_position_sync_loop())
        logger.info("üîÑ Binance position sync loop started (with auto-reconnect)!")
    else:
        logger.info("üìÑ Paper trading mode - no Binance connection")
    
    # Start Liquidation Tracker
    logger.info("üíÄ Starting Liquidation Tracker...")
    asyncio.create_task(liquidation_tracker.start())
    
    logger.info("üöÄ Starting 24/7 Background Scanner...")
    
    # Start background scanner as asyncio task (scans all coins every 10 seconds)
    background_scanner_task = asyncio.create_task(background_scanner_loop())
    
    # Start position updater task (updates open positions every 2 seconds)
    position_updater_task = asyncio.create_task(position_price_update_loop())
    
    yield  # App is running
    
    # Shutdown: stop all tasks
    logger.info("üõë Shutting down Background Tasks...")
    for task in [background_scanner_task, position_updater_task, binance_sync_task]:
        if task:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
    
    # Close Binance connection
    if live_binance_trader.exchange:
        await live_binance_trader.exchange.close()
        logger.info("üîå Binance connection closed")


# ============================================================================
# Phase 142: Helper function for coin ATR percentage
# ============================================================================

def _get_coin_atr_percent(symbol: str) -> float:
    """
    Get ATR as percentage of price for a coin.
    Used by PortfolioRecoveryManager for dynamic trailing distance.
    
    Args:
        symbol: Trading pair symbol (e.g., 'BTCUSDT')
        
    Returns:
        ATR as percentage of price (e.g., 2.0 for 2%)
    """
    try:
        if multi_coin_scanner and hasattr(multi_coin_scanner, 'opportunities'):
            opp = multi_coin_scanner.opportunities.get(symbol)
            if opp and hasattr(opp, 'atr') and hasattr(opp, 'price'):
                if opp.price and opp.price > 0:
                    return (opp.atr / opp.price) * 100
    except Exception as e:
        logger.debug(f"Could not get ATR for {symbol}: {e}")
    return 2.0  # Default 2%


async def binance_position_sync_loop():
    """
    Binance'den pozisyon/bakiye senkronizasyonu (her 5 saniye).
    Live trading modunda Binance'deki ger√ßek pozisyonlarƒ± UI'a yansƒ±tƒ±r.
    
    Phase 72: T√ºm Binance pozisyonlarƒ±nƒ± (manuel dahil) algoritma y√∂netimi altƒ±na alƒ±r.
    """
    logger.info("üîÑ Binance Position Sync Loop started")
    reconnect_interval = 30  # seconds between reconnect attempts
    last_reconnect_attempt = 0
    _phase218_recalc_done = False  # One-time flag
    
    while True:
        try:
            # ================================================================
            # Phase 218: ONE-TIME RECALC ‚Äî fix SL/TP for existing positions
            # sl_atr=15 was used as raw multiplier instead of 1.5 (=15/10)
            # This runs ONCE per server lifetime to fix all positions
            # ================================================================
            if not _phase218_recalc_done and len(global_paper_trader.positions) > 0:
                _phase218_recalc_done = True
                fixed_count = 0
                sl_atr_corrected = global_paper_trader.sl_atr / 10  # 15 ‚Üí 1.5
                tp_atr_corrected = global_paper_trader.tp_atr / 10  # 30 ‚Üí 3.0
                et = global_paper_trader.exit_tightness  # 1.2
                
                for pos in global_paper_trader.positions:
                    try:
                        entry = pos.get('entryPrice', 0)
                        if entry <= 0:
                            continue
                        
                        atr = pos.get('atr', entry * 0.02)
                        side = pos.get('side', '')
                        
                        # Calculate dynamic ATR multiplier
                        dyn_mult = global_paper_trader.calculate_dynamic_atr_multiplier(atr, entry)
                        
                        adjusted_sl = sl_atr_corrected * et * dyn_mult
                        adjusted_tp = tp_atr_corrected * et * dyn_mult
                        
                        old_sl = pos.get('stopLoss', 0)
                        old_tp = pos.get('takeProfit', 0)
                        
                        if side == 'LONG':
                            new_sl = max(entry * 0.01, entry - (atr * adjusted_sl))
                            new_tp = entry + (atr * adjusted_tp)
                        else:
                            new_sl = entry + (atr * adjusted_sl)
                            new_tp = max(entry * 0.01, entry - (atr * adjusted_tp))
                        
                        # Only fix if the values are suspiciously far (>50% from entry)
                        sl_dist_pct = abs(entry - old_sl) / entry * 100 if entry > 0 else 0
                        if sl_dist_pct > 50:  # SL is more than 50% away ‚Äî clearly wrong
                            pos['stopLoss'] = new_sl
                            pos['trailingStop'] = new_sl
                            pos['takeProfit'] = new_tp
                            
                            # Recalc trail activation/distance
                            trail_act_atr = global_paper_trader.trail_activation_atr * et * dyn_mult
                            trail_dist_atr = global_paper_trader.trail_distance_atr * et * dyn_mult
                            if side == 'LONG':
                                pos['trailActivation'] = entry + (atr * trail_act_atr)
                            else:
                                pos['trailActivation'] = entry - (atr * trail_act_atr)
                            pos['trailDistance'] = atr * trail_dist_atr
                            
                            # Reset trailing state since SL changed
                            pos['isTrailingActive'] = False
                            
                            fixed_count += 1
                            logger.warning(f"üîß Phase 218 RECALC: {pos.get('symbol')} {side} | SL: {old_sl:.6f} ‚Üí {new_sl:.6f} | TP: {old_tp:.6f} ‚Üí {new_tp:.6f}")
                    except Exception as e:
                        logger.error(f"Phase 218 recalc error for {pos.get('symbol', '?')}: {e}")
                
                if fixed_count > 0:
                    global_paper_trader.save_state()
                    logger.warning(f"üîß Phase 218: Fixed {fixed_count}/{len(global_paper_trader.positions)} positions with wrong SL/TP")
                else:
                    logger.info("‚úÖ Phase 218: All positions have correct SL/TP ‚Äî no fix needed")
            
            # Phase 189: Auto-reconnect if Binance connection lost or failed on startup
            if not live_binance_trader.enabled and live_binance_trader.trading_mode == 'live':
                now = datetime.now().timestamp()
                if now - last_reconnect_attempt > reconnect_interval:
                    last_reconnect_attempt = now
                    logger.warning(f"üîå RECONNECT: live_binance_trader.enabled=False, attempting reconnect...")
                    try:
                        success = await live_binance_trader.initialize()
                        if success:
                            logger.warning(f"‚úÖ RECONNECT SUCCESS: Binance live trading restored!")
                            # Clean ghost positions (no isLive flag) that accumulated while disconnected
                            ghost_count = len([p for p in global_paper_trader.positions if not p.get('isLive')])
                            if ghost_count > 0:
                                global_paper_trader.positions = [p for p in global_paper_trader.positions if p.get('isLive')]
                                logger.warning(f"üßπ CLEANUP: Removed {ghost_count} ghost positions (no isLive flag)")
                        else:
                            logger.error(f"‚ùå RECONNECT FAILED: {getattr(live_binance_trader, 'last_error', 'unknown')}")
                    except Exception as re:
                        logger.error(f"‚ùå RECONNECT ERROR: {re}")
                await asyncio.sleep(3)
                continue
            
            if live_binance_trader.enabled:
                # Bakiye g√ºncelle
                balance = await live_binance_trader.get_balance()
                
                # PaperTradingEngine bakiyesini Binance'den al
                global_paper_trader.balance = balance['total']
                # Phase 75: Store full balance details for scanner_update
                global_paper_trader.liveBalance = {
                    'walletBalance': balance.get('walletBalance', balance.get('total', 0)),
                    'marginBalance': balance.get('marginBalance', balance.get('total', 0)),
                    'availableBalance': balance.get('availableBalance', balance.get('free', 0)),
                    'unrealizedPnl': balance.get('unrealizedPnl', 0)
                }
                
                # ================================================================
                # Phase 142: Portfolio Recovery Trailing Check
                # ================================================================
                try:
                    total_upnl = balance.get('unrealizedPnl', 0)
                    
                    # Get BTC/ETH ATR for dynamic trailing distance
                    btc_atr_pct = _get_coin_atr_percent('BTCUSDT')
                    eth_atr_pct = _get_coin_atr_percent('ETHUSDT')
                    
                    # Update recovery manager ‚Äî use Binance Margin Balance
                    margin_bal = balance.get('marginBalance', balance.get('total', 100.0))
                    recovery_status = portfolio_recovery_manager.update(
                        total_unrealized_pnl=total_upnl,
                        btc_atr_pct=btc_atr_pct,
                        eth_atr_pct=eth_atr_pct,
                        wallet_balance=margin_bal
                    )
                    
                    # Check if we should close all positions
                    if portfolio_recovery_manager.should_close_all():
                        logger.warning(f"üî¥ RECOVERY CLOSE: Closing all {len(global_paper_trader.positions)} positions!")
                        positions_to_close = global_paper_trader.positions[:]  # Copy to avoid mutation
                        closed_count = 0
                        total_pnl = 0.0
                        
                        for pos in positions_to_close:
                            try:
                                current_price = pos.get('currentPrice', pos.get('markPrice', pos.get('entryPrice', 0)))
                                pnl_before = pos.get('unrealizedPnl', 0)
                                global_paper_trader.close_position(pos, current_price, "RECOVERY_CLOSE_ALL")
                                closed_count += 1
                                total_pnl += pnl_before
                            except Exception as pe:
                                logger.error(f"Error closing position {pos.get('symbol')}: {pe}")
                        
                        logger.warning(f"üî¥ RECOVERY COMPLETED: Closed {closed_count} positions, Total PnL: ${total_pnl:.2f}")
                        portfolio_recovery_manager.start_cooldown()
                        
                except Exception as re:
                    logger.error(f"Portfolio recovery check error: {re}")
                
                # Pozisyonlarƒ± g√ºncelle (Binance'den) - FAST MODE to reduce API calls
                # Phase 82: Use fast=True (1 API call instead of 21+)
                # Binance limits: 2400 weight/min - fast mode uses ~5 weight vs ~110 weight
                binance_positions = await live_binance_trader.get_positions(fast=True)
                logger.info(f"üìä Binance sync: {len(binance_positions)} positions from API")
                
                # Store for fallback access
                live_binance_trader.last_positions = binance_positions
                
                # ================================================================
                # PHASE 228: Fetch bookTicker for real bid-ask spread
                # Used by both position enrichment and sync trail params
                # ================================================================
                sync_book_cache = await multi_coin_scanner.fetch_book_tickers()
                
                # ================================================================
                # PHASE XXX: ENRICH POSITIONS WITH DYNAMIC SPREAD LEVEL
                # Phase 228: Use real bid-ask spread when available, ATR fallback
                for bp in binance_positions:
                    try:
                        symbol = bp.get('symbol', '')
                        # Try to get analyzer for this coin to calculate volatility
                        analyzer = multi_coin_scanner.analyzers.get(symbol) if hasattr(multi_coin_scanner, 'analyzers') else None
                        
                        # Phase 228: Use real bid-ask spread from REST bookTicker
                        book = sync_book_cache.get(symbol, {}) if sync_book_cache else {}
                        book_bid = book.get('bid', 0)
                        book_ask = book.get('ask', 0)
                        if book_bid > 0 and book_ask > 0 and book_ask > book_bid:
                            real_spread = ((book_ask - book_bid) / ((book_ask + book_bid) / 2)) * 100
                            # Classify bid-ask spread level
                            if real_spread < 0.02:
                                bp['spread_level'] = 'Very Low'
                            elif real_spread < 0.05:
                                bp['spread_level'] = 'Low'
                            elif real_spread < 0.15:
                                bp['spread_level'] = 'Normal'
                            elif real_spread < 0.40:
                                bp['spread_level'] = 'High'
                            elif real_spread < 0.80:
                                bp['spread_level'] = 'Very High'
                            elif real_spread < 1.50:
                                bp['spread_level'] = 'Extreme'
                            else:
                                bp['spread_level'] = 'Ultra'
                            bp['atr_pct'] = real_spread  # Store real spread as atr_pct for compatibility
                        elif analyzer and hasattr(analyzer, 'highs') and hasattr(analyzer, 'lows') and hasattr(analyzer, 'closes'):
                            # ATR fallback when no bookTicker data
                            highs = list(analyzer.highs)
                            lows = list(analyzer.lows)
                            closes = list(analyzer.closes)
                            if len(closes) >= 14:
                                atr_pct = calculate_atr_percentage(symbol, highs, lows, closes)
                                bp['spread_level'] = calculate_spread_level(atr_pct=atr_pct)
                                bp['atr_pct'] = atr_pct
                            else:
                                bp['spread_level'] = 'Normal'
                                bp['atr_pct'] = 2.0
                        else:
                            bp['spread_level'] = 'Normal'
                            bp['atr_pct'] = 2.0
                    except Exception as enrich_err:
                        bp['spread_level'] = 'Normal'
                        bp['atr_pct'] = 2.0
                
                # ================================================================
                # PHASE XXX: BREAKEVEN STOP & LOSS RECOVERY TRAIL
                # Check live Binance positions for breakeven and recovery conditions
                # ================================================================
                try:
                    if binance_positions and live_binance_trader.enabled:
                        # Check breakeven conditions
                        breakeven_actions = await breakeven_stop_manager.check_positions(binance_positions, live_binance_trader)
                        if breakeven_actions.get('breakeven_activated') or breakeven_actions.get('breakeven_closed'):
                            logger.info(f"üîí Breakeven: activated={breakeven_actions['breakeven_activated']}, closed={breakeven_actions['breakeven_closed']}")
                        
                        # Check loss recovery trail conditions
                        recovery_actions = await loss_recovery_trail_manager.check_positions(binance_positions, live_binance_trader)
                        if recovery_actions.get('recovery_trail_activated') or recovery_actions.get('recovery_closed'):
                            logger.info(f"üîÑ Recovery: trail_activated={recovery_actions['recovery_trail_activated']}, closed={recovery_actions['recovery_closed']}")
                except Exception as mgr_err:
                    logger.warning(f"Position manager error: {mgr_err}")
                
                # Phase 72: Sync ALL Binance positions into PaperTradingEngine
                # This ensures algorithm manages all positions (including manual)
                # ================================================================
                existing_symbols = {p.get('symbol') for p in global_paper_trader.positions if p.get('isLive')}
                
                for bp in binance_positions:
                    symbol = bp.get('symbol', '')
                    
                    # Check if position already exists in engine
                    if symbol not in existing_symbols:
                        # New position (manual or from previous session) - add with default params
                        entry_price = bp.get('entryPrice', 0)
                        mark_price = bp.get('markPrice', entry_price)
                        
                        # ================================================================
                        # Phase 151: Dynamic volatility calculation for synced positions
                        # ================================================================
                        # Get ticker data for volatility estimation
                        tickers = binance_ws_manager.get_tickers([symbol])
                        ticker = tickers.get(symbol) if tickers else None
                        
                        if ticker and entry_price > 0:
                            # Estimate ATR from 24h high/low range (rough approximation)
                            high_24h = float(ticker.get('high', entry_price * 1.02))
                            low_24h = float(ticker.get('low', entry_price * 0.98))
                            estimated_atr = (high_24h - low_24h) / 3  # ~3 ATR in 24h range
                            volatility_pct = (estimated_atr / entry_price) * 100 if entry_price > 0 else 2.0
                        else:
                            # Fallback to 2% estimate
                            estimated_atr = entry_price * 0.02 if entry_price > 0 else 0.02
                            volatility_pct = 2.0
                        
                        # Phase 228: Always use REST bookTicker for spread (independent of WS ticker)
                        book = sync_book_cache.get(symbol, {}) if sync_book_cache else {}
                        bid = book.get('bid', 0)
                        ask = book.get('ask', 0)
                        sync_spread_pct = ((ask - bid) / ((ask + bid) / 2) * 100) if bid > 0 and ask > 0 and ask > bid else 0.05
                        
                        atr = estimated_atr
                        
                        # Get dynamic trail parameters based on volatility
                        trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
                            volatility_pct=volatility_pct,
                            hurst=0.5,  # Default neutral
                            price=entry_price,
                            spread_pct=sync_spread_pct,  # Phase 178: Real spread
                            settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
                            settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
                        )
                        
                        logger.info(f"üìä Volatility calc: {symbol} ATR%={volatility_pct:.2f}% ‚Üí trail_act={trail_activation_atr}x, trail_dist={trail_distance_atr}x")
                        
                        # Calculate default exit parameters
                        # IMPORTANT: If position is already profitable, set TP beyond CURRENT price
                        # to avoid instant TP trigger on sync
                        # Phase 210: Minimum trail activation distance = 0.5 ATR
                        min_trail_distance = atr * 0.5
                        
                        if bp['side'] == 'LONG':
                            # For LONG: if mark > entry, position is profitable
                            if mark_price > entry_price:
                                # TP beyond current price, SL at breakeven or below entry
                                stop_loss = entry_price  # Breakeven
                                take_profit = mark_price + (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price + min_trail_distance  # Phase 210: Min 0.5 ATR from entry
                            else:
                                stop_loss = entry_price - (atr * global_paper_trader.sl_atr / 10)
                                take_profit = entry_price + (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price + (atr * trail_activation_atr)  # Phase 151: Dynamic
                        else:
                            # For SHORT: if mark < entry, position is profitable
                            if mark_price < entry_price:
                                # TP beyond current price, SL at breakeven or above entry
                                stop_loss = entry_price  # Breakeven
                                take_profit = mark_price - (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price - min_trail_distance  # Phase 210: Min 0.5 ATR from entry
                            else:
                                stop_loss = entry_price + (atr * global_paper_trader.sl_atr / 10)
                                take_profit = entry_price - (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price - (atr * trail_activation_atr)  # Phase 151: Dynamic
                        
                        new_pos = {
                            'id': bp.get('id', f"BIN_{symbol}_{int(datetime.now().timestamp())}"),
                            'symbol': symbol,
                            'side': bp.get('side', 'LONG'),
                            'size': bp.get('size', bp.get('contracts', 0)),  # Phase 149: Fallback to contracts
                            'sizeUsd': bp.get('sizeUsd', 0),
                            'entryPrice': entry_price,
                            'markPrice': bp.get('markPrice', entry_price),
                            'leverage': bp.get('leverage', 10),
                            'margin': bp.get('margin', 0),
                            'initialMargin': bp.get('margin', 0),
                            'openTime': bp.get('openTime', int(datetime.now().timestamp() * 1000)),
                            # Exit parameters
                            'stopLoss': stop_loss,
                            'takeProfit': take_profit,
                            'trailActivation': trail_activation,
                            'trailDistance': atr * trail_distance_atr,  # Phase 151: Dynamic trail distance
                            'trailingStop': stop_loss,
                            'isTrailingActive': False,  # Phase 213: Don't auto-activate ‚Äî wait for ROI >= 1.5%
                            'slConfirmCount': 0,
                            'atr': atr,
                            'volatilityPct': volatility_pct,  # Phase 151: Store for reference
                            'dynamicTrailActivation': trail_activation_atr,  # Phase 151: Store multiplier
                            'dynamicTrailDistance': trail_distance_atr,  # Phase 151: Store multiplier
                            'isLive': True,
                            'isSynced': True,  # Mark as synced from Binance
                            # Phase 214: Failed Continuation Detector
                            'fc_was_in_profit': False,
                            'fc_failed_count': 0,
                            'fc_max_profit_pct': 0.0,
                        }
                        
                        global_paper_trader.positions.append(new_pos)
                        logger.info(f"üì• SYNCED: {bp['side']} {symbol} @ ${entry_price:.4f} | Vol:{volatility_pct:.1f}% Trail:{trail_activation_atr}x/{trail_distance_atr}x")
                    else:
                        # Update existing position with current Binance data
                        # Phase 88: Also sync SIZE to prevent close amount mismatches
                        # Phase 141: Sync CONTRACTS alongside SIZE for consistency
                        # Phase 190: PROTECTED FIELDS ‚Äî these are NEVER overwritten by sync:
                        #   partial_tp_state, breakeven_activated, kill_switch_reduced,
                        #   isTrailingActive, trailingStop, stopLoss, takeProfit,
                        #   slConfirmCount, slBreachStartTime, highestProfit,
                        #   gradual_exit_mode, recovery_mode, recovery_sl,
                        #   time_reduced_4h, time_reduced_8h, _partial_close_ts
                        for pos in global_paper_trader.positions:
                            # Phase 155: Match by symbol only (ignore isLive for existing Binance positions)
                            if pos.get('symbol') == symbol:
                                # FORCE isLive=True for all Binance positions
                                pos['isLive'] = True
                                
                                # Phase 188: Cooldown after partial close ‚Äî don't overwrite size
                                # for 30 seconds to prevent duplicate reduction orders
                                partial_close_ts = pos.get('_partial_close_ts', 0)
                                cooldown_active = (datetime.now().timestamp() - partial_close_ts) < 30 if partial_close_ts > 0 else False
                                
                                # Sync critical values from Binance (source of truth)
                                position_size = bp.get('size', bp.get('contracts', pos.get('size')))
                                if not cooldown_active:
                                    pos['size'] = position_size      # Phase 88: Sync size!
                                    pos['contracts'] = position_size # Phase 141: Keep both in sync
                                    pos['sizeUsd'] = bp.get('sizeUsd', pos.get('sizeUsd'))
                                else:
                                    logger.info(f"‚è∏Ô∏è SYNC_COOLDOWN: {symbol} skipping size sync ({30 - (datetime.now().timestamp() - partial_close_ts):.0f}s remaining)")
                                pos['markPrice'] = bp.get('markPrice', pos.get('markPrice'))
                                pos['unrealizedPnl'] = bp.get('unrealizedPnl', 0)
                                pos['unrealizedPnlPercent'] = bp.get('unrealizedPnlPercent', 0)
                                
                                # DEBUG: Log what we're updating
                                logger.debug(f"üìä Sync update: {symbol} SL={pos.get('stopLoss', 'NONE')} TP={pos.get('takeProfit', 'NONE')} Trail={pos.get('isTrailingActive', 'NONE')}")
                                
                                mark_price = bp.get('markPrice', pos.get('markPrice', 0))
                                # Phase 204: Prefer currentPrice (close/last price) over markPrice
                                current_price_sync = pos.get('currentPrice', mark_price)
                                entry_price = pos.get('entryPrice', 0)
                                
                                # Phase 154: Initialize ALL exit params if missing
                                pos_atr = pos.get('atr', entry_price * 0.02) if entry_price > 0 else 0
                                
                                # Initialize ATR if missing
                                if not pos.get('atr') and entry_price > 0:
                                    pos['atr'] = entry_price * 0.02  # 2% default ATR
                                    pos_atr = pos['atr']
                                
                                # Initialize SL if missing or zero
                                if not pos.get('stopLoss') or pos.get('stopLoss', 0) == 0:
                                    sl_mult = global_paper_trader.sl_multiplier
                                    if pos['side'] == 'LONG':
                                        pos['stopLoss'] = max(entry_price * 0.01, entry_price - (pos_atr * sl_mult))
                                    else:
                                        pos['stopLoss'] = entry_price + (pos_atr * sl_mult)
                                    logger.info(f"üìä Exit fix: {symbol} stopLoss set to {pos['stopLoss']:.6f}")
                                
                                # Initialize TP if missing or zero
                                if not pos.get('takeProfit') or pos.get('takeProfit', 0) == 0:
                                    tp_mult = global_paper_trader.tp_multiplier
                                    if pos['side'] == 'LONG':
                                        pos['takeProfit'] = entry_price + (pos_atr * tp_mult)
                                    else:
                                        pos['takeProfit'] = max(entry_price * 0.01, entry_price - (pos_atr * tp_mult))
                                    logger.info(f"üìä Exit fix: {symbol} takeProfit set to {pos['takeProfit']:.6f}")
                                
                                # Phase 192: Fix existing negative SL/TP
                                if pos.get('stopLoss', 0) < 0:
                                    pos['stopLoss'] = entry_price * 0.01
                                    pos['trailingStop'] = pos['stopLoss']
                                    logger.warning(f"üîß Phase 192: Fixed negative SL for {symbol}")
                                if pos.get('takeProfit', 0) < 0:
                                    pos['takeProfit'] = entry_price * 0.01
                                    logger.warning(f"üîß Phase 192: Fixed negative TP for {symbol}")
                                
                                # Initialize trailActivation if missing
                                if not pos.get('trailActivation') or pos.get('trailActivation', 0) == 0:
                                    trail_act_mult = global_paper_trader.trail_activation_atr
                                    if pos['side'] == 'LONG':
                                        pos['trailActivation'] = entry_price + (pos_atr * trail_act_mult)
                                    else:
                                        pos['trailActivation'] = entry_price - (pos_atr * trail_act_mult)
                                    logger.info(f"üìä Exit fix: {symbol} trailActivation set to {pos['trailActivation']:.6f}")
                                
                                # Initialize trailDistance if missing
                                if not pos.get('trailDistance'):
                                    pos['trailDistance'] = pos_atr * global_paper_trader.trail_distance_atr
                                    logger.info(f"üìä Exit fix: {symbol} trailDistance set to {pos['trailDistance']:.6f}")
                                
                                # Initialize trailingStop if missing (use SL as initial value)
                                if not pos.get('trailingStop'):
                                    pos['trailingStop'] = pos.get('stopLoss', 0)
                                
                                # Phase 213: Trail activation requires minimum ROI of 1.5%
                                # (replaces Phase 154/210 forced activation)
                                if current_price_sync > 0 and entry_price > 0:
                                    sync_leverage = pos.get('leverage', 10)
                                    
                                    if pos['side'] == 'LONG':
                                        sync_price_move = ((current_price_sync - entry_price) / entry_price) * 100
                                    else:
                                        sync_price_move = ((entry_price - current_price_sync) / entry_price) * 100
                                    sync_roi = sync_price_move * sync_leverage
                                    
                                    # Phase 231h: Only price_move check + breakeven on activation
                                    if (sync_price_move >= 0.75 or sync_roi >= 5.0) and not pos.get('isTrailingActive', False):
                                        pos['isTrailingActive'] = True
                                        # Breakeven on BOTH stopLoss AND trailingStop
                                        if pos['side'] == 'LONG':
                                            be_price = entry_price * 1.001
                                            pos['stopLoss'] = max(pos.get('stopLoss', 0), be_price)
                                            pos['trailingStop'] = max(pos.get('trailingStop', 0), be_price)
                                        else:
                                            be_price = entry_price * 0.999
                                            pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_price)
                                            pos['trailingStop'] = min(pos.get('trailingStop', float('inf')), be_price)
                                        logger.info(f"üìä TRAIL+BE(sync): {symbol} {pos['side']} price_move={sync_price_move:.2f}%, SL+Trail‚Üíbreakeven")
                                break
                
                # ================================================================
                # Phase 100: Record externally closed positions to trade history
                # Without this, manual closes on Binance don't appear in UI history
                # ================================================================
                binance_symbols = {p.get('symbol') for p in binance_positions}
                closed_positions = []
                remaining_positions = []
                
                for p in global_paper_trader.positions:
                    if p.get('isLive') and p.get('symbol') not in binance_symbols:
                        # This position was closed externally on Binance
                        closed_positions.append(p)
                    else:
                        remaining_positions.append(p)
                
                # Record closed positions to trade history
                for pos in closed_positions:
                    symbol = pos.get('symbol', 'UNKNOWN')
                    engine_triggered = False  # Track if engine set the reason
                    
                    # Phase 138: Check if engine set a pending reason
                    if symbol in pending_close_reasons:
                        # Use engine's reason and trade data
                        reason_data = pending_close_reasons.pop(symbol)
                        trade = reason_data.get('trade_data', {})
                        # Update with actual Binance close data if available
                        trade['closeTime'] = int(datetime.now().timestamp() * 1000)
                        trade['reason'] = reason_data.get('reason', 'External Close (Binance)')
                        trade['closeReason'] = trade['reason']  # Phase 232c: dual field
                        engine_triggered = True
                        logger.info(f"üìã REASON MATCHED: {symbol} = {reason_data.get('reason')}")
                    else:
                        # No pending reason ‚Äî infer from position data
                        exit_price = pos.get('markPrice', pos.get('entryPrice', 0))
                        pnl = pos.get('unrealizedPnl', 0)
                        pnl_percent = pos.get('unrealizedPnlPercent', 0)
                        entry_price = pos.get('entryPrice', 0)
                        side = pos.get('side', 'LONG')
                        tp = pos.get('takeProfit', 0)
                        sl = pos.get('stopLoss', 0)
                        is_trailing = pos.get('isTrailingActive', False)
                        leverage_val = pos.get('leverage', 10)
                        margin_val = pos.get('initialMargin', 0) or (pos.get('sizeUsd', 0) / max(leverage_val, 1))
                        roi_val = (pnl / margin_val * 100) if margin_val > 0 else 0
                        
                        # Phase 203 + Phase 210: Smart reason inference from position state
                        inferred_reason = 'External Close (Binance)'
                        
                        # Step 1: Try TP/SL price match
                        if tp > 0 and entry_price > 0:
                            if side == 'LONG' and exit_price >= tp * 0.998:
                                inferred_reason = f"üü¢ TP: Take Profit Tetiklendi ({roi_val:+.1f}%)"
                            elif side == 'SHORT' and exit_price <= tp * 1.002:
                                inferred_reason = f"üü¢ TP: Take Profit Tetiklendi ({roi_val:+.1f}%)"
                        
                        # Step 2: Try trailing stop inference
                        if inferred_reason.startswith('External'):
                            if is_trailing and pnl >= 0:
                                inferred_reason = f"üìà TRAIL: Trailing Stop Tetiklendi ({roi_val:+.1f}%)"
                            elif is_trailing and pnl < 0:
                                inferred_reason = f"üî¥ SL: Trailing Stop Tetiklendi ({roi_val:+.1f}%)"
                            elif sl > 0:
                                if side == 'LONG' and exit_price <= sl * 1.002:
                                    inferred_reason = f"üî¥ SL: Stop Loss Tetiklendi ({roi_val:+.1f}%)"
                                elif side == 'SHORT' and exit_price >= sl * 0.998:
                                    inferred_reason = f"üî¥ SL: Stop Loss Tetiklendi ({roi_val:+.1f}%)"
                        
                        # Step 3: Phase 210 ‚Äî PnL-based fallback inference
                        if inferred_reason.startswith('External'):
                            if roi_val >= 10:
                                inferred_reason = f"üü¢ TP_INFERRED: Karlƒ± √áƒ±kƒ±≈ü ({roi_val:+.1f}%)"
                            elif roi_val <= -5:
                                inferred_reason = f"üî¥ SL_INFERRED: Zararlƒ± √áƒ±kƒ±≈ü ({roi_val:+.1f}%)"
                            elif abs(roi_val) <= 2:
                                inferred_reason = f"üìä BREAKEVEN_INFERRED: Ba≈üaba≈ü ({roi_val:+.1f}%)"
                            else:
                                inferred_reason = f"üìã CLOSE_INFERRED: Pozisyon Kapandƒ± ({roi_val:+.1f}%)"
                        
                        if 'INFERRED' in inferred_reason:
                            logger.info(f"üîç REASON INFERRED (Phase 210): {symbol} = {inferred_reason}")
                        elif inferred_reason != 'External Close (Binance)':
                            logger.info(f"üîç REASON INFERRED: {symbol} = {inferred_reason}")
                        else:
                            logger.info(f"üîó EXTERNAL CLOSE: {symbol} ‚Äî no engine reason, no inference match")
                        
                        trade = {
                            "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                            "symbol": symbol,
                            "side": side,
                            "entryPrice": entry_price,
                            "exitPrice": exit_price,
                            "size": pos.get('size', 0),
                            "sizeUsd": pos.get('sizeUsd', 0),
                            "pnl": pnl,
                            "pnlPercent": pnl_percent,
                            "margin": margin_val,
                            "roi": roi_val,
                            "openTime": pos.get('openTime', 0),
                            "closeTime": int(datetime.now().timestamp() * 1000),
                            "reason": inferred_reason,
                            "closeReason": inferred_reason,
                            "leverage": leverage_val,
                            "isLive": True,
                            "signalScore": pos.get('signalScore', 0),
                            "mtfScore": pos.get('mtfScore', 0),
                            "zScore": pos.get('zScore', 0),
                            "spreadLevel": pos.get('spreadLevel', 'unknown'),
                            "stopLoss": sl,
                            "takeProfit": tp,
                            "trailActivation": pos.get('trailActivation', 0),
                            "trailingStop": pos.get('trailingStop', 0),
                            "isTrailingActive": is_trailing,
                            "atr": pos.get('atr', 0),
                        }
                    
                    global_paper_trader.trades.append(trade)
                    
                    # Save to SQLite
                    try:
                        safe_create_task(sqlite_manager.save_trade(trade))
                    except Exception as e:
                        logger.debug(f"SQLite save error: {e}")
                    
                    # Update stats only for external closes (engine already updated stats)
                    if not engine_triggered:
                        global_paper_trader.stats['totalTrades'] += 1
                        global_paper_trader.stats['totalPnl'] += trade.get('pnl', 0)
                        if trade.get('pnl', 0) > 0:
                            global_paper_trader.stats['winningTrades'] += 1
                        else:
                            global_paper_trader.stats['losingTrades'] += 1
                    
                    logger.info(f"üì• CLOSE RECORDED: {pos.get('side')} {symbol} | PnL: ${trade.get('pnl', 0):.2f} | Reason: {trade.get('reason')}")
                
                global_paper_trader.positions = remaining_positions
                
                if closed_positions:
                    global_paper_trader.save_state()
                    logger.info(f"‚úÖ Recorded {len(closed_positions)} externally closed positions to trade history")
                
                # Sync timestamp
                live_binance_trader.last_sync_time = int(datetime.now().timestamp() * 1000)
                
                # Phase 83: Position count verification
                engine_live_count = len([p for p in global_paper_trader.positions if p.get('isLive')])
                if len(binance_positions) != engine_live_count:
                    logger.warning(f"‚ö†Ô∏è Position mismatch: Binance={len(binance_positions)}, Engine={engine_live_count}")
                
                # UI'a broadcast et
                await ui_ws_manager.broadcast('binance_sync', {
                    'balance': balance,
                    'positions': binance_positions,
                    'position_count': len(binance_positions),
                    'sync_time': live_binance_trader.last_sync_time,
                    'trading_mode': 'live'
                })
                
                # Phase 84: Refresh PnL cache every sync cycle for consistent UI display
                try:
                    pnl_data = await live_binance_trader.get_pnl_from_binance()
                    live_binance_trader.cached_pnl = pnl_data
                    logger.info(f"‚úÖ Sync: ${balance['total']:.2f} | {len(binance_positions)} pos | PnL today=${pnl_data.get('todayPnl', 0):.2f}")
                except Exception as pe:
                    logger.warning(f"PnL cache refresh failed: {pe}")
                
                # Phase 191: Update position symbols for WS callback
                binance_ws_manager.position_symbols = set(
                    p.get('symbol') for p in global_paper_trader.positions if p.get('symbol')
                )
                if binance_ws_manager.on_price_update is None:
                    binance_ws_manager.on_price_update = on_position_price_update
                    logger.info(f"‚ö° Phase 191: WebSocket callback registered for {len(binance_ws_manager.position_symbols)} symbols")
                
                # ================================================================
                # Phase 148: Periodic trade history sync from Binance
                # Runs every 5 minutes (100 loops √ó 3s = 300s = 5 min)
                # ================================================================
                if not hasattr(live_binance_trader, '_trade_sync_counter'):
                    live_binance_trader._trade_sync_counter = 0
                
                live_binance_trader._trade_sync_counter += 1
                
                if live_binance_trader._trade_sync_counter >= 100:  # Every 5 minutes
                    live_binance_trader._trade_sync_counter = 0
                    try:
                        synced = await live_binance_trader.sync_closed_trades_from_binance(hours_back=24)
                        if synced > 0:
                            logger.info(f"üì• Trade history sync: {synced} new trades added")
                    except Exception as tse:
                        logger.warning(f"Trade history sync failed: {tse}")
                
        except Exception as e:
            import traceback
            logger.error(f"Binance sync error: {e}\n{traceback.format_exc()}")
        
        # Phase 86: Reduced interval to 3s (was 10s) - utilizing ~60% of API capacity
        # Weight calculation: 20 calls/min √ó 40 weight = 800 weight/min (of 2400 limit)
        await asyncio.sleep(3)

app = FastAPI(title="HHQ-1 Quant Backend", version="2.0.0", lifespan=lifespan)

# CORS for React Frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# ATR CALCULATION (Average True Range)
# ============================================================================

def calculate_atr(highs: list, lows: list, closes: list, period: int = 14) -> float:
    """
    Calculate Average True Range for volatility-based stop loss/take profit.
    
    ATR = Average of True Range over N periods
    True Range = max(High-Low, |High-PrevClose|, |Low-PrevClose|)
    
    Args:
        highs: List of high prices
        lows: List of low prices
        closes: List of close prices
        period: ATR period (default 14)
        
    Returns:
        ATR value
    """
    if len(closes) < period + 1:
        # Not enough data, estimate from price volatility
        if closes:
            return np.std(closes[-20:]) * 2 if len(closes) >= 20 else closes[-1] * 0.02
        return 0.0
    
    try:
        highs = np.array(highs)
        lows = np.array(lows)
        closes = np.array(closes)
        
        # True Range calculation
        tr1 = highs[1:] - lows[1:]  # High - Low
        tr2 = np.abs(highs[1:] - closes[:-1])  # |High - Prev Close|
        tr3 = np.abs(lows[1:] - closes[:-1])  # |Low - Prev Close|
        
        true_range = np.maximum(np.maximum(tr1, tr2), tr3)
        
        # ATR is the moving average of True Range
        if len(true_range) >= period:
            atr = np.mean(true_range[-period:])
            return float(atr)
        return float(np.mean(true_range))
        
    except Exception as e:
        logger.warning(f"ATR calculation error: {e}")
        return 0.0


# ============================================================================
# PHASE 193: ENHANCED TECHNICAL INDICATORS (pandas-ta powered)
# ============================================================================

def calculate_enhanced_indicators(highs: list, lows: list, closes: list, volumes: list = None) -> dict:
    """
    Calculate a comprehensive set of technical indicators using pandas-ta.
    Falls back to manual calculations if pandas-ta is not available.
    
    Returns dict with:
        macd_histogram: MACD histogram value (positive=bullish momentum)
        macd_signal_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        bb_position: Price position within Bollinger Bands (-1 to +1, >1 = above upper)
        bb_width: Band width as % of price (volatility measure)
        stoch_rsi_k: Stochastic RSI %K (0-100, <20=oversold, >80=overbought)
        stoch_rsi_d: Stochastic RSI %D (smoothed)
        stoch_rsi_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        atr_pta: ATR calculated by pandas-ta (more accurate EMA smoothing)
        ema_8: 8-period EMA
        ema_21: 21-period EMA
        ema_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        vwap_value: VWAP if volumes available
    """
    result = {
        'macd_histogram': 0.0,
        'macd_signal_cross': 'NEUTRAL',
        'bb_position': 0.0,
        'bb_width': 0.0,
        'stoch_rsi_k': 50.0,
        'stoch_rsi_d': 50.0,
        'stoch_rsi_cross': 'NEUTRAL',
        'atr_pta': 0.0,
        'ema_8': 0.0,
        'ema_21': 0.0,
        'ema_cross': 'NEUTRAL',
        'vwap_value': 0.0,
    }
    
    if len(closes) < 30:
        return result
    
    try:
        if PANDAS_TA_AVAILABLE:
            df = pd.DataFrame({
                'high': highs,
                'low': lows,
                'close': closes,
            })
            if volumes:
                df['volume'] = volumes
            
            # MACD (12, 26, 9)
            macd = df.ta.macd(fast=12, slow=26, signal=9)
            if macd is not None and not macd.empty:
                hist_col = [c for c in macd.columns if 'MACDh' in c or 'Histogram' in c.title()]
                signal_col = [c for c in macd.columns if 'MACDs' in c]
                macd_col = [c for c in macd.columns if c.startswith('MACD_')]
                
                if hist_col:
                    result['macd_histogram'] = float(macd[hist_col[0]].iloc[-1] or 0)
                
                # MACD crossover detection
                if macd_col and signal_col:
                    macd_line = macd[macd_col[0]].iloc[-2:]
                    signal_line = macd[signal_col[0]].iloc[-2:]
                    if len(macd_line) >= 2 and len(signal_line) >= 2:
                        prev_diff = float(macd_line.iloc[0] or 0) - float(signal_line.iloc[0] or 0)
                        curr_diff = float(macd_line.iloc[1] or 0) - float(signal_line.iloc[1] or 0)
                        if prev_diff <= 0 and curr_diff > 0:
                            result['macd_signal_cross'] = 'BULLISH'
                        elif prev_diff >= 0 and curr_diff < 0:
                            result['macd_signal_cross'] = 'BEARISH'
            
            # Bollinger Bands (20, 2)
            bbands = df.ta.bbands(length=20, std=2)
            if bbands is not None and not bbands.empty:
                upper_col = [c for c in bbands.columns if 'BBU' in c]
                lower_col = [c for c in bbands.columns if 'BBL' in c]
                mid_col = [c for c in bbands.columns if 'BBM' in c]
                bw_col = [c for c in bbands.columns if 'BBB' in c]
                
                if upper_col and lower_col:
                    upper = float(bbands[upper_col[0]].iloc[-1] or 0)
                    lower = float(bbands[lower_col[0]].iloc[-1] or 0)
                    price = closes[-1]
                    band_range = upper - lower
                    if band_range > 0:
                        # -1 = at lower band, 0 = middle, +1 = at upper band
                        result['bb_position'] = ((price - lower) / band_range) * 2 - 1
                    if mid_col:
                        mid = float(bbands[mid_col[0]].iloc[-1] or 0)
                        if mid > 0:
                            result['bb_width'] = (band_range / mid) * 100
            
            # Stochastic RSI (14, 14, 3, 3)
            stochrsi = df.ta.stochrsi(length=14, rsi_length=14, k=3, d=3)
            if stochrsi is not None and not stochrsi.empty:
                k_col = [c for c in stochrsi.columns if 'STOCHRSIk' in c]
                d_col = [c for c in stochrsi.columns if 'STOCHRSId' in c]
                
                if k_col:
                    result['stoch_rsi_k'] = float(stochrsi[k_col[0]].iloc[-1] or 50)
                if d_col:
                    result['stoch_rsi_d'] = float(stochrsi[d_col[0]].iloc[-1] or 50)
                
                # StochRSI crossover
                if k_col and d_col and len(stochrsi) >= 2:
                    prev_k = float(stochrsi[k_col[0]].iloc[-2] or 50)
                    curr_k = result['stoch_rsi_k']
                    prev_d = float(stochrsi[d_col[0]].iloc[-2] or 50)
                    curr_d = result['stoch_rsi_d']
                    if prev_k <= prev_d and curr_k > curr_d and curr_k < 30:
                        result['stoch_rsi_cross'] = 'BULLISH'
                    elif prev_k >= prev_d and curr_k < curr_d and curr_k > 70:
                        result['stoch_rsi_cross'] = 'BEARISH'
            
            # ATR (14) ‚Äî Wilder's smoothing (more accurate than SMA)
            atr_result = df.ta.atr(length=14)
            if atr_result is not None and not atr_result.empty:
                result['atr_pta'] = float(atr_result.iloc[-1] or 0)
            
            # EMA 8 & 21 crossover
            ema8 = df.ta.ema(length=8)
            ema21 = df.ta.ema(length=21)
            if ema8 is not None and ema21 is not None and not ema8.empty and not ema21.empty:
                result['ema_8'] = float(ema8.iloc[-1] or 0)
                result['ema_21'] = float(ema21.iloc[-1] or 0)
                if result['ema_8'] > result['ema_21']:
                    result['ema_cross'] = 'BULLISH'
                elif result['ema_8'] < result['ema_21']:
                    result['ema_cross'] = 'BEARISH'
            
            # VWAP (if volumes available)
            if volumes and len(volumes) == len(closes):
                try:
                    vwap = df.ta.vwap()
                    if vwap is not None and not vwap.empty:
                        result['vwap_value'] = float(vwap.iloc[-1] or 0)
                except Exception:
                    pass
        
        else:
            # Manual fallback calculations (basic versions)
            closes_arr = np.array(closes)
            
            # Simple MACD manual
            if len(closes_arr) >= 26:
                ema12 = pd.Series(closes_arr).ewm(span=12).mean().iloc[-1]
                ema26 = pd.Series(closes_arr).ewm(span=26).mean().iloc[-1]
                result['macd_histogram'] = float(ema12 - ema26)
            
            # Simple Bollinger Bands manual
            if len(closes_arr) >= 20:
                sma20 = np.mean(closes_arr[-20:])
                std20 = np.std(closes_arr[-20:])
                upper = sma20 + 2 * std20
                lower = sma20 - 2 * std20
                band_range = upper - lower
                if band_range > 0:
                    result['bb_position'] = ((closes_arr[-1] - lower) / band_range) * 2 - 1
                    result['bb_width'] = (band_range / sma20) * 100 if sma20 > 0 else 0
            
            # Simple EMA crossover manual
            if len(closes_arr) >= 21:
                ema8 = pd.Series(closes_arr).ewm(span=8).mean().iloc[-1]
                ema21 = pd.Series(closes_arr).ewm(span=21).mean().iloc[-1]
                result['ema_8'] = float(ema8)
                result['ema_21'] = float(ema21)
                result['ema_cross'] = 'BULLISH' if ema8 > ema21 else 'BEARISH'
        
    except Exception as e:
        logger.warning(f"Enhanced indicator calculation error: {e}")
    
    return result


# ============================================================================
# HURST EXPONENT CALCULATION (R/S Analysis)
# ============================================================================

def calculate_hurst(prices: list, min_window: int = 10) -> float:
    """
    Calculate Hurst Exponent using autocorrelation-based method.
    
    Phase 128: Replaced R/S with returns autocorrelation for more natural variation.
    
    H > 0.55 ‚Üí Trending market (positive autocorrelation)
    H < 0.45 ‚Üí Mean-reverting market (negative autocorrelation)
    H ‚âà 0.50 ‚Üí Random walk (no autocorrelation)
    """
    n = len(prices)
    
    if n < 20:  # Need at least 20 prices for meaningful calculation
        return 0.5
    
    try:
        ts = np.array(prices)
        
        # Calculate log returns
        returns = np.diff(np.log(ts))
        
        if len(returns) < 15:
            return 0.5
        
        # Method 1: Autocorrelation-based Hurst estimate
        # Positive autocorrelation ‚Üí H > 0.5 (trending)
        # Negative autocorrelation ‚Üí H < 0.5 (mean-reverting)
        
        # Calculate lag-1 autocorrelation
        mean_ret = np.mean(returns)
        var_ret = np.var(returns)
        
        if var_ret == 0:
            return 0.5
        
        # Compute autocorrelation for multiple lags
        autocorr_sum = 0.0
        valid_lags = 0
        
        for lag in [1, 2, 3, 5, 8]:  # Fibonacci-like lags for multi-scale
            if lag >= len(returns):
                break
            numerator = np.sum((returns[lag:] - mean_ret) * (returns[:-lag] - mean_ret))
            denominator = len(returns[lag:]) * var_ret
            if denominator > 0:
                autocorr = numerator / denominator
                autocorr_sum += autocorr
                valid_lags += 1
        
        if valid_lags == 0:
            return 0.5
        
        avg_autocorr = autocorr_sum / valid_lags
        
        # Map autocorrelation (-1 to +1) to Hurst (0.1 to 0.9)
        # autocorr = +0.5 ‚Üí H = 0.75 (strong trending)
        # autocorr = 0.0  ‚Üí H = 0.50 (random walk)
        # autocorr = -0.5 ‚Üí H = 0.25 (strong mean reversion)
        hurst = 0.5 + (avg_autocorr * 0.5)
        
        # Add variance-based adjustment for more differentiation
        # High variance coins get slight trending bias, low variance slight MR bias
        returns_std = np.std(returns)
        median_std = 0.02  # Typical crypto daily return std
        
        if returns_std > median_std * 2:
            hurst += 0.05  # Volatile = slight trending bias
        elif returns_std < median_std * 0.5:
            hurst -= 0.05  # Calm = slight MR bias
        
        # Clamp to reasonable bounds
        hurst = max(0.15, min(0.85, hurst))
        
        return round(hurst, 3)  # 3 decimal places for variation
        
    except Exception as e:
        logger.warning(f"Hurst calculation error: {e}")
        return 0.5


# ============================================================================
# ADX (Average Directional Index) CALCULATION - Phase 137
# ============================================================================

def calculate_adx(highs: list, lows: list, closes: list, period: int = 14) -> tuple:
    """
    Calculate Average Directional Index (ADX) for trend strength and direction.
    
    Phase 137: ADX + Hurst kombinasyonu ile regime detection.
    Phase XXX: Extended to return trend direction for signal filtering.
    
    ADX > 25 ‚Üí G√º√ßl√º trend (mean reversion riskli)
    ADX < 20 ‚Üí Zayƒ±f trend / Range (mean reversion i√ßin ideal)
    ADX 20-25 ‚Üí Ge√ßi≈ü b√∂lgesi
    
    Returns:
        tuple: (adx, trend_direction, plus_di, minus_di)
        - adx: Trend strength (5-80)
        - trend_direction: "BULLISH" if +DI > -DI, "BEARISH" if -DI > +DI, else "NEUTRAL"
        - plus_di: Positive Directional Indicator
        - minus_di: Negative Directional Indicator
    """
    n = len(highs)
    
    if n < period + 1:
        return 25.0, "NEUTRAL", 0.0, 0.0  # Neutral default
    
    try:
        highs_arr = np.array(highs)
        lows_arr = np.array(lows)
        closes_arr = np.array(closes)
        
        # +DM, -DM ve True Range hesapla
        plus_dm = []
        minus_dm = []
        tr = []
        
        for i in range(1, n):
            high_diff = highs_arr[i] - highs_arr[i-1]
            low_diff = lows_arr[i-1] - lows_arr[i]
            
            # +DM: Yukarƒ± hareket daha b√ºy√ºkse ve pozitifse
            if high_diff > low_diff and high_diff > 0:
                plus_dm.append(high_diff)
            else:
                plus_dm.append(0)
            
            # -DM: A≈üaƒüƒ± hareket daha b√ºy√ºkse ve pozitifse
            if low_diff > high_diff and low_diff > 0:
                minus_dm.append(low_diff)
            else:
                minus_dm.append(0)
            
            # True Range
            tr_val = max(
                highs_arr[i] - lows_arr[i],
                abs(highs_arr[i] - closes_arr[i-1]),
                abs(lows_arr[i] - closes_arr[i-1])
            )
            tr.append(tr_val)
        
        if len(tr) < period:
            return 25.0, "NEUTRAL", 0.0, 0.0
        
        # Smoothed averages (Wilder's smoothing - period average)
        atr = sum(tr[-period:]) / period
        
        if atr == 0:
            return 25.0, "NEUTRAL", 0.0, 0.0
        
        plus_di = 100 * sum(plus_dm[-period:]) / (atr * period)
        minus_di = 100 * sum(minus_dm[-period:]) / (atr * period)
        
        # DX hesapla
        di_sum = plus_di + minus_di
        if di_sum == 0:
            return 25.0, "NEUTRAL", plus_di, minus_di
        
        dx = abs(plus_di - minus_di) / di_sum * 100
        
        # Clamp to reasonable bounds
        adx = max(5.0, min(80.0, dx))
        
        # Determine trend direction based on +DI vs -DI
        di_diff = plus_di - minus_di
        if di_diff > 5:  # Significant bullish directional movement
            trend_direction = "BULLISH"
        elif di_diff < -5:  # Significant bearish directional movement
            trend_direction = "BEARISH"
        else:
            trend_direction = "NEUTRAL"
        
        return round(adx, 1), trend_direction, round(plus_di, 1), round(minus_di, 1)
        
    except Exception as e:
        logger.warning(f"ADX calculation error: {e}")
        return 25.0, "NEUTRAL", 0.0, 0.0


# ============================================================================
# DYNAMIC SPREAD LEVEL CALCULATION - Based on ATR/Volatility
# ============================================================================

def calculate_spread_level(atr_pct: float = None, highs: list = None, lows: list = None, closes: list = None) -> str:
    """
    Calculate spread level based on price volatility (ATR as % of price).
    
    Args:
        atr_pct: Pre-calculated ATR as percentage of price (optional)
        highs, lows, closes: Raw price data to calculate volatility (optional)
        
    Returns:
        Spread level: 'Very Low', 'Low', 'Normal', 'High', 'Very High', 'Extreme', 'Ultra'
        
    Thresholds (based on typical crypto volatility):
    - Very Low: ATR < 1% (BTC, ETH)
    - Low: ATR 1-2%
    - Normal: ATR 2-4%
    - High: ATR 4-7%  
    - Very High: ATR 7-12% (meme coins)
    - Extreme: ATR 12-20% (hyper-volatile)
    - Ultra: ATR > 20% (extreme edge cases)
    """
    
    # Calculate volatility from candle data if not provided
    if atr_pct is None and highs and lows and closes:
        try:
            n = min(len(highs), len(lows), len(closes))
            if n >= 14:
                # Calculate ATR from last 14 candles
                tr_values = []
                for i in range(1, min(15, n)):
                    tr = max(
                        highs[-i] - lows[-i],
                        abs(highs[-i] - closes[-i-1]) if i < n-1 else highs[-i] - lows[-i],
                        abs(lows[-i] - closes[-i-1]) if i < n-1 else highs[-i] - lows[-i]
                    )
                    tr_values.append(tr)
                
                if tr_values:
                    atr = sum(tr_values) / len(tr_values)
                    price = closes[-1] if closes else 1
                    atr_pct = (atr / price * 100) if price > 0 else 2.0
        except Exception:
            pass
    
    # Default to Normal if calculation failed
    if atr_pct is None:
        return 'Normal'
    
    # Map ATR percentage to spread level
    if atr_pct < 1.0:
        return 'Very Low'   # BTC, ETH - stable majors
    elif atr_pct < 2.0:
        return 'Low'        # Large caps
    elif atr_pct < 4.0:
        return 'Normal'     # Mid caps
    elif atr_pct < 7.0:
        return 'High'       # Small caps, volatile
    elif atr_pct < 12.0:
        return 'Very High'  # Meme coins, very volatile
    elif atr_pct < 20.0:
        return 'Extreme'    # Hyper-volatile, new launches
    else:
        return 'Ultra'      # Extreme edge cases


def calculate_atr_percentage(symbol: str, highs: list, lows: list, closes: list, period: int = 14) -> float:
    """
    Calculate ATR as percentage of current price.
    Used for dynamic spread level and position management.
    
    Returns: ATR percentage (e.g., 2.5 means 2.5% volatility)
    """
    if len(closes) < period + 1:
        return 2.0  # Default to 2% if not enough data
    
    try:
        tr_values = []
        for i in range(1, min(period + 1, len(closes))):
            tr = max(
                highs[-i] - lows[-i],
                abs(highs[-i] - closes[-i-1]),
                abs(lows[-i] - closes[-i-1])
            )
            tr_values.append(tr)
        
        if not tr_values:
            return 2.0
            
        atr = sum(tr_values) / len(tr_values)
        current_price = closes[-1]
        
        if current_price <= 0:
            return 2.0
            
        return (atr / current_price) * 100
        
    except Exception as e:
        logger.warning(f"ATR percentage calculation error for {symbol}: {e}")
        return 2.0


# ============================================================================
# Z-SCORE CALCULATION
# ============================================================================

def calculate_zscore(spread_series: list, lookback: int = 20) -> float:
    """
    Calculate Z-Score for pairs trading / mean reversion.
    |Z| > 2.0 ‚Üí Trading opportunity
    """
    if len(spread_series) < lookback:
        return 0.0
    
    try:
        series = np.array(spread_series[-lookback:])
        mean = np.mean(series)
        std = np.std(series, ddof=1)
        
        if std > 0:
            current = series[-1]
            return (current - mean) / std
        return 0.0
        
    except Exception as e:
        logger.warning(f"Z-Score calculation error: {e}")
        return 0.0


# ============================================================================
# RSI CALCULATION (Relative Strength Index)
# ============================================================================

def calculate_rsi(closes: list, period: int = 14) -> float:
    """
    Calculate RSI (Relative Strength Index).
    
    RSI < 30 ‚Üí Oversold (LONG opportunity)
    RSI > 70 ‚Üí Overbought (SHORT opportunity)
    RSI 30-70 ‚Üí Neutral
    
    Returns: RSI value (0-100)
    """
    if len(closes) < period + 1:
        return 50.0  # Neutral
    
    try:
        prices = np.array(closes[-(period + 1):])
        deltas = np.diff(prices)
        
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        
        avg_gain = np.mean(gains)
        avg_loss = np.mean(losses)
        
        if avg_loss == 0:
            return 100.0 if avg_gain > 0 else 50.0
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
        
    except Exception as e:
        logger.warning(f"RSI calculation error: {e}")
        return 50.0


# ============================================================================
# CONSECUTIVE BAR CONFIRMATION
# ============================================================================

def check_consecutive_bars(closes: list, signal_side: str, required_bars: int = 2) -> tuple:
    """
    Check if the last N bars confirm the signal direction.
    
    For LONG signals: we want bars to be falling (creating oversold conditions)
    For SHORT signals: we want bars to be rising (creating overbought conditions)
    
    Args:
        closes: List of close prices
        signal_side: "LONG" or "SHORT"
        required_bars: Number of consecutive bars required (default 2)
        
    Returns:
        (confirmed: bool, consecutive_count: int, direction: str)
    """
    if len(closes) < required_bars + 1:
        return True, 0, "INSUFFICIENT_DATA"  # Not enough data, allow signal
    
    try:
        recent_closes = list(closes[-(required_bars + 1):])
        
        # Calculate bar directions
        bullish_count = 0
        bearish_count = 0
        
        for i in range(1, len(recent_closes)):
            if recent_closes[i] > recent_closes[i-1]:
                bullish_count += 1
            elif recent_closes[i] < recent_closes[i-1]:
                bearish_count += 1
        
        # Determine direction
        if bearish_count >= required_bars:
            direction = "BEARISH"
        elif bullish_count >= required_bars:
            direction = "BULLISH"
        else:
            direction = "MIXED"
        
        # For LONG: we want recent bars to be bearish (price falling = oversold setup)
        # For SHORT: we want recent bars to be bullish (price rising = overbought setup)
        if signal_side == "LONG":
            confirmed = bearish_count >= required_bars
            return confirmed, bearish_count, direction
        else:  # SHORT
            confirmed = bullish_count >= required_bars
            return confirmed, bullish_count, direction
            
    except Exception as e:
        logger.warning(f"Consecutive bar check error: {e}")
        return True, 0, "ERROR"  # On error, allow signal


# ============================================================================
# VOLUME SPIKE DETECTION
# ============================================================================

def detect_volume_spike(volumes: list, lookback: int = 20, threshold: float = 2.0) -> tuple:
    """
    Detect volume spikes (volume > threshold * average).
    
    Args:
        volumes: List of volume values
        lookback: Period for average calculation
        threshold: Multiple of average to consider a spike
        
    Returns:
        (is_spike: bool, volume_ratio: float)
    """
    if len(volumes) < lookback + 1:
        return False, 1.0
    
    try:
        recent_volumes = np.array(volumes[-(lookback + 1):-1])  # Exclude current
        current_volume = volumes[-1]
        
        avg_volume = np.mean(recent_volumes)
        
        if avg_volume <= 0:
            return False, 1.0
        
        volume_ratio = current_volume / avg_volume
        is_spike = volume_ratio >= threshold
        
        return is_spike, volume_ratio
        
    except Exception as e:
        logger.warning(f"Volume spike detection error: {e}")
        return False, 1.0


# ============================================================================
# PHASE 22: MULTI-TIMEFRAME CONFIGURATION
# ============================================================================

# Timeframes to analyze (exclude 3d+)
MTF_CONFIRMATION_TIMEFRAMES = ['1m', '5m', '15m', '1h', '4h', '1d']
MTF_MIN_AGREEMENT = 4  # Minimum TF agreement required

# Volatility-based parameters using ATR as percentage of price
# Phase 73: ATR% thresholds adjusted 5√ó higher to match observed values
# Observed ATR% in production: 13-55% (higher than typical due to 4h OHLCV source)
# Low volatility = tighter stops, higher leverage | High volatility = wider stops, lower leverage
# Phase 184: Leverage reduced to safer levels for small accounts
VOLATILITY_LEVELS = {
    "very_low":  {"max_atr_pct": 10.0,  "trail": 0.5, "sl": 1.5, "tp": 2.5, "leverage": 15, "pullback": 0.003},  # <10% = 15x (was 50x)
    "low":       {"max_atr_pct": 20.0,  "trail": 1.0, "sl": 2.0, "tp": 3.0, "leverage": 10, "pullback": 0.006},  # <20% = 10x (was 25x)
    "normal":    {"max_atr_pct": 30.0,  "trail": 1.5, "sl": 2.5, "tp": 4.0, "leverage": 7,  "pullback": 0.012},  # <30% = 7x (was 10x)
    "high":      {"max_atr_pct": 50.0,  "trail": 2.0, "sl": 3.0, "tp": 5.0, "leverage": 5,  "pullback": 0.018},  # <50% = 5x
    "very_high": {"max_atr_pct": 70.0,  "trail": 3.0, "sl": 4.0, "tp": 6.0, "leverage": 3,  "pullback": 0.024},  # <70% = 3x
    "extreme":   {"max_atr_pct": 90.0,  "trail": 4.0, "sl": 5.0, "tp": 8.0, "leverage": 3,  "pullback": 0.030},  # <90% = 3x, hyper-volatile
    "ultra":     {"max_atr_pct": 999,   "trail": 5.0, "sl": 6.0, "tp": 10.0,"leverage": 3,  "pullback": 0.036}   # 90%+ = 3x, extreme
}

# ============================================================================
# FIBONACCI RETRACEMENT ENGINE ‚Äî Feature Flags & Helpers
# Phase FIB: Dual-role Fibonacci (score bonus + entry refinement)
# ============================================================================

FIB_ENABLED = True               # Master switch ‚Äî ACTIVE (Canary A≈üama 1)
FIB_SCORE_ENABLED = True         # Score bonus layer (Layer 23)
FIB_ENTRY_ENABLED = True         # Entry blend layer ‚Äî ACTIVE
FIB_MAX_ENTRY_DEV_PCT = 1.0      # Max deviation between fib_entry and atr_entry (%)
FIB_BLEND_ALPHA = 0.35           # Blend weight (0=pure ATR, 1=pure fib)

# ============================================================================
# ENTRY QUALITY GATE ‚Äî Feature Flags
# Phase EQG: Filter out low-volume, weak-momentum entries
# ============================================================================

ENTRY_QUALITY_GATE_ENABLED = True
ENTRY_QUALITY_MODE = 'hard'      # 'soft' = score -15 | 'hard' = reject
EQ_MIN_VOLUME_RATIO = 1.25      # Ko≈üul A: min volume ratio
EQ_MIN_IMBALANCE = 4.0          # Ko≈üul B: min OB imbalance
EQ_MIN_OB_TREND = 2.0           # Ko≈üul B: min ob_imbalance_trend
EQ_MIN_VOLUME_24H = 1_500_000   # Ko≈üul C: min 24h volume ($)
EQ_MAX_SPREAD = 0.20            # Ko≈üul C: max spread (%)
EQ_MIN_DEPTH_USD = 120_000      # Execution: min total depth ($)
EQ_OBI_OPPOSE_VETO = 0.35       # Execution: OBI opposing veto threshold

# Fibonacci ratios
FIB_RATIOS = {
    '0.236': 0.236,
    '0.382': 0.382,
    '0.500': 0.500,
    '0.618': 0.618,
    '0.786': 0.786,
}

# Score bonus per Fibonacci level (capped at 12 total)
FIB_SCORE_MAP = {
    '0.618': 8,
    '0.500': 6,
    '0.382': 4,
    '0.236': 2,
    '0.786': 3,
}
FIB_SCORE_CAP = 12
FIB_CONFLUENCE_BONUS = 2  # Extra bonus when VP/Sweep aligns


def detect_swings_atr(highs: list, lows: list, closes: list, atr: float,
                      lookback: int = 30, k: float = 1.5) -> dict:
    """
    ATR-filtered swing high/low detection (Method 2 from Fibonacci guide).
    
    A swing is valid only if the price move from the last swing exceeds k √ó ATR,
    filtering out small fake moves and noise.
    
    Args:
        highs: List of high prices
        lows: List of low prices
        closes: List of close prices
        atr: Current ATR value
        lookback: How many bars to look back
        k: ATR multiplier threshold (1.5 = need 1.5√ó ATR move for valid swing)
    
    Returns:
        {
            'swing_high': float or None,
            'swing_low': float or None,
            'swing_high_idx': int or -1,
            'swing_low_idx': int or -1,
            'valid': bool
        }
    """
    result = {
        'swing_high': None, 'swing_low': None,
        'swing_high_idx': -1, 'swing_low_idx': -1,
        'valid': False
    }
    
    if len(highs) < lookback or len(lows) < lookback or atr <= 0:
        return result
    
    min_move = k * atr  # Minimum price move for a valid swing
    
    # Use the last `lookback` bars
    h = highs[-lookback:]
    l = lows[-lookback:]
    c = closes[-lookback:]
    
    # Find highest high and lowest low
    max_h = max(h)
    min_l = min(l)
    max_h_idx = len(h) - 1 - h[::-1].index(max_h)  # Last occurrence
    min_l_idx = len(l) - 1 - l[::-1].index(min_l)
    
    # Check if the range is significant (> k * ATR)
    swing_range = max_h - min_l
    if swing_range < min_move:
        return result  # Range too small ‚Äî no meaningful swing
    
    # Validate: use fractal confirmation (2-bar lookback)
    # Swing High: bar[i] high > bar[i-1] high AND bar[i] high > bar[i-2] high
    valid_sh = False
    for i in range(len(h) - 1, 1, -1):
        if h[i] == max_h and h[i] > h[i-1] and h[i] > h[i-2]:
            max_h_idx = i
            valid_sh = True
            break
    
    valid_sl = False
    for i in range(len(l) - 1, 1, -1):
        if l[i] == min_l and l[i] < l[i-1] and l[i] < l[i-2]:
            min_l_idx = i
            valid_sl = True
            break
    
    if not valid_sh:
        # Fallback: just use the max high
        valid_sh = True
    if not valid_sl:
        valid_sl = True
    
    # Ensure swing high happened after swing low (for uptrend) or vice versa
    # We return both and let the caller decide based on trend
    result['swing_high'] = max_h
    result['swing_low'] = min_l
    result['swing_high_idx'] = max_h_idx
    result['swing_low_idx'] = min_l_idx
    result['valid'] = valid_sh and valid_sl
    
    return result


def calculate_fib_levels(swing_high: float, swing_low: float, trend: str = 'UP') -> dict:
    """
    Calculate Fibonacci retracement levels from swing high/low.
    
    Uptrend: levels measured down from swing_high (retracement of upward move)
    Downtrend: levels measured up from swing_low (retracement of downward move)
    
    Args:
        swing_high: The swing high price
        swing_low: The swing low price
        trend: 'UP' or 'DOWN'
    
    Returns:
        {
            '0.236': price_level,
            '0.382': price_level,
            '0.500': price_level,
            '0.618': price_level,
            '0.786': price_level,
            'range': swing_high - swing_low
        }
    """
    price_range = swing_high - swing_low
    if price_range <= 0:
        return {}
    
    levels = {'range': price_range}
    
    for name, ratio in FIB_RATIOS.items():
        if trend == 'UP':
            # Uptrend retracement: price pulls back down from high
            levels[name] = swing_high - (price_range * ratio)
        else:
            # Downtrend retracement: price bounces up from low
            levels[name] = swing_low + (price_range * ratio)
    
    return levels


def build_fib_context(signal_side: str, price: float, atr: float,
                      adx: float, hurst: float, trend_data: dict,
                      sweep_result: dict = None, volume_profile_poc: float = 0) -> dict:
    """
    Build Fibonacci context for signal scoring and entry refinement.
    
    Uses cached OHLCV data from MTF trend updates to detect swings
    and calculate Fibonacci levels. Produces score bonus (capped at 12)
    and optimal entry price.
    
    Args:
        signal_side: 'LONG' or 'SHORT'
        price: Current price
        atr: Current ATR
        adx: Current ADX
        hurst: Current Hurst exponent
        trend_data: From mtf_confirmation.coin_trends[symbol]
        sweep_result: LiquiditySweep detection result (optional)
        volume_profile_poc: Volume profile POC price (optional)
    
    Returns:
        {
            'fib_active': bool,
            'fib_score_bonus': int (0-12),
            'fib_entry': float (0 if inactive),
            'fib_level': str or None ('0.618', '0.5', etc.),
            'fib_zone_upper': float,
            'fib_zone_lower': float,
            'confluence': list,
            'skip_reason': str (if inactive)
        }
    """
    result = {
        'fib_active': False,
        'fib_score_bonus': 0,
        'fib_entry': 0,
        'fib_level': None,
        'fib_zone_upper': 0,
        'fib_zone_lower': 0,
        'confluence': [],
        'skip_reason': ''
    }
    
    # Need OHLCV data from MTF cache
    ohlcv_4h = trend_data.get('ohlcv_4h', [])
    
    if not ohlcv_4h or len(ohlcv_4h) < 20:
        result['skip_reason'] = 'no_data'
        return result
    
    # Check: Fibonacci works best in trending markets
    # If Hurst < 0.45 (mean-reverting) AND ADX < 20 (no trend), skip
    if hurst < 0.40 and adx < 15:
        result['skip_reason'] = 'chop_market'
        return result
    
    # Extract OHLCV arrays
    highs_4h = [c[2] for c in ohlcv_4h]
    lows_4h = [c[3] for c in ohlcv_4h]
    closes_4h = [c[4] for c in ohlcv_4h]
    
    # Detect swings on 4H data
    swings = detect_swings_atr(highs_4h, lows_4h, closes_4h, atr, lookback=min(30, len(ohlcv_4h)), k=1.5)
    
    if not swings['valid'] or swings['swing_high'] is None or swings['swing_low'] is None:
        result['skip_reason'] = 'no_swing'
        return result
    
    # Determine trend from signal side
    trend = 'UP' if signal_side == 'LONG' else 'DOWN'
    
    # Calculate Fibonacci levels
    fib_levels = calculate_fib_levels(swings['swing_high'], swings['swing_low'], trend)
    
    if not fib_levels:
        result['skip_reason'] = 'no_range'
        return result
    
    # Zone width: ATR √ó 0.5 on each side of the fib level
    zone_width = atr * 0.5
    
    # Find which zone (if any) the current price is in
    best_level = None
    best_bonus = 0
    best_fib_price = 0
    
    for level_name in ['0.618', '0.500', '0.382', '0.786', '0.236']:
        fib_price = fib_levels.get(level_name, 0)
        if fib_price <= 0:
            continue
        
        zone_upper = fib_price + zone_width
        zone_lower = fib_price - zone_width
        
        if zone_lower <= price <= zone_upper:
            bonus = FIB_SCORE_MAP.get(level_name, 0)
            if bonus > best_bonus:
                best_bonus = bonus
                best_level = level_name
                best_fib_price = fib_price
                result['fib_zone_upper'] = zone_upper
                result['fib_zone_lower'] = zone_lower
    
    if best_level is None:
        result['skip_reason'] = 'not_in_zone'
        return result
    
    # Confluence checks
    confluence = []
    confluence_bonus = 0
    
    # Check LiquiditySweep confluence
    if sweep_result and sweep_result.get('sweep_type'):
        sweep_type = sweep_result['sweep_type']
        if (sweep_type == 'BULLISH' and signal_side == 'LONG') or \
           (sweep_type == 'BEARISH' and signal_side == 'SHORT'):
            confluence.append('LiqSweep')
            confluence_bonus += 1
    
    # Check VolumeProfile POC confluence
    if volume_profile_poc and volume_profile_poc > 0:
        poc_distance = abs(best_fib_price - volume_profile_poc)
        if poc_distance < zone_width:
            confluence.append('VP_POC')
            confluence_bonus += 1
    
    # Cap confluence bonus
    confluence_bonus = min(confluence_bonus, FIB_CONFLUENCE_BONUS)
    
    # Total score bonus (capped at FIB_SCORE_CAP)
    total_bonus = min(best_bonus + confluence_bonus, FIB_SCORE_CAP)
    
    result['fib_active'] = True
    result['fib_score_bonus'] = total_bonus
    result['fib_entry'] = best_fib_price
    result['fib_level'] = best_level
    result['confluence'] = confluence
    
    return result


# =====================================================
# DYNAMIC TRAIL PARAMETERS (Hybrid Approach)
# Calculates trail_activation and trail_distance based on:
# 1. Volatility (ATR %)
# 2. Hurst exponent (trend vs mean-reversion)
# 3. Price factor (low price = more risk)
# 4. Spread factor (high spread = more risk)
# =====================================================
def get_dynamic_trail_params(
    volatility_pct: float,
    hurst: float = 0.5,
    price: float = 0.0,
    spread_pct: float = 0.0,
    settings_activation: float = 0.0,
    settings_distance: float = 0.0
) -> tuple:
    """
    Calculate dynamic trail_activation_atr and trail_distance_atr.
    
    Phase 231: Now respects settings values as upper caps.
    
    Args:
        volatility_pct: ATR as percentage of price (e.g., 5.0 for 5%)
        hurst: Hurst exponent (0-1, >0.5 = trending, <0.5 = mean reverting)
        price: Current price for price factor calculation
        spread_pct: Current spread percentage
        settings_activation: Settings trail_activation_atr (used as cap, 0=no cap)
        settings_distance: Settings trail_distance_atr (used as cap, 0=no cap)
        
    Returns:
        tuple: (trail_activation_atr, trail_distance_atr)
    """
    import math
    
    # 1. BASE VALUES FROM VOLATILITY
    # Low volatility ‚Üí wider trails (let profits run)
    # High volatility ‚Üí tighter trails (lock in profits quickly)
    if volatility_pct <= 2.0:
        base_activation = 2.0   # Need big move before trail
        base_distance = 1.5     # Wide trail distance
    elif volatility_pct <= 4.0:
        base_activation = 1.5
        base_distance = 1.0
    elif volatility_pct <= 6.0:
        base_activation = 1.2
        base_distance = 0.8
    elif volatility_pct <= 10.0:
        base_activation = 1.0
        base_distance = 0.6
    else:
        base_activation = 0.8   # Quick activation for very volatile
        base_distance = 0.5     # Tight trail
    
    # 2. HURST ADJUSTMENT
    # Trending (>0.5) ‚Üí wider trails to capture bigger moves
    # Mean-reverting (<0.5) ‚Üí tighter trails, exit quickly
    # Phase 213: Trending coins get significantly wider trails (min 2x)
    if hurst >= 0.65:
        hurst_mult = 2.0   # Strong trend ‚Üí let it run (was 1.4)
    elif hurst >= 0.55:
        hurst_mult = 1.6   # Mild trend ‚Üí still wide (was 1.2)
    elif hurst >= 0.45:
        hurst_mult = 1.0   # Random walk
    elif hurst >= 0.35:
        hurst_mult = 0.8   # Mild mean-reversion ‚Üí tighter
    else:
        hurst_mult = 0.6   # Strong mean-reversion ‚Üí very tight
    
    # 3. PRICE FACTOR (Log scale)
    # Low price coins are riskier ‚Üí tighter trails
    if price > 0:
        log_price = math.log10(max(price, 0.0001))
        price_factor = max(0.5, min(1.0, (log_price + 2) / 4))
    else:
        price_factor = 1.0
    
    # 4. SPREAD FACTOR
    # High spread = low liquidity ‚Üí tighter trails (exit while you can)
    if spread_pct > 0:
        spread_factor = max(0.6, 1.0 - spread_pct * 1.5)
    else:
        spread_factor = 1.0
    
    # COMBINED: Riskier coins get tighter trails
    risk_mult = (price_factor + spread_factor) / 2  # Average of price and spread risk
    
    # Final calculation
    final_activation = base_activation * hurst_mult * max(0.5, risk_mult)
    final_distance = base_distance * hurst_mult * max(0.5, risk_mult)
    
    # Clamp to reasonable ranges
    final_activation = max(0.5, min(3.0, final_activation))  # 0.5-3.0 range
    final_distance = max(0.3, min(2.5, final_distance))      # 0.3-2.5 range (Phase 213: was 2.0)
    
    # Phase 213: Enforce minimum 2x distance for trending coins
    if hurst >= 0.55:
        final_distance = max(final_distance, base_distance * 1.5)  # At least 1.5x base for trending
    
    # Phase 231: Cap at settings values ‚Äî user settings always respected
    if settings_activation > 0:
        final_activation = min(final_activation, settings_activation)
    if settings_distance > 0:
        final_distance = min(final_distance, settings_distance)
    
    return round(final_activation, 2), round(final_distance, 2)


# =====================================================
# DYNAMIC TRAIL ACTIVATION THRESHOLD
# ATR + spread + volume bazlƒ± dinamik e≈üik hesaplama
# Sabit 0.75% / 5.0% yerine piyasa ko≈üullarƒ±na g√∂re ayarlanƒ±r
# =====================================================
def get_dynamic_trail_activation_threshold(atr_pct: float, spread_pct: float, volume_ratio: float, leverage: int) -> tuple:
    """
    Calculate dynamic trail activation thresholds based on market conditions.
    
    Args:
        atr_pct: ATR as percentage of price (e.g., 2.0 for 2%)
        spread_pct: Current bid-ask spread percentage
        volume_ratio: Current volume / average volume ratio
        leverage: Position leverage
    
    Returns:
        tuple: (min_price_move_pct, min_roi_pct)
    """
    # Base: ATR'nin %40'ƒ± (min 0.5%, max 2.0%)
    base_move = max(0.5, min(2.0, atr_pct * 0.40))
    
    # Spread factor: y√ºksek spread ‚Üí daha geni≈ü e≈üik (noise filtresi)
    # 0.05% normal spread, √ºst√º = ek buffer
    spread_factor = 1.0 + max(0, (spread_pct - 0.05)) * 3.0
    
    # Volume factor: d√º≈ü√ºk volume ‚Üí daha geni≈ü e≈üik (fake move filtresi)
    if volume_ratio >= 2.0:
        vol_factor = 0.85    # Y√ºksek volume: daha erken trail OK
    elif volume_ratio >= 1.0:
        vol_factor = 1.0     # Normal
    else:
        vol_factor = 1.25    # D√º≈ü√ºk volume: daha ge√ß trail
    
    min_price_move = round(base_move * spread_factor * vol_factor, 3)
    min_price_move = max(0.4, min(2.5, min_price_move))  # Hard clamp
    
    # ROI = min_price_move √ó leverage (ama min 4%, max 20%)
    min_roi = round(min_price_move * leverage, 1)
    min_roi = max(4.0, min(20.0, min_roi))
    
    return min_price_move, min_roi


def check_emergency_sl_static(pos: dict, current_price: float, trailing_stop: float) -> bool:
    """
    Phase 217: Unified trail-based Emergency SL check ‚Äî single source of truth.
    Checks if current price exceeds the trailing stop by >1% of entry price.
    Returns True if emergency breach detected.
    """
    entry_price = pos.get('entryPrice', 0)
    if entry_price <= 0 or trailing_stop <= 0:
        return False
    
    EMERGENCY_MARGIN_PCT = 1.0  # %1 of entry price
    emergency_margin = entry_price * (EMERGENCY_MARGIN_PCT / 100)
    side = pos.get('side', 'LONG')
    
    if side == 'LONG' and current_price <= (trailing_stop - emergency_margin):
        return True
    elif side == 'SHORT' and current_price >= (trailing_stop + emergency_margin):
        return True
    return False

def check_failed_continuation(pos: dict, candle_close_price: float) -> str:
    """
    Phase 214: Failed Continuation Detector
    Kalƒ±cƒ±lƒ±k saƒülayamayan pozisyonlarƒ± tespit eder.
    
    Mantƒ±k: Fiyat N kez meaningful profit zone'a girip entry'ye geri d√∂n√ºyorsa,
    giri≈ü noktasƒ± yanlƒ±≈ütƒ±r ‚Üí breakeven'da kapat.
    
    Returns: 'FAILED_CONTINUATION' if position should be closed, else ''
    """
    entry_price = pos.get('entryPrice', 0)
    if entry_price <= 0:
        return ''
    
    side = pos.get('side', 'LONG')
    pos_atr = pos.get('atr', entry_price * 0.02)
    atr_pct = (pos_atr / entry_price) * 100 if entry_price > 0 else 2.0
    
    # Skip if position already reached 5%+ profit (trail handles it)
    fc_max_profit = pos.get('fc_max_profit_pct', 0.0)
    if fc_max_profit >= 5.0:
        return ''
    
    # ---- Dynamic max attempts based on ATR% ----
    if atr_pct < 2.0:
        max_attempts = 4   # BTC/ETH ‚Äî low noise
    elif atr_pct < 4.0:
        max_attempts = 3   # Medium volatility
    elif atr_pct < 8.0:
        max_attempts = 3   # High volatility
    else:
        max_attempts = 2   # Meme coin ‚Äî fast exit
    
    # Trend mode: +1 tolerance
    if pos.get('trend_mode', False):
        max_attempts += 1
    
    # Clamp to 2-4 range (5 with trend mode)
    max_attempts = max(2, min(5, max_attempts))
    
    # Time-based reduction: after 8 hours, -1 attempt (min 2)
    open_time = pos.get('openTime', 0)
    if open_time > 0:
        elapsed_hours = (datetime.now().timestamp() * 1000 - open_time) / (1000 * 3600)
        if elapsed_hours >= 8:
            max_attempts = max(2, max_attempts - 1)
    
    # ---- Calculate current profit state ----
    # Minimum profit depth: 0.3√ó ATR for meaningful move
    min_profit_depth = pos_atr * 0.3
    # Breakeven zone: entry ¬± 0.05%
    be_tolerance = entry_price * 0.0005
    
    if side == 'LONG':
        price_vs_entry = candle_close_price - entry_price
        in_profit = price_vs_entry >= min_profit_depth
        at_breakeven = abs(candle_close_price - entry_price) <= be_tolerance
    else:  # SHORT
        price_vs_entry = entry_price - candle_close_price
        in_profit = price_vs_entry >= min_profit_depth
        at_breakeven = abs(candle_close_price - entry_price) <= be_tolerance
    
    # Track max profit % seen
    current_pnl_pct = abs(pos.get('unrealizedPnlPercent', 0))
    if current_pnl_pct > fc_max_profit:
        pos['fc_max_profit_pct'] = current_pnl_pct
    
    was_in_profit = pos.get('fc_was_in_profit', False)
    failed_count = pos.get('fc_failed_count', 0)
    
    # ---- State machine ----
    if in_profit and not was_in_profit:
        # Entered meaningful profit zone
        pos['fc_was_in_profit'] = True
    elif (at_breakeven or price_vs_entry < 0) and was_in_profit:
        # Was profitable, now back at breakeven or losing ‚Üí failed break
        pos['fc_failed_count'] = failed_count + 1
        pos['fc_was_in_profit'] = False
        failed_count = pos['fc_failed_count']
        logger.info(
            f"üìä FAILED_BREAK #{failed_count}/{max_attempts}: {pos.get('symbol','?')} {side} "
            f"(depth={min_profit_depth:.6f}, atr%={atr_pct:.1f}%)"
        )
    # Note: If price is in shallow profit (above entry but < 0.3 ATR), we keep
    # was_in_profit=True so we correctly count the failed break when price returns to BE
    
    # ---- Check if max attempts reached ----
    if failed_count >= max_attempts:
        return 'FAILED_CONTINUATION'
    
    return ''

# ===================================================================
# Phase 215: LIVE MTF POSITION GUARD
# Giri≈ü filtresi + a√ßƒ±k pozisyon sƒ±kƒ±la≈ütƒ±rma/geni≈ületme
# ===================================================================

# Son MTF guard g√ºncelleme zamanƒ± (global)
_last_mtf_guard_update = 0

def check_ma_alignment_veto(symbol: str, action: str) -> tuple:
    """
    Phase 215 Katman 1: MA Alignment Hard Veto
    4H + 1D trend + Supertrend √º√ß√º de aynƒ± y√∂nde ise ters sinyali HARD REJECT et.
    Returns: (vetoed: bool, reason: str)
    """
    trend_data = mtf_confirmation.coin_trends.get(symbol, {})
    
    trend_4h = trend_data.get('trend_4h', 'NEUTRAL')
    trend_1d = trend_data.get('trend_1d', 'NEUTRAL')
    supertrend_dir = trend_data.get('supertrend_dir', 0)  # 1=bull, -1=bear
    
    bullish_alignment = (
        trend_4h in ('BULLISH', 'STRONG_BULLISH') and
        trend_1d in ('BULLISH', 'STRONG_BULLISH') and
        supertrend_dir == 1
    )
    bearish_alignment = (
        trend_4h in ('BEARISH', 'STRONG_BEARISH') and
        trend_1d in ('BEARISH', 'STRONG_BEARISH') and
        supertrend_dir == -1
    )
    
    if action == 'SHORT' and bullish_alignment:
        return True, f"MA_VETO: 4H={trend_4h}, 1D={trend_1d}, ST=BULL ‚Üí SHORT blocked"
    if action == 'LONG' and bearish_alignment:
        return True, f"MA_VETO: 4H={trend_4h}, 1D={trend_1d}, ST=BEAR ‚Üí LONG blocked"
    
    return False, ""

def _apply_tightening(pos: dict, factor: float):
    """Phase 215: SL mesafesini, trail distance'ƒ± ve trail activation'ƒ± sƒ±kƒ±la≈ütƒ±r."""
    entry = pos['entryPrice']
    side = pos['side']
    
    # Orijinal deƒüerleri sakla (ilk seferde ‚Äî tek sefer)
    if not pos.get('_mtf_originals_saved', False):
        pos['original_sl'] = pos.get('stopLoss', 0)
        pos['original_trail_distance'] = pos.get('trailDistance', 0)
        pos['original_trail_activation'] = pos.get('trailActivation', entry)
        pos['original_tp'] = pos.get('takeProfit', 0)
        pos['_mtf_originals_saved'] = True
    
    orig_sl = pos['original_sl']
    
    # SL sƒ±kƒ±la≈ütƒ±r (sadece trail aktif DEƒûƒ∞LSE)
    if not pos.get('isTrailingActive', False) and orig_sl > 0:
        if side == 'LONG':
            sl_distance = entry - orig_sl
            new_sl = entry - (sl_distance * factor)
            # Orijinal SL'den hesapla ‚Äî factor deƒüi≈ütik√ße SL de ayarlansƒ±n
            pos['stopLoss'] = new_sl
        else:  # SHORT
            sl_distance = orig_sl - entry
            new_sl = entry + (sl_distance * factor)
            pos['stopLoss'] = new_sl
    
    # Trail distance sƒ±kƒ±la≈ütƒ±r
    orig_td = pos.get('original_trail_distance', 0)
    if orig_td > 0:
        pos['trailDistance'] = orig_td * factor
    
    # Trail activation d√º≈ü√ºr (daha erken trail ba≈ülasƒ±n)
    orig_ta = pos.get('original_trail_activation', entry)
    if side == 'LONG':
        ta_diff = orig_ta - entry
        if ta_diff > 0:
            pos['trailActivation'] = entry + (ta_diff * factor)
    else:
        ta_diff = entry - orig_ta
        if ta_diff > 0:
            pos['trailActivation'] = entry - (ta_diff * factor)
    
    pos['mtf_guard_factor'] = factor

def _apply_widening(pos: dict, expand: float):
    """Phase 215: TP ve trail distance geni≈ület (pro-trend + k√¢rda)."""
    entry = pos['entryPrice']
    side = pos['side']
    
    if not pos.get('_mtf_originals_saved', False):
        pos['original_tp'] = pos.get('takeProfit', 0)
        pos['original_trail_distance'] = pos.get('trailDistance', 0)
        pos['original_sl'] = pos.get('stopLoss', 0)
        pos['original_trail_activation'] = pos.get('trailActivation', entry)
        pos['_mtf_originals_saved'] = True
    
    orig_tp = pos.get('original_tp', 0)
    orig_td = pos.get('original_trail_distance', 0)
    
    # TP geni≈ület
    if orig_tp > 0:
        if side == 'LONG':
            tp_distance = orig_tp - entry
            if tp_distance > 0:
                pos['takeProfit'] = entry + (tp_distance * expand)
        else:
            tp_distance = entry - orig_tp
            if tp_distance > 0:
                pos['takeProfit'] = entry - (tp_distance * expand)
    
    # Trail distance geni≈ület (daha geni≈ü trail = daha ge√ß √ßƒ±kƒ±≈ü)
    if orig_td > 0:
        pos['trailDistance'] = orig_td * expand
    
    pos['mtf_guard_factor'] = expand

async def apply_mtf_position_guard(positions: list, exchange):
    """
    Phase 215 Katman 2: Her 30 dakikada bir a√ßƒ±k pozisyonlar i√ßin MTF re-evaluation.
    Contra-trend ‚Üí SL/Trail sƒ±kƒ±la≈ütƒ±r
    Pro-trend + k√¢rda ‚Üí TP/Trail geni≈ület
    """
    global _last_mtf_guard_update
    now = datetime.now().timestamp()
    
    if now - _last_mtf_guard_update < 1800:  # 30 dakika
        return
    _last_mtf_guard_update = now
    
    if not positions or not exchange:
        return
    
    logger.info(f"üìä MTF_GUARD: {len(positions)} pozisyon i√ßin trend re-evaluation ba≈ülƒ±yor")
    
    for pos in positions:
        try:
            symbol = pos.get('symbol', '')
            side = pos.get('side', 'LONG')
            entry = pos.get('entryPrice', 0)
            if entry <= 0 or not symbol:
                continue
            
            # MTF trend g√ºncelle (API call)
            await mtf_confirmation.update_coin_trend(symbol, exchange)
            mtf_result = mtf_confirmation.confirm_signal(symbol, side)
            mtf_score = mtf_result.get('mtf_score', 0)
            
            # Mevcut PnL hesapla
            current_price = pos.get('currentPrice', entry)
            if side == 'LONG':
                pnl_pct = ((current_price - entry) / entry) * 100
            else:
                pnl_pct = ((entry - current_price) / entry) * 100
            
            trends = mtf_result.get('trends', {})
            trend_info = f"15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}, 1d:{trends.get('1d','?')}"
            
            # ---- CONTRA-TREND SIKILA≈ûTIRMAa ----
            if mtf_score < 0:
                if mtf_score < -25:
                    factor = 0.30   # √ßok agresif
                elif mtf_score < -10:
                    factor = 0.50
                else:
                    factor = 0.70
                
                _apply_tightening(pos, factor)
                logger.warning(
                    f"‚ö†Ô∏è MTF_GUARD TIGHTEN: {symbol} {side} | "
                    f"MTF={mtf_score} | factor={factor:.0%} | PnL={pnl_pct:+.1f}% | {trend_info}"
                )
            
            # ---- PRO-TREND GENƒ∞≈ûLETME (sadece k√¢rda) ----
            elif mtf_score > 25 and pnl_pct > 0:
                if mtf_score > 50:
                    expand = 1.40
                else:
                    expand = 1.20
                
                _apply_widening(pos, expand)
                logger.info(
                    f"üìà MTF_GUARD WIDEN: {symbol} {side} | "
                    f"MTF={mtf_score} | expand={expand:.0%} | PnL={pnl_pct:+.1f}% | {trend_info}"
                )
            
            else:
                # N√∂tr ‚Äî orijinal deƒüerlere d√∂n ve flag temizle
                if pos.get('_mtf_originals_saved', False):
                    if not pos.get('isTrailingActive', False):
                        pos['stopLoss'] = pos.get('original_sl', pos['stopLoss'])
                    pos['trailDistance'] = pos.get('original_trail_distance', pos.get('trailDistance', 0))
                    pos['trailActivation'] = pos.get('original_trail_activation', pos.get('trailActivation', entry))
                    pos['takeProfit'] = pos.get('original_tp', pos.get('takeProfit', 0))
                    # Temizle ‚Äî yeni cycle'da taze kayƒ±t yapƒ±lsƒ±n
                    for key in ['original_sl', 'original_tp', 'original_trail_distance', 
                                'original_trail_activation', '_mtf_originals_saved']:
                        pos.pop(key, None)
                pos.pop('mtf_guard_factor', None)
                logger.debug(f"üìä MTF_GUARD NEUTRAL: {symbol} {side} | MTF={mtf_score} | restored originals")
        
        except Exception as guard_err:
            logger.debug(f"MTF Guard error for {pos.get('symbol', '?')}: {guard_err}")

def get_volatility_adjusted_params(volatility_pct: float, atr: float, price: float = 0.0, spread_pct: float = 0.0) -> dict:
    """
    Get SL/TP/Trail/Leverage based on volatility (ATR as % of price).
    Phase 35: Using ATR percentage for proper volatility classification.
    Phase 43: Combined leverage formula with price and spread factors.
    
    Combined Formula:
        base_leverage = from VOLATILITY_LEVELS (3-50x based on volatility)
        price_factor = min(price / 10, 1.0)  # $10 altƒ± s√ºrekli azalt
        spread_factor = max(0.2, 1 - spread_pct * 2)  # Spread y√ºksekse azalt
        final_leverage = base_leverage * price_factor * spread_factor
    
    Args:
        volatility_pct: ATR as percentage of price (e.g., 2.5 for 2.5%)
        atr: Absolute ATR value for calculating distances
        price: Current price for price_factor calculation
        spread_pct: Current spread percentage for spread_factor calculation
        
    Returns:
        dict with trail_distance, stop_loss, take_profit, leverage, pullback, level
    """
    for level, params in VOLATILITY_LEVELS.items():
        if volatility_pct <= params["max_atr_pct"]:
            base_leverage = params["leverage"]  # Volatility-based base (3-50x)
            
            # Phase 43: Combined leverage formula (logarithmic version)
            # Price Factor: Logarithmic reduction for low-price coins
            # Phase 61: FIXED - previous formula was broken, all prices mapped to 0.85
            # NEW: Softer gradient: $100+=1.0, $10=0.98, $1=0.95, $0.1=0.92, $0.01=0.89
            import math
            if price > 0:
                log_price = math.log10(max(price, 0.0001))  # -4 to ~5 range
                # Fixed formula: 0.95 base + 0.03 per log unit
                price_factor = max(0.85, min(1.0, 0.95 + log_price * 0.03))
            else:
                price_factor = 1.0  # If price=0, don't penalize
            
            # Spread Factor: Reduce leverage for high spread coins
            # Phase 60: Relaxed - √ó1.5 (was √ó2), min 0.65 (was 0.5)
            if spread_pct > 0:
                spread_factor = max(0.65, 1.0 - spread_pct * 1.5)  # max %23 spread = min 0.65 factor
            else:
                spread_factor = 1.0
            
            # Combined formula: base √ó price_factor √ó spread_factor
            final_leverage = base_leverage * price_factor * spread_factor
            
            # Ensure minimum 3x leverage
            final_leverage = max(3, int(round(final_leverage)))
            
            if final_leverage != base_leverage:
                logger.debug(f"Combined leverage: base={base_leverage}x √ó price={price_factor:.2f} √ó spread={spread_factor:.2f} ‚Üí final={final_leverage}x")
            
            return {
                "trail_distance": atr * params["trail"],
                "stop_loss": atr * params["sl"],
                "take_profit": atr * params["tp"],
                "leverage": final_leverage,
                "pullback": params["pullback"],
                "sl_multiplier": params["sl"],
                "tp_multiplier": params["tp"],
                "trail_multiplier": params["trail"],
                # Phase 223c: Normalize to Title Case for consumer compatibility
                "level": level.replace('_', ' ').title()
            }
    
    # Default to ultra
    params = VOLATILITY_LEVELS["ultra"]
    base_leverage = params["leverage"]
    
    # Apply logarithmic Combined Formula for default case too
    # Phase 61: FIXED formula
    import math
    if price > 0:
        log_price = math.log10(max(price, 0.0001))
        price_factor = max(0.85, min(1.0, 0.95 + log_price * 0.03))  # Fixed formula
    else:
        price_factor = 1.0
    
    spread_factor = max(0.65, 1.0 - spread_pct * 1.5) if spread_pct > 0 else 1.0  # Phase 60: Relaxed
    final_leverage = max(3, int(round(base_leverage * price_factor * spread_factor)))
    
    return {
        "trail_distance": atr * params["trail"],
        "stop_loss": atr * params["sl"],
        "take_profit": atr * params["tp"],
        "leverage": final_leverage,
        "pullback": params["pullback"],
        "sl_multiplier": params["sl"],
        "tp_multiplier": params["tp"],
        "trail_multiplier": params["trail"],
        "level": "Ultra"  # Phase 228: New top level
    }


class MultiTimeframeAnalyzer:
    """
    Phase 22: Analyze multiple timeframes for signal confirmation.
    Only enter trades when 3+ timeframes agree.
    """
    
    def __init__(self):
        self.timeframes = MTF_CONFIRMATION_TIMEFRAMES
        self.min_agreement = MTF_MIN_AGREEMENT
        self.tf_signals = {}
        self.last_update = {}
    
    def analyze_timeframe(self, closes: list, highs: list = None, lows: list = None) -> dict:
        """Analyze a single timeframe and return signal."""
        if len(closes) < 20:
            return {"direction": "NEUTRAL", "strength": 0, "hurst": 0.5, "zscore": 0}
        
        # Calculate indicators
        hurst = calculate_hurst(closes)
        
        # Calculate Z-Score from price spread
        if len(closes) >= 20:
            ma = np.mean(closes[-20:])
            spreads = [c - ma for c in closes[-20:]]
            zscore = calculate_zscore(spreads)
        else:
            zscore = 0
        
        # Determine direction
        direction = "NEUTRAL"
        strength = 0
        
        # Mean Reversion (Hurst < 0.45)
        if hurst < 0.45:
            if zscore < -2.0:
                direction = "LONG"
                strength = abs(zscore)
            elif zscore > 2.0:
                direction = "SHORT"
                strength = abs(zscore)
        
        # Trend Following (Hurst > 0.55)
        elif hurst > 0.55:
            if zscore > 1.5:
                direction = "LONG"
                strength = abs(zscore)
            elif zscore < -1.5:
                direction = "SHORT"
                strength = abs(zscore)
        
        return {
            "direction": direction,
            "strength": strength,
            "hurst": hurst,
            "zscore": zscore
        }
    
    def get_mtf_confirmation(self, tf_signals: dict, spread_pct: float = 0.05) -> dict:
        """Check if timeframes agree. Dynamic threshold based on spread."""
        if not tf_signals:
            return None
        
        # Determine strictness based on spread
        # High spread (>0.15%) requires stricter confirmation (6 TFs)
        required_agreement = 6 if spread_pct > 0.15 else self.min_agreement
        
        long_count = sum(1 for s in tf_signals.values() if s.get('direction') == 'LONG')
        short_count = sum(1 for s in tf_signals.values() if s.get('direction') == 'SHORT')
        
        total_tfs = len(tf_signals)
        
        if long_count >= required_agreement:
            long_signals = [s for s in tf_signals.values() if s.get('direction') == 'LONG']
            avg_strength = np.mean([s.get('strength', 0) for s in long_signals])
            return {
                "action": "LONG",
                "tf_count": long_count,
                "total_tfs": total_tfs,
                "required_agreement": required_agreement,
                "strength": avg_strength,
                "confidence": long_count / total_tfs,
                "details": tf_signals
            }
        elif short_count >= required_agreement:
            short_signals = [s for s in tf_signals.values() if s.get('direction') == 'SHORT']
            avg_strength = np.mean([s.get('strength', 0) for s in short_signals])
            return {
                "action": "SHORT",
                "tf_count": short_count,
                "total_tfs": total_tfs,
                "required_agreement": required_agreement,
                "strength": avg_strength,
                "confidence": short_count / total_tfs,
                "details": tf_signals
            }
        
        return None  # Not enough agreement
    
    def calculate_position_size_multiplier(self, mtf_signal: dict) -> float:
        """Calculate position size multiplier based on TF agreement."""
        if not mtf_signal:
            return 0.5
        
        tf_count = mtf_signal.get('tf_count', 0)
        
        if tf_count >= 5:
            return 2.0  # Full conviction
        elif tf_count >= 4:
            return 1.5  # High conviction
        elif tf_count >= 3:
            return 1.0  # Normal
        else:
            return 0.5  # Low conviction
            
    def calculate_dynamic_leverage(self, mtf_signal: dict) -> int:
        """Calculate dynamic leverage based on TF agreement."""
        if not mtf_signal:
            return 50
        
        tf_count = mtf_signal.get('tf_count', 0)
        
        if tf_count >= 6:
            return 100  # Maximum leverage for maximum conviction
        elif tf_count >= 5:
            return 75
        elif tf_count >= 4:
            return 50
        else:
            return 25   # Minimum leverage for low conviction


# Global MTF Analyzer instance
mtf_analyzer = MultiTimeframeAnalyzer()


# ============================================================================
# PHASE 30: VOLUME PROFILE ANALYZER
# ============================================================================

class VolumeProfileAnalyzer:
    """
    Volume Profile analizi ile POC, VAH, VAL seviyeleri.
    Entry/exit i√ßin √∂nemli destek/diren√ß seviyeleri saƒülar.
    """
    
    def __init__(self, value_area_pct: float = 0.70):
        self.value_area_pct = value_area_pct  # %70 varsayƒ±lan
        self.poc = None  # Point of Control
        self.vah = None  # Value Area High
        self.val = None  # Value Area Low
        self.profile = {}
        self.last_update = 0
        logger.info("VolumeProfileAnalyzer initialized")
    
    def calculate_profile(self, ohlcv_data: list, bins: int = 50) -> dict:
        """
        OHLCV verilerinden volume profile hesapla.
        """
        if len(ohlcv_data) < 20:
            return {}
        
        # Fiyat aralƒ±ƒüƒ±nƒ± belirle
        all_highs = [c[2] for c in ohlcv_data]
        all_lows = [c[3] for c in ohlcv_data]
        all_volumes = [c[5] for c in ohlcv_data]
        
        price_min = min(all_lows)
        price_max = max(all_highs)
        price_range = price_max - price_min
        
        if price_range <= 0:
            return {}
        
        bin_size = price_range / bins
        
        # Her bin i√ßin hacim topla
        volume_profile = {}
        for i in range(bins):
            bin_price = price_min + (i + 0.5) * bin_size
            volume_profile[bin_price] = 0
        
        for candle in ohlcv_data:
            high, low, volume = candle[2], candle[3], candle[5]
            # VWAP benzeri daƒüƒ±tƒ±m - candle boyunca hacmi daƒüƒ±t
            candle_range = high - low
            if candle_range <= 0:
                continue
            
            for bin_price in volume_profile.keys():
                if low <= bin_price <= high:
                    volume_profile[bin_price] += volume / bins
        
        self.profile = volume_profile
        
        # POC - En y√ºksek hacimli seviye
        if volume_profile:
            self.poc = max(volume_profile.keys(), key=lambda x: volume_profile[x])
        
        # Value Area hesapla (%70 hacim)
        total_volume = sum(volume_profile.values())
        target_volume = total_volume * self.value_area_pct
        
        # POC'tan ba≈ülayarak geni≈üle
        sorted_bins = sorted(volume_profile.keys(), key=lambda x: abs(x - self.poc))
        accumulated_volume = 0
        value_area_prices = []
        
        for price in sorted_bins:
            accumulated_volume += volume_profile[price]
            value_area_prices.append(price)
            if accumulated_volume >= target_volume:
                break
        
        if value_area_prices:
            self.vah = max(value_area_prices)
            self.val = min(value_area_prices)
        
        self.last_update = datetime.now().timestamp()
        
        return {
            "poc": self.poc,
            "vah": self.vah,
            "val": self.val,
            "profile": volume_profile
        }
    
    def get_signal_boost(self, current_price: float, signal_action: str) -> float:
        """
        Fiyat √∂nemli seviyelerdeyse sinyal g√ºc√ºn√º artƒ±r.
        Returns: 0.0-0.3 arasƒ± boost deƒüeri
        """
        if not self.poc or not self.vah or not self.val:
            return 0.0
        
        # Tolerans: %0.5 fiyat
        tolerance = current_price * 0.005
        
        boost = 0.0
        
        # LONG sinyali i√ßin
        if signal_action == "LONG":
            # VAL veya POC yakƒ±nƒ±nda LONG = g√º√ßl√º
            if abs(current_price - self.val) < tolerance:
                boost = 0.3  # Max boost
            elif abs(current_price - self.poc) < tolerance:
                boost = 0.2
            elif current_price < self.poc:
                boost = 0.1  # POC altƒ±nda LONG iyi
        
        # SHORT sinyali i√ßin
        elif signal_action == "SHORT":
            # VAH veya POC yakƒ±nƒ±nda SHORT = g√º√ßl√º
            if abs(current_price - self.vah) < tolerance:
                boost = 0.3
            elif abs(current_price - self.poc) < tolerance:
                boost = 0.2
            elif current_price > self.poc:
                boost = 0.1  # POC √ºst√ºnde SHORT iyi
        
        return boost
    
    def get_key_levels(self) -> dict:
        """√ñnemli seviyeleri d√∂nd√ºr."""
        return {
            "poc": self.poc,
            "vah": self.vah,
            "val": self.val
        }


# Global Volume Profile instances (per-coin for accurate POC calculations)
volume_profiler = VolumeProfileAnalyzer()  # Fallback for single-coin mode
coin_volume_profiles = {}  # {symbol: VolumeProfileAnalyzer} for multi-coin scanning


# ============================================================================
# LIQUIDITY SWEEP / SFP (Swing Failure Pattern) DETECTOR
# ============================================================================

class LiquiditySweepDetector:
    """
    Liquidity Sweep ve Swing Failure Pattern (SFP) tespiti.
    
    Mantƒ±k:
    - Fiyat √∂nceki bir tepenin (high) √ºzerine √ßƒ±kƒ±p, oradaki stop-loss emirlerini
      tetikledikten sonra hƒ±zla ters y√∂ne d√∂nerse = BEARISH sweep (SHORT sinyali g√º√ßlenir)
    - Fiyat √∂nceki bir dibin (low) altƒ±na inip, stop-loss'larƒ± tetikledikten sonra
      hƒ±zla ters y√∂ne d√∂nerse = BULLISH sweep (LONG sinyali g√º√ßlenir)
    
    Bu pattern b√ºy√ºk oyuncularƒ±n "likidite avƒ±" yaptƒ±ƒüƒ± noktalarƒ± yakalar.
    """
    
    def __init__(self, lookback: int = 20, sweep_threshold_pct: float = 0.1):
        """
        Args:
            lookback: Ka√ß bar geriye bakƒ±lacak (swing high/low i√ßin)
            sweep_threshold_pct: Sweep olarak sayƒ±lmasƒ± i√ßin minimum a≈üma y√ºzdesi
        """
        self.lookback = lookback
        self.sweep_threshold_pct = sweep_threshold_pct
        self.last_sweep = None
        self.sweep_time = 0
        
    def detect_sweep(self, highs: list, lows: list, closes: list) -> dict:
        """
        Liquidity sweep tespiti yap.
        
        Args:
            highs: Son N bar'ƒ±n high deƒüerleri
            lows: Son N bar'ƒ±n low deƒüerleri
            closes: Son N bar'ƒ±n close deƒüerleri
            
        Returns:
            {
                'sweep_type': 'BULLISH' | 'BEARISH' | None,
                'sweep_level': float (sweep edilen seviye),
                'rejection_strength': float (0-1 arasƒ±, ne kadar g√º√ßl√º reddedildi),
                'score_bonus': int (sinyal skoruna eklenecek bonus)
            }
        """
        result = {
            'sweep_type': None,
            'sweep_level': 0,
            'rejection_strength': 0,
            'score_bonus': 0
        }
        
        if len(highs) < self.lookback + 2 or len(lows) < self.lookback + 2:
            return result
        
        # Son bar hari√ß lookback period'daki swing high/low'u bul
        lookback_highs = highs[-(self.lookback + 1):-1]
        lookback_lows = lows[-(self.lookback + 1):-1]
        
        swing_high = max(lookback_highs)
        swing_low = min(lookback_lows)
        
        # Mevcut ve √∂nceki bar
        current_high = highs[-1]
        current_low = lows[-1]
        current_close = closes[-1]
        prev_close = closes[-2]
        
        # Sweep threshold hesapla
        price_range = swing_high - swing_low
        if price_range <= 0:
            return result
        
        sweep_threshold = price_range * (self.sweep_threshold_pct / 100)
        
        # BEARISH SWEEP: High sweep edip a≈üaƒüƒ± kapanƒ±≈ü
        # Fiyat swing high'ƒ±n √ºzerine √ßƒ±kƒ±p, sonra altƒ±nda kapandƒ±
        if current_high > swing_high + sweep_threshold:
            # Ne kadar √ºzerine √ßƒ±ktƒ±?
            overshoot = current_high - swing_high
            
            # Ama close swing high'ƒ±n altƒ±nda mƒ±? (rejection)
            if current_close < swing_high:
                # Rejection strength: ne kadar g√º√ßl√º reddedildi
                wick_size = current_high - current_close
                body_size = abs(current_close - prev_close)
                
                if wick_size > 0:
                    rejection_strength = min(1.0, wick_size / (wick_size + body_size + 0.0001))
                else:
                    rejection_strength = 0
                
                result['sweep_type'] = 'BEARISH'
                result['sweep_level'] = swing_high
                result['rejection_strength'] = rejection_strength
                
                # Bonus hesapla: G√º√ßl√º sweep = daha fazla bonus
                if rejection_strength > 0.7:
                    result['score_bonus'] = 20  # √áok g√º√ßl√º sweep
                elif rejection_strength > 0.5:
                    result['score_bonus'] = 15
                elif rejection_strength > 0.3:
                    result['score_bonus'] = 10
                else:
                    result['score_bonus'] = 5
                    
                self.last_sweep = result
                self.sweep_time = datetime.now().timestamp()
                return result
        
        # BULLISH SWEEP: Low sweep edip yukarƒ± kapanƒ±≈ü
        # Fiyat swing low'un altƒ±na inip, sonra √ºst√ºnde kapandƒ±
        if current_low < swing_low - sweep_threshold:
            # Ne kadar altƒ±na indi?
            undershoot = swing_low - current_low
            
            # Ama close swing low'un √ºst√ºnde mi? (rejection)
            if current_close > swing_low:
                # Rejection strength
                wick_size = current_close - current_low
                body_size = abs(current_close - prev_close)
                
                if wick_size > 0:
                    rejection_strength = min(1.0, wick_size / (wick_size + body_size + 0.0001))
                else:
                    rejection_strength = 0
                
                result['sweep_type'] = 'BULLISH'
                result['sweep_level'] = swing_low
                result['rejection_strength'] = rejection_strength
                
                # Bonus hesapla
                if rejection_strength > 0.7:
                    result['score_bonus'] = 20
                elif rejection_strength > 0.5:
                    result['score_bonus'] = 15
                elif rejection_strength > 0.3:
                    result['score_bonus'] = 10
                else:
                    result['score_bonus'] = 5
                    
                self.last_sweep = result
                self.sweep_time = datetime.now().timestamp()
                return result
        
        return result
    
    def get_signal_modifier(self, signal_side: str, sweep_result: dict) -> tuple:
        """
        Sweep sonucuna g√∂re sinyal modifikasyonu d√∂nd√ºr.
        
        Args:
            signal_side: 'LONG' veya 'SHORT'
            sweep_result: detect_sweep() sonucu
            
        Returns:
            (score_modifier: int, reason: str)
        """
        if not sweep_result or not sweep_result.get('sweep_type'):
            return 0, ""
        
        sweep_type = sweep_result['sweep_type']
        bonus = sweep_result['score_bonus']
        
        # BULLISH sweep = LONG sinyalini g√º√ßlendir
        if sweep_type == 'BULLISH' and signal_side == 'LONG':
            return bonus, f"LiqSweep(BULL+{bonus}p)"
        
        # BEARISH sweep = SHORT sinyalini g√º√ßlendir
        if sweep_type == 'BEARISH' and signal_side == 'SHORT':
            return bonus, f"LiqSweep(BEAR+{bonus}p)"
        
        # Ters y√∂nde sweep = cezalandƒ±r
        if sweep_type == 'BULLISH' and signal_side == 'SHORT':
            return -10, "LiqSweep(BULL-10p)"
        
        if sweep_type == 'BEARISH' and signal_side == 'LONG':
            return -10, "LiqSweep(BEAR-10p)"
        
        return 0, ""


# Global Liquidity Sweep Detector instance
liquidity_sweep_detector = LiquiditySweepDetector(lookback=20, sweep_threshold_pct=0.1)


# ============================================================================
# SMT DIVERGENCE (Smart Money Technique Divergence)
# ============================================================================

class SMTDivergenceDetector:
    """
    SMT Divergence: BTC ve ETH arasƒ±ndaki korelasyon kopukluƒüunu tespit eder.
    
    Mantƒ±k:
    - BTC yeni bir dip yaparken ETH o dibi yapmazsa (daha y√ºksek dipte kalƒ±rsa)
      = Gizli alƒ±m g√ºc√º var, LONG sinyali g√º√ßlenir
    - BTC yeni bir tepe yaparken ETH o tepeyi yapmazsa (daha d√º≈ü√ºk tepede kalƒ±rsa)
      = Gizli satƒ±≈ü g√ºc√º var, SHORT sinyali g√º√ßlenir
    
    Bu tek grafiƒüe bakarak g√∂r√ºlemeyen korelasyon kopukluƒüunu yakalar.
    """
    
    def __init__(self, lookback: int = 20):
        """
        Args:
            lookback: Swing high/low tespiti i√ßin geriye bakƒ±≈ü periyodu
        """
        self.lookback = lookback
        self.btc_prices = []  # (timestamp, high, low, close)
        self.eth_prices = []
        self.last_divergence = None
        self.divergence_time = 0
        
    def update_prices(self, btc_high: float, btc_low: float, btc_close: float,
                      eth_high: float, eth_low: float, eth_close: float):
        """BTC ve ETH fiyatlarƒ±nƒ± g√ºncelle."""
        now = datetime.now().timestamp()
        
        self.btc_prices.append({
            'ts': now, 'high': btc_high, 'low': btc_low, 'close': btc_close
        })
        self.eth_prices.append({
            'ts': now, 'high': eth_high, 'low': eth_low, 'close': eth_close
        })
        
        # Son 100 bar'ƒ± tut
        if len(self.btc_prices) > 100:
            self.btc_prices = self.btc_prices[-100:]
            self.eth_prices = self.eth_prices[-100:]
    
    def detect_divergence(self) -> dict:
        """
        SMT Divergence tespiti yap.
        
        Returns:
            {
                'divergence_type': 'BULLISH' | 'BEARISH' | None,
                'strength': float (0-1 arasƒ±),
                'score_bonus': int
            }
        """
        result = {
            'divergence_type': None,
            'strength': 0,
            'score_bonus': 0
        }
        
        if len(self.btc_prices) < self.lookback + 2:
            return result
        
        # Son lookback bar'daki swing high/low'larƒ± bul
        btc_highs = [p['high'] for p in self.btc_prices[-(self.lookback + 1):-1]]
        btc_lows = [p['low'] for p in self.btc_prices[-(self.lookback + 1):-1]]
        eth_highs = [p['high'] for p in self.eth_prices[-(self.lookback + 1):-1]]
        eth_lows = [p['low'] for p in self.eth_prices[-(self.lookback + 1):-1]]
        
        btc_swing_high = max(btc_highs)
        btc_swing_low = min(btc_lows)
        eth_swing_high = max(eth_highs)
        eth_swing_low = min(eth_lows)
        
        # Mevcut deƒüerler
        btc_current_high = self.btc_prices[-1]['high']
        btc_current_low = self.btc_prices[-1]['low']
        eth_current_high = self.eth_prices[-1]['high']
        eth_current_low = self.eth_prices[-1]['low']
        
        # BULLISH DIVERGENCE: BTC yeni dip yapƒ±yor, ETH yapmƒ±yor
        btc_new_low = btc_current_low < btc_swing_low
        eth_holds_low = eth_current_low > eth_swing_low
        
        if btc_new_low and eth_holds_low:
            # ETH ne kadar g√º√ßl√º tutuyor?
            eth_strength = (eth_current_low - eth_swing_low) / (eth_swing_high - eth_swing_low + 0.0001)
            strength = min(1.0, abs(eth_strength))
            
            result['divergence_type'] = 'BULLISH'
            result['strength'] = strength
            
            if strength > 0.5:
                result['score_bonus'] = 15
            elif strength > 0.3:
                result['score_bonus'] = 10
            else:
                result['score_bonus'] = 5
            
            self.last_divergence = result
            self.divergence_time = datetime.now().timestamp()
            return result
        
        # BEARISH DIVERGENCE: BTC yeni tepe yapƒ±yor, ETH yapmƒ±yor
        btc_new_high = btc_current_high > btc_swing_high
        eth_fails_high = eth_current_high < eth_swing_high
        
        if btc_new_high and eth_fails_high:
            # ETH ne kadar zayƒ±f?
            eth_weakness = (eth_swing_high - eth_current_high) / (eth_swing_high - eth_swing_low + 0.0001)
            strength = min(1.0, abs(eth_weakness))
            
            result['divergence_type'] = 'BEARISH'
            result['strength'] = strength
            
            if strength > 0.5:
                result['score_bonus'] = 15
            elif strength > 0.3:
                result['score_bonus'] = 10
            else:
                result['score_bonus'] = 5
            
            self.last_divergence = result
            self.divergence_time = datetime.now().timestamp()
            return result
        
        return result
    
    def get_signal_modifier(self, signal_side: str) -> tuple:
        """
        Divergence sonucuna g√∂re sinyal modifikasyonu d√∂nd√ºr.
        
        Returns:
            (score_modifier: int, reason: str)
        """
        # Son 5 dakika i√ßindeki divergence'ƒ± kullan
        if self.last_divergence and self.divergence_time > 0:
            age = datetime.now().timestamp() - self.divergence_time
            if age > 300:  # 5 dakikadan eski
                return 0, ""
            
            div_type = self.last_divergence.get('divergence_type')
            bonus = self.last_divergence.get('score_bonus', 0)
            
            # BULLISH divergence = LONG g√º√ßlenir
            if div_type == 'BULLISH' and signal_side == 'LONG':
                return bonus, f"SMT(BULL+{bonus}p)"
            
            # BEARISH divergence = SHORT g√º√ßlenir
            if div_type == 'BEARISH' and signal_side == 'SHORT':
                return bonus, f"SMT(BEAR+{bonus}p)"
            
            # Ters y√∂nde = ceza
            if div_type == 'BULLISH' and signal_side == 'SHORT':
                return -10, "SMT(BULL-10p)"
            
            if div_type == 'BEARISH' and signal_side == 'LONG':
                return -10, "SMT(BEAR-10p)"
        
        return 0, ""


# Global SMT Divergence Detector instance
smt_divergence_detector = SMTDivergenceDetector(lookback=20)


# ============================================================================
# PHASE 31: MULTI-COIN SCANNER
# ============================================================================

class CoinOpportunity:
    """Data class for coin opportunity information."""
    def __init__(self, symbol: str):
        self.symbol = symbol
        self.price: float = 0.0
        self.signal_score: int = 0
        self.signal_action: str = "NONE"  # LONG/SHORT/NONE
        self.zscore: float = 0.0
        self.hurst: float = 0.5
        self.spread_pct: float = 0.0  # ATR-based volatility % (legacy)
        self.bid_ask_spread_pct: float = 0.0  # Real bid-ask spread % (0 = not yet received)
        self.has_real_spread: bool = False
        self.imbalance: float = 0.0
        self.volume_24h: float = 0.0
        self.price_change_24h: float = 0.0
        self.last_signal_time: Optional[float] = None
        self.atr: float = 0.0
        self.last_update: float = 0.0
        self.leverage: int = 10  # Default leverage, updated by SignalGenerator
        self.pullback_pct: float = 0.0  # Pullback percentage for signal
        self.dynamic_trail_activation: float = 1.5  # Per-coin dynamic trail activation (ATR multiple)
        self.dynamic_trail_distance: float = 1.0  # Per-coin dynamic trail distance (ATR multiple)
        # Phase EQG + FIB: UI observability fields
        self.volume_ratio: float = 0.0
        self.is_volume_spike: bool = False
        self.ob_imbalance_trend: float = 0.0
        self.entry_quality_pass: bool = False
        self.entry_quality_reasons: list = []
        self.fib_active: bool = False
        self.fib_level: Optional[str] = None
        self.fib_bonus: int = 0
        self.fib_entry: float = 0.0
        self.fib_blend_alpha: float = 0.0
        self.entry_price: float = 0.0  # Backend ideal_entry price
    
    def to_dict(self) -> dict:
        return {
            "symbol": self.symbol,
            "price": self.price,
            "signalScore": self.signal_score,
            "signalAction": self.signal_action,
            "zscore": round(self.zscore, 2),
            "hurst": round(self.hurst, 2),
            "spreadPct": round(self.bid_ask_spread_pct, 4),  # Real bid-ask spread from WebSocket
            "hasRealSpread": bool(self.has_real_spread),  # True when real bid/ask data received
            "volatilityPct": round(self.spread_pct, 4),  # ATR-based volatility
            "imbalance": round(self.imbalance, 2),
            "volume24h": self.volume_24h,
            "priceChange24h": round(self.price_change_24h, 2),
            "lastSignalTime": self.last_signal_time,
            "atr": self.atr,
            "lastUpdate": self.last_update,
            "leverage": self.leverage,
            "pullbackPct": round(self.pullback_pct, 2),
            "dynamic_trail_activation": round(float(self.dynamic_trail_activation), 3),
            "dynamic_trail_distance": round(float(self.dynamic_trail_distance), 3),
            # Phase EQG + FIB: UI observability
            "volumeRatio": round(float(self.volume_ratio), 2),
            "isVolumeSpike": bool(self.is_volume_spike),
            "obImbalanceTrend": round(float(self.ob_imbalance_trend), 1),
            "entryQualityPass": bool(self.entry_quality_pass),
            "entryQualityReasons": list(self.entry_quality_reasons) if self.entry_quality_reasons else [],
            "fibActive": bool(self.fib_active),
            "fibLevel": self.fib_level,
            "fibBonus": int(self.fib_bonus),
            "fibEntry": round(float(self.fib_entry), 8) if self.fib_entry else 0,
            "fibBlendAlpha": float(self.fib_blend_alpha),
            "entryPriceBackend": round(float(self.entry_price), 8) if self.entry_price else 0,
        }


class LightweightCoinAnalyzer:
    """Lightweight analyzer for a single coin in multi-coin scanning."""
    
    def __init__(self, symbol: str):
        self.symbol = symbol
        self.ccxt_symbol = symbol.replace("USDT", "/USDT")
        self.prices: deque = deque(maxlen=200)
        self.highs: deque = deque(maxlen=200)
        self.lows: deque = deque(maxlen=200)
        self.closes: deque = deque(maxlen=200)
        self.volumes: deque = deque(maxlen=200)
        self.spreads: deque = deque(maxlen=100)
        self.opportunity = CoinOpportunity(symbol)
        self.signal_generator = SignalGenerator()
        self.signal_generator.min_signal_interval = 60  # 1 minute per coin in multi-scan mode
        self.is_preloaded = False  # Track if historical data is loaded
        
        # VWAP calculation variables
        self.vwap_numerator: float = 0.0
        self.vwap_denominator: float = 0.0
        self.vwap: float = 0.0
        
        # Coin-specific statistics for dynamic thresholds
        self.rsi_history: deque = deque(maxlen=100)  # Son 100 RSI deƒüeri
        self.volume_ratio_history: deque = deque(maxlen=100)  # Son 100 volume ratio
        self.hurst_history: deque = deque(maxlen=100)  # Son 100 Hurst deƒüeri
        
        # Phase 156: Order book imbalance trend tracking
        self.imbalance_history: deque = deque(maxlen=100)  # Son ~5 dk imbalance kaydƒ±
        
        # Phase 178: Tick aggregation for proper candle-like high/low/volume
        self._tick_high: float = 0.0
        self._tick_low: float = float('inf')
        self._tick_volume: float = 0.0
        self._tick_count: int = 0
        self._last_candle_time: float = 0.0
        self._candle_interval: int = 300  # 5-minute candles (matches preload)
    
    def get_coin_stats(self) -> dict:
        """
        Coin'e √∂zg√º istatistikleri d√∂nd√ºr.
        Bu deƒüerler konfirmasyon e≈üiklerini dinamik olarak ayarlamak i√ßin kullanƒ±lƒ±r.
        """
        stats = {
            'rsi_avg': 50.0,
            'rsi_std': 10.0,
            'volume_avg': 1.0,
            'volume_std': 0.5,
            'hurst_avg': 0.5,
            'hurst_std': 0.1,
            'sample_count': 0
        }
        
        if len(self.rsi_history) >= 10:
            rsi_arr = np.array(self.rsi_history)
            stats['rsi_avg'] = float(np.mean(rsi_arr))
            stats['rsi_std'] = float(np.std(rsi_arr))
        
        if len(self.volume_ratio_history) >= 10:
            vol_arr = np.array(self.volume_ratio_history)
            stats['volume_avg'] = float(np.mean(vol_arr))
            stats['volume_std'] = float(np.std(vol_arr))
        
        if len(self.hurst_history) >= 10:
            hurst_arr = np.array(self.hurst_history)
            stats['hurst_avg'] = float(np.mean(hurst_arr))
            stats['hurst_std'] = float(np.std(hurst_arr))
        
        stats['sample_count'] = min(len(self.rsi_history), len(self.volume_ratio_history), len(self.hurst_history))
        
        return stats
    
    def _get_imbalance_trend(self) -> float:
        """
        Phase 156: Son ~5 dk bid/ask imbalance trendi.
        Recent avg - Old avg = trend direction.
        > 0 ‚Üí alƒ±cƒ± baskƒ±sƒ± artƒ±yor (LONG'a bonus)
        < 0 ‚Üí satƒ±cƒ± baskƒ±sƒ± artƒ±yor (SHORT'a bonus)
        """
        if len(self.imbalance_history) < 20:
            return 0.0
        
        imb_list = list(self.imbalance_history)
        recent = imb_list[-10:]  # Son 10 tick
        older = imb_list[-30:-10] if len(imb_list) >= 30 else imb_list[:-10]
        
        if not older:
            return 0.0
        
        recent_avg = sum(recent) / len(recent)
        older_avg = sum(older) / len(older)
        
        return recent_avg - older_avg
    
    def get_daily_trend(self) -> tuple:
        """
        Coin'in kendi g√ºnl√ºk trendini hesapla.
        Mevcut closes verisinden son ~24 saat deƒüi≈üimini hesaplar.
        
        Returns:
            (trend: str, change_pct: float)
            trend: "STRONG_BULLISH", "BULLISH", "NEUTRAL", "BEARISH", "STRONG_BEARISH"
        """
        # 5 dakikalƒ±k mum kullanƒ±yorsak, 24 saat = ~288 mum
        # Ama muhtemelen daha az verimiz var, mevcut en eski veriden hesapla
        if len(self.closes) < 50:  # En az 50 bar (~4 saat 5m mumlarla)
            return "NEUTRAL", 0.0
        
        try:
            closes_list = list(self.closes)
            current = closes_list[-1]
            
            # Son 100 bar'ƒ±n ba≈üƒ±ndan kar≈üƒ±la≈ütƒ±r (yoksa en eski bar)
            lookback = min(100, len(closes_list) - 1)
            past_price = closes_list[-lookback]
            
            if past_price <= 0:
                return "NEUTRAL", 0.0
            
            change_pct = ((current - past_price) / past_price) * 100
            
            # Trend belirleme
            if change_pct > 5.0:
                return "STRONG_BULLISH", change_pct
            elif change_pct > 2.0:
                return "BULLISH", change_pct
            elif change_pct < -5.0:
                return "STRONG_BEARISH", change_pct
            elif change_pct < -2.0:
                return "BEARISH", change_pct
            else:
                return "NEUTRAL", change_pct
                
        except Exception as e:
            logger.warning(f"Daily trend calculation error for {self.symbol}: {e}")
            return "NEUTRAL", 0.0
    
    def calculate_volatility(self) -> tuple:
        """
        Close-to-close volatilite hesapla.
        Log return standard deviation kullanarak ger√ßek zamanlƒ± volatilite √∂l√ß√ºm√º.
        
        Returns:
            (volatility_pct: float, trail_multiplier: float)
            - volatility_pct: Yƒ±llƒ±k volatilite y√ºzdesi (0-200+)
            - trail_multiplier: Trail distance √ßarpanƒ± (0.6 - 2.0)
        """
        MIN_BARS = 20  # En az 20 bar gerekli
        
        if len(self.closes) < MIN_BARS:
            return 2.0, 1.0  # Yeterli veri yoksa varsayƒ±lan
        
        try:
            closes = list(self.closes)
            
            # Log returns hesapla: ln(close[i] / close[i-1])
            log_returns = []
            for i in range(1, len(closes)):
                if closes[i-1] > 0 and closes[i] > 0:
                    log_return = np.log(closes[i] / closes[i-1])
                    log_returns.append(log_return)
            
            if len(log_returns) < MIN_BARS - 1:
                return 2.0, 1.0
            
            # Volatilite = std(log_returns) * sqrt(bars_per_year)
            # 5 dakika mum ‚Üí 288 bar/g√ºn ‚Üí 105,120 bar/yƒ±l
            std_return = np.std(log_returns)
            annualized_vol = std_return * np.sqrt(105120) * 100  # Y√ºzde olarak
            
            # G√ºnl√ºk volatilite (daha pratik)
            daily_vol = std_return * np.sqrt(288) * 100  # % olarak
            
            # Trail √ßarpanƒ± hesapla
            # D√º≈ü√ºk volatilite (<%2 g√ºnl√ºk) = sƒ±kƒ± trail (0.6x)
            # Y√ºksek volatilite (>%8 g√ºnl√ºk) = geni≈ü trail (2.0x)
            if daily_vol < 1.5:
                trail_mult = 0.6   # BTC/ETH seviyesi - √ßok sƒ±kƒ±
            elif daily_vol < 3.0:
                trail_mult = 0.8   # Major altcoin
            elif daily_vol < 5.0:
                trail_mult = 1.0   # Normal
            elif daily_vol < 8.0:
                trail_mult = 1.4   # Volatil
            else:
                trail_mult = 2.0   # Meme coin - √ßok geni≈ü
            
            return daily_vol, trail_mult
            
        except Exception as e:
            logger.warning(f"Volatility calculation error for {self.symbol}: {e}")
            return 2.0, 1.0
    
    def preload_historical_data(self, ohlcv_data: list):
        """
        Preload historical OHLCV data for immediate Z-Score/Hurst calculation.
        
        Args:
            ohlcv_data: List of OHLCV candles [[timestamp, open, high, low, close, volume], ...]
        """
        if not ohlcv_data or len(ohlcv_data) < 20:
            return
        
        # Clear existing data
        self.prices.clear()
        self.highs.clear()
        self.lows.clear()
        self.closes.clear()
        self.volumes.clear()
        self.spreads.clear()
        
        # Load historical data
        for candle in ohlcv_data:
            try:
                _, open_price, high, low, close, volume = candle
                self.prices.append(close)
                self.closes.append(close)
                self.highs.append(high)
                self.lows.append(low)
                self.volumes.append(volume)
            except Exception:
                continue
        
        # Phase 114: Calculate spreads RETROACTIVELY after all candles are loaded
        # This ensures we get 20+ spreads if we have 40+ candles
        closes_list = list(self.closes)
        for i in range(19, len(closes_list)):  # Start from index 19 (20th candle)
            ma = np.mean(closes_list[max(0, i-19):i+1])  # 20-period MA ending at position i
            spread = closes_list[i] - ma
            self.spreads.append(spread)
        
        if len(self.prices) > 0:
            self.opportunity.price = self.prices[-1]
            self.opportunity.last_update = datetime.now().timestamp()
            self.is_preloaded = True
            # Phase 205: Set initial candle close from preloaded data
            last_candle_close[self.symbol] = self.prices[-1]
            
            # Preload VWAP from historical data
            self.vwap_numerator = 0.0
            self.vwap_denominator = 0.0
            for i, candle in enumerate(ohlcv_data):
                try:
                    _, _, high, low, close, volume = candle
                    typical_price = (high + low + close) / 3
                    self.vwap_numerator += typical_price * volume
                    self.vwap_denominator += volume
                except:
                    continue
            if self.vwap_denominator > 0:
                self.vwap = self.vwap_numerator / self.vwap_denominator
            
            logger.info(f"üìä {self.symbol}: Preloaded {len(self.prices)} candles, spreads={len(self.spreads)}")
        
    def update_price(self, price: float, high: float = None, low: float = None, volume: float = 0):
        """
        Update price data with tick aggregation for proper candle construction.
        
        Phase 178: Instead of appending 24H high/low from WS ticker every tick,
        accumulate ticks and create proper 5-minute candles with real per-candle
        high/low/volume data. This fixes ATR/ADX inflation.
        """
        now = datetime.now().timestamp()
        
        # Always update display price immediately
        self.opportunity.price = price
        self.opportunity.last_update = now
        
        # Track tick min/max/volume within current candle window
        self._tick_high = max(self._tick_high, price)
        if self._tick_low == float('inf'):
            self._tick_low = price
        else:
            self._tick_low = min(self._tick_low, price)
        self._tick_volume += volume
        self._tick_count += 1
        
        # Initialize candle timer on first call
        if self._last_candle_time == 0:
            self._last_candle_time = now
        
        # Close candle every _candle_interval seconds
        elapsed = now - self._last_candle_time
        if elapsed >= self._candle_interval and self._tick_count > 1:
            # Append completed candle data
            self.prices.append(price)
            self.closes.append(price)
            self.highs.append(self._tick_high)
            self.lows.append(self._tick_low)
            self.volumes.append(self._tick_volume)
            
            # Phase 205: Update global candle close price for exit decisions
            last_candle_close[self.symbol] = price
            
            # Update VWAP with proper candle data (Typical Price = (H+L+C)/3)
            typical_price = (self._tick_high + self._tick_low + price) / 3
            self.vwap_numerator += typical_price * self._tick_volume
            self.vwap_denominator += self._tick_volume
            if self.vwap_denominator > 0:
                self.vwap = self.vwap_numerator / self.vwap_denominator
            
            # Phase 115: Smart spreads calculation
            closes_len = len(self.closes)
            if closes_len >= 20:
                if closes_len >= 40 and len(self.spreads) < 20:
                    # Retroactively calculate all spreads
                    self.spreads.clear()
                    closes_list = list(self.closes)
                    for i in range(19, len(closes_list)):
                        ma = np.mean(closes_list[max(0, i-19):i+1])
                        spread = closes_list[i] - ma
                        self.spreads.append(spread)
                    logger.info(f"üìä {self.symbol}: Retroactive spreads calculated - closes={closes_len}, spreads={len(self.spreads)}")
                else:
                    # Normal incremental spread calculation
                    ma = np.mean(list(self.closes)[-20:])
                    spread = price - ma
                    self.spreads.append(spread)
            
            # Reset tick accumulators for next candle
            self._tick_high = price
            self._tick_low = price
            self._tick_volume = 0.0
            self._tick_count = 0
            self._last_candle_time = now
    
    def analyze(self, imbalance: float = 0, basis_pct: float = 0.0) -> Optional[dict]:
        """Analyze coin and generate signal if conditions met."""
        # PHASE 103: Debug analyzer.analyze() calls
        if not hasattr(self, '_analyze_count'):
            self._analyze_count = 0
        self._analyze_count += 1
        if self._analyze_count % 500 == 1:
            logger.info(f"üîç ANALYZE #{self._analyze_count}: {self.symbol} prices={len(self.prices)}")
        
        if len(self.prices) < 20:  # Reduced from 50 to 20 for faster startup
            return None
            
        prices_list = list(self.prices)
        highs_list = list(self.highs)
        lows_list = list(self.lows)
        closes_list = list(self.closes)
        
        # Calculate metrics
        # Phase 124: Adjust Hurst window for small samples (<50 candles)
        min_window = 5 if len(prices_list) < 50 else 10
        hurst = calculate_hurst(prices_list, min_window=min_window)
        
        # Phase 128: Log Hurst value for each coin (periodically to avoid spam)
        if self._analyze_count <= 5 or self._analyze_count % 100 == 0:
            logger.info(f"üìà HURST: {self.symbol} H={hurst:.3f} (prices={len(prices_list)}, min_win={min_window})")
        
        # Phase 122: Calculate Z-Score - lowered threshold to 20 closes for faster activation
        closes_count = len(self.closes)
        if closes_count >= 20:
            # Phase 125: Start calculating spreads from index 9 (using 10-period MA initially)
            # This allows us to have ~11 spreads when we hit 20 closes, ensuring immediate Z-Score
            closes_list = list(self.closes)
            temp_spreads = []
            for i in range(9, len(closes_list)):
                ma = np.mean(closes_list[max(0, i-19):i+1])
                spread = closes_list[i] - ma
                temp_spreads.append(spread)
            
            # Phase 122: Lowered from 20 to 5 spreads for faster activation
            # With 25 closes we get 6 spreads (index 19-24), enough for Z-Score
            if len(temp_spreads) >= 5:
                # Phase 124: Pass explicit lookback to override default 20
                zscore = calculate_zscore(temp_spreads, lookback=len(temp_spreads))
            else:
                zscore = 0
        else:
            zscore = 0
            if hasattr(self, '_zscore_debug_count'):
                self._zscore_debug_count += 1
            else:
                self._zscore_debug_count = 0
            if self._zscore_debug_count % 100 == 0:
                logger.info(f"üìä ZSCORE_DEBUG: {self.symbol} closes={closes_count}/40 needed")
        atr = calculate_atr(highs_list, lows_list, closes_list)
        
        # Phase 137: Calculate ADX for regime detection - now returns tuple with trend direction
        adx, adx_trend, plus_di, minus_di = calculate_adx(highs_list, lows_list, closes_list)
        
        # Phase 193: Calculate enhanced indicators (MACD, BB, StochRSI, EMA cross)
        enhanced_ind = calculate_enhanced_indicators(
            highs_list, lows_list, closes_list,
            volumes=list(self.volumes) if len(self.volumes) >= 30 else None
        )
        
        self.opportunity.hurst = hurst
        self.opportunity.zscore = zscore
        self.opportunity.atr = atr
        self.opportunity.adx = adx  # Phase 137: ADX for regime detection
        self.opportunity.adx_trend = adx_trend  # Trend direction: BULLISH/BEARISH/NEUTRAL
        self.opportunity.imbalance = imbalance
        
        # Phase 156: Record imbalance for short-term trend tracking
        self.imbalance_history.append(imbalance)
        
        # Phase 35: Calculate volatility as ATR percentage of price
        # This is the TRUE volatility measure - no artificial capping
        # BTC typically ~1.5%, SOL ~2.5%, DOGE ~4%, meme coins 5%+
        if atr > 0 and self.opportunity.price > 0:
            volatility_pct = (atr / self.opportunity.price) * 100
            self.opportunity.spread_pct = volatility_pct  # Store actual volatility %
        
        # Calculate VWAP Z-Score for Layer 3 scoring
        vwap_zscore = 0.0
        if self.vwap > 0 and len(prices_list) >= 20:
            price_std = np.std(prices_list[-20:])
            if price_std > 0:
                vwap_zscore = (self.opportunity.price - self.vwap) / price_std
        
        # Get HTF trend from global BTC filter for Layer 4 scoring
        htf_trend = "NEUTRAL"
        try:
            if 'btc_filter' in globals() and btc_filter is not None:
                htf_trend = btc_filter.btc_trend or "NEUTRAL"
        except:
            pass
        
        # Calculate RSI for Layer 10 scoring
        rsi_value = 50.0  # Default neutral
        if len(prices_list) >= 15:
            rsi_value = calculate_rsi(prices_list, period=14)
        
        # Calculate Volume Ratio for Layer 11 scoring
        # Phase XXX: Re-enabled volume spike detection for breakout warning
        volume_ratio = 1.0
        is_volume_spike = False
        if len(self.volumes) >= 21:
            is_volume_spike, volume_ratio = detect_volume_spike(list(self.volumes), lookback=20, threshold=2.0)
        
        # Update coin-specific statistics for dynamic thresholds
        self.rsi_history.append(rsi_value)
        self.volume_ratio_history.append(volume_ratio)
        self.hurst_history.append(hurst)
        
        # Get coin stats for dynamic threshold calculation
        coin_stats = self.get_coin_stats()
        
        # Detect Liquidity Sweep / SFP for Layer 13
        sweep_result = None
        if len(self.highs) >= 22 and len(self.lows) >= 22:
            sweep_result = liquidity_sweep_detector.detect_sweep(
                list(self.highs), list(self.lows), prices_list
            )
        # Get coin's own daily trend (not BTC's)
        coin_daily_trend, coin_daily_change = self.get_daily_trend()
        
        # Phase 177: Use real bid-ask spread, conservative fallback (0.10%) if not yet received
        effective_spread = self.opportunity.bid_ask_spread_pct if self.opportunity.has_real_spread else 0.10
        
        # Phase FIB: Build Fibonacci context for Cloud Scanner (OHLCV already cached by update_coin_trend)
        cs_fib_context = None
        if FIB_ENABLED:
            try:
                trend_data = mtf_confirmation.coin_trends.get(self.symbol, {}) if 'mtf_confirmation' in globals() else {}
                if trend_data:
                    # Pre-determine signal side from z-score direction (not threshold)
                    # P2 fix: actual threshold is dynamic (effective_threshold), so just use direction
                    pre_side = 'LONG' if zscore < 0 else ('SHORT' if zscore > 0 else None)
                    if pre_side:
                        cs_fib_context = build_fib_context(
                            signal_side=pre_side,
                            price=self.opportunity.price,
                            atr=atr,
                            adx=adx,
                            hurst=hurst,
                            trend_data=trend_data,
                            sweep_result=sweep_result,
                        )
            except Exception as fib_err:
                logger.debug(f"FIB context error in scanner: {fib_err}")
        
        # Generate signal with VWAP, HTF trend, Basis, Whale, RSI, Volume, Sweep, CoinStats, DailyTrend, ADX
        signal = self.signal_generator.generate_signal(
            hurst=hurst,
            zscore=zscore,
            imbalance=imbalance,
            price=self.opportunity.price,
            atr=atr,
            spread_pct=effective_spread,
            vwap_zscore=vwap_zscore,
            htf_trend=htf_trend,
            basis_pct=basis_pct,
            symbol=self.symbol,  # For liquidation cascade lookup
            whale_zscore=whale_tracker.get_whale_zscore(self.symbol),  # Whale activity
            rsi=rsi_value,  # RSI for Layer 10
            volume_ratio=volume_ratio,  # Volume spike for Layer 11
            sweep_result=sweep_result,  # Liquidity Sweep for Layer 13
            coin_stats=coin_stats,  # Coin-specific statistics for dynamic thresholds
            coin_daily_trend=coin_daily_trend,  # Coin's own daily trend (not BTC's)
            volume_24h=self.opportunity.volume_24h,  # Phase 123: Pass 24h volume
            adx=adx,  # ADX value for trend strength
            adx_trend=adx_trend,  # Trend direction: BULLISH/BEARISH/NEUTRAL
            is_volume_spike=is_volume_spike,  # Volume breakout detection
            market_regime=market_regime_detector.current_regime if 'market_regime_detector' in globals() else 'RANGING',
            ob_imbalance_trend=self._get_imbalance_trend(),  # Phase 156: Short-term OB flow
            funding_rate=funding_oi_tracker.funding_rates.get(self.symbol, 0.0),  # Phase 157
            coin_wr_penalty=trade_pattern_analyzer.get_coin_penalty(self.symbol),  # Phase 157
            side_wr_penalty=0,  # Phase 157: calculated inside generate_signal where signal_side is known
            enhanced_indicators=enhanced_ind,  # Phase 193: MACD, BB, StochRSI, EMA cross
            fib_context=cs_fib_context,  # Phase FIB: Fibonacci context
        )
        
        if signal:
            self.opportunity.signal_score = signal.get('confidenceScore', 0)
            self.opportunity.signal_action = signal.get('action', 'NONE')
            self.opportunity.leverage = signal.get('leverage', 10)
            self.opportunity.pullback_pct = signal.get('pullbackPct', 0)
            self.opportunity.dynamic_trail_activation = signal.get('dynamic_trail_activation', 1.5)
            self.opportunity.dynamic_trail_distance = signal.get('dynamic_trail_distance', 1.0)
            self.opportunity.last_signal_time = datetime.now().timestamp()
            # Phase EQG + FIB: Store observability fields
            self.opportunity.volume_ratio = signal.get('volumeRatio', 0)
            self.opportunity.is_volume_spike = signal.get('isVolumeSpike', False)
            self.opportunity.ob_imbalance_trend = signal.get('obImbalanceTrend', 0)
            self.opportunity.entry_quality_pass = signal.get('entryQualityPass', False)
            self.opportunity.entry_quality_reasons = signal.get('entryQualityReasons', [])
            self.opportunity.fib_active = signal.get('fibActive', False)
            self.opportunity.fib_level = signal.get('fibLevel')
            self.opportunity.fib_bonus = signal.get('fibBonus', 0)
            self.opportunity.fib_entry = signal.get('fibEntry', 0)
            self.opportunity.fib_blend_alpha = signal.get('fibBlendAlpha', 0)
            self.opportunity.entry_price = signal.get('entryPrice', 0) or signal.get('entry', 0)
            return signal
        else:
            # Decay signal score over time if no new signal
            if self.opportunity.last_signal_time:
                elapsed = datetime.now().timestamp() - self.opportunity.last_signal_time
                if elapsed > 300:  # 5 minutes
                    self.opportunity.signal_score = 0
                    self.opportunity.signal_action = "NONE"
            
        return None


class BinanceWebSocketManager:
    """
    Binance Futures WebSocket Manager for real-time ticker data.
    Uses !ticker@arr stream for all market tickers.
    """
    
    def __init__(self):
        self.ws = None
        self.tickers: Dict[str, dict] = {}
        self.running = False
        self.connected = False
        self.last_update = 0
        self.ws_url = "wss://fstream.binance.com/ws/!ticker@arr"  # Phase 228: bookTicker via REST instead
        self._reconnect_task = None
        # Phase 191: Callback pattern for real-time position updates
        self.position_symbols: set = set()  # Aktif pozisyonlu semboller
        self.on_price_update = None  # async callback(symbol, ticker_data)
        self._pending_updates: list = []  # Bekleyen callback √ßaƒürƒ±larƒ±
        logger.info("BinanceWebSocketManager initialized (Phase 191: callback support)")
    
    async def connect(self):
        """Connect to Binance Futures WebSocket."""
        import websockets
        
        while self.running:
            try:
                logger.info(f"Connecting to Binance WebSocket: {self.ws_url}")
                async with websockets.connect(self.ws_url, ping_interval=20, ping_timeout=10) as ws:
                    self.ws = ws
                    self.connected = True
                    logger.info("Connected to Binance WebSocket")
                    
                    async for message in ws:
                        if not self.running:
                            break
                        
                        try:
                            data = json.loads(message)
                            if isinstance(data, list):
                                self._process_ticker_message(data)
                            
                            # Phase 191: Process pending position price updates
                            if self._pending_updates:
                                updates = self._pending_updates.copy()
                                self._pending_updates.clear()
                                for sym, tick in updates:
                                    try:
                                        await self.on_price_update(sym, tick)
                                    except Exception as cb_err:
                                        logger.debug(f"WS callback error {sym}: {cb_err}")
                        except json.JSONDecodeError:
                            continue
                            
            except Exception as e:
                logger.error(f"Binance WebSocket error: {e}")
                self.connected = False
                if self.running:
                    await asyncio.sleep(5)  # Reconnect after 5 seconds
    
    def _process_ticker_message(self, data: list):
        """Process ticker array message from Binance."""
        if not isinstance(data, list):
            return
            
        for ticker in data:
            symbol = ticker.get('s', '')  # Symbol
            if not symbol.endswith('USDT'):
                continue
                
            # Calculate simple imbalance from bid/ask quantities (may be 0 for futures ticker)
            bid_qty = float(ticker.get('B', 0))  # Best bid quantity
            ask_qty = float(ticker.get('A', 0))  # Best ask quantity
            
            # Preserve existing bid/ask from bookTicker (futures ticker@arr doesn't have b/a)
            existing = self.tickers.get(symbol, {})
            
            self.tickers[symbol] = {
                'last': float(ticker.get('c', 0)),  # Close price
                'percentage': float(ticker.get('P', 0)),  # Price change percent
                'quoteVolume': float(ticker.get('q', 0)),  # Quote volume (USDT)
                'baseVolume': float(ticker.get('v', 0)),  # Base asset volume (Phase 178)
                'high': float(ticker.get('h', 0)),  # High
                'low': float(ticker.get('l', 0)),  # Low
                'bid': existing.get('bid', 0),  # Preserved from bookTicker
                'ask': existing.get('ask', 0),  # Preserved from bookTicker
                'bidQty': existing.get('bidQty', bid_qty),  # Preserved from bookTicker
                'askQty': existing.get('askQty', ask_qty),  # Preserved from bookTicker
                'imbalance': existing.get('imbalance', 0),  # Preserved from bookTicker
                'timestamp': int(ticker.get('E', 0))  # Event time
            }
        
        # Phase 178: SMT Divergence moved to update_btc_eth_state() for candle-based data
        # Using 24H high/low from ticker gave false swing high/low detection
        
        self.last_update = datetime.now().timestamp()
        
        # Phase 191: Queue position price callbacks for async processing
        if self.on_price_update and self.position_symbols:
            for ticker in data:
                sym = ticker.get('s', '')
                if sym in self.position_symbols:
                    self._pending_updates.append((sym, self.tickers[sym]))

    # Phase 228: _process_book_ticker removed ‚Äî using REST API instead (see CloudScanner.fetch_book_tickers)
    
    def get_tickers(self, symbols: list = None) -> dict:
        """Get current ticker data for specified symbols."""
        if symbols is None:
            return self.tickers
        
        return {s: self.tickers[s] for s in symbols if s in self.tickers}
    
    async def start(self):
        """Start WebSocket connection."""
        self.running = True
        asyncio.create_task(self.connect())
    
    async def stop(self):
        """Stop WebSocket connection."""
        self.running = False
        self.connected = False
        if self.ws:
            await self.ws.close()


# Global WebSocket manager
binance_ws_manager = BinanceWebSocketManager()


# ============================================================================
# LIQUIDATION CASCADE TRACKER
# ============================================================================

class LiquidationTracker:
    """
    Tracks real-time liquidations from Binance Futures.
    Detects cascade events (>$100K in 30 seconds) for signal scoring.
    
    WebSocket: wss://fstream.binance.com/ws/!forceOrder@arr
    """
    
    def __init__(self):
        self.ws = None
        self.running = False
        self.connected = False
        # symbol -> list of {timestamp, side, qty_usd}
        self.recent_liquidations: Dict[str, list] = {}
        self.cascade_threshold = 100000  # $100K threshold
        self.cascade_window = 30  # 30 seconds window
        self.total_liquidations = 0
        logger.info("üíÄ LiquidationTracker initialized")
    
    async def connect(self):
        """Connect to Binance Liquidation WebSocket stream."""
        try:
            url = "wss://fstream.binance.com/ws/!forceOrder@arr"
            self.ws = await websockets.connect(url, ping_interval=180, ping_timeout=30)
            self.connected = True
            self.running = True
            logger.info("‚úÖ Liquidation WebSocket connected")
            
            asyncio.create_task(self._listen())
            
        except Exception as e:
            logger.error(f"Liquidation WebSocket connection failed: {e}")
            self.connected = False
    
    async def _listen(self):
        """Listen for liquidation events."""
        while self.running and self.ws:
            try:
                msg = await asyncio.wait_for(self.ws.recv(), timeout=60)
                data = json.loads(msg)
                await self._process_liquidation(data)
            except asyncio.TimeoutError:
                continue
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Liquidation WebSocket disconnected")
                self.connected = False
                break
            except Exception as e:
                logger.debug(f"Liquidation stream error: {e}")
    
    async def _process_liquidation(self, data: dict):
        """Process a liquidation event."""
        try:
            # Format: {"e":"forceOrder","E":timestamp,"o":{order details}}
            if data.get('e') != 'forceOrder':
                return
            
            order = data.get('o', {})
            symbol = order.get('s', '')  # e.g., "BTCUSDT"
            side = order.get('S', '')  # "BUY" or "SELL"
            qty = float(order.get('q', 0))  # Original quantity
            price = float(order.get('p', 0))  # Price
            
            usd_value = qty * price
            now = datetime.now().timestamp()
            
            # Store liquidation
            if symbol not in self.recent_liquidations:
                self.recent_liquidations[symbol] = []
            
            self.recent_liquidations[symbol].append({
                'timestamp': now,
                'side': side,
                'usd': usd_value
            })
            
            self.total_liquidations += 1
            
            # Cleanup old entries (keep last 60 seconds)
            cutoff = now - 60
            for sym in list(self.recent_liquidations.keys()):
                self.recent_liquidations[sym] = [
                    l for l in self.recent_liquidations[sym] 
                    if l['timestamp'] > cutoff
                ]
                if not self.recent_liquidations[sym]:
                    del self.recent_liquidations[sym]
            
            # Log significant liquidations
            if usd_value > 50000:
                logger.info(f"üíÄ LIQD: {symbol} {side} ${usd_value:,.0f}")
                
        except Exception as e:
            logger.debug(f"Liquidation processing error: {e}")
    
    def get_cascade_score(self, symbol: str, signal_side: str) -> tuple:
        """
        Calculate cascade score for a symbol.
        
        Returns: (score, reason)
        - Score: 0-15 points
        - Reason: Description for logging
        """
        now = datetime.now().timestamp()
        cutoff = now - self.cascade_window
        
        if symbol not in self.recent_liquidations:
            return 0, ""
        
        # Calculate total liquidation value in window
        longs_liq = 0  # BUY = closing a short (short squeezed)
        shorts_liq = 0  # SELL = closing a long (long liquidated)
        
        for liq in self.recent_liquidations[symbol]:
            if liq['timestamp'] > cutoff:
                if liq['side'] == 'BUY':
                    longs_liq += liq['usd']
                else:
                    shorts_liq += liq['usd']
        
        # Logic:
        # If LONG signal and lots of shorts being liquidated (BUY orders) = bullish cascade
        # If SHORT signal and lots of longs being liquidated (SELL orders) = bearish cascade
        
        if signal_side == "LONG" and longs_liq > self.cascade_threshold:
            # Short squeeze happening - bullish
            return 15, f"LIQD(short-squeeze ${longs_liq:,.0f})"
        elif signal_side == "SHORT" and shorts_liq > self.cascade_threshold:
            # Long liquidation cascade - bearish
            return 15, f"LIQD(long-cascade ${shorts_liq:,.0f})"
        
        # Partial points for smaller cascades
        relevant_liq = longs_liq if signal_side == "LONG" else shorts_liq
        if relevant_liq > 50000:
            return 10, f"LIQD(${relevant_liq:,.0f})"
        elif relevant_liq > 20000:
            return 5, f"LIQD(${relevant_liq:,.0f})"
        
        return 0, ""
    
    def get_stats(self) -> dict:
        """Get tracker statistics."""
        return {
            "connected": self.connected,
            "total_tracked": self.total_liquidations,
            "active_symbols": len(self.recent_liquidations)
        }
    
    async def start(self):
        """Start the liquidation tracker."""
        await self.connect()
    
    async def stop(self):
        """Stop the liquidation tracker."""
        self.running = False
        self.connected = False
        if self.ws:
            await self.ws.close()


# Global Liquidation Tracker
liquidation_tracker = LiquidationTracker()


# ============================================================================
# WHALE ACTIVITY TRACKER
# ============================================================================

class WhaleTracker:
    """
    Tracks large trade activity (whale movements) per symbol.
    
    Uses volume spikes to detect whale activity:
    - Tracks volume over rolling windows
    - Calculates Z-score of recent volume vs average
    - Positive Z-score = high buying volume (bullish whale)
    - Negative Z-score = high selling volume (bearish whale)
    """
    
    def __init__(self):
        # symbol -> {volumes: deque, buy_volumes: deque, sell_volumes: deque, last_price: float}
        self.symbol_data: Dict[str, dict] = {}
        self.volume_window = 20  # Rolling window for Z-score
        self.whale_threshold_usd = 50000  # $50K+ trade = whale
        logger.info("üêã WhaleTracker initialized")
    
    def update(self, symbol: str, price: float, volume: float, price_change_pct: float):
        """
        Update whale tracking with new ticker data.
        
        Args:
            symbol: Trading symbol (e.g., "BTCUSDT")
            price: Current price
            volume: Recent volume in base currency
            price_change_pct: Recent price change percentage
        """
        if symbol not in self.symbol_data:
            self.symbol_data[symbol] = {
                'volumes': deque(maxlen=self.volume_window),
                'volume_changes': deque(maxlen=self.volume_window),
                'last_volume': 0,
                'last_update': 0
            }
        
        data = self.symbol_data[symbol]
        now = datetime.now().timestamp()
        
        # Skip if updated too recently (< 1 second)
        if now - data.get('last_update', 0) < 1:
            return
        
        volume_usd = volume * price
        
        # Track volume change with direction from price change
        # Positive price change + high volume = whale buying
        # Negative price change + high volume = whale selling
        if data['last_volume'] > 0 and volume_usd > self.whale_threshold_usd:
            volume_delta = volume_usd - data['last_volume']
            # Sign volume delta by price direction
            if price_change_pct > 0:
                data['volume_changes'].append(volume_delta)  # Positive = buy pressure
            else:
                data['volume_changes'].append(-abs(volume_delta))  # Negative = sell pressure
        
        data['volumes'].append(volume_usd)
        data['last_volume'] = volume_usd
        data['last_update'] = now
    
    def get_whale_zscore(self, symbol: str) -> float:
        """
        Calculate whale Z-score for a symbol.
        
        Returns:
            Z-score: positive = whale buying, negative = whale selling
        """
        if symbol not in self.symbol_data:
            return 0.0
        
        data = self.symbol_data[symbol]
        changes = list(data.get('volume_changes', []))
        
        if len(changes) < 5:
            return 0.0
        
        # Calculate Z-score of recent volume changes
        mean = sum(changes) / len(changes)
        if len(changes) < 2:
            return 0.0
        
        variance = sum((x - mean) ** 2 for x in changes) / len(changes)
        std = variance ** 0.5
        
        if std < 1:
            return 0.0
        
        # Get most recent values (last 3)
        recent = changes[-3:]
        recent_mean = sum(recent) / len(recent)
        
        zscore = (recent_mean - mean) / std
        return round(max(-5, min(5, zscore)), 2)  # Clamp to [-5, 5]
    
    def get_stats(self) -> dict:
        """Get tracker statistics."""
        return {
            "tracked_symbols": len(self.symbol_data),
            "active_whales": sum(
                1 for s in self.symbol_data.values() 
                if len(s.get('volume_changes', [])) > 5
            )
        }


# Global Whale Tracker
whale_tracker = WhaleTracker()


# ============================================================================
# PHASE 157: FUNDING RATE + OPEN INTEREST TRACKER
# Binance premiumIndex API'den funding rate √ßeker, sinyal skorlamasƒ±nda kullanƒ±r.
# ============================================================================

class FundingOITracker:
    """
    Phase 157: Funding Rate + Open Interest tracker.
    
    Funding Rate:
    - Pozitif (+) = √ßoƒüunluk LONG ‚Üí SHORT sinyali g√º√ßlenir (contrarian)
    - Negatif (-) = √ßoƒüunluk SHORT ‚Üí LONG sinyali g√º√ßlenir (contrarian)
    - Extreme (>0.08% veya <-0.08%) = kalabalƒ±kla aynƒ± y√∂ne sinyal VETOlanƒ±r
    
    5 dk cache ‚Äî her √ßaƒürƒ±da API'ye gitmez.
    """
    
    def __init__(self):
        self.funding_rates: Dict[str, float] = {}  # symbol -> funding rate
        self.last_fetch_time: float = 0
        self.fetch_interval: float = 300  # 5 dakika
        self.fetch_count: int = 0
        self.last_error: str = ""
        logger.info("üí∞ FundingOITracker initialized (Phase 157)")
    
    async def fetch_funding_rates(self, exchange) -> bool:
        """T√ºm coinlerin funding rate'ini tek API √ßaƒürƒ±sƒ±yla √ßek."""
        now = datetime.now().timestamp()
        if now - self.last_fetch_time < self.fetch_interval:
            return True  # Cache hala ge√ßerli
        
        try:
            # Binance premiumIndex ‚Äî tek √ßaƒürƒ±da t√ºm coinler
            response = await exchange.fetch(
                'https://fapi.binance.com/fapi/v1/premiumIndex'
            )
            
            if isinstance(response, list):
                for item in response:
                    symbol = item.get('symbol', '')
                    if symbol.endswith('USDT'):
                        rate = float(item.get('lastFundingRate', 0))
                        self.funding_rates[symbol] = rate
                
                self.last_fetch_time = now
                self.fetch_count += 1
                self.last_error = ""
                
                if self.fetch_count <= 3 or self.fetch_count % 20 == 0:
                    # Sample: BTC funding
                    btc_rate = self.funding_rates.get('BTCUSDT', 0)
                    logger.info(f"üí∞ Funding rates updated: {len(self.funding_rates)} coins | BTC={btc_rate*100:.4f}% | fetch #{self.fetch_count}")
                
                return True
            
        except Exception as e:
            self.last_error = str(e)[:100]
            if self.fetch_count < 5:
                logger.warning(f"üí∞ Funding rate fetch error: {self.last_error}")
            return False
        
        return False
    
    def get_funding_signal(self, symbol: str, signal_side: str) -> tuple:
        """
        Funding rate'e g√∂re sinyal bonus/penalty/veto d√∂nd√ºr.
        
        Returns:
            (score_adjustment: int, reason: str, should_veto: bool)
        """
        rate = self.funding_rates.get(symbol, 0)
        
        if rate == 0:
            return (0, "", False)
        
        rate_pct = rate * 100  # Y√ºzdeye √ßevir
        abs_rate = abs(rate_pct)
        
        # EXTREME funding ‚Äî kalabalƒ±kla aynƒ± y√∂nde sinyal VETOla
        if abs_rate > 0.08:
            if rate_pct > 0 and signal_side == "LONG":
                # Herkes LONG + biz de LONG = tehlikeli
                return (-15, f"FR_EXTREME(+{rate_pct:.3f}%)", True)
            elif rate_pct < 0 and signal_side == "SHORT":
                # Herkes SHORT + biz de SHORT = tehlikeli
                return (-15, f"FR_EXTREME({rate_pct:.3f}%)", True)
            elif rate_pct > 0 and signal_side == "SHORT":
                # Herkes LONG + biz SHORT = contrarian squeeze oynamasƒ±
                return (10, f"FR_SQUEEZE(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                # Herkes SHORT + biz LONG = contrarian squeeze oynamasƒ±
                return (10, f"FR_SQUEEZE({rate_pct:.3f}%)", False)
        
        # Y√ºksek funding ‚Äî contrarian bonus
        if abs_rate > 0.03:
            if rate_pct > 0 and signal_side == "SHORT":
                return (8, f"FR_HIGH(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                return (8, f"FR_HIGH({rate_pct:.3f}%)", False)
            elif rate_pct > 0 and signal_side == "LONG":
                return (-5, f"FR_CROWD(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "SHORT":
                return (-5, f"FR_CROWD({rate_pct:.3f}%)", False)
        
        # Normal funding ‚Äî hafif contrarian bonus
        if abs_rate > 0.01:
            if rate_pct > 0 and signal_side == "SHORT":
                return (3, f"FR(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                return (3, f"FR({rate_pct:.3f}%)", False)
        
        return (0, "", False)
    
    def get_status(self) -> dict:
        """Tracker durumunu d√∂nd√ºr."""
        return {
            "coins_tracked": len(self.funding_rates),
            "last_fetch": self.last_fetch_time,
            "fetch_count": self.fetch_count,
            "last_error": self.last_error,
            "btc_funding": self.funding_rates.get('BTCUSDT', 0) * 100,
            "eth_funding": self.funding_rates.get('ETHUSDT', 0) * 100,
        }

# Global Funding+OI Tracker
funding_oi_tracker = FundingOITracker()


# ============================================================================
# PHASE 157: TRADE PATTERN ANALYZER
# Kapanmƒ±≈ü trade'lerden √∂ƒürenme ‚Äî coin/saat/side bazlƒ± WR analizi.
# ============================================================================

class TradePatternAnalyzer:
    """
    Phase 157: Kapanmƒ±≈ü trade pattern analizi.
    
    Hangi ko≈üullarda kazanƒ±yoruz/kaybediyoruz sorusuna sistematik cevap.
    Min 20 trade gerektirir ‚Äî yetersiz veriyle penalty uygulanmaz.
    """
    
    MIN_TRADES = 20  # Minimum trade sayƒ±sƒ±
    MIN_COIN_TRADES = 5  # Coin bazlƒ± minimum
    
    def __init__(self):
        self.last_analysis = None
        self.coin_wr: Dict[str, dict] = {}  # symbol -> {wins, losses, wr}
        self.hour_wr: Dict[int, dict] = {}  # hour -> {wins, losses, wr}
        self.side_wr: Dict[str, dict] = {}  # LONG/SHORT -> {wins, losses, wr}
        self.score_bins: Dict[str, dict] = {}  # score_range -> {wins, losses, wr}
        self.analysis_time: float = 0
        self.analysis_interval: float = 3600  # 1 saat
        logger.info("üìä TradePatternAnalyzer initialized (Phase 157)")
    
    def analyze(self, trades: list) -> dict:
        """Kapanmƒ±≈ü trade pattern analizi."""
        now = datetime.now().timestamp()
        if now - self.analysis_time < self.analysis_interval and self.last_analysis:
            return self.last_analysis
        
        if len(trades) < self.MIN_TRADES:
            return {"status": "insufficient_data", "trades_needed": self.MIN_TRADES - len(trades)}
        
        # Son 100 trade'i analiz et
        recent = trades[-100:] if len(trades) > 100 else trades
        
        # Coin bazlƒ± WR
        self.coin_wr = {}
        for t in recent:
            sym = t.get('symbol', 'UNKNOWN')
            pnl = t.get('pnl', 0)
            if sym not in self.coin_wr:
                self.coin_wr[sym] = {'wins': 0, 'losses': 0, 'total_pnl': 0}
            if pnl > 0:
                self.coin_wr[sym]['wins'] += 1
            else:
                self.coin_wr[sym]['losses'] += 1
            self.coin_wr[sym]['total_pnl'] += pnl
        
        # WR hesapla
        for sym, data in self.coin_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Saat bazlƒ± WR
        self.hour_wr = {}
        for t in recent:
            close_time = t.get('closeTime', 0)
            if close_time > 0:
                hour = datetime.fromtimestamp(close_time / 1000).hour
                if hour not in self.hour_wr:
                    self.hour_wr[hour] = {'wins': 0, 'losses': 0}
                if t.get('pnl', 0) > 0:
                    self.hour_wr[hour]['wins'] += 1
                else:
                    self.hour_wr[hour]['losses'] += 1
        
        for hour, data in self.hour_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Side bazlƒ± WR
        self.side_wr = {'LONG': {'wins': 0, 'losses': 0}, 'SHORT': {'wins': 0, 'losses': 0}}
        for t in recent:
            side = t.get('side', 'LONG')
            if side in self.side_wr:
                if t.get('pnl', 0) > 0:
                    self.side_wr[side]['wins'] += 1
                else:
                    self.side_wr[side]['losses'] += 1
        
        for side, data in self.side_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Score bazlƒ± WR
        self.score_bins = {}
        for t in recent:
            score = t.get('signalScore', 0)
            if score < 60:
                bin_name = "50-59"
            elif score < 70:
                bin_name = "60-69"
            elif score < 80:
                bin_name = "70-79"
            else:
                bin_name = "80+"
            
            if bin_name not in self.score_bins:
                self.score_bins[bin_name] = {'wins': 0, 'losses': 0}
            if t.get('pnl', 0) > 0:
                self.score_bins[bin_name]['wins'] += 1
            else:
                self.score_bins[bin_name]['losses'] += 1
        
        for bin_name, data in self.score_bins.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        self.analysis_time = now
        
        # √ñzet
        total_trades = len(recent)
        total_wins = sum(1 for t in recent if t.get('pnl', 0) > 0)
        overall_wr = (total_wins / total_trades * 100) if total_trades > 0 else 50
        
        # En k√∂t√º/iyi coinler
        worst_coins = [s for s, d in self.coin_wr.items() 
                       if d['total'] >= self.MIN_COIN_TRADES and d['wr'] < 35]
        best_coins = [s for s, d in self.coin_wr.items() 
                      if d['total'] >= self.MIN_COIN_TRADES and d['wr'] > 65]
        
        self.last_analysis = {
            "status": "ok",
            "total_trades": total_trades,
            "overall_wr": overall_wr,
            "worst_coins": worst_coins,
            "best_coins": best_coins,
            "coin_count": len(self.coin_wr),
            "side_wr": {k: v['wr'] for k, v in self.side_wr.items()},
            "score_bins": {k: v['wr'] for k, v in self.score_bins.items()},
        }
        
        logger.info(f"üìä TradePattern: {total_trades} trades | WR={overall_wr:.0f}% | worst={worst_coins[:3]} | best={best_coins[:3]}")
        
        return self.last_analysis
    
    def get_coin_penalty(self, symbol: str) -> int:
        """D√º≈ü√ºk WR coin'e penalty d√∂nd√ºr."""
        data = self.coin_wr.get(symbol)
        if not data or data['total'] < self.MIN_COIN_TRADES:
            return 0
        
        wr = data['wr']
        if wr < 25:
            return -15  # √áok k√∂t√º ‚Äî g√º√ßl√º penalty
        elif wr < 35:
            return -10  # K√∂t√º
        elif wr < 40:
            return -5   # Ortalamanƒ±n altƒ±
        elif wr > 70:
            return 5    # ƒ∞yi coin ‚Äî hafif bonus
        
        return 0
    
    def get_side_penalty(self, side: str) -> int:
        """D√º≈ü√ºk WR taraf i√ßin penalty."""
        data = self.side_wr.get(side)
        if not data or data.get('total', 0) < 10:
            return 0
        
        wr = data['wr']
        if wr < 35:
            return -5  # Bu taraf zayƒ±f
        elif wr > 65:
            return 3   # Bu taraf g√º√ßl√º
        
        return 0

# Global Trade Pattern Analyzer
trade_pattern_analyzer = TradePatternAnalyzer()

# Stores all UI-relevant data in memory, updated by background scanner.
# WebSocket endpoints read from this cache instead of making fresh API calls.
# ============================================================================

class UIStateCache:
    """
    Cache for UI state - updated by background scanner every 3 seconds.
    WebSocket endpoints read from this cache for instant data delivery.
    
    Benefits:
    - Eliminates 3+ minute UI loading delay
    - Reduces Binance API rate limit usage
    - All UI clients see consistent data
    """
    
    def __init__(self):
        self.opportunities = []
        self.stats = {
            "totalCoins": 0,
            "analyzedCoins": 0,
            "longSignals": 0,
            "shortSignals": 0,
            "activeSignals": 0,
            "lastUpdate": 0
        }
        self.balance = 0
        self.live_balance = None
        self.positions = []
        self.trades = []
        self.binance_trades = []  # Phase 157: Trades fetched from Binance
        self.pnl_data = {
            "todayPnl": 0,
            "todayPnlPercent": 0,
            "totalPnl": 0,
            "totalPnlPercent": 0
        }
        self.logs = []
        self.trading_mode = "paper"
        self.last_update = 0
        self.btc_state = {}
        self.enabled = True
        self._initialized = False
        # Phase 157: Delayed trade history fetch after position close
        self.pending_trade_fetch_time = 0  # Unix timestamp when to fetch
        self.last_binance_trade_fetch = 0  # Last successful fetch time
    
    def trigger_trade_fetch(self, delay_seconds: int = 3):
        """Schedule a Binance trade history fetch after delay."""
        self.pending_trade_fetch_time = datetime.now().timestamp() + delay_seconds
        logger.info(f"üìä Trade history fetch scheduled in {delay_seconds}s")
    
    def get_state(self) -> dict:
        """Return complete UI state for WebSocket - instant, no API calls."""
        return {
            "type": "scanner_update",
            "opportunities": self.opportunities,
            "stats": self.stats,
            "portfolio": {
                "balance": self.balance,
                "positions": self.positions,
                "trades": sorted(self.trades, key=lambda t: t.get('closeTime', 0), reverse=True),
                "stats": {
                    **self.pnl_data,
                    "liveBalance": self.live_balance,
                    "winRate": 0,
                    "totalTrades": len(self.trades)
                },
                "logs": self.logs[-100:],
                "enabled": self.enabled
            },
            "tradingMode": self.trading_mode,
            "timestamp": self.last_update,
            "message": "Cache data" if self._initialized else "Initializing..."
        }
    
    def is_ready(self) -> bool:
        """Check if cache has been populated at least once."""
        return self._initialized and self.last_update > 0


# Global UI State Cache instance
ui_state_cache = UIStateCache()


class MultiCoinScanner:
    """
    Phase 31: Multi-Coin Scanner
    Scans all Binance Futures perpetual contracts for trading opportunities.
    """
    
    def __init__(self, max_coins: int = 100):
        self.max_coins = max_coins
        self.coins: list = []
        self.analyzers: Dict[str, LightweightCoinAnalyzer] = {}
        self.running = False
        self.exchange = None
        self.last_fetch_time = 0
        self.opportunities: list = []
        self.active_signals: list = []
        # Caching for rate limit protection
        self.ticker_cache: dict = {}
        self.ticker_cache_time: float = 0
        self.cache_ttl: int = 10  # Cache valid for 10 seconds (Binance optimized)
        
        # BTC Basis tracking (Spot-Futures spread)
        self.btc_basis_pct: float = 0.0
        self.btc_spot_price: float = 0.0
        self.btc_futures_price: float = 0.0
        self.last_basis_update: float = 0
        
        logger.info(f"MultiCoinScanner initialized (max_coins={max_coins})")
    
    async def fetch_all_futures_symbols(self) -> list:
        """Fetch all USDT perpetual contracts from Binance Futures."""
        
        # Method 1: Try direct Binance API (most reliable, bypasses CCXT issues)
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get("https://fapi.binance.com/fapi/v1/exchangeInfo", timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        symbols = []
                        for s in data.get('symbols', []):
                            if (s.get('symbol', '').endswith('USDT') and 
                                s.get('contractType') == 'PERPETUAL' and 
                                s.get('status') == 'TRADING'):
                                symbols.append(s['symbol'])
                        
                        if len(symbols) > 100:  # Sanity check
                            symbols = sorted(list(set(symbols)))
                            logger.info(f"‚úÖ Fetched {len(symbols)} USDT perpetual contracts (direct API)")
                            self.coins = symbols
                            return symbols
        except Exception as e:
            logger.warning(f"Direct Binance API failed: {e}, trying CCXT...")
        
        # Method 2: Try CCXT (may fail on some servers due to geo-restrictions)
        try:
            if not self.exchange:
                api_key = os.environ.get('BINANCE_API_KEY', '')
                api_secret = os.environ.get('BINANCE_SECRET', '')
                
                exchange_config = {
                    'enableRateLimit': True,
                    'options': {'defaultType': 'future'}
                }
                
                if api_key and api_secret:
                    exchange_config['apiKey'] = api_key
                    exchange_config['secret'] = api_secret
                    logger.info("Using authenticated Binance API (with API key)")
                else:
                    logger.info("Using public Binance API (no API key)")
                
                self.exchange = ccxt_async.binance(exchange_config)
            
            markets = await self.exchange.load_markets()
            
            # Filter for USDT perpetual contracts only
            symbols = []
            for symbol, market in markets.items():
                if (market.get('quote') == 'USDT' and 
                    market.get('linear', False) and 
                    market.get('active', True) and
                    ':USDT' in symbol):
                    base = market.get('base', '')
                    if base:
                        symbols.append(f"{base}USDT")
            
            symbols = sorted(list(set(symbols)))
            
            if len(symbols) > 100:
                logger.info(f"‚úÖ Fetched {len(symbols)} USDT perpetual contracts (CCXT)")
                self.coins = symbols
                return symbols
                
        except Exception as e:
            logger.error(f"CCXT also failed: {e}")
        
        # Method 3: Fallback to hardcoded top 100 coins
        logger.warning("‚ö†Ô∏è All API methods failed, using fallback 100 coin list")
        self.coins = [
            # Top 20
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT',
            'DOGEUSDT', 'ADAUSDT', 'AVAXUSDT', 'TRXUSDT', 'DOTUSDT',
            'LINKUSDT', 'MATICUSDT', 'ICPUSDT', 'SHIBUSDT', 'LTCUSDT',
            'BCHUSDT', 'UNIUSDT', 'ATOMUSDT', 'NEARUSDT', 'XLMUSDT',
            # 21-40
            'APTUSDT', 'FILUSDT', 'LDOUSDT', 'ARBUSDT', 'OPUSDT',
            'INJUSDT', 'RNDRUSDT', 'HBARUSDT', 'VETUSDT', 'AAVEUSDT',
            'IMXUSDT', 'MKRUSDT', 'GRTUSDT', 'THETAUSDT', 'FTMUSDT',
            'ALGOUSDT', 'RUNEUSDT', 'EGLDUSDT', 'SNXUSDT', 'AXSUSDT',
            # 41-60
            'SANDUSDT', 'MANAUSDT', 'GALAUSDT', 'APEUSDT', 'CHZUSDT',
            'CRVUSDT', 'LRCUSDT', 'ENJUSDT', 'DYDXUSDT', 'MINAUSDT',
            'KAVAUSDT', 'COMPUSDT', 'GMTUSDT', 'ONEUSDT', 'IOTAUSDT',
            'ZECUSDT', 'KSMUSDT', 'DASHUSDT', 'SUIUSDT', 'SEIUSDT',
            # 61-80  
            '1000PEPEUSDT', '1000SHIBUSDT', 'WIFUSDT', 'BONKUSDT', 'FLOKIUSDT',
            'ORDIUSDT', 'TIAUSDT', 'FETUSDT', 'AGIXUSDT', 'OCEANUSDT',
            'WOOUSDT', 'BLURUSDT', 'CFXUSDT', 'STXUSDT', 'ARKMUSDT',
            'PENDLEUSDT', 'JOEUSDT', 'HOOKUSDT', 'MAGICUSDT', 'TUSDT',
            # 81-100
            'CKBUSDT', 'TRUUSDT', 'SSVUSDT', 'RPLUSDT', 'GMXUSDT',
            'LEVERUSDT', 'CYBERUSDT', 'ARKUSDT', 'POLYXUSDT', 'BIGTIMEUSDT',
            'WLDUSDT', 'LQTYUSDT', 'OXTUSDT', 'AMBUSDT', 'PHBUSDT',
            'COMBOUSDT', 'MAVUSDT', 'XVSUSDT', 'EDUUSDT', 'IDUSDT'
        ]
        logger.info(f"Using fallback list of {len(self.coins)} coins")
        return self.coins
    
    def get_or_create_analyzer(self, symbol: str) -> LightweightCoinAnalyzer:
        """Get existing analyzer or create new one."""
        if symbol not in self.analyzers:
            self.analyzers[symbol] = LightweightCoinAnalyzer(symbol)
        return self.analyzers[symbol]
    
    async def fetch_ticker_data(self, symbols: list) -> dict:
        """Fetch ticker data from WebSocket stream (instant, no API call)."""
        global binance_ws_manager
        
        # Start WebSocket if not running
        if not binance_ws_manager.running:
            await binance_ws_manager.start()
            # Wait a moment for initial data
            await asyncio.sleep(2)
        
        # Get tickers from WebSocket cache
        result = binance_ws_manager.get_tickers(symbols)
        
        if result:
            logger.info(f"Got {len(result)} tickers from WebSocket (instant)")
            return result
        
        # Fallback to REST API if WebSocket has no data yet
        logger.warning("WebSocket has no data, falling back to REST API")
        try:
            if not self.exchange:
                return {}
            
            tickers = await self.exchange.fetch_tickers()
            
            rest_result = {}
            for symbol in symbols:
                ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
                if ccxt_symbol in tickers:
                    rest_result[symbol] = tickers[ccxt_symbol]
            
            logger.info(f"Fetched {len(rest_result)} tickers from REST API (fallback)")
            return rest_result
            
        except Exception as e:
            logger.error(f"Error fetching tickers: {e}")
            return {}
    
    async def fetch_ticker_data_coingecko(self, symbols: list) -> dict:
        """Fallback: Fetch ticker data from CoinGecko API (no geo restrictions)."""
        import aiohttp
        import time
        
        # Check cache first to prevent rate limits
        current_time = time.time()
        if self.ticker_cache and (current_time - self.ticker_cache_time) < self.cache_ttl:
            logger.debug("Using cached ticker data")
            return self.ticker_cache
        
        # Map symbols to CoinGecko IDs (100 coins)
        symbol_to_coingecko = {
            # Top 20
            'BTCUSDT': 'bitcoin', 'ETHUSDT': 'ethereum', 'BNBUSDT': 'binancecoin',
            'SOLUSDT': 'solana', 'XRPUSDT': 'ripple', 'DOGEUSDT': 'dogecoin',
            'ADAUSDT': 'cardano', 'AVAXUSDT': 'avalanche-2', 'TRXUSDT': 'tron',
            'DOTUSDT': 'polkadot', 'LINKUSDT': 'chainlink', 'MATICUSDT': 'matic-network',
            'ICPUSDT': 'internet-computer', 'SHIBUSDT': 'shiba-inu', 'LTCUSDT': 'litecoin',
            'BCHUSDT': 'bitcoin-cash', 'UNIUSDT': 'uniswap', 'ATOMUSDT': 'cosmos',
            'NEARUSDT': 'near', 'XLMUSDT': 'stellar',
            # 21-40
            'APTUSDT': 'aptos', 'FILUSDT': 'filecoin', 'LDOUSDT': 'lido-dao',
            'ARBUSDT': 'arbitrum', 'OPUSDT': 'optimism', 'INJUSDT': 'injective-protocol',
            'RNDRUSDT': 'render-token', 'HBARUSDT': 'hedera-hashgraph', 'VETUSDT': 'vechain',
            'AAVEUSDT': 'aave', 'IMXUSDT': 'immutable-x', 'MKRUSDT': 'maker',
            'GRTUSDT': 'the-graph', 'THETAUSDT': 'theta-token', 'FTMUSDT': 'fantom',
            'ALGOUSDT': 'algorand', 'RUNEUSDT': 'thorchain', 'EGLDUSDT': 'elrond-erd-2',
            'SNXUSDT': 'havven', 'AXSUSDT': 'axie-infinity',
            # 41-60
            'SANDUSDT': 'the-sandbox', 'MANAUSDT': 'decentraland', 'GALAUSDT': 'gala',
            'APEUSDT': 'apecoin', 'CHZUSDT': 'chiliz', 'CRVUSDT': 'curve-dao-token',
            'LRCUSDT': 'loopring', 'ENJUSDT': 'enjincoin', 'DYDXUSDT': 'dydx',
            'MINAUSDT': 'mina-protocol', 'KAVAUSDT': 'kava', 'COMPUSDT': 'compound-governance-token',
            'GMTUSDT': 'stepn', 'ONEUSDT': 'harmony', 'IOTAUSDT': 'iota',
            'ZECUSDT': 'zcash', 'KSMUSDT': 'kusama', 'DASHUSDT': 'dash',
            'SUIUSDT': 'sui', 'SEIUSDT': 'sei-network',
            # 61-80
            '1000PEPEUSDT': 'pepe', '1000SHIBUSDT': 'shiba-inu', 'WIFUSDT': 'dogwifhat',
            'BONKUSDT': 'bonk', 'FLOKIUSDT': 'floki', 'ORDIUSDT': 'ordinals',
            'TIAUSDT': 'celestia', 'FETUSDT': 'fetch-ai', 'AGIXUSDT': 'singularitynet',
            'OCEANUSDT': 'ocean-protocol', 'WOOUSDT': 'woo-network', 'BLURUSDT': 'blur',
            'CFXUSDT': 'conflux-token', 'STXUSDT': 'blockstack', 'ARKMUSDT': 'arkham',
            'PENDLEUSDT': 'pendle', 'JOEUSDT': 'joe', 'HOOKUSDT': 'hooked-protocol',
            'MAGICUSDT': 'magic', 'TUSDT': 'threshold-network-token',
            # 81-100
            'CKBUSDT': 'nervos-network', 'TRUUSDT': 'truefi', 'SSVUSDT': 'ssv-network',
            'RPLUSDT': 'rocket-pool', 'GMXUSDT': 'gmx', 'LEVERUSDT': 'leverfi',
            'CYBERUSDT': 'cyberconnect', 'ARKUSDT': 'ark', 'POLYXUSDT': 'polymesh',
            'BIGTIMEUSDT': 'big-time', 'WLDUSDT': 'worldcoin-wld', 'LQTYUSDT': 'liquity',
            'OXTUSDT': 'orchid-protocol', 'AMBUSDT': 'amber', 'PHBUSDT': 'phoenix-global',
            'COMBOUSDT': 'furucombo', 'MAVUSDT': 'maverick-protocol', 'XVSUSDT': 'venus',
            'EDUUSDT': 'edu-coin', 'IDUSDT': 'space-id'
        }
        
        try:
            # Get coins we can map
            coin_ids = [symbol_to_coingecko.get(s) for s in symbols if s in symbol_to_coingecko]
            coin_ids = [c for c in coin_ids if c]  # Remove None
            
            if not coin_ids:
                logger.warning("No coins to fetch from CoinGecko")
                return {}
            
            # CoinGecko API - free, no API key needed
            url = f"https://api.coingecko.com/api/v3/simple/price?ids={','.join(coin_ids)}&vs_currencies=usd&include_24hr_change=true&include_24hr_vol=true"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        result = {}
                        # Reverse map CoinGecko data to symbols
                        coingecko_to_symbol = {v: k for k, v in symbol_to_coingecko.items()}
                        
                        for coin_id, price_data in data.items():
                            symbol = coingecko_to_symbol.get(coin_id)
                            if symbol:
                                # Format data similar to CCXT ticker
                                price = price_data.get('usd', 0)
                                change_pct = price_data.get('usd_24h_change', 0)
                                volume = price_data.get('usd_24h_vol', 0)
                                
                                result[symbol] = {
                                    'last': price,
                                    'percentage': change_pct,
                                    'quoteVolume': volume,
                                    'high': price * 1.02,  # Approximate
                                    'low': price * 0.98,   # Approximate
                                }
                        
                        # Update cache
                        if result:
                            self.ticker_cache = result
                            self.ticker_cache_time = current_time
                        
                        logger.info(f"Fetched {len(result)} tickers from CoinGecko fallback")
                        return result
                    else:
                        logger.warning(f"CoinGecko API error: {response.status}")
                        # Return cached data if available
                        if self.ticker_cache:
                            logger.info("Returning cached data due to API error")
                            return self.ticker_cache
                        return {}
                        
        except Exception as e:
            logger.error(f"CoinGecko fallback error: {e}")
            # Return cached data if available
            if self.ticker_cache:
                logger.info("Returning cached data due to exception")
                return self.ticker_cache
            return {}
    
    async def update_btc_basis(self):
        """
        Update BTC Spot-Futures basis (spread).
        Called every minute to avoid rate limits.
        Positive basis = Futures > Spot (bullish sentiment, good for shorts)
        Negative basis = Futures < Spot (bearish sentiment, good for longs)
        """
        import aiohttp
        import time
        
        now = time.time()
        # Only update once per minute to avoid rate limits
        if now - self.last_basis_update < 60:
            return
        
        try:
            # Get BTC Futures price from our ticker cache
            btc_futures = self.ticker_cache.get('BTCUSDT', {})
            self.btc_futures_price = btc_futures.get('last', 0)
            
            if self.btc_futures_price <= 0:
                return
            
            # Fetch BTC Spot price from Binance Spot API (public, no auth needed)
            async with aiohttp.ClientSession() as session:
                url = "https://api.binance.com/api/v3/ticker/price?symbol=BTCUSDT"
                async with session.get(url, timeout=5) as response:
                    if response.status == 200:
                        data = await response.json()
                        self.btc_spot_price = float(data.get('price', 0))
                        
                        if self.btc_spot_price > 0:
                            basis = self.btc_futures_price - self.btc_spot_price
                            self.btc_basis_pct = (basis / self.btc_spot_price) * 100
                            self.last_basis_update = now
                            logger.debug(f"BTC Basis updated: {self.btc_basis_pct:.4f}% (Futures: ${self.btc_futures_price:.2f}, Spot: ${self.btc_spot_price:.2f})")
        except Exception as e:
            logger.debug(f"BTC basis update error: {e}")
    
    async def fetch_book_tickers(self) -> dict:
        """Phase 228: Fetch book tickers (bid/ask) via REST API.
        
        Binance Futures !ticker@arr WS does NOT include bid/ask fields.
        This REST call gets all book tickers in one request.
        """
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://fapi.binance.com/fapi/v1/ticker/bookTicker',
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        cache = {}
                        for item in data:
                            symbol = item.get('symbol', '')
                            if symbol.endswith('USDT'):
                                cache[symbol] = {
                                    'bid': float(item.get('bidPrice', 0)),
                                    'ask': float(item.get('askPrice', 0)),
                                    'bidQty': float(item.get('bidQty', 0)),
                                    'askQty': float(item.get('askQty', 0)),
                                }
                        return cache
                    else:
                        logger.warning(f"BookTicker REST failed: status={resp.status}")
                        return {}
        except Exception as e:
            logger.warning(f"BookTicker REST error: {e}")
            return {}
    
    async def scan_all_coins(self) -> list:
        """Scan all coins and return opportunities."""
        if not self.coins:
            await self.fetch_all_futures_symbols()
        
        # Fetch all ticker data at once
        tickers = await self.fetch_ticker_data(self.coins)
        
        # Phase 228: Fetch book tickers (bid/ask) via REST API
        book_cache = await self.fetch_book_tickers()
        # P3 fix: Log intersection with scanned coins, not total cache
        matched = len(set(book_cache.keys()) & set(tickers.keys())) if book_cache else 0
        logger.info(f"üìä BookTicker: {matched}/{len(tickers)} scanned coins have bid/ask data")
        
        # Update BTC basis (Spot-Futures spread) - once per minute
        await self.update_btc_basis()
        
        opportunities = []
        signals = []
        
        # Yield control to event loop every N coins to prevent blocking API requests
        # Lower value = more responsive API but slightly slower scan
        yield_every = 10  # Yield frequently to keep API responsive
        coin_count = 0
        
        for symbol, ticker in tickers.items():
            try:
                analyzer = self.get_or_create_analyzer(symbol)
                
                # Update price data from ticker
                price = ticker.get('last', 0)
                high = ticker.get('high', price)
                low = ticker.get('low', price)
                volume = ticker.get('baseVolume', 0)
                imbalance = ticker.get('imbalance', 0)  # L1 Order Book imbalance from WebSocket
                
                if price <= 0:
                    continue
                
                analyzer.update_price(price, high, low, volume)
                analyzer.opportunity.volume_24h = ticker.get('quoteVolume', 0)
                analyzer.opportunity.price_change_24h = ticker.get('percentage', 0)
                
                # P2 fix: Reset spread flag each scan ‚Äî prevents stale data on REST fail
                analyzer.opportunity.has_real_spread = False
                
                # P1 fix: Set WS imbalance as default, then let bookTicker override
                analyzer.opportunity.imbalance = imbalance
                
                # Phase 228: Calculate real bid-ask spread from REST bookTicker
                book = book_cache.get(symbol, {})
                bid = book.get('bid', 0)
                ask = book.get('ask', 0)
                if bid > 0 and ask > 0 and ask > bid:
                    mid = (ask + bid) / 2
                    bid_ask_spread = ((ask - bid) / mid) * 100
                    analyzer.opportunity.bid_ask_spread_pct = round(bid_ask_spread, 4)
                    analyzer.opportunity.has_real_spread = True
                    # P1 fix: Override imbalance with real L1 data from bookTicker
                    bid_qty = book.get('bidQty', 0)
                    ask_qty = book.get('askQty', 0)
                    if bid_qty + ask_qty > 0:
                        imbalance = ((bid_qty - ask_qty) / (bid_qty + ask_qty)) * 100
                        analyzer.opportunity.imbalance = imbalance
                
                # Update whale tracker with volume and price change
                whale_tracker.update(symbol, price, volume, ticker.get('percentage', 0))
                
                # Analyze for signal with BTC basis and L1 imbalance (uses bookTicker imbalance if available)
                signal = analyzer.analyze(imbalance=imbalance, basis_pct=self.btc_basis_pct)
                
                if signal:
                    signal['symbol'] = symbol
                    # Phase 230B: Propagate coin data for BTC filter multi-factor override
                    signal['priceChange24h'] = analyzer.opportunity.price_change_24h
                    signal['volume24h'] = analyzer.opportunity.volume_24h
                    signal['zscore'] = analyzer.opportunity.zscore
                    signals.append(signal)
                
                opportunities.append(analyzer.opportunity.to_dict())
                
                # Yield control to event loop periodically to allow API requests to be processed
                coin_count += 1
                if coin_count % yield_every == 0:
                    await asyncio.sleep(0)
                
            except Exception as e:
                logger.debug(f"Error analyzing {symbol}: {e}")
                continue
        
        # Sort by signal score (highest first)
        opportunities.sort(key=lambda x: x.get('signalScore', 0), reverse=True)
        
        self.opportunities = opportunities
        self.active_signals = signals
        
        # Phase 127: Log active signal count for tracing
        if signals:
            signal_symbols = [s.get('symbol', '?') for s in signals]
            logger.info(f"üì° SCAN_RESULT: {len(signals)} active signals collected: {signal_symbols[:5]}{'...' if len(signals) > 5 else ''}")
        
        return opportunities
    
    def get_scanner_stats(self) -> dict:
        """Get overall scanner statistics."""
        long_count = sum(1 for o in self.opportunities if o.get('signalAction') == 'LONG')
        short_count = sum(1 for o in self.opportunities if o.get('signalAction') == 'SHORT')
        
        return {
            "totalCoins": len(self.coins),
            "analyzedCoins": len(self.opportunities),
            "longSignals": long_count,
            "shortSignals": short_count,
            "activeSignals": len(self.active_signals),
            "lastUpdate": datetime.now().timestamp()
        }
    
    async def preload_all_coins(self, top_n: int = 50):
        """
        Preload historical OHLCV data for top N coins at startup.
        This enables immediate Z-Score/Hurst calculation without waiting for data to accumulate.
        
        Args:
            top_n: Number of top coins to preload (default 50 to balance speed and coverage)
        """
        if not self.coins:
            await self.fetch_all_futures_symbols()
        
        if not self.exchange:
            logger.info("üìä Creating exchange for OHLCV preloading...")
            try:
                import ccxt.async_support as ccxt_async
                api_key = os.environ.get('BINANCE_API_KEY', '')
                api_secret = os.environ.get('BINANCE_SECRET', '')
                exchange_config = {
                    'enableRateLimit': True,
                    'options': {'defaultType': 'future'}
                }
                if api_key and api_secret:
                    exchange_config['apiKey'] = api_key
                    exchange_config['secret'] = api_secret
                self.exchange = ccxt_async.binance(exchange_config)
                logger.info("‚úÖ Exchange created for preload")
            except Exception as e:
                logger.error(f"‚ùå Failed to create exchange for preload: {e}")
                return
        
        # Preload top N coins (most traded/popular)
        priority_coins = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 
                         'BNBUSDT', 'ADAUSDT', 'AVAXUSDT', 'DOTUSDT', 'LINKUSDT']
        
        coins_to_preload = priority_coins + [c for c in self.coins[:top_n] if c not in priority_coins]
        coins_to_preload = coins_to_preload[:top_n]
        
        logger.info(f"Starting OHLCV preload for {len(coins_to_preload)} coins...")
        
        preloaded_count = 0
        failed_count = 0
        
        for symbol in coins_to_preload:
            try:
                # Fetch 5-minute candles (last 100 = ~8 hours of data)
                ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
                ohlcv = await self.exchange.fetch_ohlcv(ccxt_symbol, '5m', limit=100)
                
                if ohlcv and len(ohlcv) >= 20:
                    analyzer = self.get_or_create_analyzer(symbol)
                    analyzer.preload_historical_data(ohlcv)
                    preloaded_count += 1
                else:
                    failed_count += 1
                    
            except Exception as e:
                logger.info(f"‚ùå Failed to preload {symbol}: {str(e)[:50]}")
                failed_count += 1
                continue
            
            # Small delay to avoid rate limits (respect Binance API limits)
            if preloaded_count % 10 == 0:
                await asyncio.sleep(0.5)
        
        logger.info(f"OHLCV preload complete: {preloaded_count} success, {failed_count} failed")
    
    async def close(self):
        """Cleanup resources."""
        if self.exchange:
            await self.exchange.close()
            self.exchange = None

# Global MultiCoinScanner instance (no limit - scans ALL perpetuals)
multi_coin_scanner = MultiCoinScanner(max_coins=999)


# ============================================================================
# PHASE 98: UI CACHE UPDATE FUNCTION
# Called by background scanner to populate cache with fresh Binance data.
# ============================================================================

async def update_ui_cache(opportunities: list, stats: dict):
    """
    Update UI state cache with latest scanner data and Binance info.
    This is called every 3 seconds by the background scanner loop.
    
    Args:
        opportunities: List of filtered coin opportunities from scanner
        stats: Scanner statistics dict
    """
    global ui_state_cache
    
    # Phase 157: Debug - log every call
    logger.info(f"üîÑ update_ui_cache CALLED: {len(opportunities)} opportunities, live={live_binance_trader.enabled}")
    
    try:
        # Apply BTC filter to opportunities
        filtered_opportunities = []
        for opp in opportunities:
            signal_action = opp.get('signalAction', 'NONE')
            symbol = opp.get('symbol', '')
            
            if signal_action == 'NONE':
                filtered_opportunities.append(opp)
            else:
                # Phase 225: PriceShock block (before BTC filter)
                shock_blocked, shock_reason = price_shock_manager.should_block_signal(signal_action, symbol)
                if shock_blocked:
                    opp['signalAction'] = 'NONE'
                    opp['signalScore'] = 0
                    opp['shockBlocked'] = shock_reason
                    filtered_opportunities.append(opp)
                    continue
                
                btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
                    symbol, signal_action,
                    coin_change_pct=opp.get('priceChange24h', 0),
                    volume_24h=opp.get('volume24h', 0),
                    zscore=opp.get('zscore', 0),
                    spread_pct=opp.get('spreadPct', 0)
                )
                if btc_allowed:
                    if btc_penalty > 0:
                        original_score = opp.get('signalScore', 0)
                        opp['signalScore'] = int(original_score * (1 - btc_penalty))
                        opp['btcFilterNote'] = btc_reason
                    # Phase 230B: Apply override risk caps
                    if btc_filter.last_override:
                        opp['overrideLeverageCap'] = 3
                        opp['overrideSizeMult'] = 0.5
                        opp['btcOverride'] = True
                    filtered_opportunities.append(opp)
                else:
                    opp['signalAction'] = 'NONE'
                    opp['signalScore'] = 0
                    opp['btcFilterBlocked'] = btc_reason
                    filtered_opportunities.append(opp)
        
        # Update opportunities and stats
        ui_state_cache.opportunities = filtered_opportunities
        
        # Calculate signal counts from filtered opportunities (only those above min confidence threshold)
        min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
        long_count = sum(1 for o in filtered_opportunities if o.get('signalAction') == 'LONG' and o.get('signalScore', 0) >= min_score)
        short_count = sum(1 for o in filtered_opportunities if o.get('signalAction') == 'SHORT' and o.get('signalScore', 0) >= min_score)
        
        ui_state_cache.stats = {
            "totalCoins": stats.get('totalCoins', len(multi_coin_scanner.coins)),
            "analyzedCoins": len(filtered_opportunities),
            "longSignals": long_count,
            "shortSignals": short_count,
            "activeSignals": long_count + short_count,
            "btcState": btc_filter.get_state(),
            "lastUpdate": datetime.now().timestamp()
        }
        
        # Fetch Binance data (live mode) or use paper trader data
        if live_binance_trader.enabled:
            try:
                # Parallel fetch for speed
                balance_task = asyncio.create_task(live_binance_trader.get_balance())
                positions_task = asyncio.create_task(live_binance_trader.get_positions())
                
                balance_data = await balance_task
                positions = await positions_task
                
                # Phase 155: Merge Binance positions with exit params from global_paper_trader
                # global_paper_trader.positions has TP/SL/Trail data from sync loop
                merged_positions = []
                paper_positions = {p.get('symbol'): p for p in global_paper_trader.positions}
                
                for bp in positions:
                    symbol = bp.get('symbol', '')
                    paper_pos = paper_positions.get(symbol, {})
                    
                    # Start with Binance data
                    merged = dict(bp)
                    
                    # Merge exit parameters from paper trader (if available)
                    if paper_pos:
                        merged['stopLoss'] = paper_pos.get('stopLoss', bp.get('stopLoss', 0))
                        merged['takeProfit'] = paper_pos.get('takeProfit', bp.get('takeProfit', 0))
                        merged['trailingStop'] = paper_pos.get('trailingStop', paper_pos.get('stopLoss', 0))
                        merged['trailActivation'] = paper_pos.get('trailActivation', 0)
                        merged['atr'] = paper_pos.get('atr', 0)
                        # Phase 231k: Use paper_pos openTime (original entry) ‚Äî not Binance updateTime
                        if paper_pos.get('openTime', 0) > 0:
                            merged['openTime'] = paper_pos['openTime']
                        
                        # Phase 156: isTrailingActive must be based on CURRENT profitability from Binance
                        # Phase 204: Use currentPrice (close/last) instead of markPrice (can spike with wicks)
                        close_price = bp.get('currentPrice', bp.get('markPrice', 0))
                        entry_price = bp.get('entryPrice', 0)
                        side = bp.get('side', 'LONG')
                        
                        if close_price > 0 and entry_price > 0:
                            # Phase 231: Use paper_pos's REAL trail state, don't infer from profitability
                            # Old bug: was setting isTrailingActive = (profitable?) which was wrong
                            merged['isTrailingActive'] = paper_pos.get('isTrailingActive', False)
                        else:
                            merged['isTrailingActive'] = paper_pos.get('isTrailingActive', False)
                    else:
                        # No paper position - calculate default exit params
                        entry = bp.get('entryPrice', 0)
                        atr = entry * 0.02 if entry > 0 else 0  # 2% default ATR
                        sl_mult = getattr(global_paper_trader, 'sl_multiplier', 2.0)  # Default 2x ATR
                        tp_mult = getattr(global_paper_trader, 'tp_multiplier', 3.0)  # Default 3x ATR
                        
                        if bp.get('side') == 'LONG':
                            merged['stopLoss'] = max(entry * 0.01, entry - (atr * sl_mult))
                            merged['takeProfit'] = entry + (atr * tp_mult)
                        else:
                            merged['stopLoss'] = entry + (atr * sl_mult)
                            merged['takeProfit'] = max(entry * 0.01, entry - (atr * tp_mult))
                        
                        merged['trailingStop'] = merged['stopLoss']
                        merged['isTrailingActive'] = False
                        merged['atr'] = atr
                    
                    merged_positions.append(merged)
                
                ui_state_cache.balance = balance_data.get('walletBalance', 0)
                ui_state_cache.live_balance = balance_data
                ui_state_cache.positions = sorted(merged_positions, key=lambda p: p.get('openTime', 0), reverse=True)
                ui_state_cache.trading_mode = "live"
                logger.info(f"üìä UI Cache updated: {len(merged_positions)} positions, balance=${balance_data.get('walletBalance', 0):.2f}")
                
                # Cache PnL data (don't fetch every cycle - expensive)
                if not ui_state_cache._initialized or datetime.now().timestamp() - ui_state_cache.last_update > 30:
                    try:
                        pnl_data = await live_binance_trader.get_pnl_from_binance()
                        ui_state_cache.pnl_data = pnl_data
                    except:
                        pass
                        
            except Exception as e:
                logger.warning(f"Binance data fetch error: {e}")
        else:
            # Paper trading mode
            ui_state_cache.balance = global_paper_trader.balance
            ui_state_cache.positions = global_paper_trader.positions
            ui_state_cache.pnl_data = global_paper_trader.get_today_pnl()
            ui_state_cache.trading_mode = "paper"
            # Phase 232: Sync trades on every cycle (fix stale cache)
            ui_state_cache.trades = sorted(
                global_paper_trader.trades,
                key=lambda t: t.get('closeTime', t.get('close_time', 0)),
                reverse=True
            )
        
        # Phase 150: Trade history ‚Äî SQLite first, then Binance delta
        now = datetime.now().timestamp()
        time_since_last_fetch = now - ui_state_cache.last_binance_trade_fetch
        triggered = ui_state_cache.pending_trade_fetch_time > 0 and now >= ui_state_cache.pending_trade_fetch_time
        periodic = time_since_last_fetch > 60
        
        # Phase 187b: Startup instant load from SQLite trades table (full data)
        if not ui_state_cache.trades:
            try:
                sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
                if sqlite_trades:
                    ui_state_cache.trades = sqlite_trades
                    logger.info(f"üìä INSTANT_LOAD: {len(sqlite_trades)} trades from SQLite trades table (full data)")
            except Exception as e:
                logger.debug(f"SQLite instant load error: {e}")
        
        should_fetch_binance = live_binance_trader.enabled and (triggered or periodic)
        
        logger.info(f"üìä TRADE_CHECK: should={should_fetch_binance}, enabled={live_binance_trader.enabled}, triggered={triggered}, periodic={periodic}, since={time_since_last_fetch:.0f}s")
        
        if should_fetch_binance:
            try:
                logger.info(f"üìä BINANCE_FETCH: Starting Binance trade history fetch (limit=1000, days=7)...")
                # Fetch up to 1000 trades to get the most recent ones after sorting
                binance_trades = await live_binance_trader.get_trade_history(limit=1000, days_back=7)
                logger.info(f"üìä BINANCE_RESULT: Got {len(binance_trades) if binance_trades else 0} trades")
                if binance_trades and len(binance_trades) > 0:
                    # Log first and last trade timestamps for debugging
                    first_trade = binance_trades[0] if binance_trades else {}
                    last_trade = binance_trades[-1] if binance_trades else {}
                    logger.info(f"üìä BINANCE_DATES: First trade={first_trade.get('date', 'N/A')} {first_trade.get('time', 'N/A')}, Last trade={last_trade.get('date', 'N/A')} {last_trade.get('time', 'N/A')}")
                    
                    # Phase 181 v2: SQLite-primary approach
                    # 1. Save each Binance trade to SQLite (enrichment happens in save_binance_trade)
                    # 2. Reload from SQLite (get_binance_trades does LEFT JOIN with position_closes)
                    # This ensures dedup + enrichment from engine close data
                    
                    saved_count = 0
                    for bt in binance_trades:
                        try:
                            bt_copy = bt.copy()
                            bt_copy['incomeId'] = f"{bt.get('symbol', 'UNK')}_{bt.get('closeTime', bt.get('timestamp', 0))}"
                            await sqlite_manager.save_binance_trade(bt_copy)
                            saved_count += 1
                        except Exception as e:
                            logger.debug(f"Save trade error: {e}")
                    
                    # Phase 187b: Reload from trades table ‚Äî canonical source with full data
                    sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
                    
                    ui_state_cache.binance_trades = binance_trades
                    ui_state_cache.trades = sqlite_trades
                    ui_state_cache.last_binance_trade_fetch = now
                    ui_state_cache.pending_trade_fetch_time = 0
                    logger.info(f"üìä Phase 187b: Saved {saved_count} Binance trades ‚Üí Loaded {len(sqlite_trades)} from trades table (full data)")
            except Exception as e:
                import traceback
                logger.error(f"üìä BINANCE_ERROR: {e}")
                logger.error(f"üìä TRACEBACK: {traceback.format_exc()}")
        
        # Phase 150: Old fallback removed ‚Äî SQLite instant load handles this at startup
        
        logger.info(f"üìä UI_CACHE_END: trades={len(ui_state_cache.trades)}, initialized={ui_state_cache._initialized}")
        
        # Update logs and metadata
        ui_state_cache.logs = global_paper_trader.logs[-100:]
        ui_state_cache.enabled = global_paper_trader.enabled
        ui_state_cache.last_update = datetime.now().timestamp()
        ui_state_cache._initialized = True
        
    except Exception as e:
        logger.error(f"UI cache update error: {e}")


# ============================================================================
# 24/7 BACKGROUND SCANNER LOOP
# ============================================================================

async def background_scanner_loop():
    """
    24/7 Background scanner that runs independently of frontend connections.
    Scans all coins, generates signals, and executes paper trades automatically.
    """
    logger.info("üîÑ Background Scanner Loop started - running 24/7")
    
    scan_interval = 3  # Phase 86: Reduced to 3s for faster signal detection (~60% API capacity)
    
    # Wait for app to fully initialize
    await asyncio.sleep(3)
    
    try:
        # Initialize scanner
        if not multi_coin_scanner.coins:
            await multi_coin_scanner.fetch_all_futures_symbols()
            logger.info(f"üìä Scanning ALL {len(multi_coin_scanner.coins)} USDT perpetual contracts")
            logger.info("Starting background OHLCV preload for Z-Score/Hurst calculation...")
            await multi_coin_scanner.preload_all_coins(top_n=50)  # Preload top 50
        
        multi_coin_scanner.running = True
        
        # Track last coin refresh time (refresh every 30 minutes)
        last_coin_refresh = datetime.now().timestamp()
        coin_refresh_interval = 1800  # 30 minutes
        
        while True:
            try:
                # PHASE 104: Track loop iterations
                if not hasattr(multi_coin_scanner, '_loop_iteration'):
                    multi_coin_scanner._loop_iteration = 0
                multi_coin_scanner._loop_iteration += 1
                
                # Update BTC trend for HTF scoring (every scan cycle)
                try:
                    if multi_coin_scanner.exchange:
                        await btc_filter.update_btc_state(multi_coin_scanner.exchange)
                except Exception as e:
                    logger.debug(f"BTC filter update error: {e}")
                
                # Phase 157: Fetch funding rates (cached ‚Äî only calls API every 5 min)
                try:
                    if multi_coin_scanner.exchange:
                        await funding_oi_tracker.fetch_funding_rates(multi_coin_scanner.exchange)
                except Exception as e:
                    logger.debug(f"Funding rate fetch error: {e}")
                
                # Phase 157: Trade pattern analysis (cached ‚Äî only runs every 1 hour)
                try:
                    if hasattr(global_paper_trader, 'trades') and global_paper_trader.trades:
                        trade_pattern_analyzer.analyze(global_paper_trader.trades)
                except Exception as e:
                    logger.debug(f"Trade pattern analysis error: {e}")
                
                # Phase 225: Check for price shocks (after BTC + funding data available)
                try:
                    price_shock_manager.check_for_shock(btc_filter, liquidation_tracker, funding_oi_tracker)
                    # If shock active, tighten exposed positions + cancel opposing pending
                    if price_shock_manager.shock_mode != 'NORMAL':
                        price_shock_manager.tighten_exposed_positions(global_paper_trader.positions)
                        cancelled = price_shock_manager.cancel_opposing_pending(global_paper_trader.pending_orders)
                        for c in cancelled:
                            global_paper_trader.add_log(f"‚ö° SHOCK_CANCEL: {c.get('side')} {c.get('symbol')} pending order cancelled ({price_shock_manager.shock_mode})")
                except Exception as e:
                    logger.debug(f"PriceShock check error: {e}")
                
                # Refresh coin list every 30 minutes to catch new listings
                now = datetime.now().timestamp()
                if now - last_coin_refresh > coin_refresh_interval:
                    old_count = len(multi_coin_scanner.coins)
                    await multi_coin_scanner.fetch_all_futures_symbols()
                    new_count = len(multi_coin_scanner.coins)
                    if new_count > old_count:
                        logger.info(f"üÜï New coins detected: {new_count - old_count} added (total: {new_count})")
                    last_coin_refresh = now
                
                # Scan all coins
                opportunities = await multi_coin_scanner.scan_all_coins()
                stats = multi_coin_scanner.get_scanner_stats()
                
                # PHASE 105: Periodic scan summary log (first 5 iterations + every 50th)
                loop_iter = multi_coin_scanner._loop_iteration
                if loop_iter <= 5 or loop_iter % 50 == 0:
                    # Get sample analyzer price count
                    sample_prices = 0
                    if multi_coin_scanner.analyzers and 'BTCUSDT' in multi_coin_scanner.analyzers:
                        sample_prices = len(multi_coin_scanner.analyzers['BTCUSDT'].prices)
                    logger.info(f"üîÑ SCAN #{loop_iter}: {len(opportunities)} coins | BTC prices={sample_prices}")
                
                # PHASE 98: Update UI cache with latest data (instant delivery to UI)
                await update_ui_cache(opportunities, stats)
                
                # Phase 152: Periodic status summary to UI logs (every ~60 sec)
                if loop_iter % 20 == 0 and 'global_paper_trader' in globals():
                    pt = global_paper_trader
                    active_sigs = len(multi_coin_scanner.active_signals)
                    total_pnl = sum(p.get('unrealizedPnl', 0) for p in pt.positions)
                    pt.add_log(f"üìä DURUM: {len(pt.positions)} poz | {active_sigs} sinyal | Bakiye: ${pt.balance:.0f} | A√ßƒ±k PnL: ${total_pnl:.2f}")
                
                # Update market regime with BTC price (from btc_filter OR from opportunities)
                try:
                    btc_price = btc_filter.btc_price
                    if not btc_price or btc_price <= 0:
                        # Fallback: get from scan results
                        btc_opp = next((o for o in opportunities if o['symbol'] == 'BTCUSDT'), None)
                        if btc_opp:
                            btc_price = btc_opp.get('currentPrice', 0)
                    if btc_price and btc_price > 0:
                        market_regime_detector.update_btc_price(btc_price)
                except Exception as regime_err:
                    logger.debug(f"Market regime update error: {regime_err}")
                
                # Process signals for paper trading (only if enabled)
                if global_paper_trader.enabled:
                    # Phase 36 IMPROVED: Position-based kill switch check
                    # Checks each position individually, applies gradual reduction
                    if global_paper_trader.positions:
                        kill_switch_actions = await daily_kill_switch.check_positions(global_paper_trader)
                        # Log and broadcast if any actions were taken
                        if kill_switch_actions.get('reduced') or kill_switch_actions.get('closed'):
                            logger.info(f"üö® Kill Switch Actions: Reduced={kill_switch_actions['reduced']}, Closed={kill_switch_actions['closed']}")
                            # Broadcast kill switch event to UI
                            await ui_ws_manager.broadcast_kill_switch(kill_switch_actions)
                        
                        # Phase 231: check_positions moved AFTER position price update (below)
                        # Was here previously ‚Äî caused partial TP to use stale PnL
                        
                        # Phase 215: Live MTF Position Guard (her 30 dakikada)
                        try:
                            await apply_mtf_position_guard(
                                global_paper_trader.positions,
                                multi_coin_scanner.exchange
                            )
                        except Exception as mtf_guard_err:
                            logger.debug(f"MTF Guard error: {mtf_guard_err}")
                    
                    # UPDATE MTF TRENDS for coins with active signals (before processing)
                    # Phase FIB: Also update for ALL scanned opportunities (cache TTL prevents re-fetch)
                    # This ensures OHLCV cache is warm for Fibonacci context on new signals
                    mtf_update_symbols = set()
                    for signal in multi_coin_scanner.active_signals:
                        s = signal.get('symbol', '')
                        if s:
                            mtf_update_symbols.add(s)
                    if FIB_ENABLED:
                        for opp in opportunities:
                            s = opp.get('symbol', '')
                            if s and opp.get('signalScore', 0) > 0:
                                mtf_update_symbols.add(s)
                    for sym in mtf_update_symbols:
                        try:
                            if multi_coin_scanner.exchange:
                                await mtf_confirmation.update_coin_trend(sym, multi_coin_scanner.exchange)
                        except Exception as mtf_err:
                            logger.debug(f"MTF update error for {sym}: {mtf_err}")
                    
                    for signal in multi_coin_scanner.active_signals:
                        try:
                            symbol = signal.get('symbol', 'UNKNOWN')
                            price = signal.get('price', 0)
                            
                            # Update paper trader symbol temporarily for this signal
                            old_symbol = global_paper_trader.symbol
                            global_paper_trader.symbol = symbol
                            
                            # Get latest ATR from analyzer
                            if symbol in multi_coin_scanner.analyzers:
                                analyzer = multi_coin_scanner.analyzers[symbol]
                                current_atr = analyzer.opportunity.atr
                                signal['atr'] = current_atr
                            
                            # Execute trade (includes MTF confirmation check)
                            await process_signal_for_paper_trading(signal, price)
                            
                            # Restore symbol
                            global_paper_trader.symbol = old_symbol
                            
                        except Exception as sig_error:
                            logger.debug(f"Signal processing error for {symbol}: {sig_error}")
                            continue
                
                # =====================================================================
                # PHASE 32: UPDATE OPEN POSITIONS WITH REAL-TIME PRICES
                # =====================================================================
                for pos in list(global_paper_trader.positions):
                    try:
                        pos_symbol = pos.get('symbol', '')
                        
                        # Find current price for this position from scanner data
                        current_price = None
                        for opp in opportunities:
                            if opp.get('symbol') == pos_symbol:
                                current_price = opp.get('price', 0)
                                break
                        
                        if current_price and current_price > 0:
                            # Calculate unrealized PnL
                            entry_price = pos.get('entryPrice', current_price)
                            size = pos.get('size', 0)
                            size_usd = pos.get('sizeUsd', 0)
                            leverage = pos.get('leverage', 1)
                            
                            if pos['side'] == 'LONG':
                                pnl = (current_price - entry_price) * size
                            else:
                                pnl = (entry_price - current_price) * size
                            
                            pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
                            
                            pos['unrealizedPnl'] = round(pnl, 2)
                            pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
                            pos['currentPrice'] = current_price  # Store for frontend
                            
                            # =========================================================
                            # Phase 183: PENDING LIMIT CLOSE MONITOR
                            # Check if any pending limit orders (TP/Trail) have filled
                            # or timed out ‚Üí market fallback
                            # =========================================================
                            pending = pos.get('pending_limit_close')
                            if pending and pos.get('isLive', False) and live_binance_trader.enabled:
                                order_id = pending.get('order_id')
                                placed_at = pending.get('placed_at', 0)
                                timeout = pending.get('timeout_seconds', 60)
                                reason = pending.get('reason', 'TP_HIT')
                                elapsed = datetime.now().timestamp() - placed_at
                                
                                try:
                                    order_status = await live_binance_trader.check_order_status(pos_symbol, order_id)
                                    status = order_status.get('status', 'unknown')
                                    
                                    if status == 'closed':
                                        # Phase 185: Check for partial fills
                                        fill_price = order_status.get('average', pending.get('limit_price', current_price))
                                        remaining_amt = order_status.get('remaining', 0)
                                        filled_amt = order_status.get('filled', 0)
                                        
                                        if remaining_amt > 0:
                                            # Phase 232: Partial fill ‚Üí weighted avg exit price
                                            logger.warning(f"‚ö†Ô∏è LIMIT_PARTIAL: {pos_symbol} filled={filled_amt:.4f} remaining={remaining_amt:.4f} ‚Üí market closing rest")
                                            limit_avg = fill_price
                                            market_avg = current_price
                                            try:
                                                mkt_result = await live_binance_trader.close_position(pos_symbol, pos['side'], remaining_amt)
                                                if mkt_result and mkt_result.get('average'):
                                                    market_avg = float(mkt_result['average'])
                                            except Exception as pf_err:
                                                logger.error(f"‚ùå Partial fill market close error: {pf_err}")
                                            # Weighted average exit
                                            exit_avg = (filled_amt * limit_avg + remaining_amt * market_avg) / (filled_amt + remaining_amt) if (filled_amt + remaining_amt) > 0 else fill_price
                                        else:
                                            exit_avg = fill_price
                                        
                                        logger.warning(f"‚úÖ LIMIT_FILLED: {pos_symbol} {pos['side']} @ ${exit_avg:.6f} | Reason: {reason} | Elapsed: {elapsed:.0f}s")
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, exit_avg, reason)
                                        continue
                                    elif status == 'canceled' or status == 'expired':
                                        # Phase 232: Distinct reason for cancelled orders
                                        cancel_reason = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                                        logger.warning(f"‚ö†Ô∏è LIMIT_CANCELLED: {pos_symbol} order {order_id} ‚Äî market close")
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, cancel_reason)
                                        continue
                                    elif elapsed >= timeout:
                                        # Phase 232: Distinct reason for timeout
                                        timeout_reason = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                                        logger.warning(f"‚è∞ LIMIT_TIMEOUT: {pos_symbol} {reason} not filled in {elapsed:.0f}s ‚Üí cancel + market")
                                        await live_binance_trader.cancel_order(pos_symbol, order_id)
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, timeout_reason)
                                        continue
                                    else:
                                        # Still open ‚Äî skip this position's SL/TP checks
                                        continue
                                except Exception as e:
                                    logger.error(f"Limit monitor error {pos_symbol}: {e}")
                                    if elapsed >= timeout:
                                        # Timeout reached even with error ‚Äî force market close
                                        try:
                                            await live_binance_trader.cancel_order(pos_symbol, order_id)
                                        except:
                                            pass
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                                        continue
                            
                            # Check SL/TP
                            # Phase 190: Skip if limit close is pending (breakeven or TP)
                            if pos.get('pending_limit_close'):
                                continue
                            
                            # Phase 212: Emergency SL runs BEFORE Flash Trade Guard
                            # Flash crash korumasƒ± ilk 60 saniyede de aktif olmalƒ±
                            sl_ws = pos.get('stopLoss', 0)
                            trailing_stop_ws = pos.get('trailingStop', sl_ws)
                            if check_emergency_sl_static(pos, current_price, trailing_stop_ws):
                                excess_pct = abs(current_price - trailing_stop_ws) / entry_price * 100
                                reason = 'EMERGENCY_SL'
                                logger.warning(f"üö® EMERGENCY SL (pre-guard): {pos_symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop_ws:.6f} | A≈üƒ±m: {excess_pct:.2f}%")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                            
                            # Phase 210: Flash Trade Guard ‚Äî minimum 60s hold time
                            MIN_HOLD_SECONDS_WS = 60
                            open_time_ms_ws = pos.get('openTime', 0)
                            if open_time_ms_ws > 0:
                                hold_duration_ws = datetime.now().timestamp() - (open_time_ms_ws / 1000)
                                if hold_duration_ws < MIN_HOLD_SECONDS_WS:
                                    continue  # Skip all exit checks ‚Äî too early
                            
                            # Phase 205: Use candle close price for exit DECISIONS (SL/TP/trail)
                            # Prevents false triggers from intra-candle wicks/spikes
                            candle_close_price = last_candle_close.get(pos_symbol, current_price)
                            
                            sl = pos.get('stopLoss', 0)
                            tp = pos.get('takeProfit', 0)
                            trailing_stop = pos.get('trailingStop', sl)
                            
                            # Phase 221: Breakeven SL varsa, trailing_stop'u breakeven seviyesinde tut
                            if pos.get('breakeven_activated', False) and sl > 0:
                                if pos['side'] == 'LONG':
                                    trailing_stop = max(trailing_stop, sl)
                                else:
                                    trailing_stop = min(trailing_stop, sl)
                                pos['trailingStop'] = trailing_stop
                            
                            # =========================================================
                            # Phase 202: STEPPED SL LOCK for Trend Mode positions
                            # Freqtrade custom_stoploss pattern ‚Äî lock profits as they grow
                            # =========================================================
                            # Phase 221: Stepped SL t√ºm trail-aktif pozisyonlara uygulanƒ±r (was trend_mode only)
                            if pos.get('isTrailingActive', False) and entry_price > 0:
                                if pos['side'] == 'LONG':
                                    current_roi = (candle_close_price - entry_price) / entry_price * 100
                                else:
                                    current_roi = (entry_price - candle_close_price) / entry_price * 100
                                
                                stepped_sl = None
                                if current_roi >= 10:
                                    # Lock %7 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.07
                                    else:
                                        stepped_sl = entry_price * 0.93
                                elif current_roi >= 5:
                                    # Lock %3 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.03
                                    else:
                                        stepped_sl = entry_price * 0.97
                                elif current_roi >= 2:
                                    # Lock %1 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.01
                                    else:
                                        stepped_sl = entry_price * 0.99
                                elif current_roi >= 0.5:
                                    # Breakeven lock
                                    stepped_sl = entry_price
                                
                                if stepped_sl is not None:
                                    # Only ratchet UP (LONG) or DOWN (SHORT) ‚Äî never weaken
                                    if pos['side'] == 'LONG' and stepped_sl > trailing_stop:
                                        old_sl = trailing_stop
                                        trailing_stop = stepped_sl
                                        pos['trailingStop'] = stepped_sl
                                        if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                                            logger.info(f"üîí STEPPED_SL: {pos.get('symbol','?')} LONG ROI={current_roi:.1f}% | SL ${old_sl:.6f} ‚Üí ${stepped_sl:.6f}")
                                    elif pos['side'] == 'SHORT' and stepped_sl < trailing_stop:
                                        old_sl = trailing_stop
                                        trailing_stop = stepped_sl
                                        pos['trailingStop'] = stepped_sl
                                        if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                                            logger.info(f"üîí STEPPED_SL: {pos.get('symbol','?')} SHORT ROI={current_roi:.1f}% | SL ${old_sl:.6f} ‚Üí ${stepped_sl:.6f}")
                            
                            # =========================================================
                            # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                            # SL triggers ONLY after 5 consecutive ticks AND 30 seconds
                            # of sustained breach. Protects against 1-min wick spikes.
                            # =========================================================
                            SL_CONFIRMATION_TICKS = 5  # Ticks required
                            SL_CONFIRMATION_SECONDS = 15  # Minimum seconds in SL zone
                            
                            # Initialize confirmation state
                            if 'slConfirmCount' not in pos:
                                pos['slConfirmCount'] = 0
                            if 'slBreachStartTime' not in pos:
                                pos['slBreachStartTime'] = 0
                            
                            # Check if price is in SL zone (candle close based)
                            sl_breached = False
                            if pos['side'] == 'LONG' and candle_close_price <= trailing_stop:
                                sl_breached = True
                            elif pos['side'] == 'SHORT' and candle_close_price >= trailing_stop:
                                sl_breached = True
                            
                            # =========================================================
                            # Phase 205b: EMERGENCY SL ‚Äî tick price WAY past SL
                            # If current_price exceeds SL by >1.5% of entry, close
                            # immediately. Bypasses both candle close AND spike confirm.
                            # Protects against major crashes mid-candle.
                            # =========================================================
                            if check_emergency_sl_static(pos, current_price, trailing_stop):
                                excess_pct = abs(current_price - trailing_stop) / entry_price * 100
                                reason = 'EMERGENCY_SL'
                                logger.warning(f"üö® EMERGENCY SL: {pos_symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop:.6f} | A≈üƒ±m: {excess_pct:.2f}% | Candle close: ${candle_close_price:.6f}")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                            
                            now_ts = datetime.now().timestamp()
                            if sl_breached:
                                # Phase 231c: Trail hit ‚Üí immediate close (no confirmation delay)
                                # Trail is profit protection ‚Äî delay loses money
                                if pos.get('isTrailingActive', False):
                                    reason = 'TRAIL_EXIT'
                                    logger.info(f"üî¥ TRAIL EXIT (immediate): {pos_symbol} {pos['side']} @ ${current_price:.6f} | Trail ${trailing_stop:.6f}")
                                    global_paper_trader.close_position(pos, current_price, reason)
                                    continue
                                
                                # Start timer on first breach (SL only, not trail)
                                if pos['slConfirmCount'] == 0:
                                    pos['slBreachStartTime'] = now_ts
                                pos['slConfirmCount'] += 1
                                breach_duration = now_ts - pos['slBreachStartTime']
                                logger.debug(f"SL breach tick {pos['slConfirmCount']}/{SL_CONFIRMATION_TICKS} ({breach_duration:.0f}s/{SL_CONFIRMATION_SECONDS}s) for {pos.get('symbol', '?')}")
                                
                                # Close only if BOTH conditions met: enough ticks AND enough time
                                if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                                    # Phase 183: Hybrid ‚Äî limit for liquid, market for illiquid
                                    spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                                    is_trailing_hit = pos.get('isTrailingActive', False)
                                    
                                    if is_trailing_hit and spread_level in ('Very Low', 'Low') and pos.get('isLive', False) and live_binance_trader.enabled and not pos.get('pending_limit_close'):
                                        # Liquid coin trailing stop ‚Üí try limit order
                                        try:
                                            contracts = abs(pos.get('contracts', pos.get('size', 0)))
                                            limit_result = await live_binance_trader.close_position_limit(
                                                pos_symbol, pos['side'], contracts, trailing_stop
                                            )
                                            if limit_result and limit_result.get('id'):
                                                pos['pending_limit_close'] = {
                                                    'order_id': limit_result['id'],
                                                    'placed_at': datetime.now().timestamp(),
                                                    'limit_price': trailing_stop,
                                                    'reason': 'TRAIL_EXIT',
                                                    'timeout_seconds': 45,
                                                }
                                                logger.warning(f"üìô TRAIL_LIMIT: {pos_symbol} {pos['side']} limit @ ${trailing_stop:.6f} (liquid coin, saves slippage)")
                                                continue
                                            else:
                                                logger.warning(f"üìô TRAIL_LIMIT_FAIL: {pos_symbol} limit failed, market close")
                                                global_paper_trader.close_position(pos, current_price, 'TRAIL_EXIT')
                                                continue
                                        except Exception as e:
                                            logger.error(f"Trail limit error {pos_symbol}: {e}")
                                            global_paper_trader.close_position(pos, current_price, 'TRAIL_EXIT')
                                            continue
                                    else:
                                        # Illiquid coin or regular SL ‚Üí market close (execution certainty)
                                        logger.info(f"üî¥ SL CONFIRMED: {pos.get('symbol', '?')} after {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                                        # ROI negatifse SL'den kapanmƒ±≈ü ‚Äî trailing aktif olsa bile etiket SL_HIT
                                        pos_roi = pos.get('unrealizedPnlPercent', 0)
                                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive', False) and pos_roi >= 0) else 'SL_HIT'
                                        global_paper_trader.close_position(pos, current_price, reason)
                                        continue
                            else:
                                # Price recovered - reset counter (spike bypassed!)
                                if pos['slConfirmCount'] > 0:
                                    bypass_duration = now_ts - pos['slBreachStartTime']
                                    logger.info(f"‚ö° Spike bypassed for {pos.get('symbol', '?')} after {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
                                pos['slConfirmCount'] = 0
                                pos['slBreachStartTime'] = 0
                            
                            # =========================================================
                            # Phase 183: TP_HIT ‚Üí Limit Order (saves slippage)
                            # Place limit at TP price. If unfilled, price went higher = more profit.
                            # Market fallback after 60 seconds.
                            # =========================================================
                            tp_hit = False
                            if pos['side'] == 'LONG' and candle_close_price >= tp:
                                tp_hit = True
                            elif pos['side'] == 'SHORT' and candle_close_price <= tp:
                                tp_hit = True
                            
                            if tp_hit and not pos.get('pending_limit_close'):
                                if pos.get('isLive', False) and live_binance_trader.enabled:
                                    try:
                                        contracts = abs(pos.get('contracts', pos.get('size', 0)))
                                        limit_result = await live_binance_trader.close_position_limit(
                                            pos_symbol, pos['side'], contracts, tp
                                        )
                                        if limit_result and limit_result.get('id'):
                                            pos['pending_limit_close'] = {
                                                'order_id': limit_result['id'],
                                                'placed_at': datetime.now().timestamp(),
                                                'limit_price': tp,
                                                'reason': 'TP_HIT',
                                                'timeout_seconds': 60,
                                            }
                                            logger.warning(f"üìó TP_LIMIT: {pos_symbol} {pos['side']} limit @ ${tp:.6f} (saves slippage vs market)")
                                            continue
                                        else:
                                            # Limit failed ‚Üí immediate market close
                                            logger.warning(f"üìó TP_LIMIT_FAIL: {pos_symbol} limit failed, falling back to market")
                                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                            continue
                                    except Exception as e:
                                        logger.error(f"TP limit error {pos_symbol}: {e}")
                                        global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                        continue
                                else:
                                    # Paper trading ‚Üí immediate close
                                    global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                    continue
                            
                            # ===================================================================
                            # Phase 214: FAILED CONTINUATION DETECTOR
                            # N kez k√¢ra ge√ßip entry'ye geri d√∂nen pozisyonlarƒ± breakeven'da kapat
                            # ===================================================================
                            fc_result = check_failed_continuation(pos, candle_close_price)
                            if fc_result == 'FAILED_CONTINUATION':
                                fc_count = pos.get('fc_failed_count', 0)
                                logger.warning(f"üìä FAILED_CONTINUATION: {pos_symbol} {pos['side']} ‚Äî {fc_count} ba≈üarƒ±sƒ±z deneme, breakeven kapatƒ±lƒ±yor")
                                # Breakeven close: entry + spread buffer
                                be_exit_price = entry_price * 1.0005 if pos['side'] == 'LONG' else entry_price * 0.9995
                                global_paper_trader.close_position(pos, be_exit_price, 'FAILED_CONTINUATION')
                                continue
                            
                            # Update trailing stop if in profit
                            trail_activation = pos.get('trailActivation', entry_price)
                            trail_distance = pos.get('trailDistance', 0)
                            
                            # ===================================================================
                            # REAL-TIME VOLATILITY-BASED TRAIL
                            # ATR y√ºzdesi √ºzerinden ger√ßek zamanlƒ± volatilite hesaplama
                            # ===================================================================
                            pos_atr = pos.get('atr', entry_price * 0.02)
                            atr_pct = (pos_atr / entry_price) * 100 if entry_price > 0 else 2.0
                            
                            # Volatilite √ßarpanƒ±: ATR % bazlƒ± dinamik hesaplama
                            # D√º≈ü√ºk ATR% (<1.5) = sƒ±kƒ± trail, Y√ºksek ATR% (>6) = geni≈ü trail
                            if atr_pct < 1.0:
                                volatility_mult = 0.6   # BTC/ETH - √ßok d√º≈ü√ºk volatilite
                            elif atr_pct < 1.5:
                                volatility_mult = 0.75  # Major altcoin
                            elif atr_pct < 2.5:
                                volatility_mult = 1.0   # Normal volatilite
                            elif atr_pct < 4.0:
                                volatility_mult = 1.3   # Volatil
                            elif atr_pct < 6.0:
                                volatility_mult = 1.6   # Y√ºksek volatilite
                            else:
                                volatility_mult = 2.0   # Meme coin - √ßok y√ºksek volatilite
                            
                            volatility_adjusted_distance = trail_distance * volatility_mult
                            
                            # ===================================================================
                            # PROFIT-BASED TRAIL: K√¢r arttƒ±k√ßa trail mesafesi sƒ±kƒ±la≈üƒ±r
                            # Phase 222: Gran√ºler ROI bazlƒ± trail daraltma
                            # ===================================================================
                            pnl_pct = pos.get('unrealizedPnlPercent', 0)
                            if pnl_pct >= 25.0:
                                dynamic_trail_distance = volatility_adjusted_distance * 0.4   # √áok y√ºksek k√¢r: √ßok sƒ±kƒ±
                            elif pnl_pct >= 15.0:
                                dynamic_trail_distance = volatility_adjusted_distance * 0.55  # Y√ºksek k√¢r
                            elif pnl_pct >= 8.0:
                                dynamic_trail_distance = volatility_adjusted_distance * 0.70  # Orta k√¢r
                            elif pnl_pct >= 4.0:
                                dynamic_trail_distance = volatility_adjusted_distance * 0.85  # D√º≈ü√ºk k√¢r
                            else:
                                dynamic_trail_distance = volatility_adjusted_distance          # Normal
                            
                            # Phase 231d: Dynamic trail activation threshold (ATR + spread + volume)
                            leverage = pos.get('leverage', 10)
                            if pos['side'] == 'LONG':
                                price_move_pct = ((candle_close_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                            else:
                                price_move_pct = ((entry_price - candle_close_price) / entry_price) * 100 if entry_price > 0 else 0
                            roi_pct = price_move_pct * leverage
                            
                            # Dynamic thresholds from market conditions
                            pos_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
                            if not pos_atr_pct and entry_price > 0:
                                pos_atr_pct = (pos.get('atr', entry_price * 0.02) / entry_price) * 100
                            pos_atr_pct = pos_atr_pct or 2.0
                            pos_spread = pos.get('spreadPct', 0.05)
                            pos_vol_ratio = pos.get('volumeRatio', 1.0)
                            min_price_move_for_trail, min_roi_for_trail = get_dynamic_trail_activation_threshold(
                                pos_atr_pct, pos_spread, pos_vol_ratio, leverage
                            )
                            
                            # Phase 231h: Fee buffer for breakeven (0.1% = taker fee both sides)
                            be_long = entry_price * 1.001
                            be_short = entry_price * 0.999
                            
                            if pos['side'] == 'LONG':
                                trail_already_active = pos.get('isTrailingActive', False)
                                # Hybrid rule: price_move >= min OR (roi >= min_roi AND price_move >= min*0.6)
                                trail_should_activate = (
                                    price_move_pct >= min_price_move_for_trail or
                                    (roi_pct >= min_roi_for_trail and price_move_pct >= min_price_move_for_trail * 0.6)
                                )
                                if trail_should_activate or trail_already_active:
                                    new_trailing = candle_close_price - dynamic_trail_distance
                                    # Phase 231h: Clamp ‚Äî trail stop never below breakeven
                                    new_trailing = max(new_trailing, be_long)
                                    if new_trailing > trailing_stop:
                                        pos['trailingStop'] = new_trailing
                                        if not trail_already_active:
                                            pos['isTrailingActive'] = True
                                            # Breakeven SL on first activation
                                            pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                                            logger.info(f"üìä TRAIL_DYN: {pos_symbol} LONG trail ON | move={price_move_pct:.2f}% roi={roi_pct:.1f}% | thresh: move>={min_price_move_for_trail:.2f}% roi>={min_roi_for_trail:.1f}% | vr={pos_vol_ratio:.1f} sp={pos_spread:.3f}% atr={pos_atr_pct:.1f}%")
                            elif pos['side'] == 'SHORT':
                                trail_already_active = pos.get('isTrailingActive', False)
                                trail_should_activate = (
                                    price_move_pct >= min_price_move_for_trail or
                                    (roi_pct >= min_roi_for_trail and price_move_pct >= min_price_move_for_trail * 0.6)
                                )
                                if trail_should_activate or trail_already_active:
                                    new_trailing = candle_close_price + dynamic_trail_distance
                                    # Phase 231h: Clamp ‚Äî trail stop never above breakeven
                                    new_trailing = min(new_trailing, be_short)
                                    if new_trailing < trailing_stop:
                                        pos['trailingStop'] = new_trailing
                                        if not trail_already_active:
                                            pos['isTrailingActive'] = True
                                            pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                                            logger.info(f"üìä TRAIL_DYN: {pos_symbol} SHORT trail ON | move={price_move_pct:.2f}% roi={roi_pct:.1f}% | thresh: move>={min_price_move_for_trail:.2f}% roi>={min_roi_for_trail:.1f}% | vr={pos_vol_ratio:.1f} sp={pos_spread:.3f}% atr={pos_atr_pct:.1f}%")
                                    
                    except Exception as pos_error:
                        logger.debug(f"Position update error: {pos_error}")
                        continue
                
                # =====================================================================
                # Phase 231: TIME-BASED POSITION MANAGEMENT (moved here from before price update)
                # Now runs AFTER position prices/PnL are updated ‚Äî fixes stale partial TP check
                # =====================================================================
                if global_paper_trader.enabled and global_paper_trader.positions:
                    logger.info(f"üìä TIME_MANAGER_CALL: positions={len(global_paper_trader.positions)}")
                    time_actions = await time_based_position_manager.check_positions(global_paper_trader)
                    if time_actions.get('trail_activated') or time_actions.get('time_reduced') or time_actions.get('partial_tp'):
                        logger.info(f"üìä Time Manager Actions: Trail={time_actions['trail_activated']}, Reduced={time_actions['time_reduced']}, TP={time_actions.get('partial_tp', [])}")
                
                # =====================================================================
                # PHASE 34: CHECK PENDING ORDERS FOR EXECUTION
                # =====================================================================
                # Phase 50: Calculate dynamic min score before processing signals
                global_paper_trader.calculate_dynamic_min_score()
                
                await global_paper_trader.check_pending_orders(opportunities)
                
                # Broadcast position updates to UI (throttled)
                if global_paper_trader.positions:
                    await ui_ws_manager.broadcast_price_update(global_paper_trader.positions)
                
                # Log periodic status (every 5 minutes = 30 iterations)
                if int(datetime.now().timestamp()) % 300 < scan_interval:
                    long_count = stats.get('longSignals', 0)
                    short_count = stats.get('shortSignals', 0)
                    pending_count = len(global_paper_trader.pending_orders)
                    tracking_count = len(post_trade_tracker.tracking)
                    logger.info(f"üìä Scanner Status: {stats.get('analyzedCoins', 0)} coins | L:{long_count} S:{short_count} | Pending: {pending_count} | Tracking: {tracking_count}")
                
                # Phase 52: Update post-trade tracker with current prices (EVERY scan cycle for accurate tracking)
                try:
                    if post_trade_tracker.tracking:  # Only if we have trades to track
                        current_prices = {opp['symbol']: opp.get('currentPrice', 0) for opp in opportunities}
                        completed_analyses = post_trade_tracker.update_prices(current_prices)
                        if completed_analyses:
                            logger.info(f"üìä Post-trade: {len(completed_analyses)} trade analizi tamamlandƒ±")
                except Exception as pt_error:
                    logger.debug(f"Post-trade update error: {pt_error}")
                
                # Phase 224D: Detect market regime periodically (every scan cycle)
                try:
                    market_regime_manager.detect_regime()
                except Exception as mr_err:
                    logger.debug(f"Regime detection error: {mr_err}")
                
                # Phase 224C3: Apply PostTradeTracker tuning recommendations every 15 min
                if int(datetime.now().timestamp()) % 900 < scan_interval:
                    try:
                        tuning = post_trade_tracker.get_tuning_recommendations()
                        if tuning:
                            regime_profile = market_regime_manager.get_profile()
                            # Store tuning for use in update loop
                            global_paper_trader._tuning_recs = tuning
                            logger.info(f"üìä Applied tuning: {tuning} regime={market_regime_manager.current_regime}")
                    except Exception as tune_err:
                        logger.debug(f"Tuning recommendations error: {tune_err}")
                
                # Phase 52: Run optimizer every 15 minutes (900 seconds)
                if int(datetime.now().timestamp()) % 900 < scan_interval:
                    logger.info("ü§ñ AI Optimizer check triggered (15-min interval)")
                    try:
                        # Phase 53: Update market regime with BTC price
                        btc_opp = next((o for o in opportunities if o['symbol'] == 'BTCUSDT'), None)
                        if btc_opp:
                            market_regime_detector.update_btc_price(btc_opp.get('currentPrice', 0))
                        regime = market_regime_detector.detect_regime()
                        regime_params = market_regime_detector.get_regime_params()
                        
                        pt_stats = post_trade_tracker.get_stats()
                        analysis = performance_analyzer.analyze(global_paper_trader.trades, pt_stats)
                        
                        # Add market regime to analysis
                        if analysis:
                            analysis['market_regime'] = regime
                            analysis['regime_params'] = regime_params
                        
                        if analysis:
                            current_settings = {
                                'z_score_threshold': global_paper_trader.z_score_threshold,
                                'min_score_low': global_paper_trader.min_score_low,
                                'min_score_high': global_paper_trader.min_score_high,
                                'entry_tightness': global_paper_trader.entry_tightness,
                                'max_positions': global_paper_trader.max_positions,
                            }
                            optimization = parameter_optimizer.optimize(analysis, current_settings)
                            
                            # Log AI analysis
                            total_pnl = analysis.get('total_pnl', 0)
                            corr_count = optimization.get('correlations_count', 0)
                            snapshots = optimization.get('trades_with_snapshot', 0)
                            logger.info(f"ü§ñ AI: PnL ${total_pnl:.0f} | WR {analysis.get('win_rate', 0):.0f}% | Correlations: {corr_count} | Snapshots: {snapshots}")
                            global_paper_trader.add_log(f"ü§ñ AI: PnL ${total_pnl:.0f} | WR {analysis.get('win_rate', 0):.0f}% | PF {analysis.get('profit_factor', 0):.2f}")
                            
                            if optimization.get('changes'):
                                global_paper_trader.add_log(f"ü§ñ √ñneri: {', '.join(optimization.get('changes', [])[:3])}")
                            
                            if optimization.get('recommendations') and parameter_optimizer.enabled:
                                applied = parameter_optimizer.apply_recommendations(global_paper_trader, optimization['recommendations'])
                                if applied:
                                    logger.info(f"ü§ñ AI Optimizer: Applied {list(applied.keys())}")
                                    global_paper_trader.add_log(f"ü§ñ Ayarlar g√ºncellendi ‚úÖ")
                        else:
                            logger.info("ü§ñ AI Optimizer: No analysis data available")
                    except Exception as opt_error:
                        logger.error(f"ü§ñ AI Optimizer error: {opt_error}")
                
                await asyncio.sleep(scan_interval)
                
            except Exception as loop_error:
                import traceback
                logger.error(f"üî¥ Scanner loop error: {loop_error}")
                logger.error(f"üî¥ Traceback:\n{traceback.format_exc()}")
                await asyncio.sleep(5)  # Wait before retry
                
    except asyncio.CancelledError:
        logger.info("Background Scanner Loop cancelled")
        multi_coin_scanner.running = False
    except Exception as e:
        import traceback
        logger.error(f"üî¥ Scanner FATAL error: {e}")
        logger.error(f"üî¥ Traceback:\n{traceback.format_exc()}")
        logger.error(f"Background scanner fatal error: {e}")
        multi_coin_scanner.running = False

# ============================================================================
# PHASE 191: REAL-TIME WEBSOCKET POSITION PRICE CALLBACK
# ============================================================================

async def on_position_price_update(symbol: str, ticker: dict):
    """
    Phase 191: WebSocket'ten gelen her fiyat g√ºncellemesinde √ßaƒürƒ±lƒ±r (~100ms).
    Aktif pozisyonun fiyatƒ±nƒ± g√ºnceller ve SL/TP/trailing kontrol eder.
    """
    current_price = ticker.get('last', 0)
    if current_price <= 0:
        return
    
    for pos in list(global_paper_trader.positions):
        if pos.get('symbol') != symbol:
            continue
        
        # ---- Fiyat + PnL g√ºncelle ----
        entry_price = pos.get('entryPrice', current_price)
        size = pos.get('size', 0)
        size_usd = pos.get('sizeUsd', 0)
        leverage = pos.get('leverage', 1)
        
        if pos['side'] == 'LONG':
            pnl = (current_price - entry_price) * size
        else:
            pnl = (entry_price - current_price) * size
        
        pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
        
        pos['currentPrice'] = current_price
        pos['unrealizedPnl'] = round(pnl, 6)
        pos['unrealizedPnlPercent'] = round(pnl_percent, 2)

        # Keep UI cache hot between scanner cycles for faster frontend updates.
        try:
            for cached_pos in ui_state_cache.positions:
                if cached_pos.get('symbol') != symbol:
                    continue
                cached_pos['currentPrice'] = current_price
                cached_pos['markPrice'] = current_price
                cached_pos['unrealizedPnl'] = round(pnl, 6)
                cached_pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
        except Exception:
            pass
        
        # ---- Pending limit close varsa SL/TP atla ----
        pending = pos.get('pending_limit_close')
        if pending and pos.get('isLive', False) and live_binance_trader.enabled:
            order_id = pending.get('order_id')
            placed_at = pending.get('placed_at', 0)
            timeout = pending.get('timeout_seconds', 60)
            reason = pending.get('reason', 'TP_HIT')
            elapsed = datetime.now().timestamp() - placed_at
            
            try:
                order_check = await live_binance_trader.check_order_status(symbol, order_id)
                chk_status = order_check.get('status', 'unknown')
                
                if chk_status == 'closed':
                    fill_price = order_check.get('average', pending.get('limit_price', current_price))
                    remaining_amt = order_check.get('remaining', 0)
                    filled_amt_ws = order_check.get('filled', 0)
                    if remaining_amt > 0:
                        limit_avg_ws = fill_price
                        market_avg_ws = current_price
                        try:
                            mkt_r = await live_binance_trader.close_position(symbol, pos['side'], remaining_amt)
                            if mkt_r and mkt_r.get('average'):
                                market_avg_ws = float(mkt_r['average'])
                        except:
                            pass
                        exit_avg_ws = (filled_amt_ws * limit_avg_ws + remaining_amt * market_avg_ws) / (filled_amt_ws + remaining_amt) if (filled_amt_ws + remaining_amt) > 0 else fill_price
                    else:
                        exit_avg_ws = fill_price
                    logger.warning(f"‚úÖ WS_LIMIT_FILLED: {symbol} @ ${exit_avg_ws:.6f} | {reason} | {elapsed:.0f}s")
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, exit_avg_ws, reason)
                    continue
                elif chk_status in ('canceled', 'expired'):
                    cancel_reason_ws = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, cancel_reason_ws)
                    continue
                elif elapsed >= timeout:
                    timeout_reason_ws = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                    logger.warning(f"‚è∞ WS_TIMEOUT: {symbol} {reason} {elapsed:.0f}s ‚Üí market")
                    await live_binance_trader.cancel_order(symbol, order_id)
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, timeout_reason_ws)
                    continue
                else:
                    continue  # Still pending ‚Äî skip SL/TP
            except Exception as pe:
                if elapsed >= timeout:
                    try:
                        await live_binance_trader.cancel_order(symbol, order_id)
                    except:
                        pass
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                    continue
            continue  # pending_limit_close aktif, SL/TP atla
        
        if pos.get('pending_limit_close'):
            continue
        
        # ---- SL/TP Kontrol√º (Spike Bypass ile) ----
        # Phase 205: Use candle close price for exit DECISIONS
        candle_close_price = last_candle_close.get(symbol, current_price)
        
        sl = pos.get('stopLoss', 0)
        tp = pos.get('takeProfit', 0)
        trailing_stop = pos.get('trailingStop', sl)
        
        # Phase 231i: Stepped SL for ALL trail-active positions (was trend_mode only)
        # Aligned with scanner path (L7816) which already uses isTrailingActive
        if pos.get('isTrailingActive', False) and entry_price > 0:
            if pos['side'] == 'LONG':
                current_roi = (candle_close_price - entry_price) / entry_price * 100
            else:
                current_roi = (entry_price - candle_close_price) / entry_price * 100
            
            stepped_sl = None
            if current_roi >= 10:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.07
                else:
                    stepped_sl = entry_price * 0.93
            elif current_roi >= 5:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.03
                else:
                    stepped_sl = entry_price * 0.97
            elif current_roi >= 2:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.01
                else:
                    stepped_sl = entry_price * 0.99
            elif current_roi >= 0.5:
                stepped_sl = entry_price
            
            if stepped_sl is not None:
                if pos['side'] == 'LONG' and stepped_sl > trailing_stop:
                    old_sl = trailing_stop
                    trailing_stop = stepped_sl
                    pos['trailingStop'] = stepped_sl
                    if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                        logger.info(f"üîí STEPPED_SL(WS): {symbol} LONG ROI={current_roi:.1f}% | SL ${old_sl:.6f} ‚Üí ${stepped_sl:.6f}")
                elif pos['side'] == 'SHORT' and stepped_sl < trailing_stop:
                    old_sl = trailing_stop
                    trailing_stop = stepped_sl
                    pos['trailingStop'] = stepped_sl
                    if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                        logger.info(f"üîí STEPPED_SL(WS): {symbol} SHORT ROI={current_roi:.1f}% | SL ${old_sl:.6f} ‚Üí ${stepped_sl:.6f}")
        
        SL_CONFIRMATION_TICKS = 3
        SL_CONFIRMATION_SECONDS = 15
        SL_MAX_WAIT_SECONDS = 60  # Phase 217: Sakin piyasada max bekleme
        
        if 'slConfirmCount' not in pos:
            pos['slConfirmCount'] = 0
        if 'slBreachStartTime' not in pos:
            pos['slBreachStartTime'] = 0
        
        sl_breached = False
        if pos['side'] == 'LONG' and candle_close_price <= trailing_stop:
            sl_breached = True
        elif pos['side'] == 'SHORT' and candle_close_price >= trailing_stop:
            sl_breached = True
        
        # Phase 205b: EMERGENCY SL ‚Äî tick price WAY past SL
        if check_emergency_sl_static(pos, current_price, trailing_stop):
            excess_pct = abs(current_price - trailing_stop) / entry_price * 100
            logger.warning(f"üö® EMERGENCY SL (WS): {symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop:.6f} | A≈üƒ±m: {excess_pct:.2f}%")
            global_paper_trader.close_position(pos, current_price, 'EMERGENCY_SL')
            continue
        
        now_ts = datetime.now().timestamp()
        if sl_breached:
            # Phase 231c: Trail hit ‚Üí immediate close (no confirmation delay)
            if pos.get('isTrailingActive', False):
                reason = 'TRAIL_EXIT'
                logger.info(f"üî¥ TRAIL EXIT (immediate, WS): {symbol} {pos['side']} @ ${current_price:.6f} | Trail ${trailing_stop:.6f}")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
            
            if pos['slConfirmCount'] == 0:
                pos['slBreachStartTime'] = now_ts
            pos['slConfirmCount'] += 1
            breach_duration = now_ts - pos['slBreachStartTime']
            if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                reason = 'SL_HIT'
                logger.info(f"üî¥ SL CONFIRMED (WS): {symbol} @ ${current_price:.6f} | {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
            elif breach_duration >= SL_MAX_WAIT_SECONDS:
                # Phase 217: Sakin piyasada tick gelmese bile s√ºre doldu
                reason = 'TRAIL_EXIT' if pos.get('isTrailingActive', False) else 'SL_HIT'
                logger.info(f"üî¥ SL TIMEOUT (WS): {symbol} @ ${current_price:.6f} | {breach_duration:.0f}s timeout")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
        else:
            if pos['slConfirmCount'] > 0:
                bypass_duration = now_ts - pos['slBreachStartTime']
                logger.info(f"‚ö° Spike bypassed (WS): {symbol} | {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
            pos['slConfirmCount'] = 0
            pos['slBreachStartTime'] = 0
        
        # TP Hit Check (anƒ±nda ‚Äî kar i√ßin onay gerekmez)
        # Phase 205: Use candle close for TP decision
        if pos['side'] == 'LONG' and candle_close_price >= tp:
            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
            logger.info(f"‚úÖ TP triggered (WS): LONG {symbol} @ ${current_price:.6f} (candle close ${candle_close_price:.6f})")
            continue
        elif pos['side'] == 'SHORT' and candle_close_price <= tp:
            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
            logger.info(f"‚úÖ TP triggered (WS): SHORT {symbol} @ ${current_price:.6f} (candle close ${candle_close_price:.6f})")
            continue
        
        # ---- Phase 214: FAILED CONTINUATION DETECTOR (WS) ----
        fc_result_ws = check_failed_continuation(pos, candle_close_price)
        if fc_result_ws == 'FAILED_CONTINUATION':
            fc_count_ws = pos.get('fc_failed_count', 0)
            logger.warning(f"üìä FAILED_CONTINUATION (WS): {symbol} {pos['side']} ‚Äî {fc_count_ws} ba≈üarƒ±sƒ±z deneme")
            be_exit_ws = entry_price * 1.0005 if pos['side'] == 'LONG' else entry_price * 0.9995
            global_paper_trader.close_position(pos, be_exit_ws, 'FAILED_CONTINUATION')
            continue
        
        # ---- Trailing Stop G√ºncelle ----
        trail_activation = pos.get('trailActivation', entry_price)
        trail_distance = pos.get('trailDistance', 0)
        
        pos_atr = pos.get('atr', entry_price * 0.02)
        atr_pct = (pos_atr / entry_price) * 100 if entry_price > 0 else 2.0
        
        if atr_pct < 1.0:
            volatility_mult = 0.6
        elif atr_pct < 1.5:
            volatility_mult = 0.75
        elif atr_pct < 2.5:
            volatility_mult = 1.0
        elif atr_pct < 4.0:
            volatility_mult = 1.3
        elif atr_pct < 6.0:
            volatility_mult = 1.6
        else:
            volatility_mult = 2.0
        
        dynamic_trail_distance = trail_distance * volatility_mult
        
        # Phase 213: Profit-based softened tightening (WS parity with scanner)
        ws_pnl_pct = pos.get('unrealizedPnlPercent', 0)
        if ws_pnl_pct >= 15.0:
            dynamic_trail_distance = dynamic_trail_distance * 0.7
        elif ws_pnl_pct >= 8.0:
            dynamic_trail_distance = dynamic_trail_distance * 0.85
        
        # Dynamic trail activation threshold (ATR + spread + volume)
        ws_leverage = pos.get('leverage', 10)
        if pos['side'] == 'LONG':
            ws_price_move_pct = ((candle_close_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
        else:
            ws_price_move_pct = ((entry_price - candle_close_price) / entry_price) * 100 if entry_price > 0 else 0
        ws_roi_pct = ws_price_move_pct * ws_leverage
        
        ws_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
        if not ws_atr_pct and entry_price > 0:
            ws_atr_pct = (pos.get('atr', entry_price * 0.02) / entry_price) * 100
        ws_atr_pct = ws_atr_pct or 2.0
        ws_spread = pos.get('spreadPct', 0.05)
        ws_vol_ratio = pos.get('volumeRatio', 1.0)
        ws_min_price_move, ws_min_roi = get_dynamic_trail_activation_threshold(
            ws_atr_pct, ws_spread, ws_vol_ratio, ws_leverage
        )
        
        # Phase 231h: Fee buffer for breakeven
        be_long = entry_price * 1.001
        be_short = entry_price * 0.999
        
        ws_trail_already_active = pos.get('isTrailingActive', False)
        if pos['side'] == 'LONG':
            # Hybrid rule: price_move >= min OR (roi >= min_roi AND price_move >= min*0.6)
            ws_should_activate = (
                ws_price_move_pct >= ws_min_price_move or
                (ws_roi_pct >= ws_min_roi and ws_price_move_pct >= ws_min_price_move * 0.6)
            )
            if ws_should_activate or ws_trail_already_active:
                new_trailing = candle_close_price - dynamic_trail_distance
                # Phase 231h: Clamp ‚Äî trail stop never below breakeven
                new_trailing = max(new_trailing, be_long)
                if new_trailing > trailing_stop:
                    pos['trailingStop'] = new_trailing
                    if not ws_trail_already_active:
                        pos['isTrailingActive'] = True
                        pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                        logger.info(f"üìä TRAIL_DYN(WS): {pos.get('symbol')} LONG trail ON | move={ws_price_move_pct:.2f}% roi={ws_roi_pct:.1f}% | thresh: move>={ws_min_price_move:.2f}% roi>={ws_min_roi:.1f}% | vr={ws_vol_ratio:.1f} sp={ws_spread:.3f}%")
        elif pos['side'] == 'SHORT':
            ws_should_activate = (
                ws_price_move_pct >= ws_min_price_move or
                (ws_roi_pct >= ws_min_roi and ws_price_move_pct >= ws_min_price_move * 0.6)
            )
            if ws_should_activate or ws_trail_already_active:
                new_trailing = candle_close_price + dynamic_trail_distance
                new_trailing = min(new_trailing, be_short)
                if new_trailing < trailing_stop:
                    pos['trailingStop'] = new_trailing
                    if not ws_trail_already_active:
                        pos['isTrailingActive'] = True
                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                        logger.info(f"üìä TRAIL_DYN(WS): {pos.get('symbol')} SHORT trail ON | move={ws_price_move_pct:.2f}% roi={ws_roi_pct:.1f}% | thresh: move>={ws_min_price_move:.2f}% roi>={ws_min_roi:.1f}% | vr={ws_vol_ratio:.1f} sp={ws_spread:.3f}%")


# ============================================================================
# PHASE 35: HIGH-FREQUENCY POSITION PRICE UPDATER (BACKUP)
# ============================================================================

async def position_price_update_loop():
    """
    High-frequency position price updater.
    Runs every 2 seconds to update prices ONLY for coins with open positions.
    This is 5x faster than the main scanner loop for critical position monitoring.
    """
    logger.info("‚ö° Position Price Updater started - 1.5s interval (Phase 185)")
    
    update_interval = 5.0  # Phase 191: Backup only ‚Äî ana g√ºncelleme WS callback'te
    
    # Wait for app to fully initialize
    await asyncio.sleep(5)
    
    try:
        while True:
            try:
                # Skip if no open positions
                if not global_paper_trader.positions:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Get unique symbols with open positions
                position_symbols = list(set(p.get('symbol', '') for p in global_paper_trader.positions if p.get('symbol')))
                
                if not position_symbols:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Get instant prices from WebSocket (no API call needed)
                tickers = binance_ws_manager.get_tickers(position_symbols)
                
                if not tickers:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Update each open position with real-time price
                for pos in list(global_paper_trader.positions):
                    try:
                        symbol = pos.get('symbol', '')
                        ticker = tickers.get(symbol)
                        
                        if not ticker:
                            continue
                        
                        current_price = ticker.get('last', 0)
                        if current_price <= 0:
                            continue
                        
                        # Calculate unrealized PnL
                        entry_price = pos.get('entryPrice', current_price)
                        size = pos.get('size', 0)
                        size_usd = pos.get('sizeUsd', 0)
                        leverage = pos.get('leverage', 1)
                        
                        if pos['side'] == 'LONG':
                            pnl = (current_price - entry_price) * size
                        else:
                            pnl = (entry_price - current_price) * size
                        
                        pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
                        
                        # Update position data
                        pos['unrealizedPnl'] = round(pnl, 6)
                        pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
                        pos['currentPrice'] = current_price
                        
                        # Phase 185: Check pending limit closes in fast loop
                        pending = pos.get('pending_limit_close')
                        if pending and pos.get('isLive', False) and live_binance_trader.enabled:
                            order_id = pending.get('order_id')
                            placed_at = pending.get('placed_at', 0)
                            timeout = pending.get('timeout_seconds', 60)
                            reason = pending.get('reason', 'TP_HIT')
                            elapsed = datetime.now().timestamp() - placed_at
                            
                            try:
                                order_check = await live_binance_trader.check_order_status(symbol, order_id)
                                chk_status = order_check.get('status', 'unknown')
                                
                                if chk_status == 'closed':
                                    fill_price = order_check.get('average', pending.get('limit_price', current_price))
                                    remaining_amt = order_check.get('remaining', 0)
                                    filled_amt_fast = order_check.get('filled', 0)
                                    if remaining_amt > 0:
                                        logger.warning(f"‚ö†Ô∏è FAST_PARTIAL: {symbol} remaining={remaining_amt:.4f} ‚Üí market close")
                                        limit_avg_fast = fill_price
                                        market_avg_fast = current_price
                                        try:
                                            mkt_rf = await live_binance_trader.close_position(symbol, pos['side'], remaining_amt)
                                            if mkt_rf and mkt_rf.get('average'):
                                                market_avg_fast = float(mkt_rf['average'])
                                        except:
                                            pass
                                        exit_avg_fast = (filled_amt_fast * limit_avg_fast + remaining_amt * market_avg_fast) / (filled_amt_fast + remaining_amt) if (filled_amt_fast + remaining_amt) > 0 else fill_price
                                    else:
                                        exit_avg_fast = fill_price
                                    logger.warning(f"‚úÖ FAST_LIMIT_FILLED: {symbol} @ ${exit_avg_fast:.6f} | {reason} | {elapsed:.0f}s")
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, exit_avg_fast, reason)
                                    continue
                                elif chk_status in ('canceled', 'expired'):
                                    cancel_reason_fast = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, cancel_reason_fast)
                                    continue
                                elif elapsed >= timeout:
                                    timeout_reason_fast = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                                    logger.warning(f"‚è∞ FAST_TIMEOUT: {symbol} {reason} {elapsed:.0f}s ‚Üí market")
                                    await live_binance_trader.cancel_order(symbol, order_id)
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, timeout_reason_fast)
                                    continue
                                else:
                                    continue  # Still pending ‚Äî skip SL/TP checks
                            except Exception as pe:
                                if elapsed >= timeout:
                                    try:
                                        await live_binance_trader.cancel_order(symbol, order_id)
                                    except:
                                        pass
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                                    continue
                        
                        # Check SL/TP exits with SPIKE BYPASS
                        # Phase 190: Skip if limit close is pending (breakeven or TP)
                        if pos.get('pending_limit_close'):
                            continue
                        sl = pos.get('stopLoss', 0)
                        tp = pos.get('takeProfit', 0)
                        trailing_stop = pos.get('trailingStop', sl)
                        
                        # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation
                        SL_CONFIRMATION_TICKS = 5
                        SL_CONFIRMATION_SECONDS = 15
                        
                        if 'slConfirmCount' not in pos:
                            pos['slConfirmCount'] = 0
                        if 'slBreachStartTime' not in pos:
                            pos['slBreachStartTime'] = 0
                        
                        sl_breached = False
                        if pos['side'] == 'LONG' and current_price <= trailing_stop:
                            sl_breached = True
                        elif pos['side'] == 'SHORT' and current_price >= trailing_stop:
                            sl_breached = True
                        
                        now_ts = datetime.now().timestamp()
                        if sl_breached:
                            if pos['slConfirmCount'] == 0:
                                pos['slBreachStartTime'] = now_ts
                            pos['slConfirmCount'] += 1
                            breach_duration = now_ts - pos['slBreachStartTime']
                            if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                                reason = 'TRAIL_EXIT' if pos.get('isTrailingActive', False) else 'SL_HIT'
                                logger.info(f"üî¥ SL CONFIRMED (fast): {symbol} @ ${current_price:.6f} | {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                        else:
                            if pos['slConfirmCount'] > 0:
                                bypass_duration = now_ts - pos['slBreachStartTime']
                                logger.info(f"‚ö° Spike bypassed (fast): {symbol} | {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
                            pos['slConfirmCount'] = 0
                            pos['slBreachStartTime'] = 0
                        
                        # TP Hit Check (immediate - no confirmation for profits)
                        if pos['side'] == 'LONG' and current_price >= tp:
                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                            logger.info(f"‚úÖ TP triggered: LONG {symbol} @ ${current_price:.6f}")
                            continue
                        elif pos['side'] == 'SHORT' and current_price <= tp:
                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                            logger.info(f"‚úÖ TP triggered: SHORT {symbol} @ ${current_price:.6f}")
                            continue
                        
                        # ---- Phase 214: FAILED CONTINUATION DETECTOR (backup) ----
                        # Phase 214 fix: Use candle close price, not tick price
                        fc_candle_close_bu = last_candle_close.get(symbol, current_price)
                        fc_result_bu = check_failed_continuation(pos, fc_candle_close_bu)
                        if fc_result_bu == 'FAILED_CONTINUATION':
                            fc_count_bu = pos.get('fc_failed_count', 0)
                            logger.warning(f"üìä FAILED_CONTINUATION (backup): {symbol} {pos['side']} ‚Äî {fc_count_bu} ba≈üarƒ±sƒ±z deneme")
                            be_exit_bu = entry_price * 1.0005 if pos['side'] == 'LONG' else entry_price * 0.9995
                            global_paper_trader.close_position(pos, be_exit_bu, 'FAILED_CONTINUATION')
                            continue
                        
                        # Update trailing stop if in profit
                        trail_activation = pos.get('trailActivation', entry_price)
                        trail_distance = pos.get('trailDistance', 0)
                        
                        # Real-time ATR% based volatility (same as main loop)
                        pos_atr = pos.get('atr', entry_price * 0.02)
                        atr_pct = (pos_atr / entry_price) * 100 if entry_price > 0 else 2.0
                        
                        if atr_pct < 1.0:
                            volatility_mult = 0.6
                        elif atr_pct < 1.5:
                            volatility_mult = 0.75
                        elif atr_pct < 2.5:
                            volatility_mult = 1.0
                        elif atr_pct < 4.0:
                            volatility_mult = 1.3
                        elif atr_pct < 6.0:
                            volatility_mult = 1.6
                        else:
                            volatility_mult = 2.0
                        
                        dynamic_trail_distance = trail_distance * volatility_mult
                        
                        # Phase 213: Profit-based softened tightening (parity with scanner/WS)
                        fast_pnl_pct = pos.get('unrealizedPnlPercent', 0)
                        if fast_pnl_pct >= 15.0:
                            dynamic_trail_distance = dynamic_trail_distance * 0.7
                        elif fast_pnl_pct >= 8.0:
                            dynamic_trail_distance = dynamic_trail_distance * 0.85
                        
                        # Dynamic trail activation threshold (ATR + spread + volume)
                        fast_leverage = pos.get('leverage', 10)
                        if pos['side'] == 'LONG':
                            fast_price_move = ((current_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                        else:
                            fast_price_move = ((entry_price - current_price) / entry_price) * 100 if entry_price > 0 else 0
                        fast_roi = fast_price_move * fast_leverage
                        
                        fast_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
                        if not fast_atr_pct and entry_price > 0:
                            fast_atr_pct = (pos.get('atr', entry_price * 0.02) / entry_price) * 100
                        fast_atr_pct = fast_atr_pct or 2.0
                        fast_spread = pos.get('spreadPct', 0.05)
                        fast_vol_ratio = pos.get('volumeRatio', 1.0)
                        fast_min_price_move, fast_min_roi = get_dynamic_trail_activation_threshold(
                            fast_atr_pct, fast_spread, fast_vol_ratio, fast_leverage
                        )
                        
                        # Phase 231h: Fee buffer for breakeven
                        be_long = entry_price * 1.001
                        be_short = entry_price * 0.999
                        
                        fast_trail_already_active = pos.get('isTrailingActive', False)
                        if pos['side'] == 'LONG':
                            fast_should_activate = (
                                fast_price_move >= fast_min_price_move or
                                (fast_roi >= fast_min_roi and fast_price_move >= fast_min_price_move * 0.6)
                            )
                            if fast_should_activate or fast_trail_already_active:
                                new_trailing = current_price - dynamic_trail_distance
                                # Phase 231h: Clamp ‚Äî trail stop never below breakeven
                                new_trailing = max(new_trailing, be_long)
                                if new_trailing > trailing_stop:
                                    pos['trailingStop'] = new_trailing
                                    if not fast_trail_already_active:
                                        pos['isTrailingActive'] = True
                                        pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                        elif pos['side'] == 'SHORT':
                            fast_should_activate = (
                                fast_price_move >= fast_min_price_move or
                                (fast_roi >= fast_min_roi and fast_price_move >= fast_min_price_move * 0.6)
                            )
                            if fast_should_activate or fast_trail_already_active:
                                new_trailing = current_price + dynamic_trail_distance
                                new_trailing = min(new_trailing, be_short)
                                if new_trailing < trailing_stop:
                                    pos['trailingStop'] = new_trailing
                                    if not fast_trail_already_active:
                                        pos['isTrailingActive'] = True
                                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                                
                    except Exception as pos_error:
                        logger.debug(f"Position update error for {symbol}: {pos_error}")
                        continue
                
                await asyncio.sleep(update_interval)
                
            except Exception as loop_error:
                logger.error(f"Position updater loop error: {loop_error}")
                await asyncio.sleep(update_interval)
                
    except asyncio.CancelledError:
        logger.info("Position Price Updater cancelled")
    except Exception as e:
        logger.error(f"Position updater fatal error: {e}")

async def process_signal_for_paper_trading(signal: dict, price: float):
    """Process a signal for paper trading execution."""
    if not global_paper_trader.enabled:
        return
    
    # ================================================================
    # Phase 142: Block signals during recovery cooldown
    # ================================================================
    if portfolio_recovery_manager.is_in_cooldown():
        cooldown_remaining = portfolio_recovery_manager.get_cooldown_remaining()
        logger.info(f"‚è∏Ô∏è RECOVERY COOLDOWN: Skipping signal {signal.get('symbol', '?')}, {cooldown_remaining:.1f}h remaining")
        return None
    
    action = signal.get('action', 'NONE')
    if action == 'NONE':
        return
    
    # Phase 225: Block signals during price shock (trade execution level gate)
    try:
        shock_blocked, shock_reason = price_shock_manager.should_block_signal(action, signal.get('symbol', ''))
        if shock_blocked:
            logger.info(f"‚ö° SHOCK_BLOCK: {signal.get('symbol', '?')} {action} blocked at execution ‚Äî {shock_reason}")
            return None
    except Exception:
        pass
    
    symbol = signal.get('symbol', global_paper_trader.symbol)
    atr = signal.get('atr', 0)
    
    # Phase 127: Log signal processing entry for tracing
    logger.info(f"üîÑ PROC_SIGNAL: Processing {symbol} {action} @ ${price:.4f}")
    
    # Prepare signal data for logging
    signal_log_data = {
        'symbol': symbol,
        'action': action,
        'price': price,
        'zscore': signal.get('zscore', 0),
        'hurst': signal.get('hurst', 0),
        'atr': atr,
        'signal_score': signal.get('confidenceScore', 0),
        'z_threshold': global_paper_trader.z_score_threshold,
        'min_confidence': global_paper_trader.min_confidence_score,
        'entry_tightness': global_paper_trader.entry_tightness,
        'exit_tightness': global_paper_trader.exit_tightness,
        'timestamp': int(datetime.now().timestamp() * 1000),
        'accepted': False,
        'reject_reason': '',
        'mtf_confirmed': True,
        'mtf_reason': '',
        'htf_trend': 'NEUTRAL',
        'blacklisted': False,
        'obi_value': 0.0,  # Phase 211: OBI depth value (updated before save)
    }
    
    # Check if we already have a position in this symbol
    existing_position = None
    for pos in global_paper_trader.positions:
        if pos.get('symbol') == symbol:
            existing_position = pos
            break
    
    # Don't open new position if we already have one in this symbol
    if existing_position:
        existing_side = existing_position.get('side', '')
        
        # Phase 200: Counter-signal detection ‚Äî ters sinyal varsa exit_tightness modifier uygula
        if existing_side != action:
            # Ters sinyal! Skor bazlƒ± modifier hesapla
            signal_score = signal.get('confidenceScore', 0)  # Phase 223: was 'score' (field didn't exist)
            if signal_score >= 90:
                modifier = 0.4
            elif signal_score >= 80:
                modifier = 0.55
            elif signal_score >= 65:
                modifier = 0.7
            elif signal_score >= 50:
                modifier = 0.85
            else:
                modifier = 1.0  # Zayƒ±f sinyal, etki yok
            
            if modifier < 1.0:
                existing_position['counter_signal_modifier'] = modifier
                existing_position['counter_signal_time'] = datetime.now().timestamp()
                effective_et = global_paper_trader.exit_tightness * modifier
                logger.info(f"‚ö° COUNTER SIGNAL: {symbol} {action} (skor:{signal_score}) vs a√ßƒ±k {existing_side} ‚Üí exit_tightness {global_paper_trader.exit_tightness:.1f}‚Üí{effective_et:.1f} (x{modifier})")
        
        signal_log_data['reject_reason'] = 'EXISTING_POSITION'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.info(f"üö´ SKIPPING {symbol}: Already have position ({existing_position.get('side', 'UNKNOWN')})")
        return
    
    # Check max positions
    if len(global_paper_trader.positions) >= global_paper_trader.max_positions:
        signal_log_data['reject_reason'] = 'MAX_POSITIONS'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.info(f"üö´ SKIPPING {symbol}: Max positions reached ({len(global_paper_trader.positions)})")
        return
    
    # Phase 219: USDT-based directional exposure limit ‚Äî early reject
    MAX_DIRECTION_EXPOSURE_PCT = 0.40
    signal_side = 'LONG' if action in ('BUY', 'LONG') else 'SHORT'
    same_dir_margin = sum(
        p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
        for p in global_paper_trader.positions if p.get('side') == signal_side
    )
    same_dir_margin += sum(
        p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
        for p in global_paper_trader.pending_orders if p.get('side') == signal_side
    )
    max_dir_exposure = global_paper_trader.balance * MAX_DIRECTION_EXPOSURE_PCT
    if same_dir_margin >= max_dir_exposure:
        signal_log_data['reject_reason'] = 'DIRECTION_EXPOSURE'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.info(f"üö´ SKIPPING {symbol}: {signal_side} exposure ${same_dir_margin:.2f} >= ${max_dir_exposure:.2f} ({MAX_DIRECTION_EXPOSURE_PCT*100:.0f}% of balance)")
        return
    
    # Check blacklist
    if global_paper_trader.is_coin_blacklisted(symbol):
        signal_log_data['reject_reason'] = 'BLACKLISTED'
        signal_log_data['blacklisted'] = True
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.info(f"üö´ SKIPPING {symbol}: Blacklisted")
        return
    
    # =====================================================
    # BTC TREND FILTER (Cloud Scanner)
    # =====================================================
    try:
        btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
            symbol, action,
            coin_change_pct=signal.get('priceChange24h', 0),
            volume_24h=signal.get('volume24h', 0),
            zscore=signal.get('zscore', 0),
            spread_pct=signal.get('spreadPct', 0)
        )
        
        if not btc_allowed:
            signal_log_data['reject_reason'] = f'BTC_FILTER:{btc_reason}'
            safe_create_task(sqlite_manager.save_signal(signal_log_data))
            logger.info(f"üö´ BTC FILTER RED: {action} {symbol} - {btc_reason}")
            return
        
        # Phase 230B: Override risk caps (leverage 3x, size 50%)
        if btc_filter.last_override:
            signal['overrideLeverageCap'] = 3
            signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), 0.5)
            logger.info(f"üí™ OVERRIDE CAPS: {symbol} | leverage‚â§3x, size‚â§0.5x")
        
        # Apply penalty to signal score and size
        if btc_penalty > 0:
            # Score penalty: 0.5 penalty = -50% score adjustment
            original_score = signal.get('confidenceScore', 60)
            score_penalty = int(original_score * btc_penalty)
            signal['confidenceScore'] = max(40, original_score - score_penalty)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 - btc_penalty)
            signal['btc_adjustment'] = btc_reason
            logger.info(f"‚ö†Ô∏è BTC PENALTY: {action} {symbol} | Score: -{score_penalty} | Size: -{btc_penalty*100:.0f}%")
        elif btc_penalty < 0:
            # Bonus for aligned signals
            bonus = abs(btc_penalty)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + bonus)
            signal['btc_adjustment'] = btc_reason
            logger.info(f"‚úÖ BTC BONUS: {action} {symbol} | Size: +{bonus*100:.0f}%")
        else:
            # Phase 127: Log pass when no penalty/bonus
            logger.info(f"‚úÖ BTC_FILTER PASS: {symbol} {action}")
            
    except Exception as btc_err:
        logger.warning(f"BTC Filter error: {btc_err}")
    
    # =====================================================
    # Phase 211: OBI DEPTH FILTER ‚Äî L2 Order Book Pressure
    # Sadece sinyal √ºretilmi≈ü coinler i√ßin depth √ßekilir (rate limit safe)
    # Tiered: |OBI| > 0.6 = VETO, 0.3-0.6 = -15 penalty, < 0.3 = neutral
    # =====================================================
    try:
        obi_value = await obi_detector.get_obi(symbol)
        
        # Phase 212: Thin Order Book Guard ‚Äî min bid+ask depth (Phase EQG: $50K ‚Üí $120K)
        try:
            depth_data = obi_detector.obi_cache.get(symbol, {})
            total_depth = depth_data.get('total_bid_usd', 0) + depth_data.get('total_ask_usd', 0)
            if 0 < total_depth < EQ_MIN_DEPTH_USD:  # Phase EQG: Dynamic threshold
                signal_log_data['reject_reason'] = f'THIN_BOOK:depth_${total_depth:.0f}'
                signal_log_data['obi_value'] = round(obi_value, 4)
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                logger.info(f"üìä THIN_BOOK: {action} {symbol} | Depth=${total_depth:.0f} < ${EQ_MIN_DEPTH_USD/1000:.0f}K ‚Üí BLOCKED")
                return
        except Exception:
            pass  # depth data may not always be available
        
        # Determine if OBI opposes or aligns with signal direction
        is_opposing = False
        is_aligned = False
        
        if obi_value > 0.3:  # Buying pressure (bid heavy)
            if action == "SHORT":
                is_opposing = True
            elif action == "LONG":
                is_aligned = True
        elif obi_value < -0.3:  # Selling pressure (ask heavy)
            if action == "LONG":
                is_opposing = True
            elif action == "SHORT":
                is_aligned = True
        
        if is_opposing:
            if abs(obi_value) > EQ_OBI_OPPOSE_VETO:  # Phase EQG: 0.6 ‚Üí 0.35
                # Strong opposing pressure ‚Üí VETO
                signal_log_data['reject_reason'] = f'OBI_VETO:opposing_{obi_value:.3f}'
                signal_log_data['obi_value'] = round(obi_value, 4)
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                logger.info(f"üìä OBI_VETO: {action} {symbol} | OBI={obi_value:+.3f} > {EQ_OBI_OPPOSE_VETO} | Opposing pressure ‚Üí BLOCKED")
                return
            else:
                # Moderate opposing pressure ‚Üí Soft penalty (-15)
                original_score = signal.get('confidenceScore', 60)
                signal['confidenceScore'] = max(40, original_score - 15)
                signal_log_data['obi_value'] = round(obi_value, 4)
                logger.info(f"üìä OBI_PENALTY: {action} {symbol} | OBI={obi_value:+.3f} | Score: {original_score} ‚Üí {signal['confidenceScore']} (-15)")
        elif is_aligned:
            signal_log_data['obi_value'] = round(obi_value, 4)
            logger.info(f"üìä OBI_CONFIRM: {action} {symbol} | OBI={obi_value:+.3f} | Order book aligned ‚úÖ")
        else:
            # Phase EQG: Neutral OBI + d√º≈ü√ºk hacim ise reject
            signal_log_data['obi_value'] = round(obi_value, 4)
            vol_ratio_val = signal.get('volumeRatio', 1.0)
            if abs(obi_value) < 0.12 and vol_ratio_val < 1.2:
                signal_log_data['reject_reason'] = f'OBI_NEUTRAL_LOW_VOL:obi={obi_value:.3f},vr={vol_ratio_val:.1f}'
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                logger.info(f"üìä OBI_NEUTRAL_LOW_VOL: {action} {symbol} | OBI={obi_value:+.3f} vol_ratio={vol_ratio_val:.1f} ‚Üí BLOCKED")
                return
            logger.debug(f"üìä OBI_NEUTRAL: {action} {symbol} | OBI={obi_value:+.3f}")
        
    except Exception as obi_err:
        logger.debug(f"OBI filter error for {symbol}: {obi_err}")
    
    # =====================================================
    # Phase 60: MARKET REGIME FILTER
    # TRENDING_DOWN durumunda LONG sinyallere ek kontrol
    # =====================================================
    try:
        current_regime = market_regime_detector.current_regime
        regime_params = market_regime_detector.get_regime_params()
        
        # TRENDING_DOWN durumunda LONG sinyallere aƒüƒ±r penalty
        if current_regime == "TRENDING_DOWN" and action == "LONG":
            long_penalty = regime_params.get('long_penalty', 0.5)
            
            # %50+ penalty varsa sinyali reddet
            if long_penalty >= 0.5:
                signal_log_data['reject_reason'] = f'REGIME_BLOCKED:TRENDING_DOWN'
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                logger.info(f"üö´ REGIME BLOCK: {action} {symbol} - TRENDING_DOWN blocks LONGs")
                return
            else:
                # D√º≈ü√ºk penalty - sadece uyar
                original_score = signal.get('confidenceScore', 60)
                penalty_amount = int(original_score * long_penalty)
                signal['confidenceScore'] = max(40, original_score - penalty_amount)
                signal['regime_adjustment'] = f"TRENDING_DOWN penalty -{penalty_amount}"
                logger.info(f"‚ö†Ô∏è REGIME PENALTY: {action} {symbol} | Score: -{penalty_amount}")
        
        # TRENDING_UP durumunda SHORT sinyallere uyarƒ±
        elif current_regime == "TRENDING_UP" and action == "SHORT":
            short_penalty = regime_params.get('short_penalty', 0.2)
            original_score = signal.get('confidenceScore', 60)
            penalty_amount = int(original_score * short_penalty)
            signal['confidenceScore'] = max(40, original_score - penalty_amount)
            signal['regime_adjustment'] = f"TRENDING_UP penalty -{penalty_amount}"
            logger.info(f"‚ö†Ô∏è REGIME PENALTY: {action} {symbol} | Score: -{penalty_amount}")
        
        # TRENDING_UP + LONG veya TRENDING_DOWN + SHORT = bonus
        elif (current_regime == "TRENDING_UP" and action == "LONG"):
            long_bonus = regime_params.get('long_bonus', 0.15)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + long_bonus)
            signal['regime_adjustment'] = f"TRENDING_UP bonus +{int(long_bonus*100)}%"
            logger.info(f"‚úÖ REGIME BONUS: {action} {symbol} | Size: +{int(long_bonus*100)}%")
        elif (current_regime == "TRENDING_DOWN" and action == "SHORT"):
            short_bonus = regime_params.get('short_bonus', 0.2)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + short_bonus)
            signal['regime_adjustment'] = f"TRENDING_DOWN bonus +{int(short_bonus*100)}%"
            logger.info(f"‚úÖ REGIME BONUS: {action} {symbol} | Size: +{int(short_bonus*100)}%")
    except Exception as regime_err:
        logger.debug(f"Market Regime Filter error: {regime_err}")
    
    # ================================================================
    # Phase 215: MA ALIGNMENT HARD VETO
    # 4H + 1D + Supertrend √º√ß√º aynƒ± y√∂nde ‚Üí ters sinyal HARD REJECT
    # ================================================================
    ma_vetoed, ma_veto_reason = check_ma_alignment_veto(symbol, action)
    if ma_vetoed:
        signal_log_data['reject_reason'] = f"MA_ALIGNMENT_VETO:{ma_veto_reason}"
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.warning(f"üö´ MA_VETO: {action} {symbol} ‚Äî {ma_veto_reason}")
        return
    
    # MULTI-TIMEFRAME CONFIRMATION CHECK
    # Verify signal aligns with higher timeframe (1h) trend
    mtf_result = mtf_confirmation.confirm_signal(symbol, action)
    signal_log_data['htf_trend'] = mtf_result.get('htf_trend', 'NEUTRAL')
    signal_log_data['mtf_confirmed'] = mtf_result['confirmed']
    signal_log_data['mtf_reason'] = mtf_result.get('reason', '')
    
    if not mtf_result['confirmed']:
        signal_log_data['reject_reason'] = f"MTF_REJECTED:{mtf_result['reason']}"
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        logger.info(f"üö´ MTF RED: {action} {symbol} (skor: {mtf_result.get('mtf_score', 0)}) - {mtf_result['reason']}")
        return
    
    # Phase 127: Log MTF confirmation pass
    logger.info(f"‚úÖ MTF_CONFIRMATION PASS: {symbol} {action} (score: {mtf_result.get('mtf_score', 0)})")
    
    # Signal is ACCEPTED
    signal_log_data['accepted'] = True
    safe_create_task(sqlite_manager.save_signal(signal_log_data))
    
    # Log MTF score info
    mtf_score = mtf_result.get('mtf_score', 0)
    score_modifier = mtf_result.get('score_modifier', 1.0)
    if score_modifier > 1.0:
        logger.info(f"‚úÖ MTF BONUS: {action} {symbol} (skor: +{mtf_score}) - pozisyon +%10 b√ºy√ºk")
    elif score_modifier < 1.0:
        logger.info(f"‚ö†Ô∏è MTF PENALTY: {action} {symbol} (skor: {mtf_score}) - pozisyon -%20 k√º√ß√ºk")
    
    # Add MTF size modifier to signal for position sizing
    signal['mtf_size_modifier'] = score_modifier
    
    # Phase 202: Pass trend_mode and strong_trend data to signal
    signal['trend_mode'] = mtf_result.get('trend_mode', False)
    signal['strong_trend_size_mult'] = mtf_result.get('strong_trend_size_mult', 1.0)
    signal['adx_4h'] = mtf_result.get('adx_4h', 0)
    signal['supertrend_dir'] = mtf_result.get('supertrend_dir', 0)
    if signal['trend_mode']:
        logger.warning(f"üöÄ TREND_MODE SIGNAL: {action} {symbol} | ADX_4H={signal['adx_4h']:.0f} ST={signal['supertrend_dir']} Size√ó{signal['strong_trend_size_mult']:.0%}")
    
    # =====================================================
    # PHASE 99: MTF LEVERAGE ADJUSTMENT (Bonus/Penalty Only)
    # SignalGenerator already calculated unified leverage
    # Here we only apply MTF confirmation bonus/penalty
    # =====================================================
    try:
        # Calculate TF count from scores (positive score = aligned)
        scores = mtf_result.get('scores', {'15m': 0, '1h': 0, '4h': 0, '1d': 0})
        tf_count = sum(1 for s in scores.values() if s > 0)
        
        # Get existing leverage from SignalGenerator (unified calculation)
        current_leverage = signal.get('leverage', 25)
        
        # Apply MTF bonus/penalty (don't overwrite, just adjust)
        if tf_count >= 4:
            mtf_mult = 1.1   # +10% for all 4 TFs aligned
        elif tf_count >= 3:
            mtf_mult = 1.0   # No change for 3 TFs
        elif tf_count >= 2:
            mtf_mult = 0.8   # -20% for only 2 TFs
        else:
            mtf_mult = 0.6   # -40% for 0-1 TF aligned
        
        adjusted_leverage = int(round(current_leverage * mtf_mult))
        adjusted_leverage = max(3, min(50, adjusted_leverage))  # Phase 184: cap 75‚Üí50
        
        signal['leverage'] = adjusted_leverage
        signal['tf_count'] = tf_count
        signal['mtf_leverage_mult'] = mtf_mult
        
        # Log if MTF adjusted leverage
        if mtf_mult != 1.0:
            logger.info(f"üìä MTF Adjustment: {current_leverage}x √ó {mtf_mult:.1f} (TF:{tf_count}/4) ‚Üí {adjusted_leverage}x | {symbol}")
    except Exception as lev_err:
        logger.warning(f"MTF leverage adjustment error: {lev_err}")
    
    # =====================================================
    # VOLUME PROFILE BOOST (Cloud Scanner - WebSocket Parity)
    # FIX #4: Per-coin Volume Profile (accurate POC/VAH/VAL)
    # =====================================================
    try:
        # Get or create per-coin volume profiler
        if symbol not in coin_volume_profiles:
            coin_volume_profiles[symbol] = VolumeProfileAnalyzer()
        
        coin_vp = coin_volume_profiles[symbol]
        
        # Update volume profile if stale (every hour)
        if datetime.now().timestamp() - coin_vp.last_update > 3600:
            # Try to get OHLCV from scanner's exchange
            if multi_coin_scanner.exchange:
                ccxt_symbol = symbol.replace('USDT', '/USDT')
                ohlcv_4h = await multi_coin_scanner.exchange.fetch_ohlcv(ccxt_symbol, '4h', limit=100)
                if ohlcv_4h:
                    coin_vp.calculate_profile(ohlcv_4h)
                    logger.debug(f"Updated VP for {symbol}: POC={coin_vp.poc:.6f}")
        
        # Get boost based on price proximity to key levels
        vp_boost = coin_vp.get_signal_boost(price, action)
        if vp_boost > 0:
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + vp_boost)
            signal['vp_boost'] = vp_boost
            logger.info(f"üìà VP BOOST: {symbol} +{vp_boost*100:.0f}% @ POC={coin_vp.poc:.6f}")
    except Exception as vp_err:
        logger.warning(f"Volume Profile error: {vp_err}")
    
    # =====================================================
    # DYNAMIC TRAIL PARAMETERS (Cloud Scanner - WebSocket Parity)
    # Calculate trail_activation and trail_distance per-coin
    # =====================================================
    try:
        # Get Hurst from signal if available
        hurst = signal.get('hurst', 0.5)
        volatility_pct = signal.get('volatility_pct', (atr / price * 100) if price > 0 else 3.0)
        spread_pct = signal.get('spreadPct', 0.05)
        
        # Calculate dynamic trail params
        trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
            volatility_pct=volatility_pct,
            hurst=hurst,
            price=price,
            spread_pct=spread_pct,
            settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
            settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
        )
        
        signal['dynamic_trail_activation'] = trail_activation_atr
        signal['dynamic_trail_distance'] = trail_distance_atr
        
        # Log if significantly different from defaults (1.5, 1.0)
        if abs(trail_activation_atr - 1.5) > 0.3 or abs(trail_distance_atr - 1.0) > 0.2:
            logger.info(f"üéØ Dynamic Trail: act={trail_activation_atr}x, dist={trail_distance_atr}x | {symbol} (vol:{volatility_pct:.1f}%, hurst:{hurst:.2f})")
    except Exception as trail_err:
        logger.debug(f"Dynamic trail params error: {trail_err}")
    
    # =====================================================
    # Phase 224B: SIGNAL FLIP PENALTY
    # Same coin opposite signal within 5min ‚Üí score penalty
    # =====================================================
    try:
        now_ts = datetime.now().timestamp()
        last_sig = global_paper_trader.last_signal_per_coin.get(symbol, {})
        if last_sig:
            time_since_last = now_ts - last_sig.get('time', 0)
            was_opposite = last_sig.get('side') != action
            if was_opposite and time_since_last < 300:  # 5dk i√ßinde flip
                penalty = max(5, int(15 - (time_since_last / 20)))
                original_score = signal.get('confidenceScore', 60)
                signal['confidenceScore'] = max(40, original_score - penalty)
                logger.info(f"üîÑ FLIP_PENALTY: {symbol} {action} -{penalty}pt (flip {time_since_last:.0f}s ago, score {original_score}‚Üí{signal['confidenceScore']})")
        global_paper_trader.last_signal_per_coin[symbol] = {'side': action, 'time': now_ts}
    except Exception as flip_err:
        logger.debug(f"Flip penalty error: {flip_err}")
    
    # =====================================================
    # Phase 224B: EV-BASED SIGNAL FILTER
    # Reject signals with negative expected value
    # =====================================================
    try:
        ev = global_paper_trader.calculate_signal_ev(signal)
        signal['ev'] = round(ev, 4)
        if ev <= -0.5:
            signal_log_data['reject_reason'] = f'NEGATIVE_EV:{ev:.4f}'
            safe_create_task(sqlite_manager.save_signal(signal_log_data))
            logger.info(f"üìâ EV_REJECT: {action} {symbol} | EV={ev:.4f} <= -0.5 | score={signal.get('confidenceScore', 0)}")
            return
        elif ev < 0:
            logger.info(f"‚ö†Ô∏è EV_WARNING: {action} {symbol} | EV={ev:.4f} (weak but passing)")
    except Exception as ev_err:
        logger.debug(f"EV filter error: {ev_err}")
    
    # Execute trade
    try:
        await global_paper_trader.open_position(
            side=action,
            price=price,
            atr=atr,
            signal=signal,
            symbol=symbol
        )
        trends = mtf_result.get('trends', {})
        logger.info(f"ü§ñ Auto-Trade: {action} {symbol} @ ${price:.4f} | MTF:{mtf_score} | Lev:{signal.get('leverage', 50)}x | 15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}, 1d:{trends.get('1d','?')}")
    except Exception as e:
        logger.error(f"Auto-trade execution error: {e}")


# ============================================================================
# PHASE 30: SESSION-BASED TRADING
# ============================================================================

TRADING_SESSIONS = {
    "asia": {
        "hours_utc": (0, 8),
        "name": "Asya",
        "volatility": "low",
        "preferred_strategy": "mean_reversion",
        "leverage_mult": 0.7,
        "risk_mult": 0.8
    },
    "europe": {
        "hours_utc": (8, 14),
        "name": "Avrupa",
        "volatility": "medium",
        "preferred_strategy": "breakout",
        "leverage_mult": 1.0,
        "risk_mult": 1.0
    },
    "us": {
        "hours_utc": (14, 22),
        "name": "Amerika",
        "volatility": "high",
        "preferred_strategy": "momentum",
        "leverage_mult": 1.2,
        "risk_mult": 1.1
    },
    "overnight": {
        "hours_utc": (22, 24),
        "name": "Gece",
        "volatility": "low",
        # Phase 59: "avoid" -> "low_volatility" - t√ºm saatlerde sinyal √ºret
        # Gelecekte tekrar aktif etmek i√ßin: "avoid" yapƒ±n
        "preferred_strategy": "low_volatility",  # WAS: "avoid"
        "leverage_mult": 0.5,
        "risk_mult": 0.5
    }
}


class SessionManager:
    """
    Seans bazlƒ± trading ayarlarƒ±.
    Asia/Europe/US/Overnight session'larƒ±na g√∂re strateji ayarla.
    """
    
    def __init__(self):
        self.sessions = TRADING_SESSIONS
        self.current_session = None
        self.current_config = None
        logger.info("SessionManager initialized")
    
    def get_current_session(self) -> tuple:
        """Mevcut session'ƒ± d√∂nd√ºr."""
        hour_utc = datetime.utcnow().hour
        
        for name, config in self.sessions.items():
            start, end = config['hours_utc']
            if start <= hour_utc < end:
                self.current_session = name
                self.current_config = config
                return name, config
        
        # Fallback overnight
        self.current_session = "overnight"
        self.current_config = self.sessions["overnight"]
        return "overnight", self.sessions["overnight"]
    
    def adjust_leverage(self, base_leverage: int) -> int:
        """Session'a g√∂re kaldƒ±ra√ß ayarla."""
        _, config = self.get_current_session()
        adjusted = int(base_leverage * config['leverage_mult'])
        return max(3, min(75, adjusted))
    
    def adjust_risk(self, base_risk: float) -> float:
        """Session'a g√∂re risk ayarla."""
        _, config = self.get_current_session()
        return base_risk * config['risk_mult']
    
    def should_trade(self) -> bool:
        """
        Bu session'da trade yapƒ±lmalƒ± mƒ±?
        
        Phase 59: Deaktive edildi - t√ºm saatlerde sinyal √ºretilecek.
        Gelecekte tekrar aktif etmek i√ßin:
        return config['preferred_strategy'] != "avoid"
        """
        # _, config = self.get_current_session()
        # return config['preferred_strategy'] != "avoid"
        return True  # Always trade - session restriction disabled
    
    def get_session_info(self) -> dict:
        """Session bilgisi."""
        name, config = self.get_current_session()
        return {
            "session": name,
            "name_tr": config['name'],
            "volatility": config['volatility'],
            "strategy": config['preferred_strategy'],
            "leverage_mult": config['leverage_mult'],
            "risk_mult": config['risk_mult']
        }


# Global Session Manager instance
session_manager = SessionManager()


# ============================================================================
# MULTI-TIMEFRAME CONFIRMATION
# Confirms signals align with higher timeframe (1h) trends
# ============================================================================

class MultiTimeframeConfirmation:
    """
    Multi-Timeframe (MTF) Scoring System for signal validation.
    
    Checks 3 timeframes: 15m, 1h, 4h
    Each timeframe contributes points based on trend alignment:
    - 15m: 20 points (short-term momentum)
    - 1h:  30 points (main trend)
    - 4h:  50 points (major trend direction)
    
    Total possible: 100 points (fully aligned) to -100 (fully opposite)
    
    Decision thresholds:
    - Score > 50:  BONUS (+10% signal score)
    - Score 0-50:  NORMAL (proceed as usual)
    - Score 0 to -50: PENALTY (-20% signal score, but still allow)
    - Score < -50: BLOCK (too risky, strong counter-trend)
    """
    
    # Timeframe weights
    WEIGHTS = {
        '15m': 10,
        '1h': 20,
        '4h': 30,
        '1d': 40
    }
    
    def __init__(self):
        self.coin_trends = {}  # symbol -> {trend_15m, trend_1h, trend_4h, trend_1d, last_update, mtf_score}
        self.cache_ttl = 300  # 5 minutes cache per coin
        logger.info("üìä MTF Scoring System initialized (15m:10, 1h:20, 4h:30, 1d:40)")
    
    def get_trend_from_closes(self, closes: list) -> dict:
        """Calculate trend from close prices using EMA and price change."""
        if len(closes) < 10:
            return {"trend": "NEUTRAL", "strength": 0.0}
        
        closes_arr = np.array(closes[-30:] if len(closes) >= 30 else closes)
        
        # Simple EMA10
        alpha = 2 / (10 + 1)
        ema = closes_arr[0]
        for c in closes_arr[1:]:
            ema = alpha * c + (1 - alpha) * ema
        
        current_price = closes_arr[-1]
        
        # % change over last 4 candles
        if len(closes_arr) >= 4:
            change_pct = ((closes_arr[-1] - closes_arr[-4]) / closes_arr[-4]) * 100
        else:
            change_pct = 0
        
        # Determine trend
        if current_price > ema and change_pct > 0.2:
            if change_pct > 1.0:
                return {"trend": "STRONG_BULLISH", "strength": min(1.0, change_pct / 3.0)}
            return {"trend": "BULLISH", "strength": min(1.0, change_pct / 2.0)}
        elif current_price < ema and change_pct < -0.2:
            if change_pct < -1.0:
                return {"trend": "STRONG_BEARISH", "strength": min(1.0, abs(change_pct) / 3.0)}
            return {"trend": "BEARISH", "strength": min(1.0, abs(change_pct) / 2.0)}
        else:
            return {"trend": "NEUTRAL", "strength": 0.0}
    
    def calculate_trend_score(self, trend: str, signal_action: str, weight: int) -> int:
        """Calculate score contribution for a single timeframe."""
        # For LONG signals: Bullish trend = positive, Bearish = negative
        # For SHORT signals: Bearish trend = positive, Bullish = negative
        
        if signal_action == 'LONG':
            if trend in ['BULLISH', 'STRONG_BULLISH']:
                return weight  # Full positive
            elif trend in ['BEARISH', 'STRONG_BEARISH']:
                return -weight  # Full negative
            else:
                return 0  # Neutral
        
        elif signal_action == 'SHORT':
            if trend in ['BEARISH', 'STRONG_BEARISH']:
                return weight  # Full positive
            elif trend in ['BULLISH', 'STRONG_BULLISH']:
                return -weight  # Full negative
            else:
                return 0  # Neutral
        
        return 0
    
    def calculate_strong_trend_penalty(self, price_change_pct: float, signal_action: str, adx: float = 0) -> tuple:
        """
        Phase 143 + Phase 202: Strong Trend Filter + Pro-Trend Bonus
        
        Counter-trend: penalty + size reduction (Phase 143)
        Pro-trend: bonus + size increase + trend_mode flag (Phase 202)
        
        Returns:
            (score_modifier: int, size_multiplier: float, is_trend_mode: bool)
        """
        abs_change = abs(price_change_pct)
        
        # Trend y√∂n√º belirle
        is_bullish = price_change_pct > 0
        is_counter_trend = (is_bullish and signal_action == "SHORT") or \
                           (not is_bullish and signal_action == "LONG")
        is_pro_trend = (is_bullish and signal_action == "LONG") or \
                       (not is_bullish and signal_action == "SHORT")
        
        # ========== Phase 202: Pro-Trend Bonus ==========
        if is_pro_trend and abs_change >= 5 and adx >= 40:
            if abs_change >= 20:
                logger.warning(f"üöÄ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} ‚Üí {signal_action} BOOST (+15pts, 130% size)")
                return (+15, 1.30, True)
            elif abs_change >= 10:
                logger.warning(f"üöÄ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} ‚Üí {signal_action} BOOST (+10pts, 120% size)")
                return (+10, 1.20, True)
            elif abs_change >= 5:
                logger.info(f"üöÄ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} ‚Üí {signal_action} BOOST (+5pts, 110% size)")
                return (+5, 1.10, True)
        
        # ========== Phase 143: Counter-Trend Penalty ==========
        if not is_counter_trend or abs_change < 5:
            return (0, 1.0, False)
        
        if abs_change >= 20:
            logger.warning(f"‚ö†Ô∏è STRONG_TREND: {price_change_pct:+.1f}% ‚Üí {signal_action} penalized (-30, 25% size)")
            return (-30, 0.25, False)
        elif abs_change >= 10:
            logger.warning(f"‚ö†Ô∏è STRONG_TREND: {price_change_pct:+.1f}% ‚Üí {signal_action} penalized (-20, 50% size)")
            return (-20, 0.50, False)
        elif abs_change >= 5:
            logger.info(f"üìä STRONG_TREND: {price_change_pct:+.1f}% ‚Üí {signal_action} penalized (-10, 75% size)")
            return (-10, 0.75, False)
        
        return (0, 1.0, False)
    
    async def update_coin_trend(self, symbol: str, exchange) -> dict:
        """Fetch 15m, 1h, 4h, 1d candles and calculate MTF data."""
        now = datetime.now().timestamp()
        
        # Check cache
        if symbol in self.coin_trends:
            cache = self.coin_trends[symbol]
            if now - cache.get('last_update', 0) < self.cache_ttl:
                return cache
        
        result = {
            'symbol': symbol,
            'trend_15m': 'NEUTRAL',
            'trend_1h': 'NEUTRAL',
            'trend_4h': 'NEUTRAL',
            'trend_1d': 'NEUTRAL',
            'last_update': now
        }
        
        try:
            ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
            
            # Fetch all 4 timeframes
            ohlcv_15m = await exchange.fetch_ohlcv(ccxt_symbol, '15m', limit=30)
            ohlcv_1h = await exchange.fetch_ohlcv(ccxt_symbol, '1h', limit=30)
            ohlcv_4h = await exchange.fetch_ohlcv(ccxt_symbol, '4h', limit=30)
            ohlcv_1d = await exchange.fetch_ohlcv(ccxt_symbol, '1d', limit=30)
            
            # Calculate trends
            if ohlcv_15m and len(ohlcv_15m) >= 10:
                closes_15m = [c[4] for c in ohlcv_15m]
                trend_15m = self.get_trend_from_closes(closes_15m)
                result['trend_15m'] = trend_15m['trend']
            
            if ohlcv_1h and len(ohlcv_1h) >= 10:
                closes_1h = [c[4] for c in ohlcv_1h]
                trend_1h = self.get_trend_from_closes(closes_1h)
                result['trend_1h'] = trend_1h['trend']
            
            if ohlcv_4h and len(ohlcv_4h) >= 10:
                closes_4h = [c[4] for c in ohlcv_4h]
                trend_4h = self.get_trend_from_closes(closes_4h)
                result['trend_4h'] = trend_4h['trend']
                
                # Phase 143: Calculate price change over last 20 4H candles for Strong Trend Filter
                if len(ohlcv_4h) >= 20:
                    first_close = ohlcv_4h[-20][4]  # 20 candle ago
                    last_close = ohlcv_4h[-1][4]    # Current
                    price_change_pct = ((last_close - first_close) / first_close) * 100
                    result['price_change_4h_20'] = round(price_change_pct, 2)
                else:
                    result['price_change_4h_20'] = 0.0
                
                # Phase 202: Supertrend calculation for trend mode
                try:
                    if PANDAS_TA_AVAILABLE and len(ohlcv_4h) >= 14:
                        import pandas as pd
                        df_4h = pd.DataFrame(ohlcv_4h, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                        st = pta.supertrend(df_4h['high'], df_4h['low'], df_4h['close'], length=10, multiplier=3.0)
                        if st is not None and len(st) > 0:
                            st_dir = st.iloc[-1][f'SUPERTd_10_3.0']
                            result['supertrend_dir'] = int(st_dir)  # 1=bullish, -1=bearish
                        else:
                            result['supertrend_dir'] = 0
                    else:
                        result['supertrend_dir'] = 0
                except Exception as st_err:
                    logger.debug(f"Supertrend calc error {symbol}: {st_err}")
                    result['supertrend_dir'] = 0
                
                # Phase 202: ADX from 4H data for trend mode
                try:
                    highs_4h = [c[2] for c in ohlcv_4h]
                    lows_4h = [c[3] for c in ohlcv_4h]
                    closes_4h_list = [c[4] for c in ohlcv_4h]
                    adx_4h, adx_trend_4h, _, _ = calculate_adx(highs_4h, lows_4h, closes_4h_list)
                    result['adx_4h'] = adx_4h
                    result['adx_trend_4h'] = adx_trend_4h
                except Exception as adx_err:
                    logger.debug(f"ADX 4H calc error {symbol}: {adx_err}")
                    result['adx_4h'] = 0
                    result['adx_trend_4h'] = 'NEUTRAL'
            
            if ohlcv_1d and len(ohlcv_1d) >= 10:
                closes_1d = [c[4] for c in ohlcv_1d]
                trend_1d = self.get_trend_from_closes(closes_1d)
                result['trend_1d'] = trend_1d['trend']
            
            # Phase FIB: Cache OHLCV snapshots for Fibonacci swing detection
            if ohlcv_1h:
                result['ohlcv_1h'] = ohlcv_1h[-30:]
            if ohlcv_4h:
                result['ohlcv_4h'] = ohlcv_4h[-30:]
            
            self.coin_trends[symbol] = result
            logger.debug(f"MTF {symbol}: 15m={result['trend_15m']}, 1h={result['trend_1h']}, 4h={result['trend_4h']}, 1d={result['trend_1d']}, 4h_20_chg={result.get('price_change_4h_20', 0):.1f}%")
            
        except Exception as e:
            logger.debug(f"MTF update failed for {symbol}: {e}")
        
        return result
    
    def confirm_signal(self, symbol: str, signal_action: str) -> dict:
        """
        Calculate MTF score and determine if signal should proceed.
        
        Returns: {
            'mtf_score': int (-100 to +100),
            'confirmed': bool,
            'score_modifier': float (0.8 to 1.1),
            'reason': str,
            'trends': {15m, 1h, 4h}
        }
        """
        trend_data = self.coin_trends.get(symbol, {
            'trend_15m': 'NEUTRAL',
            'trend_1h': 'NEUTRAL', 
            'trend_4h': 'NEUTRAL'
        })
        
        # Calculate score for each timeframe
        score_15m = self.calculate_trend_score(trend_data.get('trend_15m', 'NEUTRAL'), signal_action, self.WEIGHTS['15m'])
        score_1h = self.calculate_trend_score(trend_data.get('trend_1h', 'NEUTRAL'), signal_action, self.WEIGHTS['1h'])
        score_4h = self.calculate_trend_score(trend_data.get('trend_4h', 'NEUTRAL'), signal_action, self.WEIGHTS['4h'])
        score_1d = self.calculate_trend_score(trend_data.get('trend_1d', 'NEUTRAL'), signal_action, self.WEIGHTS['1d'])
        
        total_score = score_15m + score_1h + score_4h + score_1d
        
        result = {
            'mtf_score': total_score,
            'confirmed': True,
            'score_modifier': 1.0,
            'reason': '',
            'htf_trend': trend_data.get('trend_1h', 'NEUTRAL'),  # Keep for compatibility
            'trends': {
                '15m': trend_data.get('trend_15m', 'NEUTRAL'),
                '1h': trend_data.get('trend_1h', 'NEUTRAL'),
                '4h': trend_data.get('trend_4h', 'NEUTRAL'),
                '1d': trend_data.get('trend_1d', 'NEUTRAL')
            },
            'scores': {
                '15m': score_15m,
                '1h': score_1h,
                '4h': score_4h,
                '1d': score_1d
            }
        }
        
        # Decision based on score
        if total_score > 50:
            # Strong alignment - BONUS
            result['score_modifier'] = 1.15  # +15% bonus
            result['reason'] = f"MTF uyumlu (+{total_score}): 15m:{result['trends']['15m']}, 1h:{result['trends']['1h']}, 4h:{result['trends']['4h']}, 1d:{result['trends']['1d']}"
        
        elif total_score >= 0:
            # Neutral to slight positive - NORMAL
            result['score_modifier'] = 1.0
            result['reason'] = f"MTF n√∂tr ({total_score}): 15m:{result['trends']['15m']}, 1h:{result['trends']['1h']}, 4h:{result['trends']['4h']}, 1d:{result['trends']['1d']}"
        
        elif total_score > -25:
            # Against trend but not too strong - PENALTY
            result['score_modifier'] = 0.8  # -20% penalty
            result['reason'] = f"MTF kar≈üƒ±t ({total_score}): pozisyon a√ßƒ±lacak ama %20 d√º≈ü√ºk skor"
        
        else:
            # Strongly against trend - BLOCK (< -25)
            result['confirmed'] = False
            result['score_modifier'] = 0.0
            result['reason'] = f"MTF RED ({total_score}): √ßok g√º√ßl√º kar≈üƒ± trend"
        
        # ================================================================
        # Phase 143 + 202: Strong Trend Filter + Pro-Trend Bonus
        # ================================================================
        price_change_4h_20 = trend_data.get('price_change_4h_20', 0.0)
        adx_4h = trend_data.get('adx_4h', 0)
        supertrend_dir = trend_data.get('supertrend_dir', 0)
        
        strong_trend_penalty, strong_trend_size_mult, is_trend_mode = self.calculate_strong_trend_penalty(
            price_change_4h_20, signal_action, adx=adx_4h
        )
        
        # Phase 202: Validate trend_mode with Supertrend confirmation
        if is_trend_mode:
            # Supertrend must agree: LONG needs bullish(1), SHORT needs bearish(-1)
            st_confirms = (signal_action == 'LONG' and supertrend_dir == 1) or \
                          (signal_action == 'SHORT' and supertrend_dir == -1)
            if not st_confirms:
                logger.info(f"üìä TREND_MODE downgrade: {signal_action} but Supertrend={supertrend_dir} ‚Äî disabling trend mode")
                is_trend_mode = False
                # Keep the score bonus but don't apply wider params
        
        # Apply modifier to mtf_score
        result['mtf_score'] += strong_trend_penalty
        result['strong_trend_penalty'] = strong_trend_penalty
        result['strong_trend_size_mult'] = strong_trend_size_mult
        result['price_change_4h_20'] = price_change_4h_20
        result['trend_mode'] = is_trend_mode
        result['adx_4h'] = adx_4h
        result['supertrend_dir'] = supertrend_dir
        
        # Adjust reason
        if is_trend_mode:
            result['reason'] += f" | üöÄ TREND_MODE(4h:{price_change_4h_20:+.1f}% ADX:{adx_4h:.0f} ST:{supertrend_dir}): +{strong_trend_penalty}pts, {int(strong_trend_size_mult*100)}% size"
        elif strong_trend_penalty < 0:
            result['reason'] += f" | STRONG_TREND({price_change_4h_20:+.1f}%): {strong_trend_penalty}pts, {int(strong_trend_size_mult*100)}% size"
        
        return result
    
    def clean_stale_cache(self):
        """Remove old cache entries."""
        now = datetime.now().timestamp()
        stale_limit = self.cache_ttl * 3
        stale = [s for s, d in self.coin_trends.items() if now - d.get('last_update', 0) > stale_limit]
        for s in stale:
            del self.coin_trends[s]

# Global MTF Confirmation instance
mtf_confirmation = MultiTimeframeConfirmation()

# ============================================================================
# PHASE 30: BTC CORRELATION FILTER
# ============================================================================

class BTCCorrelationFilter:
    """
    ALT coin sinyallerini BTC trendiyle filtrele.
    BTC d√º≈üerken ALT LONG'lara dikkat, BTC y√ºkselirken ALT SHORT'lara dikkat.
    """
    
    def __init__(self):
        self.btc_trend = "NEUTRAL"
        self.btc_trend_daily = "NEUTRAL"  # G√ºnl√ºk trend
        self.btc_momentum = 0.0
        self.btc_price = 0.0
        self.btc_change_30m = 0.0  # Phase 60b: 30m hƒ±zlƒ± momentum
        self.btc_change_1h = 0.0
        self.btc_change_4h = 0.0
        self.btc_change_1d = 0.0  # G√ºnl√ºk deƒüi≈üim
        self.last_update = 0
        self.base_update_interval = 120  # 2 dakikada bir g√ºncelle (was 300)
        self.update_interval = 120  # Dinamik aralƒ±k
        
        # Phase 60: Emergency Mode - Strong bearish market protection
        self.emergency_mode = False
        self.emergency_reason = ""
        self.emergency_start_time = None
        self.flash_crash_active = False  # Phase 60b: 30m hƒ±zlƒ± d√º≈ü√º≈ü algƒ±lama
        
        # Phase 36: Pairs correlation + Phase 60c: ETH Trend Filter
        self.eth_price = 0.0
        self.eth_change_30m = 0.0  # Phase 60c
        self.eth_change_1h = 0.0
        self.eth_change_4h = 0.0   # Phase 60c
        self.eth_trend = "NEUTRAL"  # Phase 60c: ETH specific trend
        self.eth_flash_crash = False  # Phase 60c: ETH 30m hƒ±zlƒ± d√º≈ü√º≈ü
        self.spread_history = []  # Rolling spread values
        self.spread_window = 100  # Last 100 values for Z-score
        self.beta = 0.052  # ETH typically ~5.2% of BTC price
        
        # Phase 60d: Recovery Detection - Karma Yakla≈üƒ±m (ƒ∞ki Y√∂nl√º)
        # BEARISH Recovery (Flash Crash ‚Üí LONG)
        self.flash_crash_start_time = None  # Flash crash ba≈ülangƒ±√ß zamanƒ±
        self.flash_crash_active = False
        self.prev_btc_change_30m = 0.0      # √ñnceki 30m deƒüi≈üim (momentum shift)
        self.prev_eth_change_30m = 0.0      # √ñnceki ETH 30m deƒüi≈üim
        self.btc_momentum_improving = False  # BTC momentum iyile≈üiyor mu? (d√º≈ü√º≈ü yava≈ülƒ±yor)
        self.eth_momentum_improving = False  # ETH momentum iyile≈üiyor mu?
        self.recovery_phase = "NORMAL"       # BLOCKED / PENALTY_HIGH / PENALTY_LOW / NORMAL
        
        # BULLISH Recovery (Flash Pump ‚Üí SHORT)
        self.flash_pump_active = False       # Hƒ±zlƒ± y√ºkseli≈ü aktif mi?
        self.flash_pump_start_time = None    # Flash pump ba≈ülangƒ±√ß zamanƒ±
        self.btc_momentum_weakening = False  # Y√ºkseli≈ü yava≈ülƒ±yor mu?
        self.recovery_phase_short = "NORMAL" # SHORT i√ßin recovery phase
        
        # Phase 60e: MTF Momentum Tracking
        self.btc_change_15m = 0.0           # 15m deƒüi≈üim
        self.prev_btc_change_15m = 0.0      # √ñnceki 15m deƒüi≈üim
        self.prev_btc_change_1h = 0.0       # √ñnceki 1H deƒüi≈üim
        self.prev_btc_change_4h = 0.0       # √ñnceki 4H deƒüi≈üim
        
        # Phase 230B: Coin Strength Override tracking
        self.last_override = False          # Set per should_allow_signal call
        
        logger.info("üìä BTCCorrelationFilter initialized with MTF Recovery + Coin Strength Override")
    
    async def update_btc_state(self, exchange) -> dict:
        """BTC durumunu g√ºncelle."""
        now = datetime.now().timestamp()
        
        # Rate limiting
        if now - self.last_update < self.update_interval:
            return self.get_state()
        
        try:
            # Phase 60e: BTC 15m, 30m, 1H, 4H ve 1D verileri √ßek
            # Rate limit fix: 100ms delay between calls
            logger.info("üìä Fetching BTC OHLCV data...")
            ohlcv_15m = await exchange.fetch_ohlcv('BTC/USDT', '15m', limit=4)
            await asyncio.sleep(0.1)
            ohlcv_30m = await exchange.fetch_ohlcv('BTC/USDT', '30m', limit=4)
            await asyncio.sleep(0.1)
            ohlcv_1h = await exchange.fetch_ohlcv('BTC/USDT', '1h', limit=24)
            await asyncio.sleep(0.1)
            ohlcv_4h = await exchange.fetch_ohlcv('BTC/USDT', '4h', limit=12)
            await asyncio.sleep(0.1)
            ohlcv_1d = await exchange.fetch_ohlcv('BTC/USDT', '1d', limit=3)
            logger.info(f"üìä BTC OHLCV fetched: 15m={len(ohlcv_15m) if ohlcv_15m else 0}, 30m={len(ohlcv_30m) if ohlcv_30m else 0}, 1h={len(ohlcv_1h) if ohlcv_1h else 0}, 4h={len(ohlcv_4h) if ohlcv_4h else 0}, 1d={len(ohlcv_1d) if ohlcv_1d else 0}")
            
            # Phase 60e: 15m momentum hesapla
            if ohlcv_15m and len(ohlcv_15m) >= 2:
                current = ohlcv_15m[-1][4]
                prev = ohlcv_15m[-2][4]
                self.prev_btc_change_15m = self.btc_change_15m
                self.btc_change_15m = ((current - prev) / prev) * 100
            
            # Phase 60b: 30m momentum hesapla (hƒ±zlƒ± d√º≈ü√º≈ü algƒ±lama)
            if ohlcv_30m and len(ohlcv_30m) >= 2:
                current = ohlcv_30m[-1][4]  # Close
                prev_30m = ohlcv_30m[-2][4]
                new_change = ((current - prev_30m) / prev_30m) * 100
                
                # =================================================================
                # Phase 60d: MOMENTUM SHIFT DETECTION
                # D√º≈ü√º≈ü yava≈ülƒ±yorsa momentum iyile≈üiyor
                # =================================================================
                if self.prev_btc_change_30m < -1.0:  # √ñnceden d√º≈ü√º≈üteydik
                    # Yeni deƒüer daha iyi mi? (daha az negatif veya pozitif)
                    if new_change > self.prev_btc_change_30m + 0.5:  # En az 0.5% iyile≈üme
                        if not self.btc_momentum_improving:
                            logger.info(f"üìà BTC MOMENTUM SHIFT: {self.prev_btc_change_30m:.1f}% ‚Üí {new_change:.1f}% (improving)")
                        self.btc_momentum_improving = True
                    else:
                        self.btc_momentum_improving = False
                else:
                    self.btc_momentum_improving = False
                
                self.prev_btc_change_30m = self.btc_change_30m  # √ñnceki deƒüeri sakla
                self.btc_change_30m = new_change
                
                # =================================================================
                # Phase 60d: FLASH CRASH + TIME-BASED RECOVERY
                # =================================================================
                if self.btc_change_30m < -2.0:
                    # Flash crash ba≈üladƒ± veya devam ediyor
                    if not self.flash_crash_active:
                        logger.warning(f"‚ö° FLASH CRASH DETECTED: 30m:{self.btc_change_30m:.1f}%")
                        self.flash_crash_start_time = datetime.now()
                    self.flash_crash_active = True
                    
                    # Time-based recovery phase belirleme
                    if self.flash_crash_start_time:
                        elapsed_minutes = (datetime.now() - self.flash_crash_start_time).total_seconds() / 60
                        
                        if elapsed_minutes < 10:
                            self.recovery_phase = "BLOCKED"
                        elif elapsed_minutes < 20:
                            self.recovery_phase = "PENALTY_HIGH"  # 50% penalty
                        elif elapsed_minutes < 30:
                            self.recovery_phase = "PENALTY_LOW"   # 25% penalty
                        else:
                            self.recovery_phase = "NORMAL"
                        
                        # Momentum iyile≈üiyorsa fazƒ± hƒ±zlandƒ±r
                        if self.btc_momentum_improving and self.recovery_phase == "BLOCKED":
                            self.recovery_phase = "PENALTY_HIGH"
                            logger.info(f"üìà RECOVERY ACCELERATED: Momentum improving, phase ‚Üí PENALTY_HIGH")
                    
                elif self.btc_change_30m > -1.0:
                    # Flash crash sona erdi
                    if self.flash_crash_active:
                        logger.info(f"‚úÖ FLASH CRASH ENDED: 30m recovered to {self.btc_change_30m:.1f}%")
                    self.flash_crash_active = False
                    self.flash_crash_start_time = None
                    self.recovery_phase = "NORMAL"
                
                # =================================================================
                # Phase 60d: FLASH PUMP + TIME-BASED RECOVERY (BULLISH ‚Üí SHORT)
                # A≈üƒ±rƒ± y√ºkseli≈ü sonrasƒ± SHORT sinyalleri i√ßin recovery
                # =================================================================
                if self.btc_change_30m > 2.0:
                    # Flash pump ba≈üladƒ± veya devam ediyor
                    if not self.flash_pump_active:
                        logger.warning(f"üöÄ FLASH PUMP DETECTED: 30m:+{self.btc_change_30m:.1f}%")
                        self.flash_pump_start_time = datetime.now()
                    self.flash_pump_active = True
                    
                    # Momentum zayƒ±flama kontrol√º (y√ºkseli≈ü yava≈ülƒ±yor mu?)
                    if self.prev_btc_change_30m > 1.0:  # √ñnceden y√ºkseli≈üteydi
                        if new_change < self.prev_btc_change_30m - 0.5:  # Yava≈ülƒ±yor
                            if not self.btc_momentum_weakening:
                                logger.info(f"üìâ BTC MOMENTUM WEAKENING: {self.prev_btc_change_30m:.1f}% ‚Üí {new_change:.1f}%")
                            self.btc_momentum_weakening = True
                        else:
                            self.btc_momentum_weakening = False
                    else:
                        self.btc_momentum_weakening = False
                    
                    # Time-based recovery phase for SHORT
                    if self.flash_pump_start_time:
                        elapsed_minutes = (datetime.now() - self.flash_pump_start_time).total_seconds() / 60
                        
                        if elapsed_minutes < 10:
                            self.recovery_phase_short = "BLOCKED"
                        elif elapsed_minutes < 20:
                            self.recovery_phase_short = "PENALTY_HIGH"
                        elif elapsed_minutes < 30:
                            self.recovery_phase_short = "PENALTY_LOW"
                        else:
                            self.recovery_phase_short = "NORMAL"
                        
                        # Momentum zayƒ±flƒ±yorsa fazƒ± hƒ±zlandƒ±r
                        if self.btc_momentum_weakening and self.recovery_phase_short == "BLOCKED":
                            self.recovery_phase_short = "PENALTY_HIGH"
                            logger.info(f"üìâ SHORT RECOVERY ACCELERATED: Momentum weakening, phase ‚Üí PENALTY_HIGH")
                
                elif self.btc_change_30m < 1.0:
                    # Flash pump sona erdi
                    if self.flash_pump_active:
                        logger.info(f"‚úÖ FLASH PUMP ENDED: 30m cooled to {self.btc_change_30m:.1f}%")
                    self.flash_pump_active = False
                    self.flash_pump_start_time = None
                    self.recovery_phase_short = "NORMAL"
            
            if ohlcv_1h and len(ohlcv_1h) >= 2:
                current = ohlcv_1h[-1][4]  # Close
                prev_1h = ohlcv_1h[-2][4]
                self.btc_price = current
                self.prev_btc_change_1h = self.btc_change_1h  # Phase 60e: prev sakla
                self.btc_change_1h = ((current - prev_1h) / prev_1h) * 100
            
            if ohlcv_4h and len(ohlcv_4h) >= 2:
                current = ohlcv_4h[-1][4]
                prev_4h = ohlcv_4h[-2][4]
                self.prev_btc_change_4h = self.btc_change_4h  # Phase 60e: prev sakla
                self.btc_change_4h = ((current - prev_4h) / prev_4h) * 100
            
            # 1D (G√ºnl√ºk) deƒüi≈üim hesapla
            if ohlcv_1d and len(ohlcv_1d) >= 2:
                current = ohlcv_1d[-1][4]  # Bug√ºn√ºn kapanƒ±≈üƒ±
                prev_1d = ohlcv_1d[-2][4]  # D√ºn√ºn kapanƒ±≈üƒ±
                self.btc_change_1d = ((current - prev_1d) / prev_1d) * 100
                
                # G√ºnl√ºk trend belirleme
                if self.btc_change_1d > 3.0:
                    self.btc_trend_daily = "STRONG_BULLISH"
                elif self.btc_change_1d > 1.0:
                    self.btc_trend_daily = "BULLISH"
                elif self.btc_change_1d < -3.0:
                    self.btc_trend_daily = "STRONG_BEARISH"
                elif self.btc_change_1d < -1.0:
                    self.btc_trend_daily = "BEARISH"
                else:
                    self.btc_trend_daily = "NEUTRAL"
            
            # =================================================================
            # Phase 60b: IMPROVED STRONG_BEARISH Detection
            # 1H e≈üiƒüi gev≈üetildi (-0.5% ‚Üí -1.5%), 30m flash crash eklendi
            # =================================================================
            
            # STRONG_BULLISH: 1H ve 4H ikisi de pozitif
            if self.btc_change_1h > 1.5 and self.btc_change_4h > 2.0:
                self.btc_trend = "STRONG_BULLISH"
                self.btc_momentum = 1.0
            elif self.btc_change_1h > 0.5:
                self.btc_trend = "BULLISH"
                self.btc_momentum = 0.5
            # FLASH CRASH: 30m'de %2+ d√º≈ü√º≈ü = anlƒ±k STRONG_BEARISH
            elif self.flash_crash_active or self.btc_change_30m < -1.5:
                self.btc_trend = "STRONG_BEARISH"
                self.btc_momentum = -1.0
            # STRONG_BEARISH: 1H < -1.5% VEYA 4H < -3.0% (gev≈üetildi)
            elif self.btc_change_1h < -1.5 or self.btc_change_4h < -3.0:
                self.btc_trend = "STRONG_BEARISH"
                self.btc_momentum = -1.0
            # BEARISH: 1H < -0.5% VEYA 4H < -1.5% (gev≈üetildi)
            elif self.btc_change_1h < -0.5 or self.btc_change_4h < -1.5:
                self.btc_trend = "BEARISH"
                self.btc_momentum = -0.5
            elif self.btc_change_1h < -0.2:
                self.btc_trend = "BEARISH"
                self.btc_momentum = -0.3
            else:
                self.btc_trend = "NEUTRAL"
                self.btc_momentum = 0.0
            
            # =================================================================
            # Phase 60c: ETH TREND TRACKING
            # BTC stabil ama ETH/ALT'lar d√º≈üerse koruma saƒülar
            # =================================================================
            try:
                # Rate limit fix: 100ms delay between calls
                eth_30m = await exchange.fetch_ohlcv('ETH/USDT', '30m', limit=4)
                await asyncio.sleep(0.1)
                eth_1h = await exchange.fetch_ohlcv('ETH/USDT', '1h', limit=4)
                await asyncio.sleep(0.1)
                eth_4h = await exchange.fetch_ohlcv('ETH/USDT', '4h', limit=4)
                
                if eth_30m and len(eth_30m) >= 2:
                    curr = eth_30m[-1][4]
                    prev = eth_30m[-2][4]
                    new_eth_change = ((curr - prev) / prev) * 100
                    self.eth_price = curr
                    
                    # Phase 60d: ETH Momentum Shift Detection
                    if self.prev_eth_change_30m < -1.5:
                        if new_eth_change > self.prev_eth_change_30m + 0.5:
                            if not self.eth_momentum_improving:
                                logger.info(f"üìà ETH MOMENTUM SHIFT: {self.prev_eth_change_30m:.1f}% ‚Üí {new_eth_change:.1f}%")
                            self.eth_momentum_improving = True
                        else:
                            self.eth_momentum_improving = False
                    else:
                        self.eth_momentum_improving = False
                    
                    self.prev_eth_change_30m = self.eth_change_30m
                    self.eth_change_30m = new_eth_change
                    
                    # ETH Flash crash: 30m'de %3+ d√º≈ü√º≈ü
                    if self.eth_change_30m < -3.0:
                        if not self.eth_flash_crash:
                            logger.warning(f"‚ö° ETH FLASH CRASH: 30m:{self.eth_change_30m:.1f}%")
                        self.eth_flash_crash = True
                    elif self.eth_change_30m > -1.5:
                        self.eth_flash_crash = False
                
                if eth_1h and len(eth_1h) >= 2:
                    curr = eth_1h[-1][4]
                    prev = eth_1h[-2][4]
                    self.eth_change_1h = ((curr - prev) / prev) * 100
                
                if eth_4h and len(eth_4h) >= 2:
                    curr = eth_4h[-1][4]
                    prev = eth_4h[-2][4]
                    self.eth_change_4h = ((curr - prev) / prev) * 100
                
                # ETH Trend belirleme
                if self.eth_flash_crash or self.eth_change_30m < -2.0:
                    self.eth_trend = "STRONG_BEARISH"
                elif self.eth_change_1h < -2.0 or self.eth_change_4h < -4.0:
                    self.eth_trend = "STRONG_BEARISH"
                elif self.eth_change_1h < -1.0 or self.eth_change_4h < -2.0:
                    self.eth_trend = "BEARISH"
                elif self.eth_change_1h > 2.0 and self.eth_change_4h > 3.0:
                    self.eth_trend = "STRONG_BULLISH"
                elif self.eth_change_1h > 1.0:
                    self.eth_trend = "BULLISH"
                else:
                    self.eth_trend = "NEUTRAL"
                
                # ETH State log
                logger.info(f"üìä ETH State: {self.eth_trend} | 30m:{self.eth_change_30m:.2f}% | 1H:{self.eth_change_1h:.2f}% | 4H:{self.eth_change_4h:.2f}% | Price:${self.eth_price:.2f}")
                    
            except Exception as eth_err:
                logger.debug(f"ETH fetch error: {eth_err}")
            
            # =================================================================
            # Phase 178: SMT Divergence with candle-based data
            # Uses BTC 15m and ETH 30m OHLCV for proper swing high/low detection
            # (Moved from WS ticker which used 24H high/low = wrong)
            # =================================================================
            try:
                if ohlcv_15m and len(ohlcv_15m) >= 2:
                    # Clear old ticker-based data and feed candle data
                    for i, btc_candle in enumerate(ohlcv_15m):
                        _, _, btc_h, btc_l, btc_c, _ = btc_candle
                        # Use ETH 30m if available, otherwise estimate from ticker
                        eth_h, eth_l, eth_c = btc_h, btc_l, btc_c  # fallback
                        if eth_30m and i < len(eth_30m):
                            _, _, eth_h, eth_l, eth_c, _ = eth_30m[i]
                        elif eth_1h and len(eth_1h) > 0:
                            _, _, eth_h, eth_l, eth_c, _ = eth_1h[-1]
                        
                        smt_divergence_detector.update_prices(
                            btc_high=btc_h, btc_low=btc_l, btc_close=btc_c,
                            eth_high=eth_h, eth_low=eth_l, eth_close=eth_c
                        )
                    smt_divergence_detector.detect_divergence()
            except Exception as smt_err:
                logger.debug(f"SMT update error: {smt_err}")
            
            # =================================================================
            # Phase 60: EMERGENCY MODE - Extreme market conditions
            # BEARISH: 4H'da %5+ d√º≈ü√º≈ü veya 1D'da %6+ d√º≈ü√º≈ü = Emergency Bearish
            # BULLISH: 4H'da %5+ y√ºkseli≈ü veya 1D'da %6+ y√ºkseli≈ü = Emergency Bullish
            # =================================================================
            prev_emergency = self.emergency_mode
            
            # Emergency BEARISH (Strong d√º≈ü√º≈ü)
            if self.btc_change_4h < -5.0 or self.btc_change_1d < -6.0:
                self.emergency_mode = "BEARISH"
                self.emergency_reason = f"üö® EMERGENCY BEARISH: 4H:{self.btc_change_4h:.1f}%, 1D:{self.btc_change_1d:.1f}%"
                if prev_emergency != "BEARISH":
                    self.emergency_start_time = datetime.now()
                    logger.warning(f"üö®üö®üö® EMERGENCY BEARISH ACTIVATED: {self.emergency_reason}")
            # Emergency BULLISH (Strong y√ºkseli≈ü)
            elif self.btc_change_4h > 5.0 or self.btc_change_1d > 6.0:
                self.emergency_mode = "BULLISH"
                self.emergency_reason = f"üöÄ EMERGENCY BULLISH: 4H:+{self.btc_change_4h:.1f}%, 1D:+{self.btc_change_1d:.1f}%"
                if prev_emergency != "BULLISH":
                    self.emergency_start_time = datetime.now()
                    logger.warning(f"üöÄüöÄüöÄ EMERGENCY BULLISH ACTIVATED: {self.emergency_reason}")
            elif abs(self.btc_change_4h) < 3.0 and abs(self.btc_change_1d) < 4.0:
                # Normal piyasa - emergency moddan √ßƒ±k
                if prev_emergency:
                    logger.info(f"‚úÖ Emergency Mode deactivated - market normalized")
                self.emergency_mode = False
                self.emergency_reason = ""
            else:
                # Orta seviye - mevcut durumu koru
                pass
            
            # =================================================================
            # Phase 60: DYNAMIC UPDATE INTERVAL
            # Volatil d√∂nemlerde g√ºncelleme hƒ±zƒ±nƒ± artƒ±r
            # =================================================================
            if abs(self.btc_change_1h) > 2.0 or abs(self.btc_change_4h) > 4.0:
                self.update_interval = 60  # Hƒ±zlƒ± hareket: 1 dakika
            elif abs(self.btc_change_1h) > 1.0 or abs(self.btc_change_4h) > 2.0:
                self.update_interval = 90  # Orta hareket: 1.5 dakika
            else:
                self.update_interval = self.base_update_interval  # Normal: 2 dakika
            
            self.last_update = now
            # Her zaman INFO seviyesinde logla (debug g√∂r√ºnm√ºyor)
            logger.info(f"üìä BTC State: {self.btc_trend} | Daily:{self.btc_trend_daily} | 1H:{self.btc_change_1h:.2f}% | 4H:{self.btc_change_4h:.2f}% | 1D:{self.btc_change_1d:.2f}% | Emergency:{self.emergency_mode} | Interval:{self.update_interval}s")
            
        except Exception as e:
            logger.warning(f"BTC state update failed: {e}")
        
        return self.get_state()
    
    def should_allow_signal(self, symbol: str, signal_action: str, 
                            coin_change_pct: float = 0.0, volume_24h: float = 0.0,
                            zscore: float = 0.0, spread_pct: float = 0.0) -> tuple:
        """
        Phase 230B (Codex): Multi-factor coin strength override.
        Returns: (allowed: bool, penalty: float, reason: str)
        Sets self.last_override = True when coin strength exception fires.
        """
        self.last_override = False  # Reset per call
        # BTC kendisi ise filtreleme yok
        if 'BTC' in symbol:
            return (True, 0.0, "BTC no filter")
        
        # ===================================================================
        # Phase 60b: BTC VERƒ∞Sƒ∞ KONTROL√ú
        # BTC verisi hen√ºz g√ºncellenmemi≈üse sinyali reddet (g√ºvenlik √∂nlemi)
        # ===================================================================
        if self.last_update == 0:
            logger.warning(f"‚ö†Ô∏è BTC DATA NOT READY: {symbol} {signal_action} blocked - waiting for BTC state update")
            return (False, 1.0, "‚ö†Ô∏è BTC Data Not Ready - Signal Blocked")
        
        # ===================================================================
        # Phase 60d: FLASH CRASH + RECOVERY DETECTION (Karma Yakla≈üƒ±m)
        # Tam blokaj yerine kademeli penalty sistemi
        # ===================================================================
        if self.flash_crash_active and signal_action == "LONG":
            if self.recovery_phase == "BLOCKED":
                # ƒ∞lk 10 dk veya momentum k√∂t√ºle≈üiyor = tam blokaj
                if not self.btc_momentum_improving:
                    logger.warning(f"‚ö° FLASH CRASH BLOCKED: {symbol} LONG rejected - Phase:{self.recovery_phase}, Momentum:{self.btc_momentum_improving}")
                    return (False, 1.0, f"‚ö° Flash Crash [{self.recovery_phase}] - LONG BLOCKED")
                else:
                    # Momentum iyile≈üiyor ama hen√ºz erken - y√ºksek penalty ile izin ver
                    logger.info(f"üìà RECOVERY LONG: {symbol} - Momentum improving, penalty=50%")
                    return (True, 0.5, f"üìà Recovery Phase (momentum improving) - 50% penalty")
            
            elif self.recovery_phase == "PENALTY_HIGH":
                # 10-20 dk arasƒ± = %50 penalty ile izin ver
                logger.info(f"üìà RECOVERY LONG: {symbol} - Phase:{self.recovery_phase}, penalty=50%")
                return (True, 0.5, f"üìà Recovery Phase [{self.recovery_phase}] - 50% penalty")
            
            elif self.recovery_phase == "PENALTY_LOW":
                # 20-30 dk arasƒ± = %25 penalty ile izin ver
                logger.info(f"üìà RECOVERY LONG: {symbol} - Phase:{self.recovery_phase}, penalty=25%")
                return (True, 0.25, f"üìà Recovery Phase [{self.recovery_phase}] - 25% penalty")
            
            else:
                # 30+ dk = normal
                pass
        
        # ===================================================================
        # Phase 60d: FLASH PUMP + RECOVERY DETECTION (BULLISH ‚Üí SHORT)
        # A≈üƒ±rƒ± y√ºkseli≈ü sonrasƒ± SHORT sinyalleri i√ßin kademeli izin
        # ===================================================================
        if self.flash_pump_active and signal_action == "SHORT":
            if self.recovery_phase_short == "BLOCKED":
                # ƒ∞lk 10 dk veya momentum g√º√ßlenmeye devam ediyor = tam blokaj
                if not self.btc_momentum_weakening:
                    logger.warning(f"üöÄ FLASH PUMP BLOCKED: {symbol} SHORT rejected - Phase:{self.recovery_phase_short}")
                    return (False, 1.0, f"üöÄ Flash Pump [{self.recovery_phase_short}] - SHORT BLOCKED")
                else:
                    # Momentum zayƒ±flƒ±yor ama hen√ºz erken - y√ºksek penalty ile izin ver
                    logger.info(f"üìâ RECOVERY SHORT: {symbol} - Momentum weakening, penalty=50%")
                    return (True, 0.5, f"üìâ Recovery Phase (momentum weakening) - 50% penalty")
            
            elif self.recovery_phase_short == "PENALTY_HIGH":
                # 10-20 dk arasƒ± = %50 penalty ile izin ver
                logger.info(f"üìâ RECOVERY SHORT: {symbol} - Phase:{self.recovery_phase_short}, penalty=50%")
                return (True, 0.5, f"üìâ Recovery Phase [{self.recovery_phase_short}] - 50% penalty")
            
            elif self.recovery_phase_short == "PENALTY_LOW":
                # 20-30 dk arasƒ± = %25 penalty ile izin ver
                logger.info(f"üìâ RECOVERY SHORT: {symbol} - Phase:{self.recovery_phase_short}, penalty=25%")
                return (True, 0.25, f"üìâ Recovery Phase [{self.recovery_phase_short}] - 25% penalty")
            
            else:
                # 30+ dk = normal
                pass
        
        # ===================================================================
        # Phase 60c: ETH DIVERGENCE FILTER
        # BTC stabil ama ETH d√º≈ü√ºyorsa ALT LONG'larƒ± bloke et
        # ===================================================================
        # ETH kendisi ise filtreleme yok
        if 'ETH' in symbol:
            pass  # ETH i√ßin sadece BTC filter yeterli
        elif self.eth_flash_crash and signal_action == "LONG":
            logger.warning(f"‚ö° ETH FLASH CRASH BLOCK: {symbol} LONG rejected - ETH 30m:{self.eth_change_30m:.1f}%")
            return (False, 1.0, f"‚ö° ETH Flash Crash (30m:{self.eth_change_30m:.1f}%) - ALT LONG BLOCKED")
        elif self.eth_trend == "STRONG_BEARISH" and signal_action == "LONG":
            # ETH strong bearish ama BTC normal ise - ALT'lar genelde ETH'yi takip eder
            if self.btc_trend not in ["STRONG_BEARISH", "BEARISH"]:
                logger.info(f"üîª ETH DIVERGENCE: {symbol} LONG penalty - ETH:{self.eth_trend}, BTC:{self.btc_trend}")
                return (True, 0.3, f"ETH Divergence (ETH bearish, BTC stable) - HIGH RISK")
        
        # ETH BULLISH iken SHORT sinyallere dikkat
        elif self.eth_trend == "STRONG_BULLISH" and signal_action == "SHORT":
            if self.btc_trend not in ["STRONG_BULLISH", "BULLISH"]:
                logger.info(f"üî∫ ETH DIVERGENCE: {symbol} SHORT penalty - ETH:{self.eth_trend}, BTC:{self.btc_trend}")
                return (True, 0.3, f"ETH Divergence (ETH bullish, BTC stable) - HIGH RISK")
        
        # Phase 60e: EMERGENCY MODE + MTF RECOVERY
        # MTF skor bazlƒ± kademeli recovery
        # ===================================================================
        if self.emergency_mode == "BEARISH":
            if signal_action == "LONG":
                # MTF Momentum Score hesapla
                mtf_score = self.calculate_mtf_momentum_score("LONG")
                
                if mtf_score == 0:
                    # Hi√ßbir TF iyile≈ümiyor = tam blokaj
                    logger.warning(f"üö® EMERGENCY BEARISH BLOCK: {symbol} LONG - MTF:{mtf_score}/7")
                    return (False, 1.0, f"üö® Emergency BEARISH (MTF:{mtf_score}/7) - LONG BLOCKED")
                elif mtf_score <= 2:
                    # Sadece kƒ±sa vade = 60% penalty
                    logger.info(f"üìà MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=60%")
                    return (True, 0.6, f"üìà MTF Recovery ({mtf_score}/7) - 60% penalty")
                elif mtf_score <= 4:
                    # Orta vade = 40% penalty
                    logger.info(f"üìà MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=40%")
                    return (True, 0.4, f"üìà MTF Recovery ({mtf_score}/7) - 40% penalty")
                else:
                    # G√º√ßl√º d√∂n√º≈ü = 25% penalty
                    logger.info(f"üìà STRONG MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=25%")
                    return (True, 0.25, f"üìà Strong MTF Recovery ({mtf_score}/7) - 25% penalty")
            else:
                # SHORT sinyallere bonus ver
                return (True, -0.25, f"‚úÖ Emergency SHORT allowed - trend aligned")
        
        elif self.emergency_mode == "BULLISH":
            if signal_action == "SHORT":
                # MTF Momentum Score hesapla
                mtf_score = self.calculate_mtf_momentum_score("SHORT")
                
                if mtf_score == 0:
                    # Hi√ßbir TF zayƒ±flamƒ±yor = tam blokaj
                    logger.warning(f"üöÄ EMERGENCY BULLISH BLOCK: {symbol} SHORT - MTF:{mtf_score}/7")
                    return (False, 1.0, f"üöÄ Emergency BULLISH (MTF:{mtf_score}/7) - SHORT BLOCKED")
                elif mtf_score <= 2:
                    logger.info(f"üìâ MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=60%")
                    return (True, 0.6, f"üìâ MTF Recovery ({mtf_score}/7) - 60% penalty")
                elif mtf_score <= 4:
                    logger.info(f"üìâ MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=40%")
                    return (True, 0.4, f"üìâ MTF Recovery ({mtf_score}/7) - 40% penalty")
                else:
                    logger.info(f"üìâ STRONG MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=25%")
                    return (True, 0.25, f"üìâ Strong MTF Recovery ({mtf_score}/7) - 25% penalty")
            else:
                # LONG sinyallere bonus ver
                return (True, -0.25, f"‚úÖ Emergency LONG allowed - trend aligned")
        
        penalty = 0.0
        reason = ""
        
        # ===================================================================
        # Phase 60: FULL ALIGNMENT VETO
        # Daily + Short-term trend aynƒ± y√∂ndeyse, ters sinyal mutlak veto
        # ===================================================================
        full_bearish = (self.btc_trend_daily in ["BEARISH", "STRONG_BEARISH"] and 
                        self.btc_trend in ["BEARISH", "STRONG_BEARISH"])
        full_bullish = (self.btc_trend_daily in ["BULLISH", "STRONG_BULLISH"] and 
                        self.btc_trend in ["BULLISH", "STRONG_BULLISH"])
        
        if full_bearish and signal_action == "LONG":
            # Phase 230B: Multi-factor coin strength check
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                logger.warning(f"üí™ COIN STRENGTH OVERRIDE: {symbol} LONG (coin:{coin_change_pct:+.1f}%) despite Full Bearish | {factors_detail}")
                return (True, 0.30, f"üí™ Override ({coin_change_pct:+.1f}%) [{factors_detail}] - Full Bearish bypassed")
            else:
                # Phase 230B: Soft veto ‚Äî 75% penalty instead of hard block
                logger.info(f"üö´ FULL ALIGNMENT PENALTY: {symbol} LONG (coin:{coin_change_pct:+.1f}%, {factors_detail}) | penalty=0.75")
                return (True, 0.75, f"üö´ Full Bearish Alignment - 75% penalty ({factors_detail})")
        
        if full_bullish and signal_action == "SHORT":
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                logger.warning(f"üí™ COIN STRENGTH OVERRIDE: {symbol} SHORT (coin:{coin_change_pct:+.1f}%) despite Full Bullish | {factors_detail}")
                return (True, 0.30, f"üí™ Override ({coin_change_pct:+.1f}%) [{factors_detail}] - Full Bullish bypassed")
            else:
                logger.info(f"üö´ FULL ALIGNMENT PENALTY: {symbol} SHORT (coin:{coin_change_pct:+.1f}%, {factors_detail}) | penalty=0.75")
                return (True, 0.75, f"üö´ Full Bullish Alignment - 75% penalty ({factors_detail})")
        
        # ===================================================================
        # G√úNL√úK TREND Fƒ∞LTRESƒ∞ (EN G√ú√áL√ú)
        # G√ºnl√ºk trend ters y√∂ndeyse sinyali tamamen reddet
        # ===================================================================
        if self.btc_trend_daily == "STRONG_BEARISH" and signal_action == "LONG":
            return (False, 1.0, "üö´ Daily STRONG_BEARISH - LONG blocked")
        
        if self.btc_trend_daily == "STRONG_BULLISH" and signal_action == "SHORT":
            return (False, 1.0, "üö´ Daily STRONG_BULLISH - SHORT blocked")
        
        # G√ºnl√ºk trend orta d√ºzeyde ters ise y√ºksek ceza
        if self.btc_trend_daily == "BEARISH" and signal_action == "LONG":
            penalty = 0.5  # %50 skor d√º≈ü√ºr (sƒ±kƒ±la≈ütƒ±rƒ±ldƒ±)
            reason = "Daily BEARISH - LONG risky"
        elif self.btc_trend_daily == "BULLISH" and signal_action == "SHORT":
            penalty = 0.5  # %50 skor d√º≈ü√ºr (sƒ±kƒ±la≈ütƒ±rƒ±ldƒ±)
            reason = "Daily BULLISH - SHORT risky"
        
        # Kƒ±sa vadeli trend kontrol√º (1H + 4H)
        # BTC STRONG_BEARISH iken ALT LONG risky
        if self.btc_trend == "STRONG_BEARISH" and signal_action == "LONG":
            penalty = max(penalty, 0.4)  # %40 skor d√º≈ü√ºr (was 0.3)
            reason = reason or "BTC Strong Bearish - ALT LONG risky"
        
        # BTC BEARISH iken ALT LONG dikkat
        elif self.btc_trend == "BEARISH" and signal_action == "LONG":
            penalty = max(penalty, 0.2)  # %20 (was 0.15)
            reason = reason or "BTC Bearish - ALT LONG caution"
        
        # BTC STRONG_BULLISH iken ALT SHORT risky
        elif self.btc_trend == "STRONG_BULLISH" and signal_action == "SHORT":
            penalty = max(penalty, 0.4)  # %40 (was 0.3)
            reason = reason or "BTC Strong Bullish - ALT SHORT risky"
        
        # BTC BULLISH iken ALT SHORT dikkat
        elif self.btc_trend == "BULLISH" and signal_action == "SHORT":
            penalty = max(penalty, 0.2)  # %20 (was 0.15)
            reason = reason or "BTC Bullish - ALT SHORT caution"
        
        # Aynƒ± y√∂nde ise bonus
        elif (self.btc_trend in ["BULLISH", "STRONG_BULLISH"] and signal_action == "LONG") or \
             (self.btc_trend in ["BEARISH", "STRONG_BEARISH"] and signal_action == "SHORT"):
            penalty = -0.2  # G√ºnl√ºk aynƒ± y√∂ndeyse daha b√ºy√ºk bonus (was -0.15)
            reason = "‚úÖ BTC trend aligned with signal"
        
        # Y√ºksek penalty ise reddet (threshold sƒ±kƒ±la≈ütƒ±rƒ±ldƒ±)
        allowed = penalty < 0.35  # was 0.30
        
        return (allowed, penalty, reason)
    
    def _check_coin_strength_override(self, symbol: str, signal_action: str,
                                       coin_change_pct: float, volume_24h: float,
                                       zscore: float, spread_pct: float) -> tuple:
        """
        Phase 230B (Codex): Multi-factor coin strength validation.
        Requires at least 3 of 4 factors to pass for override.
        Returns: (override_allowed: bool, factors_detail: str)
        """
        factors_passed = 0
        factors_labels = []
        
        # Factor 1: Price Momentum ‚Äî coin moving strongly in signal direction
        if signal_action == "LONG":
            momentum_ok = coin_change_pct > 5.0
        else:
            momentum_ok = coin_change_pct < -5.0
        if momentum_ok:
            factors_passed += 1
            factors_labels.append(f"‚úÖMOM({coin_change_pct:+.1f}%)")
        else:
            factors_labels.append(f"‚ùåMOM({coin_change_pct:+.1f}%)")
        
        # Factor 2: Volume ‚Äî healthy liquidity (>$500K daily volume)
        volume_ok = volume_24h > 500_000
        if volume_ok:
            factors_passed += 1
            factors_labels.append(f"‚úÖVOL(${volume_24h/1e6:.1f}M)")
        else:
            factors_labels.append(f"‚ùåVOL(${volume_24h/1e6:.1f}M)")
        
        # Factor 3: Z-score not extreme ‚Äî avoid buying tops or selling bottoms
        if signal_action == "LONG":
            zscore_ok = zscore < 2.5  # Not overbought
        else:
            zscore_ok = zscore > -2.5  # Not oversold
        if zscore_ok:
            factors_passed += 1
            factors_labels.append(f"‚úÖZ({zscore:.1f})")
        else:
            factors_labels.append(f"‚ùåZ({zscore:.1f})")
        
        # Factor 4: Spread acceptable ‚Äî entry cost reasonable
        spread_ok = spread_pct < 0.5  # Less than 0.5% spread
        if spread_ok:
            factors_passed += 1
            factors_labels.append(f"‚úÖSPR({spread_pct:.2f}%)")
        else:
            factors_labels.append(f"‚ùåSPR({spread_pct:.2f}%)")
        
        detail = f"{factors_passed}/4 [{' '.join(factors_labels)}]"
        override_allowed = factors_passed >= 3
        
        return (override_allowed, detail)
    
    def calculate_mtf_momentum_score(self, direction: str = "LONG") -> int:
        """
        Phase 60e: MTF Momentum Score hesapla.
        direction: "LONG" = d√º≈ü√º≈üten d√∂n√º≈ü, "SHORT" = y√ºkseli≈üten d√∂n√º≈ü
        Returns: 0-7 arasƒ± skor (7 = g√º√ßl√º d√∂n√º≈ü sinyali)
        """
        score = 0
        
        if direction == "LONG":  # D√º≈ü√º≈üten d√∂n√º≈ü - deƒüerler iyile≈üiyor mu?
            # 15m: +0.3% iyile≈üme = 1 puan
            if self.btc_change_15m > self.prev_btc_change_15m + 0.3:
                score += 1
            # 30m: +0.5% iyile≈üme = 1 puan
            if self.btc_change_30m > self.prev_btc_change_30m + 0.5:
                score += 1
            # 1H: +0.5% iyile≈üme = 2 puan
            if self.btc_change_1h > self.prev_btc_change_1h + 0.5:
                score += 2
            # 4H: +1.0% iyile≈üme = 3 puan
            if self.btc_change_4h > self.prev_btc_change_4h + 1.0:
                score += 3
        else:  # SHORT - y√ºkseli≈üten d√∂n√º≈ü - deƒüerler zayƒ±flƒ±yor mu?
            # 15m: -0.3% zayƒ±flama = 1 puan
            if self.btc_change_15m < self.prev_btc_change_15m - 0.3:
                score += 1
            # 30m: -0.5% zayƒ±flama = 1 puan
            if self.btc_change_30m < self.prev_btc_change_30m - 0.5:
                score += 1
            # 1H: -0.5% zayƒ±flama = 2 puan
            if self.btc_change_1h < self.prev_btc_change_1h - 0.5:
                score += 2
            # 4H: -1.0% zayƒ±flama = 3 puan
            if self.btc_change_4h < self.prev_btc_change_4h - 1.0:
                score += 3
        
        return score
    
    def get_state(self) -> dict:
        """BTC ve ETH durumu."""
        return {
            "trend": self.btc_trend,
            "trend_daily": self.btc_trend_daily,
            "momentum": self.btc_momentum,
            "price": self.btc_price,
            "change_30m": round(self.btc_change_30m, 2),
            "change_1h": round(self.btc_change_1h, 2),
            "change_4h": round(self.btc_change_4h, 2),
            "change_1d": round(self.btc_change_1d, 2),
            "flash_crash_active": self.flash_crash_active,
            "emergency_mode": self.emergency_mode,
            "emergency_reason": self.emergency_reason,
            "update_interval": self.update_interval,
            # Phase 60c: ETH State
            "eth_trend": self.eth_trend,
            "eth_price": round(self.eth_price, 2),
            "eth_change_30m": round(self.eth_change_30m, 2),
            "eth_change_1h": round(self.eth_change_1h, 2),
            "eth_change_4h": round(self.eth_change_4h, 2),
            "eth_flash_crash": self.eth_flash_crash,
            # Phase 60d: Recovery Detection (Bidirectional)
            "recovery_phase": self.recovery_phase,
            "recovery_phase_short": self.recovery_phase_short,
            "btc_momentum_improving": self.btc_momentum_improving,
            "btc_momentum_weakening": self.btc_momentum_weakening,
            "eth_momentum_improving": self.eth_momentum_improving,
            "flash_crash_active": self.flash_crash_active,
            "flash_pump_active": self.flash_pump_active,
            "flash_crash_start_time": self.flash_crash_start_time.isoformat() if self.flash_crash_start_time else None,
            "flash_pump_start_time": self.flash_pump_start_time.isoformat() if self.flash_pump_start_time else None,
            # Phase 60e: MTF Recovery
            "change_15m": round(self.btc_change_15m, 2),
            "mtf_score_long": self.calculate_mtf_momentum_score("LONG"),
            "mtf_score_short": self.calculate_mtf_momentum_score("SHORT")
        }
    
    # =========================================================================
    # PHASE 36: BTC-ETH PAIRS CORRELATION
    # =========================================================================
    
    def calculate_pairs_spread(self) -> float:
        """
        Calculate BTC-ETH spread using cointegration formula.
        Spread = ETH - (Œ≤ √ó BTC)
        """
        if self.btc_price <= 0 or self.eth_price <= 0:
            return 0.0
        
        expected_eth = self.beta * self.btc_price
        spread = self.eth_price - expected_eth
        return spread
    
    def calculate_spread_zscore(self) -> float:
        """
        Calculate Z-Score of the spread for mean reversion signals.
        Z = (Spread - Œº) / œÉ
        """
        if len(self.spread_history) < 20:
            return 0.0
        
        # numpy already imported globally
        spread_array = np.array(self.spread_history[-self.spread_window:])
        mean = np.mean(spread_array)
        std = np.std(spread_array)
        
        if std == 0:
            return 0.0
        
        current_spread = self.calculate_pairs_spread()
        zscore = (current_spread - mean) / std
        
        return round(zscore, 2)
    
    async def update_eth_price(self, exchange) -> None:
        """Update ETH price for pairs calculation."""
        try:
            ohlcv = await exchange.fetch_ohlcv('ETH/USDT', '1h', limit=2)
            if ohlcv and len(ohlcv) >= 2:
                self.eth_price = ohlcv[-1][4]
                prev = ohlcv[-2][4]
                self.eth_change_1h = ((self.eth_price - prev) / prev) * 100
                
                # Update spread history
                spread = self.calculate_pairs_spread()
                self.spread_history.append(spread)
                if len(self.spread_history) > self.spread_window * 2:
                    self.spread_history = self.spread_history[-self.spread_window:]
                    
        except Exception as e:
            logger.debug(f"ETH price update failed: {e}")
    
    def get_pairs_signal(self) -> Optional[str]:
        """
        Get pairs trading signal based on spread Z-score.
        
        Returns:
            "LONG_ETH" if Z < -2 (ETH underpriced)
            "SHORT_ETH" if Z > 2 (ETH overpriced)
            None if no clear signal
        """
        zscore = self.calculate_spread_zscore()
        
        if zscore > 2.0:
            return "SHORT_ETH"  # ETH overpriced relative to BTC
        elif zscore < -2.0:
            return "LONG_ETH"  # ETH underpriced relative to BTC
        
        return None
    
    def get_pairs_state(self) -> dict:
        """Get pairs correlation state for UI."""
        return {
            "btc_price": self.btc_price,
            "eth_price": self.eth_price,
            "beta": self.beta,
            "spread": round(self.calculate_pairs_spread(), 2),
            "spread_zscore": self.calculate_spread_zscore(),
            "pairs_signal": self.get_pairs_signal(),
            "history_length": len(self.spread_history)
        }


# Global BTC Correlation Filter instance
btc_filter = BTCCorrelationFilter()


# ============================================================================
# PHASE 28: DYNAMIC COIN PROFILER
# ============================================================================

class CoinProfiler:
    """
    Coin-bazlƒ± dinamik parametre optimizasyonu.
    Her coin i√ßin tarihsel veri analizi yaparak optimal e≈üikleri hesaplar.
    
    Analiz Metrikleri:
    - Ortalama ATR %
    - Z-Score standart sapmasƒ± ve 95. persentil
    - Optimal threshold (sinyal √ºretim e≈üiƒüi)
    - Dinamik minimum skor
    """
    
    def __init__(self):
        self.profiles = {}  # Cache: {symbol: profile_data}
        self.profile_expiry = 3600  # 1 saat cache s√ºresi (saniye)
        logger.info("CoinProfiler initialized - Dynamic parameter optimization enabled")
    
    async def analyze_coin(self, symbol: str, exchange) -> dict:
        """
        Coin i√ßin istatistiksel analiz yap ve optimal parametreleri d√∂nd√ºr.
        
        Args:
            symbol: Coin sembol√º (√∂rn. "BTC/USDT")
            exchange: CCXT exchange instance
            
        Returns:
            dict: Coin profil verileri ve optimal parametreler
        """
        try:
            logger.info(f"üîç Analyzing coin profile for {symbol}...")
            
            # 1. Son 500 mum verisi al (4H timeframe - ~83 g√ºn)
            ohlcv = await exchange.fetch_ohlcv(symbol, '4h', limit=500)
            
            if not ohlcv or len(ohlcv) < 100:
                logger.warning(f"Insufficient data for {symbol}, using default profile")
                return self._get_default_profile(symbol)
            
            # 2. Veriyi parse et
            closes = np.array([float(c[4]) for c in ohlcv])
            highs = np.array([float(c[2]) for c in ohlcv])
            lows = np.array([float(c[3]) for c in ohlcv])
            
            # 3. ATR % hesapla (volatilite metriƒüi)
            atr_values = []
            for i in range(14, len(closes)):
                tr = max(
                    highs[i] - lows[i],
                    abs(highs[i] - closes[i-1]),
                    abs(lows[i] - closes[i-1])
                )
                atr_pct = (tr / closes[i]) * 100 if closes[i] > 0 else 0
                atr_values.append(atr_pct)
            
            avg_atr_pct = np.mean(atr_values) if atr_values else 2.0
            
            # 4. Z-Score aralƒ±ƒüƒ± hesapla
            zscore_values = []
            for i in range(20, len(closes)):
                sma = np.mean(closes[i-20:i])
                spread = closes[i] - sma
                std = np.std(closes[i-20:i])
                zscore = spread / std if std > 0 else 0
                zscore_values.append(abs(zscore))
            
            if zscore_values:
                zscore_95th = float(np.percentile(zscore_values, 95))
                zscore_std = float(np.std(zscore_values))
                zscore_mean = float(np.mean(zscore_values))
            else:
                zscore_95th = 2.0
                zscore_std = 0.5
                zscore_mean = 0.8
            
            # 5. Optimal parametreleri hesapla
            # Threshold: %95 persentil / 1.5 (sinyal frekansƒ± i√ßin)
            # Alt limit 0.8, √ºst limit 2.0
            raw_threshold = zscore_95th / 1.5
            optimal_threshold = max(0.8, min(2.0, raw_threshold))
            
            # Minimum skor: Volatil coinler i√ßin daha d√º≈ü√ºk
            if avg_atr_pct > 4.0:  # √áok volatil (DOGE, SHIB, PEPE)
                min_score = 55
            elif avg_atr_pct > 2.5:  # Volatil (SOL, MATIC)
                min_score = 65
            else:  # Normal (BTC, ETH)
                min_score = 75
            
            # ATR √ßarpanlarƒ± (volatiliteye g√∂re)
            if avg_atr_pct > 3.0:
                sl_atr = 1.5  # Volatil coinler i√ßin sƒ±kƒ± SL
                tp_atr = 4.0  # Geni≈ü TP
            else:
                sl_atr = 2.0
                tp_atr = 3.0
            
            profile = {
                'symbol': symbol,
                'avg_atr_pct': round(avg_atr_pct, 4),
                'zscore_95th': round(zscore_95th, 4),
                'zscore_std': round(zscore_std, 4),
                'zscore_mean': round(zscore_mean, 4),
                'optimal_threshold': round(optimal_threshold, 2),
                'min_score': min_score,
                'sl_atr': sl_atr,
                'tp_atr': tp_atr,
                'data_points': len(ohlcv),
                'updated_at': datetime.now().timestamp()
            }
            
            logger.info(f"‚úÖ Coin Profile for {symbol}: Threshold={optimal_threshold:.2f}, MinScore={min_score}, ATR%={avg_atr_pct:.2f}")
            
            return profile
            
        except Exception as e:
            logger.error(f"Error analyzing {symbol}: {e}")
            return self._get_default_profile(symbol)
    
    def _get_default_profile(self, symbol: str) -> dict:
        """Varsayƒ±lan profil (analiz ba≈üarƒ±sƒ±z olursa)."""
        return {
            'symbol': symbol,
            'avg_atr_pct': 2.0,
            'zscore_95th': 2.0,
            'zscore_std': 0.5,
            'zscore_mean': 0.8,
            'optimal_threshold': 1.4,
            'min_score': 70,
            'sl_atr': 2.0,
            'tp_atr': 3.0,
            'data_points': 0,
            'updated_at': datetime.now().timestamp(),
            'is_default': True
        }
    
    async def get_or_update(self, symbol: str, exchange) -> dict:
        """
        Cache'den profili al veya yeni analiz yap.
        
        Args:
            symbol: Coin sembol√º
            exchange: CCXT exchange instance
            
        Returns:
            dict: Coin profil verileri
        """
        now = datetime.now().timestamp()
        
        # Cache'de var mƒ± ve s√ºresi dolmamƒ±≈ü mƒ± kontrol et
        if symbol in self.profiles:
            cached = self.profiles[symbol]
            age = now - cached.get('updated_at', 0)
            
            if age < self.profile_expiry:
                logger.debug(f"Using cached profile for {symbol} (age: {age:.0f}s)")
                return cached
        
        # Yeni analiz yap
        profile = await self.analyze_coin(symbol, exchange)
        self.profiles[symbol] = profile
        
        return profile
    
    def get_cached(self, symbol: str) -> Optional[dict]:
        """Cache'deki profili d√∂nd√ºr (yoksa None)."""
        return self.profiles.get(symbol)


# Global CoinProfiler instance
coin_profiler = CoinProfiler()


# ============================================================================
# PHASE 29: BALANCE PROTECTOR
# ============================================================================

class BalanceProtector:
    """
    Bakiye koruma ve b√ºy√ºtme odaklƒ± karar sistemi.
    Win rate deƒüil, toplam bakiye b√ºy√ºmesi optimizasyonu.
    
    Prensip: C√ºzdan bakiyesini korumak ve b√ºy√ºtmek ana hedeftir.
    """
    
    def __init__(self, initial_balance: float = 10000.0):
        self.initial_balance = initial_balance
        self.peak_balance = initial_balance
        self.drawdown_threshold = 5.0  # %5 drawdown'da agresif koruma
        self.profit_lock_threshold = 10.0  # %10 karda profit locking aktif
        self.profit_lock_ratio = 0.5  # Karƒ±n %50'sini kilitle
        logger.info(f"BalanceProtector initialized with ${initial_balance:.2f}")
    
    def update_peak(self, current_balance: float):
        """Peak balance'ƒ± g√ºncelle."""
        if current_balance > self.peak_balance:
            self.peak_balance = current_balance
            logger.debug(f"New peak balance: ${self.peak_balance:.2f}")
    
    def get_current_drawdown(self, current_balance: float) -> float:
        """Mevcut drawdown y√ºzdesini hesapla."""
        if self.peak_balance <= 0:
            return 0.0
        return ((self.peak_balance - current_balance) / self.peak_balance) * 100
    
    def get_profit_percent(self, current_balance: float) -> float:
        """Ba≈ülangƒ±√ßtan itibaren kar y√ºzdesini hesapla."""
        if self.initial_balance <= 0:
            return 0.0
        return ((current_balance - self.initial_balance) / self.initial_balance) * 100
    
    def should_reduce_risk(self, current_balance: float) -> bool:
        """Bakiye d√º≈ü√º≈ü√ºnde risk azaltƒ±lmalƒ± mƒ±?"""
        drawdown = self.get_current_drawdown(current_balance)
        return drawdown > self.drawdown_threshold
    
    def should_lock_profits(self, current_balance: float) -> bool:
        """Kar kilitleme aktif edilmeli mi?"""
        profit_pct = self.get_profit_percent(current_balance)
        return profit_pct > self.profit_lock_threshold
    
    def calculate_position_size_multiplier(self, current_balance: float) -> float:
        """
        Bakiye durumuna g√∂re pozisyon boyutu √ßarpanƒ±.
        
        Returns:
            float: 0.3 ile 1.5 arasƒ± √ßarpan
        """
        profit_pct = self.get_profit_percent(current_balance)
        drawdown = self.get_current_drawdown(current_balance)
        
        # Drawdown durumunda defansif ol
        if drawdown > 10:
            return 0.3  # √áok defansif
        elif drawdown > 5:
            return 0.5  # Defansif
        
        # Kar durumunda
        if profit_pct > 30:
            return 1.5  # √áok agresif
        elif profit_pct > 20:
            return 1.3  # Agresif
        elif profit_pct > 10:
            return 1.1  # Hafif agresif
        
        return 1.0  # Normal
    
    def calculate_leverage_multiplier(self, current_balance: float) -> float:
        """
        Bakiye durumuna g√∂re kaldƒ±ra√ß √ßarpanƒ±.
        Drawdown'da kaldƒ±racƒ± azalt, karda artƒ±r.
        
        Returns:
            float: 0.5 ile 1.2 arasƒ± √ßarpan
        """
        drawdown = self.get_current_drawdown(current_balance)
        profit_pct = self.get_profit_percent(current_balance)
        
        if drawdown > 10:
            return 0.5  # Kaldƒ±racƒ± yarƒ±ya d√º≈ü√ºr
        elif drawdown > 5:
            return 0.7  # Kaldƒ±racƒ± azalt
        
        if profit_pct > 20:
            return 1.2  # Kaldƒ±racƒ± artƒ±r
        
        return 1.0
    
    def get_protection_status(self, current_balance: float) -> dict:
        """Koruma durumu √∂zeti."""
        return {
            "initial_balance": self.initial_balance,
            "peak_balance": self.peak_balance,
            "current_balance": current_balance,
            "drawdown_pct": round(self.get_current_drawdown(current_balance), 2),
            "profit_pct": round(self.get_profit_percent(current_balance), 2),
            "size_multiplier": self.calculate_position_size_multiplier(current_balance),
            "leverage_multiplier": self.calculate_leverage_multiplier(current_balance),
            "reduce_risk": self.should_reduce_risk(current_balance),
            "lock_profits": self.should_lock_profits(current_balance)
        }


# Global BalanceProtector instance
balance_protector = BalanceProtector()


# ============================================================================
# PHASE 193: STOPLOSS FREQUENCY GUARD (Freqtrade-inspired)
# Belirli s√ºrede √ßok fazla SL tetiklenirse trading'i duraklat
# Kill Switch'ten baƒüƒ±msƒ±z, tamamlayƒ±cƒ± koruma katmanƒ±
# ============================================================================

class StoplossFrequencyGuard:
    """
    Freqtrade'in StoplossGuard pattern'inden esinlenilmi≈ü:
    Son N dakikada X adet SL-triggered exit olmu≈üsa, t√ºm trading'i duraklat.
    
    Kill Switch = margin bazlƒ± (b√ºy√ºk kayƒ±p), StoplossGuard = frekans bazlƒ± (art arda kayƒ±p).
    """
    
    def __init__(self):
        self.lookback_minutes: int = 60       # Son 60 dakika
        self.max_stoplosses: int = 3          # Max 3 SL
        self.cooldown_minutes: int = 30       # 30 dk duraklat
        self.only_per_pair: bool = False      # Global veya pair bazlƒ±
        self.enabled: bool = True
        
        # Internal tracking
        self._stoploss_events: list = []  # [(timestamp, symbol, reason), ...]
        self._lock_until: float = 0       # Global lock timestamp
        self._pair_locks: Dict[str, float] = {}  # symbol -> lock_until
        
        logger.info("StoplossFrequencyGuard initialized (lookback=60min, max_sl=3, cooldown=30min)")
    
    def record_stoploss(self, symbol: str, reason: str = "SL"):
        """Record a stoploss exit event."""
        now = time.time()
        self._stoploss_events.append((now, symbol, reason))
        
        # Cleanup old events (older than 2x lookback)
        cutoff = now - (self.lookback_minutes * 60 * 2)
        self._stoploss_events = [(t, s, r) for t, s, r in self._stoploss_events if t > cutoff]
        
        # Check if guard should trigger
        self._check_guard(symbol)
    
    def _check_guard(self, triggered_symbol: str):
        """Check if too many SLs, trigger cooldown if so."""
        now = time.time()
        lookback_start = now - (self.lookback_minutes * 60)
        
        if self.only_per_pair:
            # Per-pair check
            pair_events = [(t, s, r) for t, s, r in self._stoploss_events 
                          if t > lookback_start and s == triggered_symbol]
            if len(pair_events) >= self.max_stoplosses:
                lock_until = now + (self.cooldown_minutes * 60)
                self._pair_locks[triggered_symbol] = lock_until
                logger.warning(
                    f"üõë STOPLOSS_GUARD: {triggered_symbol} locked for {self.cooldown_minutes}min "
                    f"({len(pair_events)} SLs in {self.lookback_minutes}min)"
                )
        else:
            # Global check
            recent_events = [(t, s, r) for t, s, r in self._stoploss_events if t > lookback_start]
            if len(recent_events) >= self.max_stoplosses:
                lock_until = now + (self.cooldown_minutes * 60)
                self._lock_until = lock_until
                logger.warning(
                    f"üõë STOPLOSS_GUARD: ALL TRADING locked for {self.cooldown_minutes}min "
                    f"({len(recent_events)} SLs in {self.lookback_minutes}min)"
                )
    
    def is_locked(self, symbol: str = "") -> bool:
        """Check if trading is locked (globally or per-pair)."""
        if not self.enabled:
            return False
        
        now = time.time()
        
        # Global lock check
        if self._lock_until > now:
            return True
        
        # Per-pair lock check
        if symbol and self.only_per_pair:
            pair_lock = self._pair_locks.get(symbol, 0)
            if pair_lock > now:
                return True
        
        return False
    
    def get_lock_reason(self, symbol: str = "") -> str:
        """Get human-readable lock reason."""
        now = time.time()
        
        if self._lock_until > now:
            remaining = int((self._lock_until - now) / 60)
            return f"Global SL guard: {remaining}min remaining"
        
        if symbol and self.only_per_pair:
            pair_lock = self._pair_locks.get(symbol, 0)
            if pair_lock > now:
                remaining = int((pair_lock - now) / 60)
                return f"{symbol} SL guard: {remaining}min remaining"
        
        return ""
    
    def get_status(self) -> dict:
        """Get guard status for monitoring."""
        now = time.time()
        lookback_start = now - (self.lookback_minutes * 60)
        recent = [(t, s, r) for t, s, r in self._stoploss_events if t > lookback_start]
        
        return {
            'enabled': self.enabled,
            'global_locked': self._lock_until > now,
            'global_lock_remaining_min': max(0, int((self._lock_until - now) / 60)) if self._lock_until > now else 0,
            'recent_stoplosses': len(recent),
            'max_stoplosses': self.max_stoplosses,
            'lookback_minutes': self.lookback_minutes,
            'cooldown_minutes': self.cooldown_minutes,
            'only_per_pair': self.only_per_pair,
            'pair_locks': {s: int((t - now) / 60) for s, t in self._pair_locks.items() if t > now},
        }
    
    def update_settings(self, settings: dict):
        """Update guard settings from UI."""
        if 'sl_guard_enabled' in settings:
            self.enabled = settings['sl_guard_enabled']
        if 'sl_guard_lookback' in settings:
            self.lookback_minutes = max(5, min(240, settings['sl_guard_lookback']))
        if 'sl_guard_max_sl' in settings:
            self.max_stoplosses = max(1, min(20, settings['sl_guard_max_sl']))
        if 'sl_guard_cooldown' in settings:
            self.cooldown_minutes = max(5, min(120, settings['sl_guard_cooldown']))
        if 'sl_guard_per_pair' in settings:
            self.only_per_pair = settings['sl_guard_per_pair']
        logger.info(f"StoplossFrequencyGuard settings updated: {self.get_status()}")


# Global instance
stoploss_frequency_guard = StoplossFrequencyGuard()


# ============================================================================
# PHASE 36: POSITION-BASED KILL SWITCH (IMPROVED)
# ============================================================================

class PositionBasedKillSwitch:
    """
    Dynamic Kill Switch - thresholds calculated per-position based on leverage.
    
    Base thresholds (at 10x leverage):
    - First Reduction: -30% of invested margin ‚Üí close 50% of position
    - Full Close: -60% of invested margin ‚Üí close entire position
    
    Leverage adjustment:
    - Higher leverage (>10x): Looser thresholds (more room)
    - Lower leverage (<10x): Tighter thresholds (less room)
    
    Formula: threshold = base_threshold * sqrt(leverage / 10)
    - 25x leverage: -30% * sqrt(2.5) = -47% first, -95% full
    - 10x leverage: -30% * 1.0 = -30% first, -60% full  
    - 5x leverage: -30% * sqrt(0.5) = -21% first, -42% full
    """
    
    def __init__(self, reduction_size: float = 0.5):
        # Base thresholds at 10x leverage (reference point)
        self.base_first_reduction = -30.0  # -30% of invested margin
        self.base_full_close = -60.0       # -60% of invested margin
        self.reduction_size = reduction_size  # 50% reduction at first level
        
        # Track which positions have been partially closed
        self.partially_closed = {}  # {position_id: reduction_count}
        
        # Daily stats
        self.day_start_balance = 10000.0
        self.last_reset_date = None
        
        # Keep these for backwards compatibility (but they're not used anymore)
        self.first_reduction_pct = self.base_first_reduction
        self.full_close_pct = self.base_full_close
        
        logger.info(f"üö® Dynamic Kill Switch initialized: Base thresholds {self.base_first_reduction}%/{self.base_full_close}% (adjusted by leverage)")
    
    def get_dynamic_thresholds(self, leverage: int) -> tuple:
        """
        Calculate dynamic thresholds based on position's leverage.
        
        Higher leverage = LOOSER thresholds (more tolerance for volatility)
        Lower leverage = TIGHTER thresholds (less tolerance needed)
        
        Logic: High leverage coins (BTC/ETH) are low spread, so we give more room.
               Low leverage coins (shitcoins) are high spread, but we close earlier
               because they have higher risk.
        
        Returns: (first_reduction_pct, full_close_pct)
        """
        if leverage <= 0:
            leverage = 10  # Default
        
        # Adjustment factor: leverage / 10
        # Higher leverage = larger factor = looser threshold
        # Lower leverage = smaller factor = tighter threshold
        # Using sqrt for smoother scaling
        factor = (leverage / 10.0) ** 0.5  # sqrt scaling
        
        # Use UI-configured thresholds (first_reduction_pct, full_close_pct) as base
        # These can be changed via Settings Modal
        first_reduction = self.first_reduction_pct * factor
        full_close = self.full_close_pct * factor
        
        # Clamp to reasonable bounds
        # Min: -40% (very tight) for low leverage shitcoins
        # Max: -120% (loose) for high leverage majors
        first_reduction = max(-200.0, min(-30.0, first_reduction))
        full_close = max(-300.0, min(-60.0, full_close))
        
        return (first_reduction, full_close)

    
    def reset_for_new_day(self, current_balance: float):
        """Reset for new trading day."""
        # Phase 60: Use Turkey timezone (UTC+3)
        # pytz imported globally
        turkey_tz = pytz.timezone('Europe/Istanbul')
        today = datetime.now(turkey_tz).date()
        if self.last_reset_date != today:
            self.day_start_balance = current_balance
            self.last_reset_date = today
            # Phase 217: Sadece biten pozisyonlarƒ± temizle, a√ßƒ±k pozisyonlarƒ±n durumunu koru
            try:
                active_position_ids = {p.get('id', '') for p in global_paper_trader.positions} if 'global_paper_trader' in globals() else set()
                self.partially_closed = {
                    pid: count for pid, count in self.partially_closed.items()
                    if pid in active_position_ids
                }
            except Exception:
                self.partially_closed.clear()
            logger.info(f"üìÖ New trading day (Turkey): Starting balance ${current_balance:.2f}")
    
    async def check_positions(self, paper_trader) -> dict:
        """
        Check all positions and apply gradual reduction or close.
        Uses POSITION-BASED UNLEVERAGED LOSS percentage: (PnL / invested_margin) * 100
        This means -10% threshold triggers when you've lost 10% of your invested capital.
        Returns summary of actions taken.
        """
        self.reset_for_new_day(paper_trader.balance)
        
        actions = {
            "reduced": [],
            "closed": [],
            "skipped_profitable": []
        }
        
        for pos in list(paper_trader.positions):
            try:
                pos_id = pos.get('id', '')
                symbol = pos.get('symbol', '')
                side = pos.get('side', '')
                entry_price = pos.get('entryPrice', 0)
                current_price = pos.get('currentPrice', entry_price)
                unrealized_pnl = pos.get('unrealizedPnl', 0)
                
                # Get invested margin (actual capital at risk, not leveraged size)
                initial_margin = pos.get('initialMargin', 0)
                leverage = pos.get('leverage', 10)
                size_usd = pos.get('sizeUsd', 0)
                
                # Calculate margin if not stored
                if initial_margin <= 0:
                    initial_margin = size_usd / leverage if leverage > 0 else size_usd
                
                # Skip if no margin (invalid position)
                if initial_margin <= 0:
                    logger.warning(f"Kill switch: {symbol} has no margin data, skipping")
                    continue
                
                # Skip profitable positions (don't touch winners!)
                if unrealized_pnl >= 0:
                    actions["skipped_profitable"].append(symbol)
                    continue
                
                # Phase 152: Use LEVERAGED ROI instead of unleveraged margin loss
                # unrealizedPnlPercent is already leveraged (pnl / sizeUsd * 100 * leverage)
                position_loss_pct = pos.get('unrealizedPnlPercent', 0)
                # Phase 221: Fallback calculation for paper positions where unrealizedPnlPercent=0
                if position_loss_pct == 0 and unrealized_pnl < 0 and initial_margin > 0:
                    position_loss_pct = (unrealized_pnl / initial_margin) * 100
                
                # Get DYNAMIC thresholds based on this position's leverage
                first_threshold, full_threshold = self.get_dynamic_thresholds(leverage)
                
                # Phase 222: Kill Switch must not trigger before SL
                sl_price = pos.get('stopLoss', 0)
                if sl_price > 0 and entry_price > 0:
                    if side == 'LONG':
                        sl_roi = ((sl_price - entry_price) / entry_price) * 100 * leverage
                    else:
                        sl_roi = ((entry_price - sl_price) / entry_price) * 100 * leverage
                    # SL ROI is negative for losses ‚Äî if SL would close at a tighter loss than kill switch, let SL handle it
                    if -sl_roi > -full_threshold:
                        continue
                
                # Log for debugging with dynamic thresholds
                logger.info(f"üéØ Kill switch check {symbol} [{leverage}x]: ROI={position_loss_pct:.1f}% | Thresholds: {first_threshold:.0f}%/{full_threshold:.0f}%")
                
                # Check loss thresholds using POSITION LOSS with DYNAMIC thresholds
                if position_loss_pct <= full_threshold:
                    # Full close threshold reached
                    paper_trader.close_position(pos, current_price, 'KILL_SWITCH_FULL')
                    # Note: close_position already handles Binance close for isLive positions
                    actions["closed"].append(f"{symbol} ({position_loss_pct:.1f}%)")
                    logger.warning(f"üö® KILL SWITCH FULL [{leverage}x]: Closed {side} {symbol} at {position_loss_pct:.1f}% loss (threshold: {full_threshold:.0f}%)")
                    # Phase 48: Record fault for this coin
                    kill_switch_fault_tracker.record_fault(symbol, 'KILL_SWITCH_FULL')
                    
                elif position_loss_pct <= first_threshold:
                    # First reduction threshold - close 50% (only once per position)
                    already_reduced = pos.get('kill_switch_reduced', False)
                    
                    if not already_reduced:
                        # First reduction - close 50%
                        pos['kill_switch_reduced'] = True  # Mark as reduced
                        await self._reduce_position(paper_trader, pos, current_price, self.reduction_size)
                        self.partially_closed[pos_id] = 1  # Keep for backwards compat
                        actions["reduced"].append(f"{symbol} ({position_loss_pct:.1f}%)")
                        logger.warning(f"‚ö†Ô∏è KILL SWITCH REDUCE [{leverage}x]: Reduced {side} {symbol} by 50% at {position_loss_pct:.1f}% loss (threshold: {first_threshold:.0f}%)")
                        # Phase 48: Record fault for this coin
                        kill_switch_fault_tracker.record_fault(symbol, 'KILL_SWITCH_PARTIAL')
                    # If already_reduced, wait for full_threshold to trigger
                        
            except Exception as e:
                logger.error(f"Kill switch check error for {pos.get('symbol', 'unknown')}: {e}")
        
        return actions
    
    async def _reduce_position(self, paper_trader, pos: dict, current_price: float, reduction_pct: float):
        """
        Reduce position size by specified percentage.
        Records partial close in trade history.
        For LIVE positions, sends actual Binance partial close order.
        """
        # Phase 141: Use contracts with size fallback for consistency
        original_size = pos.get('contracts', pos.get('size', 0))
        original_size_usd = pos.get('sizeUsd', 0)
        reduction_size = original_size * reduction_pct
        reduction_size_usd = original_size_usd * reduction_pct
        
        # Calculate PnL for the reduced portion
        entry_price = pos.get('entryPrice', current_price)
        side = pos.get('side', 'LONG')
        symbol = pos.get('symbol', '')
        
        if side == 'LONG':
            price_diff = current_price - entry_price
        else:
            price_diff = entry_price - current_price
        
        pnl = reduction_size * price_diff
        pnl_pct = (price_diff / entry_price) * 100 if entry_price > 0 else 0
        
        # LIVE positions: Execute actual Binance partial close
        if pos.get('isLive', False) and reduction_size > 0:
            try:
                result = await live_binance_trader.close_position(symbol, side, reduction_size)
                if result:
                    # Phase 188: Set cooldown to prevent Binance sync from restoring old size
                    pos['_partial_close_ts'] = datetime.now().timestamp()
                    close_oid = str(result.get('id', ''))
                    logger.warning(f"üìä KILL_SWITCH LIVE ‚úÖ: {symbol} reduced {reduction_pct*100:.0f}% on Binance ({reduction_size:.4f} contracts) | Order: {close_oid[:12]}")
                    # Phase 229b: Persist close order ID
                    if close_oid:
                        safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                else:
                    logger.error(f"‚ùå KILL_SWITCH LIVE FAILED: {symbol} - close_position returned None")
            except Exception as e:
                logger.error(f"‚ùå KILL_SWITCH LIVE ERROR: {symbol} - {e}")
        
        # Update balance with initial margin portion + PnL
        # Initial Margin = sizeUsd / leverage
        leverage = pos.get('leverage', 10)
        reduction_initial_margin = reduction_size_usd / leverage
        paper_trader.balance += reduction_initial_margin + pnl
        
        # Update position with reduced size
        pos['size'] = original_size - reduction_size
        pos['sizeUsd'] = original_size_usd - reduction_size_usd
        # Update initialMargin proportionally
        if 'initialMargin' in pos:
            pos['initialMargin'] = pos['initialMargin'] * (1 - reduction_pct)
        
        # Record partial close in trade history
        partial_trade = {
            "id": f"{pos.get('id', '')}_PARTIAL",
            "symbol": symbol,
            "side": side,
            "entryPrice": entry_price,
            "exitPrice": current_price,
            "size": reduction_size,
            "sizeUsd": reduction_size_usd,
            "pnl": pnl,
            "pnlPercent": pnl_pct,
            "openTime": pos.get('openTime', 0),
            "closeTime": int(datetime.now().timestamp() * 1000),
            "reason": "KILL_SWITCH_PARTIAL",
            "closeReason": "KILL_SWITCH_PARTIAL",
            "leverage": pos.get('leverage', 10)
        }
        paper_trader.trades.append(partial_trade)
        paper_trader.add_log(f"‚ö†Ô∏è PARTIAL CLOSE: {side} {symbol} reduced by {reduction_pct*100:.0f}% | PnL: ${pnl:.2f}")
    
    def get_status(self, current_balance: float) -> dict:
        """Get kill switch status for UI."""
        if self.day_start_balance <= 0:
            return {"first_reduction_pct": self.first_reduction_pct, "full_close_pct": self.full_close_pct}
        
        daily_pnl = current_balance - self.day_start_balance
        daily_pnl_pct = (daily_pnl / self.day_start_balance) * 100
        
        return {
            "type": "POSITION_BASED",
            "first_reduction_pct": self.first_reduction_pct,
            "full_close_pct": self.full_close_pct,
            "day_start_balance": self.day_start_balance,
            "daily_pnl": round(daily_pnl, 2),
            "daily_pnl_pct": round(daily_pnl_pct, 2),
            "partially_closed_count": len(self.partially_closed)
        }


# Global PositionBasedKillSwitch instance (replaces DailyKillSwitch)
daily_kill_switch = PositionBasedKillSwitch()


# ============================================================================
# PHASE 49: TIME-BASED POSITION MANAGER
# ============================================================================

class TimeBasedPositionManager:
    """
    Manages positions based on time elapsed without favorable movement.
    
    STAGNANT PROFITABLE POSITIONS:
    - If in profit but hasn't moved in favor for 30+ minutes, activate trailing stop early
    
    STAGNANT LOSING POSITIONS:
    - Gradually reduce position size if not recovering:
      - 1 hour without profit: reduce 10%
      - 2 hours without profit: reduce 20%
      - 4 hours without profit: reduce 20%
      - 8 hours without profit: reduce 20%
    """
    
    def __init__(self):
        # Track position reductions: {pos_id: {'1h': bool, '2h': bool, '4h': bool, '8h': bool}}
        self.time_reductions = {}
        
        # Time thresholds and reduction percentages
        # 4h = 10% reduce, 8h = 10% reduce (less aggressive with kill switch active)
        self.reduction_schedule = [
            {'hours': 4, 'reduction_pct': 0.10, 'key': '4h'},   # 4 hours: 10% reduce
            {'hours': 8, 'reduction_pct': 0.10, 'key': '8h'},   # 8 hours: 10% reduce
        ]
        
        # Trail activation settings for stagnant profitable positions
        self.early_trail_minutes = 30  # Activate trail if profitable but stagnant for 30 min
        
        logger.info("üìä TimeBasedPositionManager initialized")
    
    async def check_positions(self, paper_trader) -> dict:
        """
        Check all positions for time-based management.
        Returns summary of actions taken.
        """
        actions = {
            "trail_activated": [],
            "time_reduced": [],
            "time_closed": [],
            "partial_tp": [],  # Phase 137: Partial take profit tracking
            "checked": 0
        }
        
        positions_to_remove = []  # Phase 56: Track positions to remove after 100% reduction
        current_time_ms = int(datetime.now().timestamp() * 1000)
        
        for pos in list(paper_trader.positions):
            try:
                pos_id = pos.get('id', '')
                symbol = pos.get('symbol', '')
                side = pos.get('side', '')
                open_time = pos.get('openTime', current_time_ms)
                unrealized_pnl = pos.get('unrealizedPnl', 0)
                is_trailing_active = pos.get('isTrailingActive', False)
                current_price = pos.get('currentPrice', pos.get('entryPrice', 0))
                entry_price = pos.get('entryPrice', current_price)
                contracts = pos.get('contracts', 0)
                
                # Calculate position age in hours
                age_hours = (current_time_ms - open_time) / (1000 * 60 * 60)
                
                actions["checked"] += 1
                
                # Phase 137 DEBUG: Trace log before CASE checks (every 100th call to reduce spam)
                if not hasattr(self, '_debug_count'):
                    self._debug_count = 0
                self._debug_count += 1
                if self._debug_count % 100 == 1:
                    logger.info(f"üìä POS_DEBUG: {symbol} age={age_hours:.1f}h pnl={unrealized_pnl:.2f} entry={entry_price:.4f} curr={current_price:.4f}")
                
                # ===============================================
                # PHASE 137: DYNAMIC PARTIAL TAKE PROFIT
                # Spread ve volatiliteye g√∂re dinamik TP seviyeleri
                # ===============================================
                if unrealized_pnl > 0 and contracts > 0:
                    # Get spread level and ATR for dynamic TP calculation
                    spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223: was only 'spread_level'
                    atr = pos.get('atr', current_price * 0.02)
                    
                    # ATR as percentage of price
                    atr_pct = (atr / current_price * 100) if current_price > 0 else 2.0
                    
                    # Spread multipliers for TP levels
                    spread_mults = {
                        'Very Low': 0.5,   # BTC/ETH - tighter TPs
                        'Low': 0.75,
                        'Normal': 1.0,
                        'High': 1.5,
                        'Very High': 2.5,  # Meme coins - wider TPs
                        'Extreme': 3.5,    # Hyper-volatile
                        'Ultra': 5.0       # Extreme edge cases
                    }
                    mult = spread_mults.get(spread_level, 1.0)
                    
                    # Dynamic base for TP levels: ATR_pct * multiplier
                    base_tp_pct = atr_pct * mult
                    
                    # Phase 224C2: Leverage-normalized TP levels
                    # TP hedefleri margin-based ROI olarak tanƒ±mlanƒ±r
                    leverage = pos.get('leverage', 10)
                    
                    # ROI-based TP targets (margin √ºzerinden)
                    tp1_price_pct = max(base_tp_pct * 1.0, 8.0 / leverage)   # ~8% ROI
                    tp2_price_pct = max(base_tp_pct * 2.0, 20.0 / leverage)  # ~20% ROI
                    tp3_price_pct = max(base_tp_pct * 3.5, 40.0 / leverage)  # ~40% ROI
                    
                    tp_levels = [
                        {'pct': tp1_price_pct, 'close_pct': 0.40, 'key': 'tp1'},
                        {'pct': tp2_price_pct, 'close_pct': 0.30, 'key': 'tp2'},
                        {'pct': tp3_price_pct, 'close_pct': 0.30, 'key': 'tp3'},
                    ]
                    
                    # Current profit percentage
                    if entry_price > 0:
                        if side == 'LONG':
                            profit_pct = (current_price - entry_price) / entry_price * 100
                        else:  # SHORT
                            profit_pct = (entry_price - current_price) / entry_price * 100
                        
                        # Track which TPs have been hit
                        partial_tp_state = pos.get('partial_tp_state', {})
                        
                        for level in tp_levels:
                            if profit_pct >= level['pct'] and not partial_tp_state.get(level['key'], False):
                                # TP level hit - mark as closed
                                partial_tp_state[level['key']] = True
                                pos['partial_tp_state'] = partial_tp_state
                                
                                # Phase 231e: Use ORIGINAL contracts for percentage calc
                                # Prevents compounding: 40/18/12.6 ‚Üí correct 40/30/30
                                original_contracts = pos.get('original_contracts', contracts)
                                if original_contracts == 0:
                                    original_contracts = contracts
                                close_contracts = original_contracts * level['close_pct']
                                
                                # LIVE positions: Execute actual Binance partial close
                                if pos.get('isLive', False) and close_contracts > 0:
                                    live_success = False
                                    try:
                                        result = await live_binance_trader.close_position(symbol, side, close_contracts)
                                        if result:
                                            live_success = True
                                            # Phase 188: Set cooldown to prevent Binance sync from restoring old size
                                            pos['_partial_close_ts'] = datetime.now().timestamp()
                                            close_oid = str(result.get('id', ''))
                                            logger.warning(f"üí∞ PARTIAL_TP LIVE ‚úÖ: {symbol} closed {level['close_pct']*100:.0f}% on Binance ({close_contracts:.4f} contracts) at {profit_pct:.2f}% profit | Order: {close_oid[:12]}")
                                            # Phase 229b: Persist close order ID
                                            if close_oid:
                                                safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                        else:
                                            logger.error(f"‚ùå PARTIAL_TP LIVE FAILED: {symbol} - close_position returned None")
                                    except Exception as e:
                                        logger.error(f"‚ùå PARTIAL_TP LIVE ERROR: {symbol} - {e}")
                                    
                                    # Phase 231: Only update local state if Binance close succeeded
                                    if not live_success:
                                        # Revert TP state ‚Äî Binance failed, don't mark as closed
                                        partial_tp_state[level['key']] = False
                                        pos['partial_tp_state'] = partial_tp_state
                                        logger.warning(f"‚ö†Ô∏è PARTIAL_TP REVERTED: {symbol} {level['key']} ‚Äî Binance close failed, state rolled back")
                                        continue  # Skip contract update and trail activation
                                
                                # Phase 231e: Save original values BEFORE first reduction
                                if not pos.get('original_contracts'):
                                    pos['original_contracts'] = contracts
                                    pos['original_size'] = pos.get('size', contracts)
                                    pos['original_sizeUsd'] = pos.get('sizeUsd', 0)
                                    pos['original_initialMargin'] = pos.get('initialMargin', 0)
                                
                                # Phase 231g: Clamp to prevent negative contracts
                                new_contracts = max(0, pos.get('contracts', contracts) - close_contracts)
                                pos['contracts'] = new_contracts
                                
                                # Ratio-based sync: all fields scale proportionally
                                ratio = new_contracts / contracts if contracts > 0 else 1.0
                                pos['size'] = new_contracts  # size = contracts (same unit)
                                pos['sizeUsd'] = pos.get('sizeUsd', 0) * (new_contracts / (new_contracts + close_contracts)) if (new_contracts + close_contracts) > 0 else 0
                                pos['initialMargin'] = pos.get('initialMargin', 0) * (new_contracts / (new_contracts + close_contracts)) if (new_contracts + close_contracts) > 0 else 0
                                
                                # =====================================================
                                # Phase 220: TP1 ‚Üí Force Trail + Breakeven SL
                                # Kalan pozisyonu trail ile koru, SL'i entry+fee'ye ta≈üƒ±
                                # =====================================================
                                if level['key'] == 'tp1':
                                    # 1) Force-activate trailing stop for remaining position
                                    trail_dist = pos.get('trailDistance', atr * 1.5)
                                    if side == 'LONG':
                                        new_trail_stop = current_price - trail_dist
                                        # Trail stop should be at least at entry
                                        new_trail_stop = max(new_trail_stop, entry_price)
                                        pos['trailingStop'] = new_trail_stop
                                    else:  # SHORT
                                        new_trail_stop = current_price + trail_dist
                                        new_trail_stop = min(new_trail_stop, entry_price)
                                        pos['trailingStop'] = new_trail_stop
                                    pos['isTrailingActive'] = True
                                    logger.warning(f"üìä TP1_TRAIL: {symbol} {side} trail FORCED ON | stop=${pos['trailingStop']:.6f} dist=${trail_dist:.6f}")
                                    
                                    # 2) Move SL to breakeven (entry + fee buffer)
                                    fee_buffers = {
                                        'Very Low': 0.005, 'Low': 0.005, 'Normal': 0.006,
                                        'High': 0.008, 'Very High': 0.010,
                                        'Extreme': 0.015, 'Ultra': 0.020
                                    }
                                    fee_buffer = fee_buffers.get(spread_level, 0.006)
                                    if side == 'LONG':
                                        breakeven_sl = entry_price * (1 + fee_buffer)
                                        if breakeven_sl > pos.get('stopLoss', 0):
                                            pos['stopLoss'] = breakeven_sl
                                    else:  # SHORT
                                        breakeven_sl = entry_price * (1 - fee_buffer)
                                        if breakeven_sl < pos.get('stopLoss', float('inf')):
                                            pos['stopLoss'] = breakeven_sl
                                    pos['breakeven_activated'] = True
                                    logger.warning(f"üîí TP1_BREAKEVEN: {symbol} {side} SL ‚Üí breakeven ${breakeven_sl:.6f} (entry+{fee_buffer*100:.1f}%)")
                                    
                                    # 3) For LIVE positions: Update SL on Binance
                                    if pos.get('isLive', False):
                                        try:
                                            remaining_contracts = pos['contracts']
                                            sl_result = await live_binance_trader.set_stop_loss(symbol, side, remaining_contracts, breakeven_sl)
                                            if sl_result:
                                                logger.warning(f"üîí TP1_BREAKEVEN LIVE ‚úÖ: {symbol} SL set to ${breakeven_sl:.6f} on Binance")
                                            else:
                                                logger.error(f"‚ùå TP1_BREAKEVEN LIVE FAILED: {symbol} - set_stop_loss returned None")
                                        except Exception as be_err:
                                            logger.warning(f"‚ö†Ô∏è TP1_BREAKEVEN LIVE SKIP: {symbol} - {be_err} (will use internal SL)")
                                
                                # Log partial TP
                                logger.info(f"üí∞ PARTIAL_TP: {symbol} closed {level['close_pct']*100:.0f}% at {profit_pct:.2f}% profit (level: {level['key']}, base: {base_tp_pct:.2f}%)")
                                actions["partial_tp"].append(f"{symbol}_{level['key']}({profit_pct:.1f}%)")
                                
                                # Phase 220b: Update local contracts for next TP level calculation
                                contracts = pos['contracts']
                
                # Phase 190: REMOVED duplicate breakeven (Phase 137)
                # BreakevenStopManager handles this better with limit orders + fee buffer
                # Old code moved SL to exact entry (no buffer) ‚Äî caused commission losses
                

                # ===============================================
                # CASE 1: PROFITABLE - DYNAMIC PULLBACK TRAIL
                # Phase 51: Spread-based dynamic pullback threshold
                # ===============================================
                if unrealized_pnl > 0 and not is_trailing_active:
                    age_minutes = age_hours * 60
                    
                    # Only consider early trail after 30 minutes
                    if age_minutes >= self.early_trail_minutes:
                        # Get ATR and spread level from position
                        atr = pos.get('atr', current_price * 0.02)  # Default 2% if no ATR
                        spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                        
                        # Dynamic pullback multiplier based on spread
                        spread_multipliers = {
                            'Very Low': 0.5,   # BTC, ETH - small pullback triggers trail
                            'Low': 0.75,
                            'Normal': 1.0,
                            'High': 1.5,
                            'Very High': 2.0,  # Meme coins - wait for larger pullback
                            'Extreme': 3.0,    # Hyper-volatile
                            'Ultra': 4.0       # Extreme edge cases
                        }
                        multiplier = spread_multipliers.get(spread_level, 1.0)
                        pullback_threshold = atr * multiplier
                        
                        # Track highest profit reached
                        highest_profit = pos.get('highestProfit', unrealized_pnl)
                        if unrealized_pnl > highest_profit:
                            pos['highestProfit'] = unrealized_pnl
                            highest_profit = unrealized_pnl
                        
                        # Calculate pullback from highest profit
                        profit_pullback = highest_profit - unrealized_pnl
                        
                        # Activate trail if pullback exceeds threshold
                        if profit_pullback >= pullback_threshold:
                            pos['isTrailingActive'] = True
                            pos['trailingStop'] = current_price
                            actions["trail_activated"].append(f"{symbol} (pullback ${profit_pullback:.2f})")
                            logger.info(f"üìä EARLY TRAIL: {symbol} activated - pullback ${profit_pullback:.2f} >= threshold ${pullback_threshold:.2f} (spread: {spread_level})")
                
                # ===============================================
                # CASE 2: LOSING AND STAGNANT - GRADUAL REDUCTION
                # Phase 137 FIX: Changed elif to if - CASE 2 should run independently
                # Phase 188: SKIP for LIVE positions ‚Äî Kill Switch handles risk management
                # Time-based reduction on live causes duplicate Binance orders due to sync overwrite
                # ===============================================
                # Phase 190: Enabled for LIVE positions (was paper-only)
                if unrealized_pnl < 0:
                    # Initialize tracking for this position
                    if pos_id not in self.time_reductions:
                        self.time_reductions[pos_id] = {item['key']: False for item in self.reduction_schedule}
                    
                    # Phase 137 ONE-TIME FIX: Reset broken flags from old code
                    # Old code used 'size' (always 0), never reduced, but flags got set somehow
                    # Reset flags if position has contracts but hasn't actually been reduced
                    if not hasattr(self, '_flags_reset_done'):
                        self._flags_reset_done = True
                        for p in paper_trader.positions:
                            # If position has contracts (not reduced) but flags are True, reset them
                            if p.get('contracts', 0) > 0:
                                if p.get('time_reduced_4h', False) or p.get('time_reduced_8h', False):
                                    logger.warning(f"üìä FLAG_RESET: {p.get('symbol')} resetting broken time reduction flags")
                                    p['time_reduced_4h'] = False
                                    p['time_reduced_8h'] = False
                    
                    # Phase 137 DEBUG: Trace log for CASE 2 entry
                    logger.info(f"üìä TIME_CHECK: {symbol} age={age_hours:.1f}h pnl={unrealized_pnl:.2f} flags={pos.get('time_reduced_4h', False)}/{pos.get('time_reduced_8h', False)}")
                    
                    # Check each time threshold
                    for schedule in self.reduction_schedule:
                        threshold_hours = schedule['hours']
                        reduction_pct = schedule['reduction_pct']
                        key = schedule['key']
                        
                        # Phase 55: Use position-internal flag to survive restarts
                        pos_flag_key = f"time_reduced_{key}"
                        already_reduced_flag = pos.get(pos_flag_key, False)
                        
                        # Check if we've passed this threshold and haven't reduced yet
                        if age_hours >= threshold_hours and not already_reduced_flag:
                            # Phase 137 FIX: Use 'contracts' (from Binance) instead of 'size'
                            position_contracts = pos.get('contracts', pos.get('size', 0))
                            position_notional = pos.get('notional', pos.get('sizeUsd', 0))
                            
                            reduction_amount = position_contracts * reduction_pct
                            reduction_usd = position_notional * reduction_pct
                            
                            if reduction_amount > 0:
                                # Calculate partial close PnL
                                if side == 'LONG':
                                    partial_pnl = (current_price - pos['entryPrice']) * reduction_amount
                                else:
                                    partial_pnl = (pos['entryPrice'] - current_price) * reduction_amount
                                
                                # Update position size
                                pos['size'] -= reduction_amount
                                pos['sizeUsd'] -= reduction_usd
                                
                                # Return margin proportionally
                                initial_margin = pos.get('initialMargin', 0)
                                margin_return = initial_margin * reduction_pct
                                pos['initialMargin'] = initial_margin - margin_return
                                paper_trader.balance += margin_return + partial_pnl
                                
                                # Mark as reduced - BOTH in dictionary and position
                                self.time_reductions[pos_id][key] = True
                                pos[pos_flag_key] = True  # Position-internal flag
                                
                                actions["time_reduced"].append(f"{symbol} {key} (-{reduction_pct*100:.0f}%)")
                                logger.warning(f"üìä TIME REDUCE: {symbol} reduced {reduction_pct*100:.0f}% after {threshold_hours}h (PnL: ${partial_pnl:.2f})")
                                
                                # LIVE positions: Execute actual Binance partial close
                                if pos.get('isLive', False):
                                    try:
                                        result = await live_binance_trader.close_position(symbol, side, reduction_amount)
                                        if result:
                                            close_oid = str(result.get('id', ''))
                                            logger.warning(f"üìä TIME REDUCE LIVE ‚úÖ: {symbol} closed {reduction_pct*100:.0f}% on Binance ({reduction_amount:.4f} contracts) | Order: {close_oid[:12]}")
                                            # Phase 229b: Persist close order ID
                                            if close_oid:
                                                safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                        else:
                                            logger.error(f"‚ùå TIME REDUCE LIVE FAILED: {symbol} - close_position returned None")
                                    except Exception as e:
                                        logger.error(f"‚ùå TIME REDUCE LIVE ERROR: {symbol} - {e}")
                                
                                # Phase 152: Don't spam UI logs ‚Äî summary log added at end of cycle
                                
                                # ===== RECORD AS TRADE FOR HISTORY =====
                                close_reason = f"TIME_REDUCE_{key.upper()}"
                                trade_record = {
                                    'symbol': symbol,
                                    'side': side,
                                    'entryPrice': pos['entryPrice'],
                                    'exitPrice': current_price,
                                    'size': reduction_amount,
                                    'sizeUsd': reduction_usd,
                                    'pnl': partial_pnl,
                                    'pnlPercent': (partial_pnl / margin_return * 100) if margin_return > 0 else 0,
                                    'openTime': pos.get('openTime', 0),
                                    'closeTime': int(datetime.now().timestamp() * 1000),
                                    'closeReason': close_reason,
                                    'reason': close_reason,
                                    'leverage': pos.get('leverage', 10),
                                    'margin': margin_return,
                                    'isPartialClose': reduction_pct < 1.0  # Only partial if not 100%
                                }
                                paper_trader.trades.append(trade_record)
                                paper_trader.stats['totalTrades'] += 1
                                if partial_pnl > 0:
                                    paper_trader.stats['winningTrades'] += 1  # Phase 223: was 'winTrades' (KeyError)
                                
                                # Phase 56: If 100% reduction, mark position for removal
                                if reduction_pct >= 1.0 or pos.get('size', 0) <= 0 or pos.get('sizeUsd', 0) <= 0.01:
                                    positions_to_remove.append(pos_id)
                                    logger.warning(f"üìä TIME CLOSE: {symbol} fully closed after {threshold_hours}h (PnL: ${partial_pnl:.2f})")
                                    paper_trader.add_log(f"‚è∞ TIME CLOSE: {symbol} fully closed after {threshold_hours}h")
                                
                                paper_trader.save_state()
                
            except Exception as e:
                logger.error(f"Error in time-based position check: {e}")
        
        # Phase 56: Remove positions that were fully closed (100% reduction)
        if positions_to_remove:
            paper_trader.positions = [p for p in paper_trader.positions if p.get('id') not in positions_to_remove]
            actions["time_closed"] = positions_to_remove
            logger.info(f"üìä TIME CLOSE: Removed {len(positions_to_remove)} fully closed positions")
            paper_trader.save_state()
        
        # Phase 152: Single summary log for UI instead of per-position spam
        if actions.get("time_reduced"):
            symbols = [r.split()[0] for r in actions["time_reduced"]]
            paper_trader.add_log(f"‚è∞ TIME REDUCE: {len(symbols)} poz k√º√ß√ºlt√ºld√º: {', '.join(symbols[:5])}{'...' if len(symbols) > 5 else ''}")
        
        # Cleanup old tracking data for closed positions
        active_pos_ids = {p.get('id') for p in paper_trader.positions}
        self.time_reductions = {k: v for k, v in self.time_reductions.items() if k in active_pos_ids}
        
        return actions
    
    def get_status(self) -> dict:
        """Get current status for UI."""
        return {
            "type": "TIME_BASED",
            "tracked_positions": len(self.time_reductions),
            "early_trail_minutes": self.early_trail_minutes,
            "reduction_schedule": [f"{s['hours']}h: {s['reduction_pct']*100:.0f}%" for s in self.reduction_schedule]
        }


# Global TimeBasedPositionManager instance
time_based_position_manager = TimeBasedPositionManager()


# ============================================================================
# PHASE 142: PORTFOLIO RECOVERY TRAILING
# ============================================================================

class PortfolioRecoveryManager:
    """
    Phase 142: Portfolio Recovery Trailing System
    
    Total Unrealized PnL 12+ saat ekside kalƒ±p artƒ±ya d√∂nerse,
    trailing ile t√ºm pozisyonlarƒ± kapatarak bakiyeyi korur.
    
    Mantƒ±k:
    1. Total uPnL < 0 ise, underwater timer ba≈ülat
    2. 12+ saat underwater ‚Üí "Recovery Candidate" i≈üaretle
    3. uPnL >= +$0.50 olduƒüunda ‚Üí Trailing aktifle≈ütir
    4. Trailing mesafesi = (BTC_ATR% + ETH_ATR%) / 2, min 1.5%, max 5%
    5. Peak'ten geri √ßekilme > trailing distance ‚Üí T√úM pozisyonlarƒ± kapat
    6. Kapatma sonrasƒ± 6 saat cooldown (yeni sinyal engeli)
    """
    
    def __init__(self):
        # State tracking
        self.underwater_start_time = None      # When uPnL first went negative
        self.is_recovery_candidate = False     # 12h+ underwater flag
        self.recovery_trailing_active = False  # Trailing mode active
        self.peak_positive_pnl = 0.0          # Highest positive uPnL seen during trailing
        self.trailing_distance_pct = 2.5       # Dynamic, based on BTC/ETH ATR
        self.cooldown_until = None            # Timestamp for cooldown end
        self.should_trigger_close = False     # Flag for sync loop to close all
        self.last_total_upnl = 0.0            # Last recorded total uPnL
        
        # Configuration
        # Phase 190: Removed 12h wait ‚Äî recovery candidate activates immediately
        self.underwater_threshold_hours = 0    # Immediate ‚Äî artƒ±ya ge√ßince trail ba≈ülar
        self.min_positive_pct = 0.03           # Phase 200: Margin Balance'ƒ±n %3'√º (dinamik, min $5)
        self.min_trailing_pct = 5.0            # Phase 200: 5.0% minimum trailing distance (was 1.5%)
        self.max_trailing_pct = 10.0           # 10.0% maximum trailing distance
        self.cooldown_hours = 6               # Hours to wait after recovery close
        
        logger.info(f"üîÑ PortfolioRecoveryManager initialized: min_positive=%3 of balance, trail=5-10%")
    
    def update(self, total_unrealized_pnl: float, btc_atr_pct: float, eth_atr_pct: float, wallet_balance: float = 100.0) -> str:
        """
        Main update method - called every sync cycle.
        
        Args:
            total_unrealized_pnl: Total unrealized PnL across all positions
            btc_atr_pct: BTC ATR as percentage of price
            eth_atr_pct: ETH ATR as percentage of price
            wallet_balance: Current wallet balance for dynamic threshold
            
        Returns:
            Status string for logging
        """
        self.last_total_upnl = total_unrealized_pnl
        self.should_trigger_close = False  # Reset each cycle
        now = datetime.now()
        
        # Check if in cooldown
        if self.is_in_cooldown():
            return "COOLDOWN"
        
        # ===== PHASE 1: UNDERWATER TRACKING =====
        if total_unrealized_pnl < 0:
            # Start or continue underwater tracking
            if self.underwater_start_time is None:
                self.underwater_start_time = now
                logger.info(f"üìä RECOVERY TRACKING: Total uPnL negative (${total_unrealized_pnl:.2f}), starting timer")
            
            # Check if we've been underwater long enough
            hours_underwater = (now - self.underwater_start_time).total_seconds() / 3600
            
            if hours_underwater >= self.underwater_threshold_hours and not self.is_recovery_candidate:
                self.is_recovery_candidate = True
                logger.warning(f"‚ö†Ô∏è RECOVERY CANDIDATE: {hours_underwater:.1f}h underwater, waiting for positive uPnL")
            
            # Reset trailing if we're still negative
            if self.recovery_trailing_active:
                logger.info(f"üìä RECOVERY: uPnL dropped negative again (${total_unrealized_pnl:.2f}), resetting trailing")
                self.recovery_trailing_active = False
                self.peak_positive_pnl = 0.0
            
            return f"UNDERWATER_{hours_underwater:.1f}h"
        
        # ===== PHASE 2: POSITIVE PNL CHECK =====
        # Dynamic threshold: 3% of margin balance, min $5
        dynamic_threshold = max(wallet_balance * self.min_positive_pct, 5.0)  # Min $5 floor
        if total_unrealized_pnl >= dynamic_threshold:
            
            # If we're a recovery candidate and PnL turned positive, activate trailing
            if self.is_recovery_candidate and not self.recovery_trailing_active:
                # Calculate dynamic trailing distance
                self.trailing_distance_pct = self._calculate_trailing_distance(btc_atr_pct, eth_atr_pct)
                self.recovery_trailing_active = True
                self.peak_positive_pnl = total_unrealized_pnl
                
                hours_was_underwater = (now - self.underwater_start_time).total_seconds() / 3600 if self.underwater_start_time else 0
                logger.warning(f"üîÑ RECOVERY ACTIVATED: uPnL +${total_unrealized_pnl:.2f} after {hours_was_underwater:.1f}h underwater! Trail: {self.trailing_distance_pct:.2f}%")
            
            # ===== PHASE 3: TRAILING LOGIC =====
            if self.recovery_trailing_active:
                # Update peak if higher
                if total_unrealized_pnl > self.peak_positive_pnl:
                    self.peak_positive_pnl = total_unrealized_pnl
                    logger.info(f"üìà RECOVERY PEAK: New peak +${self.peak_positive_pnl:.2f}")
                
                # Calculate pullback percentage
                # Pullback = (peak - current) / peak * 100
                if self.peak_positive_pnl > 0:
                    pullback_pct = ((self.peak_positive_pnl - total_unrealized_pnl) / self.peak_positive_pnl) * 100
                    
                    # Check if pullback exceeds trailing distance
                    if pullback_pct >= self.trailing_distance_pct:
                        logger.warning(f"üî¥ RECOVERY TRIGGER: Pullback {pullback_pct:.2f}% >= trail {self.trailing_distance_pct:.2f}% | Peak: ${self.peak_positive_pnl:.2f} ‚Üí Current: ${total_unrealized_pnl:.2f}")
                        self.should_trigger_close = True
                        return "CLOSE_TRIGGERED"
                    
                    return f"TRAILING_peak={self.peak_positive_pnl:.2f}_pullback={pullback_pct:.1f}%"
        
        # Not underwater and not in trailing - reset state
        if total_unrealized_pnl >= 0 and not self.is_recovery_candidate:
            self.underwater_start_time = None
            return "NORMAL"
        
        return "MONITORING"
    
    def _calculate_trailing_distance(self, btc_atr_pct: float, eth_atr_pct: float) -> float:
        """
        Calculate dynamic trailing distance based on BTC/ETH average ATR.
        
        Higher volatility = larger trailing distance
        Lower volatility = tighter trailing distance
        """
        avg_atr = (btc_atr_pct + eth_atr_pct) / 2
        
        # Clamp to min/max bounds
        distance = max(self.min_trailing_pct, min(self.max_trailing_pct, avg_atr))
        
        logger.info(f"üìê RECOVERY TRAIL: BTC ATR={btc_atr_pct:.2f}%, ETH ATR={eth_atr_pct:.2f}% ‚Üí Trail={distance:.2f}%")
        return distance
    
    def should_close_all(self) -> bool:
        """Check if recovery trailing has triggered a close all signal."""
        return self.should_trigger_close
    
    def start_cooldown(self):
        """Start cooldown period after recovery close."""
        self.cooldown_until = datetime.now() + timedelta(hours=self.cooldown_hours)
        self.reset_state()
        logger.info(f"‚è∏Ô∏è RECOVERY COOLDOWN: Started {self.cooldown_hours}h cooldown until {self.cooldown_until}")
    
    def is_in_cooldown(self) -> bool:
        """Check if new positions should be blocked."""
        if self.cooldown_until is None:
            return False
        return datetime.now() < self.cooldown_until
    
    def get_cooldown_remaining(self) -> float:
        """Get remaining cooldown time in hours."""
        if self.cooldown_until is None:
            return 0.0
        remaining = (self.cooldown_until - datetime.now()).total_seconds() / 3600
        return max(0.0, remaining)
    
    def reset_state(self):
        """Reset all tracking state."""
        self.underwater_start_time = None
        self.is_recovery_candidate = False
        self.recovery_trailing_active = False
        self.peak_positive_pnl = 0.0
        self.should_trigger_close = False
    
    def get_status(self) -> dict:
        """Get current status for UI/logging."""
        hours_underwater = 0.0
        if self.underwater_start_time:
            hours_underwater = (datetime.now() - self.underwater_start_time).total_seconds() / 3600
        
        return {
            "type": "PORTFOLIO_RECOVERY",
            "is_recovery_candidate": self.is_recovery_candidate,
            "trailing_active": self.recovery_trailing_active,
            "hours_underwater": round(hours_underwater, 1),
            "peak_pnl": round(self.peak_positive_pnl, 2),
            "trailing_distance_pct": round(self.trailing_distance_pct, 2),
            "cooldown_remaining_hours": round(self.get_cooldown_remaining(), 1),
            "last_upnl": round(self.last_total_upnl, 2)
        }


# Global PortfolioRecoveryManager instance
portfolio_recovery_manager = PortfolioRecoveryManager()


# ============================================================================
# PHASE XXX: BREAKEVEN STOP MANAGER
# Moves virtual stop to entry price when position reaches profit threshold
# ============================================================================

class BreakevenStopManager:
    """
    Breakeven Stop Management for LIVE Binance positions.
    
    When position reaches dynamic profit threshold (based on spread/volatility),
    activates a virtual stop at entry price. If price returns to entry, closes position.
    
    Thresholds:
    - Very Low spread (BTC/ETH): 0.5% profit ‚Üí breakeven
    - Low spread: 0.75% profit ‚Üí breakeven
    - Normal spread: 1.0% profit ‚Üí breakeven  
    - High spread: 1.5% profit ‚Üí breakeven
    - Very High spread (meme): 2.5% profit ‚Üí breakeven
    """
    
    def __init__(self):
        # Track breakeven state per position: {symbol: {active: bool, entry_price: float, activation_time: datetime}}
        self.breakeven_state = {}
        
        # Phase 182: ATR-based dynamic activation thresholds
        # Activation = max(floor, ATR_pct * atr_mult)
        # This ensures breakeven only activates after a move meaningful for that coin's volatility
        # Phase 190: Lowered activation thresholds for faster breakeven
        self.activation_config = {
            'Very Low':  {'floor': 0.5, 'atr_mult': 1.0},   # BTC: max(0.5%, ATR*1.0)
            'Low':       {'floor': 0.7, 'atr_mult': 1.2},   # SOL/AVAX
            'Normal':    {'floor': 1.0, 'atr_mult': 1.5},   # Mid-cap
            'High':      {'floor': 1.5, 'atr_mult': 2.0},   # Low liquidity
            'Very High': {'floor': 2.0, 'atr_mult': 2.5},   # Meme coins
            'Extreme':   {'floor': 3.0, 'atr_mult': 3.0},   # Hyper-volatile
            'Ultra':     {'floor': 4.0, 'atr_mult': 4.0},   # Extreme edge cases
        }
        
        # Phase 185: Fee buffer increased ‚Äî minimum 0.5% for all levels
        # Prevents partial fills on low-liquidity coins (ZKUSDT bug)
        # Limit placed further from entry ‚Üí fills completely before price reverses
        self.fee_buffers = {
            'Very Low':  0.005,   # 0.50% (was 0.05%)
            'Low':       0.005,   # 0.50% (was 0.10%)
            'Normal':    0.006,   # 0.60% (was 0.15%)
            'High':      0.008,   # 0.80% (was 0.20%)
            'Very High': 0.010,   # 1.00% (was 0.30%)
            'Extreme':   0.015,   # 1.50%
            'Ultra':     0.020,   # 2.00%
        }
        
        # Phase 190: Reduced min age from 30 to 5 minutes
        self.min_breakeven_age_minutes = 5
        
        logger.info("üìä BreakevenStopManager v2 initialized (ATR-based)")
    
    async def load_from_sqlite(self):
        """Load persisted breakeven states from SQLite on startup."""
        try:
            loaded = await sqlite_manager.load_breakeven_states()
            if loaded:
                self.breakeven_state.update(loaded)
                logger.warning(f"üîí Restored {len(loaded)} breakeven states from SQLite: {list(loaded.keys())}")
        except Exception as e:
            logger.error(f"Failed to load breakeven states: {e}")
    
    async def check_positions(self, positions: list, live_trader) -> dict:
        """
        Check all Binance positions for breakeven conditions.
        
        Args:
            positions: List of Binance positions from live_trader.get_positions()
            live_trader: LiveBinanceTrader instance for closing positions
            
        Returns:
            Summary of actions taken
        """
        actions = {
            "breakeven_activated": [],
            "breakeven_closed": [],
            "checked": 0
        }
        
        if not live_trader or not live_trader.enabled:
            return actions
        
        for pos in positions:
            try:
                symbol = pos.get('symbol', '')
                if not symbol:
                    continue
                    
                side = pos.get('side', '')
                entry_price = float(pos.get('entryPrice', 0))
                current_price = float(pos.get('currentPrice', pos.get('markPrice', 0)))
                contracts = float(pos.get('contracts', pos.get('positionAmt', 0)))
                spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                
                if entry_price <= 0 or current_price <= 0 or contracts == 0:
                    continue
                
                actions["checked"] += 1
                
                # Calculate profit percentage
                if side == 'LONG':
                    profit_pct = (current_price - entry_price) / entry_price * 100
                else:  # SHORT
                    profit_pct = (entry_price - current_price) / entry_price * 100
                
                # Phase 182: ATR-based dynamic activation threshold
                atr = float(pos.get('atr', entry_price * 0.02))  # Default 2% if no ATR
                atr_pct = (atr / entry_price) * 100 if entry_price > 0 else 2.0
                config = self.activation_config.get(spread_level, {'floor': 2.0, 'atr_mult': 2.0})
                activation_threshold = max(config['floor'], atr_pct * config['atr_mult'])
                
                # Phase 182: Minimum hold time guard (30 min)
                open_time = pos.get('openTime', 0)
                if open_time > 0:
                    age_minutes = (datetime.now().timestamp() * 1000 - open_time) / 60000
                else:
                    age_minutes = 999  # Unknown age, don't block
                
                # State key
                state_key = f"{symbol}_{side}"
                
                # Check if breakeven already activated for this position
                state = self.breakeven_state.get(state_key, {})
                
                if not state.get('active', False):
                    # Phase 221: Phase 220 zaten breakeven set ettiyse atla
                    if pos.get('breakeven_activated', False):
                        continue
                    # Not yet activated - check if we should activate
                    if age_minutes < self.min_breakeven_age_minutes:
                        # Too young ‚Äî skip breakeven (let trade develop)
                        continue
                    
                    if profit_pct >= activation_threshold:
                        # Phase 182: Calculate limit price with fee buffer
                        fee_buffer = self.fee_buffers.get(spread_level, 0.0015)
                        if side == 'LONG':
                            limit_price = entry_price * (1 + fee_buffer)
                        else:
                            limit_price = entry_price * (1 - fee_buffer)
                        
                        logger.warning(f"üîí BREAKEVEN v2: {symbol} {side} profit={profit_pct:.2f}% >= {activation_threshold:.2f}% (ATR={atr_pct:.2f}%, floor={config['floor']}%, spread={spread_level}) | Limit @ ${limit_price:.6f} (entry+{fee_buffer*100:.2f}%)")
                        
                        # Place limit close order at entry + fee buffer
                        limit_result = await live_trader.close_position_limit(
                            symbol, side, abs(contracts), limit_price
                        )
                        
                        order_id = limit_result.get('id') if limit_result else None
                        
                        self.breakeven_state[state_key] = {
                            'active': True,
                            'entry_price': entry_price,
                            'activation_price': current_price,
                            'activation_time': datetime.now(),
                            'spread_level': spread_level,
                            'order_id': order_id,  # Phase 179: Track limit order
                            'contracts': abs(contracts),
                        }
                        actions["breakeven_activated"].append(symbol)
                        
                        # Phase 154: Persist to SQLite
                        safe_create_task(sqlite_manager.save_breakeven_state(
                            state_key, symbol, side, entry_price, current_price,
                            datetime.now().isoformat(), spread_level
                        ), name=f"persist_breakeven_{symbol}")
                        
                        if not limit_result:
                            logger.error(f"‚ùå BREAKEVEN LIMIT ORDER FAILED: {symbol} - will retry next cycle")
                else:
                    # Phase 179: Breakeven active ‚Äî monitor limit order status
                    order_id = state.get('order_id')
                    
                    if order_id:
                        # Check if limit order has been filled
                        order_status = await live_trader.check_order_status(symbol, order_id)
                        status = order_status.get('status', 'unknown')
                        
                        if status == 'closed':
                            # Phase 185: Check for partial fills!
                            filled_amount = order_status.get('filled', 0)
                            remaining_amount = order_status.get('remaining', 0)
                            fill_price = order_status.get('average', entry_price)
                            total_contracts = state.get('contracts', abs(contracts))
                            
                            # If remaining > 0, limit only partially filled ‚Üí market close the rest
                            if remaining_amount > 0 and remaining_amount > total_contracts * 0.01:
                                logger.warning(f"‚ö†Ô∏è BREAKEVEN PARTIAL FILL: {symbol} filled={filled_amount:.4f} remaining={remaining_amount:.4f} ‚Üí market closing remainder")
                                try:
                                    market_result = await live_trader.close_position(symbol, side, remaining_amount)
                                    if market_result:
                                        close_oid = str(market_result.get('id', ''))
                                        logger.warning(f"‚úÖ BREAKEVEN REMAINDER CLOSED: {symbol} {remaining_amount:.4f} contracts via market | Order: {close_oid[:12]}")
                                        # Phase 229b: Persist close order ID
                                        if close_oid:
                                            safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                    else:
                                        logger.error(f"‚ùå BREAKEVEN REMAINDER FAILED: {symbol} ‚Äî orphaned {remaining_amount:.4f} contracts!")
                                except Exception as mkt_err:
                                    logger.error(f"‚ùå BREAKEVEN MARKET FALLBACK ERROR: {symbol} ‚Äî {mkt_err}")
                            
                            # Limit order filled (fully or partially)! Record breakeven
                            # Phase 229b: Persist limit order ID for trade matching
                            if order_id:
                                safe_create_task(sqlite_manager.update_close_order_id(symbol, str(order_id)))
                            
                            # Calculate real PnL
                            if side == 'LONG':
                                real_pnl = (fill_price - entry_price) * state.get('contracts', 0)
                            else:
                                real_pnl = (entry_price - fill_price) * state.get('contracts', 0)
                            
                            logger.warning(f"‚úÖ BREAKEVEN LIMIT FILLED: {symbol} {side} @ ${fill_price} | PnL: ${real_pnl:.4f}")
                            
                            # Record trade with real data
                            # Phase 181: Include full trade_data so Binance sync records correctly
                            size_usd = pos.get('sizeUsd', 0)
                            leverage_val = pos.get('leverage', 10)
                            margin_val = size_usd / leverage_val if leverage_val > 0 and size_usd > 0 else 0
                            roi_val = (real_pnl / margin_val * 100) if margin_val > 0 else 0
                            
                            pending_close_reasons[symbol] = {
                                "reason": f"BREAKEVEN_CLOSE: {spread_level} spread, limit filled @ ${fill_price}",
                                "original_reason": "BREAKEVEN_CLOSE",
                                "pnl": round(real_pnl, 4),
                                "exitPrice": fill_price,
                                "timestamp": int(datetime.now().timestamp() * 1000),
                                "trade_data": {
                                    "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                                    "symbol": symbol,
                                    "side": side,
                                    "entryPrice": entry_price,
                                    "exitPrice": fill_price,
                                    "size": abs(state.get('contracts', 0)),
                                    "sizeUsd": size_usd,
                                    "pnl": round(real_pnl, 4),
                                    "pnlPercent": roi_val,
                                    "margin": round(margin_val, 4),
                                    "roi": round(roi_val, 2),
                                    "openTime": pos.get('openTime', 0),
                                    "leverage": leverage_val,
                                    "isLive": True,
                                    "closeReason": "BREAKEVEN_CLOSE",  # Phase 232c: dual field
                                }
                            }
                            safe_create_task(sqlite_manager.save_position_close({
                                'symbol': symbol,
                                'side': side,
                                'reason': f"BREAKEVEN_CLOSE: {spread_level} spread, limit filled @ ${fill_price}",
                                'original_reason': 'BREAKEVEN_CLOSE',
                                'entryPrice': entry_price,
                                'exitPrice': fill_price,
                                'pnl': round(real_pnl, 4),
                                'leverage': pos.get('leverage', 10),
                                'sizeUsd': pos.get('sizeUsd', 0),
                                'margin': round(margin_val, 4),
                                'roi': round(roi_val, 2),
                                'timestamp': int(datetime.now().timestamp() * 1000)
                            }), name=f"persist_breakeven_{symbol}")
                            
                            actions["breakeven_closed"].append(symbol)
                            del self.breakeven_state[state_key]
                            safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                            
                        elif status == 'canceled':
                            # Order was cancelled externally ‚Äî clean up
                            logger.warning(f"‚ö†Ô∏è BREAKEVEN ORDER CANCELLED: {symbol} - clearing state")
                            del self.breakeven_state[state_key]
                            safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                            
                        elif status == 'error':
                            # Could not check ‚Äî retry next cycle
                            logger.debug(f"‚è≥ BREAKEVEN ORDER CHECK FAILED: {symbol} #{order_id} - will retry")
                            
                        # else: status == 'open' ‚Äî still waiting, do nothing
                        
                    else:
                        # No order ID ‚Äî retry placing limit order
                        logger.warning(f"üîÑ BREAKEVEN RETRY: {symbol} - no order ID, placing limit order")
                        limit_result = await live_trader.close_position_limit(
                            symbol, side, abs(contracts), entry_price
                        )
                        if limit_result:
                            state['order_id'] = limit_result.get('id')
                    
                    # Safety: if position no longer exists on Binance, cancel order & clean up
                    if contracts == 0 and order_id:
                        logger.warning(f"üßπ BREAKEVEN CLEANUP: {symbol} - position gone, cancelling order")
                        await live_trader.cancel_order(symbol, order_id)
                        if state_key in self.breakeven_state:
                            del self.breakeven_state[state_key]
                        safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                
            except Exception as e:
                logger.warning(f"Breakeven check error for position: {e}")
        
        return actions
    
    def get_status(self) -> dict:
        """Get current breakeven status for UI."""
        return {
            "type": "BREAKEVEN_STOP",
            "active_breakevens": len([s for s in self.breakeven_state.values() if s.get('active')]),
            "positions_tracked": list(self.breakeven_state.keys())
        }


# Global BreakevenStopManager instance
breakeven_stop_manager = BreakevenStopManager()


# ============================================================================
# PHASE XXX: LOSS RECOVERY TRAIL MANAGER  
# Trails from loss recovery - when position recovers from deep loss, trail to lock in recovery
# ============================================================================

class LossRecoveryTrailManager:
    """
    Loss Recovery Trailing for LIVE Binance positions.
    
    When position is in deep loss but starts recovering, activates trailing to lock in recovery.
    
    Logic:
    1. Position must be in significant loss (> threshold based on spread)
    2. Position must recover at least 30% of the loss
    3. Activate trailing - if gives back 50% of recovery, close
    
    Dynamic thresholds based on spread:
    - Very Low spread: -3% loss triggers, trail after -2% recovery
    - Low spread: -4% loss triggers
    - Normal spread: -5% loss triggers  
    - High spread: -7% loss triggers
    - Very High spread: -10% loss triggers
    """
    
    def __init__(self):
        # Track recovery state: {symbol: {peak_loss: float, peak_recovery: float, trail_active: bool}}
        self.recovery_state = {}
        
        # Spread-based loss thresholds (how deep loss before recovery tracking)
        self.loss_thresholds = {
            'Very Low': -3.0,   # BTC/ETH
            'Low': -4.0,
            'Normal': -5.0,
            'High': -7.0,
            'Very High': -10.0, # Meme coins - need more room
            'Extreme': -15.0,   # Hyper-volatile
            'Ultra': -20.0      # Extreme edge cases
        }
        
        # Recovery percentages
        self.recovery_activation_pct = 0.30  # Must recover 30% of loss to activate trail
        self.trail_giveback_pct = 0.50       # Close if gives back 50% of recovery
        
        logger.info("üìä LossRecoveryTrailManager initialized")
    
    async def check_positions(self, positions: list, live_trader) -> dict:
        """
        Check all Binance positions for loss recovery conditions.
        
        Args:
            positions: List of Binance positions from live_trader.get_positions()
            live_trader: LiveBinanceTrader instance for closing positions
            
        Returns:
            Summary of actions taken
        """
        actions = {
            "recovery_tracking": [],
            "recovery_trail_activated": [],
            "recovery_closed": [],
            "checked": 0
        }
        
        if not live_trader or not live_trader.enabled:
            return actions
        
        for pos in positions:
            try:
                symbol = pos.get('symbol', '')
                if not symbol:
                    continue
                    
                side = pos.get('side', '')
                entry_price = float(pos.get('entryPrice', 0))
                current_price = float(pos.get('currentPrice', pos.get('markPrice', 0)))
                contracts = float(pos.get('contracts', pos.get('positionAmt', 0)))
                spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                
                if entry_price <= 0 or current_price <= 0 or contracts == 0:
                    continue
                
                actions["checked"] += 1
                
                # Calculate profit percentage (negative = loss)
                if side == 'LONG':
                    pnl_pct = (current_price - entry_price) / entry_price * 100
                else:  # SHORT
                    pnl_pct = (entry_price - current_price) / entry_price * 100
                
                # Get dynamic loss threshold based on spread level
                loss_threshold = self.loss_thresholds.get(spread_level, -5.0)
                
                # State key
                state_key = f"{symbol}_{side}"
                state = self.recovery_state.get(state_key, {})
                
                # === PHASE 1: Track peak loss ===
                if pnl_pct < loss_threshold:
                    # Position is in deep loss - start tracking
                    peak_loss = min(state.get('peak_loss', 0), pnl_pct)
                    self.recovery_state[state_key] = {
                        'peak_loss': peak_loss,
                        'peak_recovery': pnl_pct,  # Will be updated if recovers
                        'trail_active': False,
                        'spread_level': spread_level
                    }
                    if state_key not in [a for a in actions["recovery_tracking"]]:
                        actions["recovery_tracking"].append(symbol)
                
                # === PHASE 2: Track recovery and activate trail ===
                elif state.get('peak_loss', 0) < loss_threshold:
                    peak_loss = state['peak_loss']
                    
                    # How much have we recovered?
                    recovery_amount = pnl_pct - peak_loss  # Always positive if recovering
                    total_loss_amount = abs(peak_loss)
                    recovery_ratio = recovery_amount / total_loss_amount if total_loss_amount > 0 else 0
                    
                    # Update peak recovery if higher
                    peak_recovery = max(state.get('peak_recovery', peak_loss), pnl_pct)
                    state['peak_recovery'] = peak_recovery
                    
                    if not state.get('trail_active', False):
                        # Check if we should activate trail
                        if recovery_ratio >= self.recovery_activation_pct:
                            state['trail_active'] = True
                            state['trail_activation_pnl'] = pnl_pct
                            self.recovery_state[state_key] = state
                            actions["recovery_trail_activated"].append(symbol)
                            logger.warning(f"üîÑ RECOVERY TRAIL ACTIVATED: {symbol} {side} peak_loss={peak_loss:.2f}% current={pnl_pct:.2f}% recovered={recovery_ratio*100:.0f}%")
                    else:
                        # Trail is active - check if giving back too much
                        peak_recovery_pnl = state['peak_recovery']
                        recovery_from_peak = peak_recovery_pnl - peak_loss
                        current_recovery = pnl_pct - peak_loss
                        
                        giveback_ratio = 1 - (current_recovery / recovery_from_peak) if recovery_from_peak > 0 else 0
                        
                        if giveback_ratio >= self.trail_giveback_pct:
                            # Gave back too much - CLOSE!
                            logger.warning(f"üîÑ RECOVERY TRAIL CLOSE: {symbol} {side} - gave back {giveback_ratio*100:.0f}% of recovery")
                            try:
                                # Phase 181: Set reason with full trade_data for trade history
                                size_usd = pos.get('sizeUsd', 0)
                                leverage_val = pos.get('leverage', 10)
                                margin_val = size_usd / leverage_val if leverage_val > 0 and size_usd > 0 else 0
                                
                                # Calculate actual PnL from prices
                                if side == 'LONG':
                                    actual_pnl = (current_price - entry_price) * abs(contracts)
                                else:
                                    actual_pnl = (entry_price - current_price) * abs(contracts)
                                roi_val = (actual_pnl / margin_val * 100) if margin_val > 0 else 0
                                
                                pending_close_reasons[symbol] = {
                                    "reason": f"RECOVERY_TRAIL_CLOSE: peak_loss={peak_loss:.1f}%, recovered to {peak_recovery_pnl:.1f}%, gave back {giveback_ratio*100:.0f}%",
                                    "original_reason": "RECOVERY_TRAIL_CLOSE",
                                    "pnl": round(actual_pnl, 4),
                                    "exitPrice": current_price,
                                    "timestamp": int(datetime.now().timestamp() * 1000),
                                    "trade_data": {
                                        "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                                        "symbol": symbol,
                                        "side": side,
                                        "entryPrice": entry_price,
                                        "exitPrice": current_price,
                                        "size": abs(contracts),
                                        "sizeUsd": size_usd,
                                        "pnl": round(actual_pnl, 4),
                                        "pnlPercent": round(roi_val, 2),
                                        "margin": round(margin_val, 4),
                                        "roi": round(roi_val, 2),
                                        "openTime": pos.get('openTime', 0),
                                        "leverage": leverage_val,
                                        "isLive": True,
                                        "closeReason": "RECOVERY_TRAIL_CLOSE",  # Phase 232c: dual field
                                    }
                                }
                                # Persist to SQLite so data survives restart
                                safe_create_task(sqlite_manager.save_position_close({
                                    'symbol': symbol,
                                    'side': side,
                                    'reason': f"RECOVERY_TRAIL_CLOSE: peak_loss={peak_loss:.1f}%, recovered to {peak_recovery_pnl:.1f}%, gave back {giveback_ratio*100:.0f}%",
                                    'original_reason': 'RECOVERY_TRAIL_CLOSE',
                                    'entryPrice': entry_price,
                                    'exitPrice': current_price,
                                    'pnl': round(actual_pnl, 4),
                                    'leverage': pos.get('leverage', 10),
                                    'sizeUsd': pos.get('sizeUsd', 0),
                                    'margin': round(margin_val, 4),
                                    'roi': round(roi_val, 2),
                                    'timestamp': int(datetime.now().timestamp() * 1000)
                                }), name=f"persist_recovery_{symbol}")
                                result = await live_trader.close_position(symbol, side, abs(contracts))
                                if result:
                                    close_oid = str(result.get('id', ''))
                                    actions["recovery_closed"].append(symbol)
                                    # Clear state
                                    del self.recovery_state[state_key]
                                    logger.warning(f"‚úÖ RECOVERY CLOSE SUCCESS: {symbol} | Order: {close_oid[:12]}")
                                    # Phase 229b: Persist close order ID
                                    if close_oid:
                                        safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                else:
                                    logger.error(f"‚ùå RECOVERY CLOSE FAILED: {symbol}")
                            except Exception as e:
                                logger.error(f"‚ùå RECOVERY CLOSE ERROR: {symbol} - {e}")
                        
                        self.recovery_state[state_key] = state
                
                # === PHASE 3: Clear state if position turned profitable ===
                elif pnl_pct > 0 and state_key in self.recovery_state:
                    # Position is now profitable - clear recovery state
                    del self.recovery_state[state_key]
                    logger.info(f"üìà RECOVERY CLEARED: {symbol} now profitable at {pnl_pct:.2f}%")
                
            except Exception as e:
                logger.warning(f"Recovery trail check error for position: {e}")
        
        return actions
    
    def get_status(self) -> dict:
        """Get current recovery trail status for UI."""
        return {
            "type": "LOSS_RECOVERY_TRAIL",
            "tracking_count": len(self.recovery_state),
            "trail_active_count": len([s for s in self.recovery_state.values() if s.get('trail_active')]),
            "positions_tracked": list(self.recovery_state.keys())
        }


# Global LossRecoveryTrailManager instance
loss_recovery_trail_manager = LossRecoveryTrailManager()


# ============================================================================
# PHASE 50: DOUBLE TREND CONFIRMATION
# ============================================================================

class DoubleTrendConfirmation:
    """
    Pending order doldurulmadan √∂nce trendin hala ge√ßerli olduƒüunu onaylar.
    V-Reversal korumasƒ± saƒülar.
    
    S√ºre√ß:
    1. Pending order olu≈üturulur (sinyal geldiƒüinde)
    2. Fiyat pullback seviyesine ula≈üƒ±r
    3. [BU SINIF] ƒ∞kinci trend onayƒ± yapƒ±lƒ±r:
       - Fiyat hala sinyal y√∂n√ºnde mi?
       - Z-Score hala threshold √ºst√ºnde mi?
       - BTC hala aynƒ± y√∂nde mi?
    4. Onay ge√ßerse order doldurulur, deƒüilse iptal edilir
    """
    
    def __init__(self, confirmation_delay_seconds: int = 300):  # 5 dakika
        self.confirmation_delay = confirmation_delay_seconds
        self.pending_confirmations = {}  # order_id -> {signal_data, price_at_signal, timestamp}
        logger.info(f"üîÑ DoubleTrendConfirmation initialized: {confirmation_delay_seconds}s delay")
    
    def register_pending_order(self, order_id: str, signal: dict, price_at_signal: float):
        """Pending order olu≈üturulduƒüunda kaydet."""
        self.pending_confirmations[order_id] = {
            'signal': signal,
            'price_at_signal': price_at_signal,
            'timestamp': datetime.now().timestamp(),
            'side': signal.get('side', 'LONG'),
            'zscore': signal.get('zscore', 0),
            'symbol': signal.get('symbol', '')
        }
        logger.info(f"üîÑ Registered for double confirmation: {signal.get('symbol')} {signal.get('side')}")
    
    def check_confirmation(self, order_id: str, current_price: float, current_zscore: float, 
                          btc_trend: str = None) -> dict:
        """
        Pending order dolmadan √∂nce trendin hala ge√ßerli olduƒüunu kontrol et.
        
        Returns:
            {
                'confirmed': bool,
                'reason': str,
                'checks': {price: bool, zscore: bool, btc: bool}
            }
        """
        if order_id not in self.pending_confirmations:
            # Kayƒ±t yok, onay gerekmiyor (eski sistemle uyumluluk)
            return {'confirmed': True, 'reason': 'No confirmation needed', 'checks': {}}
        
        data = self.pending_confirmations[order_id]
        side = data['side']
        signal_price = data['price_at_signal']
        signal_zscore = data['zscore']
        symbol = data['symbol']
        
        checks = {
            'price_direction': False,
            'zscore_valid': False,
            'btc_aligned': True  # Default True if no BTC check
        }
        
        # CHECK 1: Fiyat hala sinyal y√∂n√ºnde mi?
        if side == 'LONG':
            # LONG i√ßin: fiyat d√º≈ümemeli (pullback sonrasƒ± y√ºkseliyor olmalƒ±)
            price_ok = current_price >= signal_price * 0.995  # %0.5 tolerans
            checks['price_direction'] = price_ok
        else:
            # SHORT i√ßin: fiyat y√ºkselmemeli (pullback sonrasƒ± d√º≈ü√ºyor olmalƒ±)
            price_ok = current_price <= signal_price * 1.005  # %0.5 tolerans
            checks['price_direction'] = price_ok
        
        # CHECK 2: Z-Score hala threshold √ºst√ºnde mi?
        zscore_threshold = 0.8  # Daha d√º≈ü√ºk threshold (relaxed)
        if side == 'LONG':
            zscore_ok = current_zscore < -zscore_threshold  # Negative for oversold
        else:
            zscore_ok = current_zscore > zscore_threshold  # Positive for overbought
        checks['zscore_valid'] = zscore_ok
        
        # CHECK 3: BTC trend hala uyumlu mu?
        if btc_trend:
            if side == 'LONG':
                btc_ok = btc_trend in ['BULLISH', 'NEUTRAL']
            else:
                btc_ok = btc_trend in ['BEARISH', 'NEUTRAL']
            checks['btc_aligned'] = btc_ok
        
        # T√ºm kontroller ge√ßti mi?
        all_passed = all(checks.values())
        
        if all_passed:
            # Kayƒ±t temizle
            del self.pending_confirmations[order_id]
            return {
                'confirmed': True,
                'reason': 'All checks passed',
                'checks': checks
            }
        else:
            # Hangi kontroller ba≈üarƒ±sƒ±z?
            failed = [k for k, v in checks.items() if not v]
            logger.warning(f"üö´ Double confirmation FAILED for {symbol} {side}: {failed}")
            # Kayƒ±t temizle
            del self.pending_confirmations[order_id]
            return {
                'confirmed': False,
                'reason': f"Failed: {', '.join(failed)}",
                'checks': checks
            }
    
    def cleanup_expired(self, max_age_seconds: int = 1800):
        """30 dakikadan eski kayƒ±tlarƒ± temizle."""
        now = datetime.now().timestamp()
        expired = [k for k, v in self.pending_confirmations.items() 
                   if now - v['timestamp'] > max_age_seconds]
        for k in expired:
            del self.pending_confirmations[k]
    
    def get_status(self) -> dict:
        """Get current status for UI."""
        return {
            "type": "DOUBLE_CONFIRMATION",
            "pending_count": len(self.pending_confirmations),
            "delay_seconds": self.confirmation_delay
        }


# Global DoubleTrendConfirmation instance
double_trend_confirmation = DoubleTrendConfirmation()


# ============================================================================
# PHASE 52: ADAPTIVE TRADING SYSTEM - POST-TRADE TRACKER
# ============================================================================

class PostTradeTracker:
    """
    Kapatƒ±lan trade'leri 24 saat takip eder.
    Erken/ge√ß √ßƒ±kƒ±≈ü analizi yaparak optimizasyona veri saƒülar.
    """
    
    def __init__(self, tracking_hours: int = 24):
        self.tracking_hours = tracking_hours
        self.tracking = {}  # {trade_id: tracking_data}
        self.analysis_results = []  # Tamamlanan analizler
        self.max_results = 200  # Son 200 analiz sakla
        logger.info(f"üìä PostTradeTracker initialized: {tracking_hours}h tracking")
    
    def start_tracking(self, closed_trade: dict):
        """Trade kapandƒ±ƒüƒ±nda takibe al."""
        trade_id = closed_trade.get('id', str(datetime.now().timestamp()))
        
        self.tracking[trade_id] = {
            'trade': closed_trade,
            'symbol': closed_trade.get('symbol', ''),
            'side': closed_trade.get('side', ''),
            'exit_price': closed_trade.get('exitPrice', 0),
            'exit_time': datetime.now(),
            'pnl': closed_trade.get('pnl', 0),
            'reason': closed_trade.get('reason', closed_trade.get('closeReason', '')),
            'max_price_after': closed_trade.get('exitPrice', 0),
            'min_price_after': closed_trade.get('exitPrice', 0),
            'price_samples': 0,
        }
        logger.debug(f"üìä POST-TRADE: Started tracking {closed_trade.get('symbol')} ({closed_trade.get('side')})")
    
    def update_prices(self, current_prices: dict):
        """Fiyatlarƒ± g√ºncelle - her 15 dakikada √ßaƒürƒ±lmalƒ±."""
        now = datetime.now()
        completed = []
        
        for trade_id, data in list(self.tracking.items()):
            symbol = data['symbol']
            current_price = current_prices.get(symbol, 0)
            
            if current_price > 0:
                data['price_samples'] += 1
                data['max_price_after'] = max(data['max_price_after'], current_price)
                data['min_price_after'] = min(data['min_price_after'], current_price)
            
            # 24 saat doldu mu?
            hours_passed = (now - data['exit_time']).total_seconds() / 3600
            if hours_passed >= self.tracking_hours:
                result = self._finalize_analysis(trade_id, data)
                completed.append(result)
        
        return completed
    
    def _finalize_analysis(self, trade_id: str, data: dict) -> dict:
        """24 saat sonunda sonu√ßlarƒ± hesapla."""
        self.tracking.pop(trade_id, None)
        
        side = data['side']
        exit_price = data['exit_price']
        
        if exit_price <= 0:
            return {}
        
        if side == 'LONG':
            # LONG i√ßin: √áƒ±kƒ±≈ütan sonra fiyat ne kadar y√ºkseldi?
            best_price = data['max_price_after']
            missed_profit_pct = (best_price - exit_price) / exit_price * 100
            worst_price = data['min_price_after']
            avoided_loss_pct = (exit_price - worst_price) / exit_price * 100
        else:
            # SHORT i√ßin: √áƒ±kƒ±≈ütan sonra fiyat ne kadar d√º≈üt√º?
            best_price = data['min_price_after']
            missed_profit_pct = (exit_price - best_price) / exit_price * 100
            worst_price = data['max_price_after']
            avoided_loss_pct = (worst_price - exit_price) / exit_price * 100
        
        was_early = missed_profit_pct > 2  # %2'den fazla ka√ßƒ±rƒ±ldƒ± mƒ±?
        was_correct = avoided_loss_pct > 1  # %1'den fazla zarar √∂nlendi mi?
        
        result = {
            'trade_id': trade_id,
            'symbol': data['symbol'],
            'side': side,
            'exit_price': exit_price,
            'best_price_24h': best_price,
            'worst_price_24h': worst_price,
            'missed_profit_pct': round(missed_profit_pct, 2),
            'avoided_loss_pct': round(avoided_loss_pct, 2),
            'was_early_exit': was_early,
            'was_correct_exit': was_correct,
            'actual_pnl': data['pnl'],
            'close_reason': data['reason'],
            'analysis_time': datetime.now().isoformat()
        }
        
        self.analysis_results.append(result)
        # Eski sonu√ßlarƒ± temizle
        if len(self.analysis_results) > self.max_results:
            self.analysis_results = self.analysis_results[-self.max_results:]
        
        status = 'üî¥ ERKEN' if was_early else ('üü¢ DOƒûRU' if was_correct else 'üü° N√ñTR')
        logger.info(f"üìä POST-TRADE COMPLETE: {data['symbol']} {side} - {status} | Ka√ßƒ±rƒ±lan: %{missed_profit_pct:.1f} | √ñnlenen: %{avoided_loss_pct:.1f}")
        
        return result
    
    def get_early_exit_rate(self, recent_count: int = 50) -> float:
        """Son N analizde erken √ßƒ±kƒ±≈ü oranƒ±."""
        recent = self.analysis_results[-recent_count:]
        if not recent:
            return 0.0
        early_count = sum(1 for r in recent if r.get('was_early_exit', False))
        return early_count / len(recent) * 100
    
    def get_stats(self) -> dict:
        """√ñzet istatistikler."""
        recent = self.analysis_results[-50:]
        return {
            'tracking_count': len(self.tracking),
            'completed_count': len(self.analysis_results),
            'early_exit_rate': self.get_early_exit_rate(),
            'avg_missed_profit': sum(r.get('missed_profit_pct', 0) for r in recent) / len(recent) if recent else 0,
            'avg_avoided_loss': sum(r.get('avoided_loss_pct', 0) for r in recent) / len(recent) if recent else 0,
        }

    # Phase 224C3: Exit parameter tuning recommendations
    def get_tuning_recommendations(self) -> dict:
        """Son 50 analiz sonucundan exit parametre √∂nerileri √ºret."""
        recent = self.analysis_results[-50:]
        if len(recent) < 20:
            return {}
        
        early_exits = [r for r in recent if r.get('was_early_exit', False)]
        correct_exits = [r for r in recent if r.get('was_correct_exit', False)]
        
        recommendations = {}
        
        early_pct = len(early_exits) / len(recent)
        correct_pct = len(correct_exits) / len(recent)
        
        # %60+ erken √ßƒ±kƒ±≈ü ‚Üí trail distance artƒ±r
        if early_pct > 0.6:
            recommendations['trail_distance_mult'] = 1.1
            recommendations['reason_trail'] = f'Erken √ßƒ±kƒ±≈ü oranƒ± y√ºksek: %{early_pct*100:.0f}'
        elif early_pct < 0.2:
            recommendations['trail_distance_mult'] = 0.95
            recommendations['reason_trail'] = f'Erken √ßƒ±kƒ±≈ü oranƒ± d√º≈ü√ºk: %{early_pct*100:.0f}'
        
        # %40+ doƒüru √ßƒ±kƒ±≈ü ‚Üí TP'leri sƒ±kƒ±la≈ütƒ±r (iyi √ßalƒ±≈üƒ±yor)
        # %20- doƒüru √ßƒ±kƒ±≈ü ‚Üí TP'leri gev≈üet (√ßok erken kapanƒ±yor)
        if correct_pct < 0.20:
            recommendations['tp_mult'] = 1.1
            recommendations['reason_tp'] = f'Doƒüru √ßƒ±kƒ±≈ü oranƒ± d√º≈ü√ºk: %{correct_pct*100:.0f}'
        elif correct_pct > 0.5:
            recommendations['tp_mult'] = 0.9
            recommendations['reason_tp'] = f'Doƒüru √ßƒ±kƒ±≈ü oranƒ± y√ºksek: %{correct_pct*100:.0f}'
        
        if recommendations:
            logger.info(f"üìä TUNING_REC: {recommendations}")
        
        return recommendations


# ============================================================================
# PHASE 224C: EXIT ARBITRATOR
# Central coordinator for exit decisions ‚Äî logs, prioritizes, recommends
# ============================================================================

class ExitArbitrator:
    """
    Phase 224C: T√ºm exit kararlarƒ±nƒ± merkezi bir yerde koordine eder.
    
    Mevcut update() loop'undaki exit sƒ±rasƒ±nƒ± DEƒûƒ∞≈ûTƒ∞RMEZ,
    ancak her √ßƒ±kƒ±≈ü kararƒ±nƒ± loglar ve analiz saƒülar.
    Priority: EMERGENCY > KILL_SWITCH > ADVERSE > TIME > SL > TRAIL > TP > BREAKEVEN
    """
    
    PRIORITY = {
        'EMERGENCY_SL': 1,
        'KILL_SWITCH': 2,
        'ADVERSE': 3,
        'TIME': 4,
        'SL_HIT': 5,
        'TRAIL_EXIT': 6,
        'TP_HIT': 7,
        'BREAKEVEN': 8,
        'LOSS_RECOVERY': 9,
        'PARTIAL_TP': 10,
    }
    
    def __init__(self):
        self.exit_stats = {}  # {reason: {count, total_pnl, avg_roi}}
        self.recent_exits = deque(maxlen=200)  # Son 200 √ßƒ±kƒ±≈ü
        logger.info("‚öñÔ∏è ExitArbitrator initialized")
    
    def record_exit(self, symbol: str, reason: str, roi: float, pnl: float, decision_trace: list = None):
        """√áƒ±kƒ±≈ü kararƒ±nƒ± kaydet ve analiz et."""
        if reason not in self.exit_stats:
            self.exit_stats[reason] = {'count': 0, 'total_pnl': 0.0, 'total_roi': 0.0}
        
        self.exit_stats[reason]['count'] += 1
        self.exit_stats[reason]['total_pnl'] += pnl
        self.exit_stats[reason]['total_roi'] += roi
        
        exit_record = {
            'symbol': symbol,
            'reason': reason,
            'roi': round(roi, 2),
            'pnl': round(pnl, 4),
            'time': datetime.now().isoformat(),
            'trace_len': len(decision_trace) if decision_trace else 0,
            'priority': self.PRIORITY.get(reason, 99),
        }
        self.recent_exits.append(exit_record)
    
    def get_stats(self) -> dict:
        """√áƒ±kƒ±≈ü istatistikleri ‚Äî hangi manager en √ßok/en az k√¢rlƒ±."""
        result = {}
        for reason, stats in self.exit_stats.items():
            count = stats['count']
            result[reason] = {
                'count': count,
                'avg_pnl': round(stats['total_pnl'] / max(1, count), 4),
                'avg_roi': round(stats['total_roi'] / max(1, count), 2),
                'total_pnl': round(stats['total_pnl'], 4),
            }
        return result
    
    def get_worst_exit_reasons(self, n: int = 3) -> list:
        """En k√∂t√º performans g√∂steren exit reason'lar."""
        stats = self.get_stats()
        sorted_reasons = sorted(stats.items(), key=lambda x: x[1]['avg_pnl'])
        return sorted_reasons[:n]

# Global instance
exit_arbitrator = ExitArbitrator()


# ============================================================================
# PHASE 224D: MARKET REGIME MANAGER
# VOLATILE / QUIET / TRENDING regime detection + parameter profiles
# ============================================================================

# Regime-based parameter profiles
REGIME_PROFILES = {
    'VOLATILE': {
        'min_score_offset': 10,      # Daha se√ßici
        'trail_distance_mult': 1.3,  # Daha geni≈ü trail
        'tp_mult': 1.2,              # Daha geni≈ü TP
        'sl_mult': 1.2,              # Daha geni≈ü SL
        'confirmation_mult': 0.5,    # Daha kƒ±sa bekleme (hƒ±zlƒ± hareket)
    },
    'QUIET': {
        'min_score_offset': -5,      # Daha agresif
        'trail_distance_mult': 0.8,  # Daha sƒ±kƒ± trail
        'tp_mult': 0.8,
        'sl_mult': 0.9,
        'confirmation_mult': 1.5,    # Daha uzun bekleme
    },
    'TRENDING': {
        'min_score_offset': -10,     # Trend'e g√ºven
        'trail_distance_mult': 1.0,
        'tp_mult': 1.5,              # Trend'de TP uzak
        'sl_mult': 0.8,              # Trend'de SL sƒ±kƒ±
        'confirmation_mult': 0.7,    # Trend'de hƒ±zlƒ± entry
    }
}

class MarketRegimeManager:
    """
    Phase 224D: BTC volatilite ve trend'den rejim tespit et.
    Rejime g√∂re parametreleri ayarla.
    """
    
    def __init__(self):
        self.current_regime = 'QUIET'
        self.regime_history = deque(maxlen=100)
        self._last_update = 0
        logger.info("üé≠ MarketRegimeManager initialized")
    
    def detect_regime(self) -> str:
        """BTC volatilite ve trend'den rejim tespit et."""
        try:
            btc_atr_pct = 2.0
            btc_trend = 'neutral'
            
            # Read from btc_filter (BTCCorrelationFilter global instance)
            if 'btc_filter' in globals() and btc_filter:
                btc_trend_raw = getattr(btc_filter, 'btc_trend', 'NEUTRAL')
                # Map BTCCorrelationFilter trend strings to regime format
                if btc_trend_raw in ('BULLISH', 'STRONG_BULLISH'):
                    btc_trend = 'bullish'
                elif btc_trend_raw in ('BEARISH', 'STRONG_BEARISH'):
                    btc_trend = 'bearish'
                else:
                    btc_trend = 'neutral'
                # ATR estimate from 30m + 1h momentum
                btc_1h_change = abs(getattr(btc_filter, 'btc_change_1h', 0))
                btc_4h_change = abs(getattr(btc_filter, 'btc_change_4h', 0))
                btc_atr_pct = max(btc_1h_change, btc_4h_change / 2, 1.0)
            
            if btc_atr_pct > 4.0:
                regime = 'VOLATILE'
            elif btc_trend in ('bullish', 'bearish') and btc_atr_pct < 3.0:
                regime = 'TRENDING'
            else:
                regime = 'QUIET'
            
            if regime != self.current_regime:
                logger.info(f"üé≠ REGIME_CHANGE: {self.current_regime} ‚Üí {regime} (BTC ATR={btc_atr_pct:.1f}%, trend={btc_trend})")
                self.current_regime = regime
            
            self.regime_history.append({
                'regime': regime,
                'time': datetime.now().isoformat(),
                'btc_atr_pct': btc_atr_pct,
                'btc_trend': btc_trend,
            })
            
            return regime
        except Exception as e:
            logger.debug(f"Regime detection error: {e}")
            return self.current_regime
    
    def get_profile(self) -> dict:
        """Mevcut rejime ait parametre profili."""
        return REGIME_PROFILES.get(self.current_regime, REGIME_PROFILES['QUIET'])
    
    def get_adjusted_min_score(self, base_score: int) -> int:
        """Rejime g√∂re ayarlanmƒ±≈ü minimum skor."""
        profile = self.get_profile()
        return base_score + profile.get('min_score_offset', 0)

# Global instance
market_regime_manager = MarketRegimeManager()


# ============================================================================
# PHASE 224D3: CANARY MODE - A/B Test Infrastructure
# Test new parameters on ~10% of positions
# ============================================================================

class CanaryMode:
    """
    Yeni parametre setini rastgele %10 pozisyonda dene.
    Deterministik: pozisyon ID hash'ine g√∂re.
    """
    
    def __init__(self, canary_pct: float = 0.10):
        self.canary_pct = canary_pct
        self.canary_params = {}      # Deneysel parametreler {key: value}
        self.canary_results = []     # Canary pozisyon PnL'leri
        self.control_results = []    # Normal pozisyon PnL'leri
        self.enabled = False         # Ba≈ülangƒ±√ßta kapalƒ±
        logger.info(f"üê§ CanaryMode initialized (pct={canary_pct*100:.0f}%)")
    
    def should_use_canary(self, pos_id: str) -> bool:
        """Deterministik: pos_id hash'inin son 2 hanesi < canary_pct * 100."""
        if not self.enabled or not self.canary_params:
            return False
        import hashlib
        h = int(hashlib.md5(pos_id.encode()).hexdigest(), 16)
        return (h % 100) < int(self.canary_pct * 100)
    
    def get_params(self, pos_id: str, base_params: dict) -> dict:
        """Base params + canary overrides."""
        if not self.should_use_canary(pos_id):
            return base_params
        merged = {**base_params, **self.canary_params}
        return merged
    
    def record_result(self, pos_id: str, pnl: float, is_canary: bool = None):
        """Trade kapanƒ±nca sonucu kaydet. Use stored is_canary flag if available."""
        if is_canary is None:
            is_canary = self.should_use_canary(pos_id)
        if is_canary:
            self.canary_results.append(pnl)
        else:
            self.control_results.append(pnl)
    
    def get_report(self) -> dict:
        """A/B test sonu√ßlarƒ±."""
        canary_n = len(self.canary_results)
        control_n = len(self.control_results)
        
        canary_wr = sum(1 for r in self.canary_results if r > 0) / max(1, canary_n)
        control_wr = sum(1 for r in self.control_results if r > 0) / max(1, control_n)
        
        canary_avg = sum(self.canary_results) / max(1, canary_n)
        control_avg = sum(self.control_results) / max(1, control_n)
        
        return {
            'canary': {'n': canary_n, 'win_rate': round(canary_wr * 100, 1), 'avg_pnl': round(canary_avg, 4)},
            'control': {'n': control_n, 'win_rate': round(control_wr * 100, 1), 'avg_pnl': round(control_avg, 4)},
            'canary_params': self.canary_params,
            'is_better': canary_avg > control_avg if canary_n >= 10 and control_n >= 10 else None,
        }

# Global instance
canary_mode = CanaryMode()

# ============================================================================
# PHASE 225: PRICE SHOCK MANAGER
# ============================================================================

class PriceShockManager:
    """
    Bidirectional price shock detection + automatic response.
    
    Detects sudden BTC/coin price moves using ATR-dynamic thresholds and
    4-filter validation (price, volume, sustained, liquidation/funding).
    
    Response: block opposing signals, cancel opposing pending orders,
    tighten SL on exposed positions (idempotent, entry-distance based).
    
    Guardrails:
    1. SL tightening = entry-SL distance √ó 0.7 (not price √ó 0.7), idempotent
    2. Shock deactivation restores original SL from snapshot
    3. Market shock > coin shock priority
    4. Funding = supporting evidence only (not sole trigger)
    5. Full event logging (filters passed, actions taken, duration)
    """
    
    def __init__(self):
        self.shock_mode = 'NORMAL'  # NORMAL | BEAR_SHOCK | BULL_SHOCK
        self.shock_start_time = None
        self.shock_cooldown_until = 0  # timestamp
        self.min_shock_duration = 600  # 10 minutes minimum
        self.shock_ttl = 900  # 15 minutes TTL
        self.cooldown_duration = 900  # 15 minutes cooldown after shock ends
        self.sl_tighten_factor = 0.7  # SL distance √ó 0.7
        self.recovery_cancel_pct = 0.60  # %60 recovery ‚Üí fake alarm
        self.recovery_check_delay = 180  # 3 minutes
        
        # Snapshots for restore
        self.sl_snapshots = {}  # {pos_id: {'sl': original_sl, 'trailing': original_trailing}}
        self.shock_trigger_price = 0.0  # BTC price at shock trigger
        
        # History for logging
        self.shock_history = []  # [{type, timestamp, filters, actions, duration}]
        self.current_shock_event = None
        
        # BTC price tracking for 5m change
        self.btc_price_history = []  # [(timestamp, price)] ‚Äî last 10 minutes
        
        logger.info("‚ö° PriceShockManager initialized (Phase 225)")
    
    def _update_price_history(self, btc_price: float):
        """Track BTC price for 5-minute change calculation."""
        now = datetime.now().timestamp()
        self.btc_price_history.append((now, btc_price))
        # Keep last 10 minutes
        cutoff = now - 600
        self.btc_price_history = [(t, p) for t, p in self.btc_price_history if t > cutoff]
    
    def _get_btc_5m_change(self) -> float:
        """Calculate BTC % change over last 5 minutes."""
        now = datetime.now().timestamp()
        current_prices = [(t, p) for t, p in self.btc_price_history if t > now - 30]
        old_prices = [(t, p) for t, p in self.btc_price_history if now - 330 < t < now - 270]
        
        if not current_prices or not old_prices:
            return 0.0
        
        current = current_prices[-1][1]
        old = sum(p for _, p in old_prices) / len(old_prices)
        
        if old <= 0:
            return 0.0
        return ((current - old) / old) * 100
    
    def _get_dynamic_threshold(self, btc_filter) -> float:
        """ATR-based dynamic threshold. Higher in volatile markets, lower in quiet."""
        btc_1h = abs(getattr(btc_filter, 'btc_change_1h', 0))
        btc_4h = abs(getattr(btc_filter, 'btc_change_4h', 0))
        
        # Estimate 5m ATR from 1h and 4h changes
        estimated_5m_atr = max(btc_1h / 4, btc_4h / 12, 0.3)
        
        # Threshold = 1.5 √ó estimated ATR, clamped to [0.5%, 2.0%]
        threshold = max(0.5, min(2.0, 1.5 * estimated_5m_atr))
        return threshold
    
    def check_for_shock(self, btc_filter, liquidation_tracker, funding_oi_tracker):
        """Main shock detection ‚Äî called every scanner cycle."""
        now = datetime.now().timestamp()
        btc_price = getattr(btc_filter, 'btc_price', 0)
        
        if btc_price <= 0:
            return
        
        self._update_price_history(btc_price)
        
        # Check TTL expiry for active shock
        if self.shock_mode != 'NORMAL':
            elapsed = now - (self.shock_start_time or now)
            
            # Fake alarm check: recovery within 3 minutes
            if elapsed > self.recovery_check_delay and self.shock_trigger_price > 0:
                if self.shock_mode == 'BEAR_SHOCK':
                    # Calculate actual % recovery from trigger price
                    drop_pct = abs(((self.shock_trigger_price - btc_price) / self.shock_trigger_price) * 100) if self.shock_trigger_price > 0 else 0
                    # Price has recovered above trigger = fake alarm
                    if btc_price > self.shock_trigger_price:
                        logger.warning(f"‚ö° SHOCK_FAKE_ALARM: BTC recovered above trigger ${self.shock_trigger_price:.0f} ‚Üí ${btc_price:.0f} ‚Äî cancelling BEAR_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                    # Original drop was X%, now only Y% ‚Üí if recovered >60% of drop
                    original_5m_drop = abs(self.current_shock_event.get('btc_change_5m', 0)) if self.current_shock_event else 1
                    if original_5m_drop > 0 and drop_pct < original_5m_drop * (1 - self.recovery_cancel_pct):
                        logger.warning(f"‚ö° SHOCK_FAKE_ALARM: Drop shrunk {original_5m_drop:.2f}%‚Üí{drop_pct:.2f}% (>60% recovered) ‚Äî cancelling BEAR_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                elif self.shock_mode == 'BULL_SHOCK':
                    pump_pct = abs(((btc_price - self.shock_trigger_price) / self.shock_trigger_price) * 100) if self.shock_trigger_price > 0 else 0
                    if btc_price < self.shock_trigger_price:
                        logger.warning(f"‚ö° SHOCK_FAKE_ALARM: BTC reversed below trigger ${self.shock_trigger_price:.0f} ‚Üí ${btc_price:.0f} ‚Äî cancelling BULL_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                    original_5m_pump = abs(self.current_shock_event.get('btc_change_5m', 0)) if self.current_shock_event else 1
                    if original_5m_pump > 0 and pump_pct < original_5m_pump * (1 - self.recovery_cancel_pct):
                        logger.warning(f"‚ö° SHOCK_FAKE_ALARM: Pump shrunk {original_5m_pump:.2f}%‚Üí{pump_pct:.2f}% (>60% recovered) ‚Äî cancelling BULL_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
            
            # TTL expiry (after minimum duration)
            if elapsed > max(self.min_shock_duration, self.shock_ttl):
                logger.info(f"‚ö° SHOCK_TTL: {self.shock_mode} expired after {elapsed/60:.1f}min")
                self._deactivate_shock('TTL_EXPIRED')
                return
            
            # If shock still active, check if it should extend
            btc_5m = self._get_btc_5m_change()
            threshold = self._get_dynamic_threshold(btc_filter)
            if abs(btc_5m) > threshold:
                # Extend TTL
                self.shock_start_time = now - self.min_shock_duration  # Keep min duration passed
                logger.debug(f"‚ö° SHOCK_EXTEND: {self.shock_mode} TTL extended (BTC 5m={btc_5m:+.2f}%)")
            return
        
        # Cooldown check
        if now < self.shock_cooldown_until:
            return
        
        # === DETECTION ===
        btc_5m = self._get_btc_5m_change()
        threshold = self._get_dynamic_threshold(btc_filter)
        
        if abs(btc_5m) < threshold:
            return  # No shock candidate
        
        # 4-filter validation (need 3/4)
        filters_passed = []
        
        # Filter 1: Price shock (already confirmed above)
        filters_passed.append('price')
        
        # Filter 2: Volume spike ‚Äî use 30m momentum as proxy
        btc_30m = abs(getattr(btc_filter, 'btc_change_30m', 0))
        if btc_30m > threshold * 0.8:
            filters_passed.append('volume_momentum')
        
        # Filter 3: No quick recovery ‚Äî check if move is sustained
        # Use ratio of 30m vs 5m changes (if both same direction, sustained)
        if btc_5m * getattr(btc_filter, 'btc_change_30m', 0) > 0:  # Same sign
            filters_passed.append('sustained')
        
        # Filter 4: Liquidation spike OR funding extreme
        try:
            # Check BTCUSDT liquidations
            btc_liqs = liquidation_tracker.recent_liquidations.get('BTCUSDT', [])
            recent_liq_usd = sum(
                l.get('usd', 0) for l in btc_liqs 
                if l.get('timestamp', 0) > now - 60
            )
            if recent_liq_usd > 200000:  # $200K+ BTC liquidations in 60s
                filters_passed.append('liquidation')
        except:
            pass
        
        if 'liquidation' not in filters_passed:
            try:
                btc_funding = funding_oi_tracker.funding_rates.get('BTCUSDT', 0)
                if abs(btc_funding) > 0.001:  # 0.1%+ extreme funding
                    filters_passed.append('funding_extreme')
            except:
                pass
        
        # Need 3/4 filters
        if len(filters_passed) < 3:
            logger.debug(f"‚ö° SHOCK_INSUFFICIENT: BTC 5m={btc_5m:+.2f}% but only {len(filters_passed)}/4 filters: {filters_passed}")
            return
        
        # === ACTIVATE SHOCK ===
        shock_type = 'BEAR_SHOCK' if btc_5m < 0 else 'BULL_SHOCK'
        self.shock_mode = shock_type
        self.shock_start_time = now
        self.shock_trigger_price = btc_price
        
        self.current_shock_event = {
            'type': shock_type,
            'timestamp': now,
            'btc_change_5m': round(btc_5m, 2),
            'threshold': round(threshold, 2),
            'filters_passed': filters_passed,
            'btc_price': btc_price,
            'actions': [],
            'positions_affected': [],
        }
        
        logger.warning(f"‚ö° PRICE_SHOCK: {shock_type} activated | BTC 5m={btc_5m:+.2f}% (threshold={threshold:.2f}%) | Filters: {filters_passed}")
    
    def should_block_signal(self, signal_action: str, symbol: str = '') -> tuple:
        """Check if signal should be blocked due to active shock."""
        if self.shock_mode == 'NORMAL':
            return False, ''
        
        if self.shock_mode == 'BEAR_SHOCK' and signal_action == 'LONG':
            return True, f'BEAR_SHOCK: LONG blocked (BTC crash detected)'
        
        if self.shock_mode == 'BULL_SHOCK' and signal_action == 'SHORT':
            return True, f'BULL_SHOCK: SHORT blocked (BTC pump detected)'
        
        return False, ''
    
    def cancel_opposing_pending(self, pending_orders: list) -> list:
        """Cancel pending orders opposing the shock direction. Returns cancelled list."""
        if self.shock_mode == 'NORMAL':
            return []
        
        cancelled = []
        cancel_side = 'LONG' if self.shock_mode == 'BEAR_SHOCK' else 'SHORT'
        
        for order in list(pending_orders):
            if order.get('side') == cancel_side:
                cancelled.append(order)
                pending_orders.remove(order)
        
        if cancelled and self.current_shock_event:
            self.current_shock_event['actions'].append(f'cancel_pending_{cancel_side}_{len(cancelled)}')
        
        return cancelled
    
    def tighten_exposed_positions(self, positions: list):
        """
        Tighten SL for positions exposed to shock direction.
        Guardrail 1: Uses entry-SL DISTANCE √ó 0.7, not price √ó 0.7.
        Idempotent: snapshots prevent double-tightening.
        """
        if self.shock_mode == 'NORMAL':
            return
        
        exposed_side = 'LONG' if self.shock_mode == 'BEAR_SHOCK' else 'SHORT'
        
        for pos in positions:
            if pos.get('side') != exposed_side:
                continue
            
            pos_id = pos.get('id', '')
            
            # Idempotent: skip if already tightened
            if pos_id in self.sl_snapshots:
                continue
            
            entry = pos.get('entryPrice', 0)
            current_sl = pos.get('stopLoss', 0)
            current_trailing = pos.get('trailingStop', 0)
            
            if entry <= 0:
                continue
            
            # Snapshot original values for restore
            self.sl_snapshots[pos_id] = {
                'sl': current_sl,
                'trailing': current_trailing,
            }
            
            # Tighten: entry-SL distance √ó 0.7
            # If trailingStop is 0 (not set), fall back to SL value
            effective_trailing = current_trailing if current_trailing > 0 else current_sl
            
            if exposed_side == 'LONG':
                sl_distance = entry - current_sl  # positive for valid SL below entry
                trail_distance = entry - effective_trailing
                # Guard: skip if SL already above entry (profitable position with moved stops)
                if sl_distance <= 0:
                    del self.sl_snapshots[pos_id]  # Remove snapshot since we're skipping
                    logger.debug(f"‚ö° SHOCK_SKIP: {pos.get('symbol')} LONG ‚Äî SL already above entry (profitable), no tightening needed")
                    continue
                new_sl = entry - (sl_distance * self.sl_tighten_factor)
                new_trailing = entry - (trail_distance * self.sl_tighten_factor) if trail_distance > 0 else new_sl
            else:
                sl_distance = current_sl - entry  # positive for valid SL above entry
                trail_distance = effective_trailing - entry
                # Guard: skip if SL already below entry (profitable position with moved stops)
                if sl_distance <= 0:
                    del self.sl_snapshots[pos_id]
                    logger.debug(f"‚ö° SHOCK_SKIP: {pos.get('symbol')} SHORT ‚Äî SL already below entry (profitable), no tightening needed")
                    continue
                new_sl = entry + (sl_distance * self.sl_tighten_factor)
                new_trailing = entry + (trail_distance * self.sl_tighten_factor) if trail_distance > 0 else new_sl
            
            pos['stopLoss'] = new_sl
            pos['trailingStop'] = new_trailing
            
            if self.current_shock_event:
                self.current_shock_event['positions_affected'].append(pos_id)
                self.current_shock_event['actions'].append(f'tighten_sl_{pos_id[-8:]}')
            
            logger.warning(f"üìâ SHOCK_TIGHTEN: {pos.get('symbol')} {exposed_side} | SL {current_sl:.4f}‚Üí{new_sl:.4f} (distance√ó{self.sl_tighten_factor})")
    
    def _deactivate_shock(self, reason: str = 'TTL_EXPIRED'):
        """Deactivate shock and restore original SL values."""
        now = datetime.now().timestamp()
        duration = now - (self.shock_start_time or now)
        
        # Restore SL snapshots (Guardrail 2 ‚Äî smart restore: don't overwrite improved trailing)
        restored_count = 0
        for pos_id, snapshot in self.sl_snapshots.items():
            try:
                for pos in global_paper_trader.positions:
                    if pos.get('id') == pos_id:
                        current_sl = pos.get('stopLoss', 0)
                        current_trailing = pos.get('trailingStop', 0)
                        side = pos.get('side', 'LONG')
                        
                        # Smart restore: only restore if snapshot SL is more protective than current
                        # For LONG: higher SL = more protective
                        # For SHORT: lower SL = more protective
                        if side == 'LONG':
                            restore_sl = max(snapshot['sl'], current_sl)  # Keep the higher (more protective)
                            restore_trail = max(snapshot['trailing'], current_trailing)
                        else:
                            restore_sl = min(snapshot['sl'], current_sl)  # Keep the lower (more protective)
                            restore_trail = min(snapshot['trailing'], current_trailing)
                        
                        pos['stopLoss'] = restore_sl
                        pos['trailingStop'] = restore_trail
                        restored_count += 1
                        logger.info(f"‚úÖ SHOCK_RESTORE: {pos.get('symbol')} SL‚Üí{restore_sl:.4f} trail‚Üí{restore_trail:.4f} (smart restore)")
                        break
            except:
                pass
        
        # Log event
        if self.current_shock_event:
            self.current_shock_event['duration_seconds'] = round(duration)
            self.current_shock_event['deactivation_reason'] = reason
            self.current_shock_event['restored_count'] = restored_count
            self.shock_history.append(self.current_shock_event)
            # Keep last 50 events
            self.shock_history = self.shock_history[-50:]
        
        old_mode = self.shock_mode
        self.shock_mode = 'NORMAL'
        self.shock_start_time = None
        self.shock_trigger_price = 0.0
        self.sl_snapshots.clear()
        self.current_shock_event = None
        
        # Set cooldown (Guardrail: hysteresis)
        self.shock_cooldown_until = now + self.cooldown_duration
        
        logger.warning(f"‚ö° SHOCK_DEACTIVATED: {old_mode} ‚Üí NORMAL | reason={reason} | duration={duration/60:.1f}min | restored={restored_count} positions | cooldown={self.cooldown_duration/60:.0f}min")
    
    def get_shock_status(self) -> dict:
        """Get current shock status for API/dashboard."""
        now = datetime.now().timestamp()
        return {
            'mode': self.shock_mode,
            'active': self.shock_mode != 'NORMAL',
            'start_time': self.shock_start_time,
            'elapsed_seconds': round(now - self.shock_start_time) if self.shock_start_time else 0,
            'trigger_price': self.shock_trigger_price,
            'cooldown_remaining': max(0, round(self.shock_cooldown_until - now)),
            'sl_snapshots_count': len(self.sl_snapshots),
            'history_count': len(self.shock_history),
            'last_event': self.shock_history[-1] if self.shock_history else None,
        }

# Global instance
price_shock_manager = PriceShockManager()

# ============================================================================
# PHASE 155: AI OPTIMIZER - PnL-CORRELATED PERFORMANCE ANALYZER
# ============================================================================

class PerformanceAnalyzer:
    """
    Phase 155: PnL-korelasyon bazlƒ± analiz.
    Her parametre i√ßin k√¢rlƒ± vs zararlƒ± trade'lerin ortalama deƒüerlerini kar≈üƒ±la≈ütƒ±rƒ±r.
    Target = k√¢rlƒ± trade'lerin PnL-aƒüƒ±rlƒ±klƒ± ortalamasƒ±.
    """
    
    # AI Optimizer'ƒ±n kontrol ettiƒüi parametreler
    OPTIMIZABLE_PARAMS = ['entry_tightness', 'z_score_threshold', 'min_score_low', 'min_score_high', 'max_positions']
    
    def __init__(self):
        self.last_analysis = None
        self.last_correlations = None
        self.analysis_interval_minutes = 60
        logger.info("üìà PerformanceAnalyzer initialized (Phase 155: PnL-Correlation)")
    
    def analyze(self, trades: list, post_trade_stats: dict = None) -> dict:
        """Son trade'leri analiz et ‚Äî genel istatistikler + parametre korelasyonu."""
        if not trades:
            return {}
        
        recent_trades = trades[-100:]
        
        # === GENEL ƒ∞STATƒ∞STƒ∞KLER ===
        winners = [t for t in recent_trades if t.get('pnl', 0) > 0]
        losers = [t for t in recent_trades if t.get('pnl', 0) < 0]
        
        win_rate = len(winners) / len(recent_trades) * 100 if recent_trades else 0
        avg_winner = sum(t.get('pnl', 0) for t in winners) / len(winners) if winners else 0
        avg_loser = sum(t.get('pnl', 0) for t in losers) / len(losers) if losers else 0
        profit_factor = abs(avg_winner * len(winners)) / abs(avg_loser * len(losers)) if losers and avg_loser != 0 else 999
        total_pnl = sum(t.get('pnl', 0) for t in recent_trades)
        
        # Coin bazlƒ± performans
        coin_performance = {}
        for t in recent_trades:
            symbol = t.get('symbol', '').replace('USDT', '')
            if symbol not in coin_performance:
                coin_performance[symbol] = {'wins': 0, 'losses': 0, 'pnl': 0}
            if t.get('pnl', 0) > 0:
                coin_performance[symbol]['wins'] += 1
            else:
                coin_performance[symbol]['losses'] += 1
            coin_performance[symbol]['pnl'] += t.get('pnl', 0)
        
        sorted_coins = sorted(coin_performance.items(), key=lambda x: x[1]['pnl'], reverse=True)
        top_coins = [c[0] for c in sorted_coins[:5] if c[1]['pnl'] > 0]
        worst_coins = [c[0] for c in sorted_coins[-5:] if c[1]['pnl'] < 0]
        
        # Reason bazlƒ± analiz
        reason_performance = {}
        for t in recent_trades:
            reason = t.get('reason', t.get('closeReason', 'UNKNOWN'))
            if reason not in reason_performance:
                reason_performance[reason] = {'count': 0, 'pnl': 0, 'wins': 0}
            reason_performance[reason]['count'] += 1
            reason_performance[reason]['pnl'] += t.get('pnl', 0)
            if t.get('pnl', 0) > 0:
                reason_performance[reason]['wins'] += 1
        
        kill_switch_trades = [t for t in recent_trades if 'KILL_SWITCH' in str(t.get('reason', '')) or 'KILL_SWITCH' in str(t.get('closeReason', ''))]
        kill_switch_rate = len(kill_switch_trades) / len(recent_trades) * 100 if recent_trades else 0
        
        # === PHASE 155: PARAMETRE KORELASYON ANALƒ∞Zƒ∞ ===
        correlations = self._analyze_settings_correlation(recent_trades)
        self.last_correlations = correlations
        
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_time = datetime.now(turkey_tz)
        
        analysis = {
            'timestamp': turkey_time.strftime('%d.%m.%Y %H:%M:%S'),
            'trade_count': len(recent_trades),
            'total_pnl': round(total_pnl, 2),
            'win_rate': round(win_rate, 1),
            'avg_winner': round(avg_winner, 2),
            'avg_loser': round(avg_loser, 2),
            'profit_factor': round(min(profit_factor, 99), 2),
            'top_coins': top_coins,
            'worst_coins': worst_coins,
            'reason_performance': reason_performance,
            'early_exit_rate': post_trade_stats.get('early_exit_rate', 0) if post_trade_stats else 0,
            'kill_switch_rate': round(kill_switch_rate, 1),
            # Phase 155: Korelasyon verileri
            'correlations': correlations,
            'trades_with_snapshot': len([t for t in recent_trades if t.get('settingsSnapshot')]),
        }
        
        self.last_analysis = analysis
        
        corr_summary = ""
        if correlations:
            corr_parts = [f"{p}: {d.get('direction', '?')}" for p, d in correlations.items()]
            corr_summary = f" | Corr: {', '.join(corr_parts[:3])}"
        
        logger.info(f"üìà ANALYSIS: PnL ${total_pnl:.0f} | WR {win_rate:.1f}% | PF {profit_factor:.2f} | Snapshots: {analysis['trades_with_snapshot']}{corr_summary}")
        
        return analysis
    
    def _analyze_settings_correlation(self, trades: list) -> dict:
        """
        Phase 155: Her parametre i√ßin k√¢rlƒ± trade'lerdeki ortalama vs zararlƒ± trade'lerdeki ortalama.
        PnL-aƒüƒ±rlƒ±klƒ± ortalama kullanƒ±r ‚Äî b√ºy√ºk k√¢rlar daha fazla etki eder.
        """
        # Sadece settings snapshot'ƒ± olan trade'leri kullan
        trades_with_snapshot = [t for t in trades if t.get('settingsSnapshot') and isinstance(t.get('settingsSnapshot'), dict) and len(t.get('settingsSnapshot', {})) > 0]
        
        if len(trades_with_snapshot) < 10:
            logger.debug(f"üìà Correlation: Not enough trades with snapshot ({len(trades_with_snapshot)}/10 min)")
            return {}
        
        winners = [t for t in trades_with_snapshot if t.get('pnl', 0) > 0]
        losers = [t for t in trades_with_snapshot if t.get('pnl', 0) < 0]
        
        if len(winners) < 3 or len(losers) < 3:
            logger.debug(f"üìà Correlation: Not enough winners({len(winners)}) or losers({len(losers)})")
            return {}
        
        correlations = {}
        
        for param in self.OPTIMIZABLE_PARAMS:
            # Winner deƒüerleri (PnL-aƒüƒ±rlƒ±klƒ± ortalama)
            winner_data = [(t['settingsSnapshot'].get(param), t.get('pnl', 0)) 
                          for t in winners if t['settingsSnapshot'].get(param) is not None]
            # Loser deƒüerleri (basit ortalama ‚Äî zarar miktarƒ± e≈üit aƒüƒ±rlƒ±klƒ±)
            loser_data = [(t['settingsSnapshot'].get(param), t.get('pnl', 0)) 
                         for t in losers if t['settingsSnapshot'].get(param) is not None]
            
            if len(winner_data) < 3 or len(loser_data) < 3:
                continue
            
            # PnL-aƒüƒ±rlƒ±klƒ± winner ortalamasƒ± (b√ºy√ºk k√¢rlar daha fazla √ßeker)
            total_winner_pnl = sum(pnl for _, pnl in winner_data)
            if total_winner_pnl > 0:
                winner_avg = sum(val * pnl for val, pnl in winner_data) / total_winner_pnl
            else:
                winner_avg = sum(val for val, _ in winner_data) / len(winner_data)
            
            # Basit loser ortalamasƒ±
            loser_avg = sum(val for val, _ in loser_data) / len(loser_data)
            
            # T√ºm trade'lerin ortalamasƒ± (referans)
            all_avg = sum(val for val, _ in winner_data + loser_data) / len(winner_data + loser_data)
            
            # Target: k√¢rlƒ± trade'lerin ortalamasƒ±na doƒüru git
            target = winner_avg
            direction = 'UP' if winner_avg > loser_avg else 'DOWN'
            
            correlations[param] = {
                'winner_avg': round(winner_avg, 3),
                'loser_avg': round(loser_avg, 3),
                'all_avg': round(all_avg, 3),
                'target': round(target, 3),
                'direction': direction,
                'winner_count': len(winner_data),
                'loser_count': len(loser_data),
                'confidence': min(len(winner_data), len(loser_data)),  # How many data points
            }
        
        if correlations:
            logger.info(f"üìà CORRELATIONS: {len(correlations)} params analyzed from {len(trades_with_snapshot)} trades")
        
        return correlations


# ============================================================================
# PHASE 155: AI OPTIMIZER - GRADIENT-BASED PARAMETER OPTIMIZER
# ============================================================================

class ParameterOptimizer:
    """
    Phase 155: Korelasyon bazlƒ± gradient optimizer.
    
    Mantƒ±k:
    1. PerformanceAnalyzer her parametre i√ßin k√¢rlƒ±/zararlƒ± trade ortalamalarƒ±nƒ± hesaplar
    2. Target = k√¢rlƒ± trade'lerin PnL-aƒüƒ±rlƒ±klƒ± ortalamasƒ±
    3. Her d√∂ng√ºde mevcut deƒüeri target'a doƒüru k√º√ß√ºk adƒ±mlarla kaydƒ±r
    4. G√ºvenlik limitleri ve max step ile kontrol et
    
    Sadece settings modal'dan aktif edildiƒüinde √ßalƒ±≈üƒ±r (self.enabled = False default).
    """
    
    def __init__(self):
        self.last_optimization = None
        self.optimization_history = []
        self.enabled = False  # Varsayƒ±lan KAPALI ‚Äî sadece settings modal'dan a√ßƒ±lƒ±r
        
        # G√ºvenlik sƒ±nƒ±rlarƒ± ‚Äî sadece ger√ßekten optimize edilen parametreler
        self.limits = {
            'entry_tightness': (0.5, 4.0),
            'z_score_threshold': (0.8, 2.5),
            'min_score_low': (30, 60),
            'min_score_high': (60, 95),
            'max_positions': (2, 15),
        }
        
        # Max step ‚Äî bir d√∂ng√ºde maksimum deƒüi≈üim (ani sƒ±√ßrama √∂nleme)
        self.max_steps = {
            'entry_tightness': 0.2,
            'z_score_threshold': 0.1,
            'min_score_low': 3,
            'min_score_high': 3,
            'max_positions': 1,
        }
        
        # Step ratio ‚Äî target'a her d√∂ng√ºde mesafenin ka√ßta ka√ßƒ± kadar yakla≈ü
        self.step_ratio = 0.20  # %20 ‚Äî yava≈ü ve g√ºvenli
        
        logger.info("ü§ñ ParameterOptimizer initialized (Phase 155: Gradient-based, disabled by default)")
    
    def optimize(self, analysis: dict, current_settings: dict) -> dict:
        """
        Korelasyon verilerine g√∂re parametreleri target'a doƒüru kaydƒ±r.
        
        Args:
            analysis: PerformanceAnalyzer'dan gelen analiz (correlations dahil)
            current_settings: Mevcut paper_trader ayarlarƒ±
        
        Returns:
            dict: timestamp, recommendations, changes, applied bilgileri
        """
        if not analysis:
            return {}
        
        recommendations = {}
        changes = []
        
        correlations = analysis.get('correlations', {})
        total_pnl = analysis.get('total_pnl', 0)
        trades_with_snapshot = analysis.get('trades_with_snapshot', 0)
        
        # Yeterli veri yoksa sadece log yaz, √∂neri √ºretme
        if not correlations:
            logger.info(f"ü§ñ OPTIMIZER: No correlations yet (snapshots: {trades_with_snapshot}) ‚Äî collecting data")
        else:
            # === GRADIENT-BAZLI OPTƒ∞Mƒ∞ZASYON ===
            for param, corr_data in correlations.items():
                current_val = current_settings.get(param)
                target_val = corr_data.get('target')
                confidence = corr_data.get('confidence', 0)
                
                if current_val is None or target_val is None:
                    continue
                
                # Minimum confidence: en az 5 veri noktasƒ±
                if confidence < 5:
                    continue
                
                # Mesafe hesapla
                distance = target_val - current_val
                
                # K√º√ß√ºk adƒ±mla yakla≈ü (mesafenin %20'si, max step ile sƒ±nƒ±rlƒ±)
                max_step = self.max_steps.get(param, 0.2)
                step = distance * self.step_ratio
                step = max(-max_step, min(max_step, step))
                
                new_val = current_val + step
                
                # G√ºvenlik limitleri uygula
                limits = self.limits.get(param)
                if limits:
                    new_val = max(limits[0], min(limits[1], new_val))
                
                # Integer parametreler (max_positions, min_score)
                if param in ('max_positions', 'min_score_low', 'min_score_high'):
                    new_val = int(round(new_val))
                else:
                    new_val = round(new_val, 2)
                
                # Deƒüi≈üim anlamlƒ± mƒ±? (minimum threshold)
                min_change = {
                    'entry_tightness': 0.05,
                    'z_score_threshold': 0.05,
                    'min_score_low': 1,
                    'min_score_high': 1,
                    'max_positions': 1,
                }.get(param, 0.01)
                
                if abs(new_val - current_val) >= min_change:
                    recommendations[param] = new_val
                    direction = corr_data.get('direction', '?')
                    changes.append(f"{param}: {current_val}‚Üí{new_val} (win_avg={corr_data.get('winner_avg', '?')}, {direction})")
        
        # === SONU√á ===
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_time = datetime.now(turkey_tz)
        
        result = {
            'timestamp': turkey_time.strftime('%d.%m.%Y %H:%M:%S'),
            'total_pnl': total_pnl,
            'recommendations': recommendations,
            'changes': changes,
            'applied': False,
            'correlations_count': len(correlations),
            'trades_with_snapshot': trades_with_snapshot,
        }
        
        self.last_optimization = result
        self.optimization_history.append(result)
        if len(self.optimization_history) > 50:
            self.optimization_history = self.optimization_history[-50:]
        
        if changes:
            logger.info(f"ü§ñ OPTIMIZER: {len(changes)} gradient changes ‚Äî {', '.join(changes[:3])}")
        
        return result
    
    def apply_recommendations(self, paper_trader, recommendations: dict) -> dict:
        """
        Optimizasyon √∂nerilerini uygula (sadece enabled ise).
        
        Returns:
            dict: Uygulanan ayarlar {param_name: new_value} veya bo≈ü dict
        """
        if not self.enabled:
            logger.info("ü§ñ OPTIMIZER: Disabled ‚Äî skipping apply")
            return {}
        
        if not recommendations:
            return {}
        
        applied = {}
        
        # Phase 155: Sadece optimize edilen parametreler
        param_map = {
            'entry_tightness': 'entry_tightness',
            'z_score_threshold': 'z_score_threshold',
            'min_score_low': 'min_score_low',
            'min_score_high': 'min_score_high',
            'max_positions': 'max_positions',
        }
        
        for param, attr_name in param_map.items():
            if param in recommendations:
                old_val = getattr(paper_trader, attr_name, None)
                new_val = recommendations[param]
                setattr(paper_trader, attr_name, new_val)
                applied[param] = {'old': old_val, 'new': new_val}
        
        if applied:
            applied_summary = ", ".join(f"{p}: {d['old']}‚Üí{d['new']}" for p, d in applied.items())
            logger.info(f"ü§ñ OPTIMIZER APPLIED: {applied_summary}")
            paper_trader.add_log(f"ü§ñ AI g√ºncelledi: {applied_summary}")
            paper_trader.save_state()
            
            # Mark as applied
            if self.last_optimization:
                self.last_optimization['applied'] = True
                from zoneinfo import ZoneInfo
                turkey_tz = ZoneInfo('Europe/Istanbul')
                self.last_optimization['applied_at'] = datetime.now(turkey_tz).strftime('%d.%m.%Y %H:%M:%S')
                self.last_optimization['applied_settings'] = list(applied.keys())
        
        return applied
    
    def get_status(self) -> dict:
        return {
            'enabled': self.enabled,
            'last_optimization': self.last_optimization,
            'history_count': len(self.optimization_history),
            'correlations': performance_analyzer.last_correlations if performance_analyzer else None,
        }


# Global Adaptive Trading instances
post_trade_tracker = PostTradeTracker()
performance_analyzer = PerformanceAnalyzer()
parameter_optimizer = ParameterOptimizer()


# ============================================================================
# PHASE 53: MARKET REGIME DETECTOR
# ============================================================================

class MarketRegimeDetector:
    """
    Piyasa durumunu algƒ±lar ve AI optimizasyonuna veri saƒülar.
    BTC price action, volatilite ve trend analizi yapar.
    
    Phase 60: TRENDING_DOWN/TRENDING_UP ayrƒ±mƒ± eklendi.
    D√º≈ü√º≈ü trendinde LONG sinyallere aƒüƒ±r penalize uygulanƒ±r.
    """
    
    TRENDING_UP = "TRENDING_UP"      # G√º√ßl√º y√ºkselis trendi, LONG'lara bonus
    TRENDING_DOWN = "TRENDING_DOWN"  # G√º√ßl√º d√º≈ü√º≈ü trendi, LONG'lara veto
    TRENDING = "TRENDING"            # Eski uyumluluk i√ßin (y√∂n belirsiz)
    RANGING = "RANGING"              # Yatay piyasa, SL sƒ±kƒ±la≈ütƒ±r, TP yakƒ±nla≈ütƒ±r
    VOLATILE = "VOLATILE"            # Y√ºksek volatilite, y√ºksek min score, se√ßici ol
    QUIET = "QUIET"                  # D√º≈ü√ºk volatilite, d√º≈ü√ºk min score, agresif ol
    
    def __init__(self):
        self.current_regime = self.RANGING
        self.trend_direction = "NEUTRAL"  # UP, DOWN, NEUTRAL
        self.btc_prices = []  # Son 24 saatlik BTC fiyatlarƒ±
        self.last_update = None
        self.regime_history = []
        self.max_history = 100
        logger.info("üìä MarketRegimeDetector initialized with Direction Awareness")
    
    def update_btc_price(self, price: float):
        """BTC fiyatƒ±nƒ± kaydet."""
        self.btc_prices.append({
            'price': price,
            'time': datetime.now()
        })
        # Son 24 saat tut (1440 dakika, her 5dk'da 1 kayƒ±t = 288 kayƒ±t)
        if len(self.btc_prices) > 300:
            self.btc_prices = self.btc_prices[-300:]
    
    def detect_regime(self) -> str:
        """Piyasa durumunu algƒ±la."""
        if len(self.btc_prices) < 10:
            return self.RANGING  # Yeterli veri yok
        
        prices = [p['price'] for p in self.btc_prices[-50:]]  # Son ~4 saat
        
        if len(prices) < 10:
            return self.RANGING
        
        # Volatilite hesapla (standart sapma / ortalama)
        avg_price = sum(prices) / len(prices)
        variance = sum((p - avg_price) ** 2 for p in prices) / len(prices)
        std_dev = variance ** 0.5
        volatility = (std_dev / avg_price) * 100  # Y√ºzde olarak
        
        # Trend hesapla (ilk vs son fiyat)
        first_half = sum(prices[:len(prices)//2]) / (len(prices)//2)
        second_half = sum(prices[len(prices)//2:]) / (len(prices) - len(prices)//2)
        trend_strength = abs((second_half - first_half) / first_half) * 100  # Y√ºzde
        
        # Phase 60: Trend y√∂n√ºn√º belirle
        trend_direction_raw = (second_half - first_half) / first_half * 100
        if trend_direction_raw > 1.0:
            self.trend_direction = "UP"
        elif trend_direction_raw < -1.0:
            self.trend_direction = "DOWN"
        else:
            self.trend_direction = "NEUTRAL"
        
        # Price range hesapla
        price_range = (max(prices) - min(prices)) / avg_price * 100  # Y√ºzde
        
        # Regime belirleme (Phase 60: Y√∂n farkƒ±ndalƒ±ƒüƒ± eklendi)
        if volatility > 2.0 or price_range > 5.0:
            regime = self.VOLATILE
        elif trend_strength > 1.5 and price_range > 2.0:
            # Phase 60: Trend y√∂n√ºne g√∂re TRENDING_UP veya TRENDING_DOWN
            if self.trend_direction == "DOWN":
                regime = self.TRENDING_DOWN
            elif self.trend_direction == "UP":
                regime = self.TRENDING_UP
            else:
                regime = self.TRENDING  # Eski uyumluluk
        elif volatility < 0.5 and price_range < 1.0:
            regime = self.QUIET
        else:
            regime = self.RANGING
        
        # Deƒüi≈üiklik varsa logla
        if regime != self.current_regime:
            logger.info(f"üìä MARKET REGIME CHANGE: {self.current_regime} ‚Üí {regime} (vol:{volatility:.2f}%, trend:{trend_strength:.2f}%, dir:{self.trend_direction}, range:{price_range:.2f}%)")
            self.regime_history.append({
                'from': self.current_regime,
                'to': regime,
                'time': datetime.now().isoformat(),
                'volatility': volatility,
                'trend_strength': trend_strength,
                'trend_direction': self.trend_direction
            })
            if len(self.regime_history) > self.max_history:
                self.regime_history = self.regime_history[-self.max_history:]
        
        self.current_regime = regime
        self.last_update = datetime.now()
        
        return regime
    
    def get_regime_params(self) -> dict:
        """
        Mevcut regime i√ßin √∂nerilen parametreleri d√∂nd√ºr.
        Bu deƒüerler ParameterOptimizer tarafƒ±ndan kullanƒ±lƒ±r.
        """
        params = {
            # Phase 60: TRENDING_UP - Y√ºkseli≈ü trendinde LONG'lara bonus
            self.TRENDING_UP: {
                'min_score_adjustment': -5,    # Daha agresif LONG
                'trail_distance_mult': 1.3,    # Trail'i gev≈üet, trend devam etsin
                'sl_atr_mult': 1.2,            # SL biraz gev≈üet
                'tp_atr_mult': 1.5,            # TP'yi uzat
                'long_bonus': 0.15,            # LONG sinyallere bonus
                'short_penalty': 0.2,          # SHORT sinyallere penalty
                'description': 'üìà Y√ºkseli≈ü trendi - LONG bonus, SHORT riskli'
            },
            # Phase 60: TRENDING_DOWN - D√º≈ü√º≈ü trendinde LONG'lara veto
            self.TRENDING_DOWN: {
                'min_score_adjustment': +15,   # √áok se√ßici (LONG i√ßin)
                'trail_distance_mult': 0.7,    # Trail'i sƒ±kƒ±la≈ütƒ±r, hƒ±zlƒ± √ßƒ±k
                'sl_atr_mult': 0.8,            # SL sƒ±kƒ± tut
                'tp_atr_mult': 0.7,            # TP yakƒ±n, hƒ±zlƒ± k√¢r al
                'long_penalty': 0.5,           # LONG sinyallere aƒüƒ±r penalty
                'short_bonus': 0.2,            # SHORT sinyallere bonus
                'description': 'üìâ D√º≈ü√º≈ü trendi - LONG riskli, SHORT bonus'
            },
            self.TRENDING: {
                'min_score_adjustment': -5,    # Daha agresif
                'trail_distance_mult': 1.3,    # Trail'i gev≈üet, trend devam etsin
                'sl_atr_mult': 1.2,            # SL biraz gev≈üet
                'tp_atr_mult': 1.5,            # TP'yi uzat
                'description': 'Trend takibi modu - TP uzun, trail gev≈üek'
            },
            self.RANGING: {
                'min_score_adjustment': 0,     # Normal
                'trail_distance_mult': 1.0,
                'sl_atr_mult': 1.0,
                'tp_atr_mult': 1.0,
                'description': 'Yatay piyasa - standart ayarlar'
            },
            self.VOLATILE: {
                'min_score_adjustment': +10,   # √áok se√ßici
                'trail_distance_mult': 0.8,    # Trail'i sƒ±kƒ±la≈ütƒ±r
                'sl_atr_mult': 1.3,            # SL gev≈üet (whipsaw korumasƒ±)
                'tp_atr_mult': 0.8,            # TP yakƒ±nla≈ütƒ±r
                'description': 'Volatil piyasa - y√ºksek se√ßicilik, hƒ±zlƒ± √ßƒ±kƒ±≈ü'
            },
            self.QUIET: {
                'min_score_adjustment': -10,   # Agresif
                'trail_distance_mult': 0.9,    # Trail orta
                'sl_atr_mult': 0.9,            # SL sƒ±kƒ±
                'tp_atr_mult': 0.9,            # TP yakƒ±n
                'description': 'Sakin piyasa - agresif giri≈ü, sƒ±kƒ± √ßƒ±kƒ±≈ü'
            }
        }
        return params.get(self.current_regime, params[self.RANGING])
    
    def get_status(self) -> dict:
        """API i√ßin durum √∂zeti."""
        return {
            'currentRegime': self.current_regime,
            'trendDirection': self.trend_direction,
            'lastUpdate': self.last_update.isoformat() if self.last_update else None,
            'priceCount': len(self.btc_prices),
            'params': self.get_regime_params(),
            'recentChanges': self.regime_history[-5:] if self.regime_history else []
        }


# Global Market Regime instance
market_regime_detector = MarketRegimeDetector()


# ============================================================================
# PHASE 54: SCORE COMPONENT ANALYZER
# ============================================================================

class ScoreComponentAnalyzer:
    """
    Hangi skor bile≈üeninin en √ßok k√¢r getirdiƒüini analiz eder.
    Korelasyon analizi yaparak aƒüƒ±rlƒ±k √∂nerileri √ºretir.
    """
    
    def __init__(self):
        self.trade_components = []  # Trade'lerin skor bile≈üenleri
        self.max_records = 500
        self.last_analysis = None
        self.weight_recommendations = {}
        logger.info("üìä ScoreComponentAnalyzer initialized")
    
    def record_trade(self, trade: dict, components: dict):
        """
        Trade kapandƒ±ƒüƒ±nda skor bile≈üenlerini kaydet.
        components: {zscore, hurst, volume_spike, imbalance, mtf_score, spread_level}
        """
        record = {
            'trade_id': trade.get('id', ''),
            'pnl': trade.get('pnl', 0),
            'is_win': trade.get('pnl', 0) > 0,
            'pnl_percent': trade.get('pnlPercent', 0),
            'components': {
                'zscore': abs(components.get('zScore', 0)),
                'hurst': components.get('hurst', 0.5),
                'volume_spike': 1 if components.get('volumeSpike', False) else 0,
                'imbalance': abs(components.get('imbalance', 0)),
                'mtf_score': components.get('mtfScore', 0),
                'spread_level': self._spread_to_numeric(components.get('spreadLevel', 'medium')),
                'signal_score': components.get('signalScore', 0),
            },
            'timestamp': datetime.now().isoformat()
        }
        
        self.trade_components.append(record)
        
        if len(self.trade_components) > self.max_records:
            self.trade_components = self.trade_components[-self.max_records:]
        
        logger.debug(f"üìä SCORE RECORD: {trade.get('symbol')} PnL:{trade.get('pnl', 0):.2f} ZS:{components.get('zScore', 0):.2f}")
    
    def _spread_to_numeric(self, spread_level: str) -> float:
        """Spread seviyesini sayƒ±ya √ßevir. Phase 223d: Title Case uyumlu."""
        mapping = {
            'Very Low': 0.9,
            'Low': 0.7,
            'Normal': 0.5,
            'High': 0.3,
            'Very High': 0.1,
            'Extreme': 0.05,
            'Ultra': 0.02
        }
        return mapping.get(spread_level, 0.5)
    
    def analyze(self) -> dict:
        """Korelasyon analizi yap ve aƒüƒ±rlƒ±k √∂nerileri √ºret."""
        if len(self.trade_components) < 20:
            return {'error': 'Yeterli veri yok (min 20 trade)'}
        
        recent = self.trade_components[-100:]  # Son 100 trade
        
        # Her bile≈üen i√ßin kazanan/kaybeden ortalamalarƒ±nƒ± hesapla
        component_stats = {}
        component_names = ['zscore', 'hurst', 'volume_spike', 'imbalance', 'mtf_score', 'spread_level', 'signal_score']
        
        for comp in component_names:
            winners = [r['components'][comp] for r in recent if r['is_win']]
            losers = [r['components'][comp] for r in recent if not r['is_win']]
            
            avg_winner = sum(winners) / len(winners) if winners else 0
            avg_loser = sum(losers) / len(losers) if losers else 0
            
            # Kazanan/kaybeden farkƒ± (pozitif = kazananlarda daha y√ºksek)
            diff = avg_winner - avg_loser
            
            # Korelasyon hesapla (basit yakla≈üƒ±m)
            all_values = [r['components'][comp] for r in recent]
            all_pnls = [r['pnl'] for r in recent]
            
            correlation = self._calculate_correlation(all_values, all_pnls)
            
            component_stats[comp] = {
                'avg_winner': round(avg_winner, 3),
                'avg_loser': round(avg_loser, 3),
                'diff': round(diff, 3),
                'correlation': round(correlation, 3),
                'importance': abs(correlation)  # Mutlak korelasyon
            }
        
        # Importance'a g√∂re sƒ±rala
        sorted_components = sorted(component_stats.items(), key=lambda x: x[1]['importance'], reverse=True)
        
        # Aƒüƒ±rlƒ±k √∂nerileri √ºret
        recommendations = {}
        for comp, stats in sorted_components[:3]:  # Top 3 √∂nemli
            if stats['correlation'] > 0.15:
                recommendations[comp] = 'INCREASE'
            elif stats['correlation'] < -0.15:
                recommendations[comp] = 'DECREASE'
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'trade_count': len(recent),
            'component_stats': component_stats,
            'ranked_components': [{'name': k, **v} for k, v in sorted_components],
            'weight_recommendations': recommendations,
            'top_component': sorted_components[0][0] if sorted_components else None,
            'worst_component': sorted_components[-1][0] if sorted_components else None,
        }
        
        self.last_analysis = result
        self.weight_recommendations = recommendations
        
        top_comp = sorted_components[0] if sorted_components else ('N/A', {})
        logger.info(f"üìä SCORE ANALYSIS: Top={top_comp[0]} (corr:{top_comp[1].get('correlation', 0):.2f}) | {len(recommendations)} √∂neri")
        
        return result
    
    def _calculate_correlation(self, x: list, y: list) -> float:
        """Basit Pearson korelasyonu hesapla."""
        if len(x) < 2 or len(x) != len(y):
            return 0.0
        
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(xi ** 2 for xi in x)
        sum_y2 = sum(yi ** 2 for yi in y)
        
        numerator = n * sum_xy - sum_x * sum_y
        denominator = ((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2)) ** 0.5
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def get_status(self) -> dict:
        """API i√ßin durum √∂zeti."""
        return {
            'recordCount': len(self.trade_components),
            'lastAnalysis': self.last_analysis,
            'recommendations': self.weight_recommendations
        }


# Global Score Component Analyzer instance
score_component_analyzer = ScoreComponentAnalyzer()


# ============================================================================
# PHASE 48: KILL SWITCH FAULT TRACKER (Enhanced)
# ============================================================================



class KillSwitchFaultTracker:
    """
    Tracks coins that have triggered kill switch and applies penalty to future signals.
    
    Phase 60 - REDUCED DURATIONS:
    - Each kill switch adds -15 points to the coin's fault score (was -25)
    - Fault score decays by 10 points per 24 hours (was 5)
    - Coins with kill switch in last 2h are BLOCKED from new positions (was 4h)
    - Full recovery in ~1.5 days instead of 5 days
    """
    
    def __init__(self, penalty_per_fault: int = -5, decay_per_day: int = 10):
        self.faults: Dict[str, list] = {}  # symbol -> list of fault timestamps
        self.penalty_per_fault = penalty_per_fault  # -5 points per kill switch (Phase 121: was -15)
        self.decay_per_day = decay_per_day  # 10 points decay per 24h
        self.max_penalty = -30  # Maximum penalty cap (Phase 121: was -50)
        self.block_hours = 4  # Block new positions for 4 hours after KS (Phase 121)
        logger.info(f"üìã KillSwitchFaultTracker: {penalty_per_fault} pts/fault, {decay_per_day} decay/day, {self.block_hours}h block")
    
    def load_from_trade_history(self, trades: list):
        """Load fault history from existing trades on startup."""
        ks_count = 0
        for trade in trades:
            reason = trade.get('reason', '')
            if 'KILL_SWITCH' in reason:
                symbol = trade.get('symbol', '')
                close_time = trade.get('closeTime', 0)
                if symbol and close_time:
                    if symbol not in self.faults:
                        self.faults[symbol] = []
                    self.faults[symbol].append({
                        'timestamp': close_time / 1000,  # Convert from ms to seconds
                        'reason': reason
                    })
                    ks_count += 1
        
        # Clean up old faults
        self._cleanup_old_faults()
        
        active_faults = sum(len(f) for f in self.faults.values())
        logger.info(f"üìã Loaded {ks_count} kill switch faults from trade history, {active_faults} still active")
    
    def _cleanup_old_faults(self):
        """Remove faults older than 7 days."""
        cutoff = datetime.now().timestamp() - (7 * 24 * 60 * 60)
        for symbol in list(self.faults.keys()):
            self.faults[symbol] = [f for f in self.faults[symbol] if f['timestamp'] > cutoff]
            if not self.faults[symbol]:
                del self.faults[symbol]
    
    def record_fault(self, symbol: str, reason: str = "KILL_SWITCH"):
        """Record a kill switch fault for a symbol."""
        if symbol not in self.faults:
            self.faults[symbol] = []
        
        self.faults[symbol].append({
            'timestamp': datetime.now().timestamp(),
            'reason': reason
        })
        
        self._cleanup_old_faults()
        
        penalty = self.get_penalty(symbol)
        is_blocked = self.is_blocked(symbol)
        block_status = f"üö´ BLOCKED {self.block_hours}h" if is_blocked else ""
        logger.warning(f"üìã FAULT RECORDED: {symbol} ({reason}) - Penalty: {penalty}p {block_status}")
    
    def is_blocked(self, symbol: str) -> bool:
        """Check if a coin is blocked from new positions (KS within last 24h)."""
        if symbol not in self.faults or not self.faults[symbol]:
            return False
        
        now = datetime.now().timestamp()
        block_cutoff = now - (self.block_hours * 60 * 60)
        
        for fault in self.faults[symbol]:
            if fault['timestamp'] > block_cutoff:
                return True
        
        return False
    
    def get_penalty(self, symbol: str) -> int:
        """
        Calculate penalty for a symbol based on fault history.
        Newer faults have full penalty, older faults decay.
        """
        if symbol not in self.faults or not self.faults[symbol]:
            return 0
        
        now = datetime.now().timestamp()
        total_penalty = 0
        
        for fault in self.faults[symbol]:
            age_hours = (now - fault['timestamp']) / 3600
            age_days = age_hours / 24
            
            # Calculate decayed penalty
            decayed_penalty = self.penalty_per_fault + (self.decay_per_day * age_days)
            if decayed_penalty < 0:  # Only apply if still negative
                total_penalty += int(decayed_penalty)
        
        # Cap at max penalty
        return max(total_penalty, self.max_penalty)
    
    def get_all_faults(self) -> Dict[str, dict]:
        """Get summary of all faults for UI display."""
        result = {}
        for symbol, faults in self.faults.items():
            if faults:
                penalty = self.get_penalty(symbol)
                is_blocked = self.is_blocked(symbol)
                if penalty < 0 or is_blocked:
                    result[symbol] = {
                        'fault_count': len(faults),
                        'penalty': penalty,
                        'is_blocked': is_blocked,
                        'last_fault': max(f['timestamp'] for f in faults)
                    }
        return result


# Global KillSwitchFaultTracker instance
kill_switch_fault_tracker = KillSwitchFaultTracker()


# ============================================================================
# PHASE 59: COIN PERFORMANCE TRACKER (Coin-Based Learning)
# ============================================================================

class CoinPerformanceTracker:
    """
    Coin bazlƒ± performans takibi ve √∂ƒürenme sistemi.
    Her coin i√ßin win rate, ortalama PnL ve kill switch sayƒ±sƒ±nƒ± takip eder.
    AI optimizer'a veri saƒülar ve d√º≈ü√ºk performanslƒ± coinleri otomatik bloklar.
    """
    
    def __init__(self, min_trades_for_stats: int = 5, block_threshold_wr: float = 20.0):
        self.coin_stats: Dict[str, dict] = {}  # {symbol: stats}
        self.min_trades_for_stats = min_trades_for_stats
        self.block_threshold_wr = block_threshold_wr  # Block if WR < 20%
        self.max_history_per_coin = 50  # Son 50 trade tut
        logger.info("üìä CoinPerformanceTracker initialized (Phase 59)")
    
    def load_from_trade_history(self, trades: list):
        """Mevcut trade history'den coin istatistiklerini y√ºkle."""
        for trade in trades:
            symbol = trade.get('symbol', '')
            if not symbol:
                continue
            
            pnl = trade.get('pnl', 0)
            reason = trade.get('reason', trade.get('closeReason', ''))
            close_time = trade.get('closeTime', 0)
            size_usd = trade.get('size_usd', trade.get('sizeUsd', 100))  # Kaldƒ±ra√ßlƒ± pozisyon
            leverage = trade.get('leverage', 10)  # Kaldƒ±ra√ß
            
            self._record_trade_internal(symbol, pnl, reason, close_time, size_usd, leverage)
        
        logger.info(f"üìä CoinPerformanceTracker: Loaded stats for {len(self.coin_stats)} coins")
    
    def _record_trade_internal(self, symbol: str, pnl: float, reason: str, close_time: int = 0, size_usd: float = 100.0, leverage: int = 10):
        """Dahili trade kayƒ±t fonksiyonu."""
        if symbol not in self.coin_stats:
            self.coin_stats[symbol] = {
                'trades': [],
                'total_trades': 0,
                'wins': 0,
                'losses': 0,
                'total_pnl': 0.0,
                'total_invested': 0.0,  # Toplam yatƒ±rƒ±lan miktar
                'kill_switch_count': 0,
                'last_trade_time': 0
            }
        
        stats = self.coin_stats[symbol]
        
        # Trade kaydet
        stats['trades'].append({
            'pnl': pnl,
            'size_usd': size_usd,  # Kaldƒ±ra√ßlƒ± pozisyon boyutu
            'leverage': leverage,  # Kaldƒ±ra√ß
            'margin': size_usd / leverage if leverage > 0 else size_usd,  # Ger√ßek yatƒ±rƒ±lan
            'reason': reason,
            'time': close_time or int(datetime.now().timestamp() * 1000)
        })
        
        # Son N trade tut
        if len(stats['trades']) > self.max_history_per_coin:
            stats['trades'] = stats['trades'][-self.max_history_per_coin:]
        
        # ƒ∞statistikleri g√ºncelle
        stats['total_trades'] += 1
        stats['total_pnl'] += pnl
        stats['total_invested'] = stats.get('total_invested', 0) + size_usd
        stats['last_trade_time'] = close_time or int(datetime.now().timestamp() * 1000)
        
        if pnl > 0:
            stats['wins'] += 1
        else:
            stats['losses'] += 1
        
        if 'KILL_SWITCH' in reason:
            stats['kill_switch_count'] += 1
    
    def record_trade(self, symbol: str, pnl: float, reason: str):
        """Yeni trade kaydet."""
        self._record_trade_internal(symbol, pnl, reason)
        
        # Coin performance logla
        stats = self.coin_stats.get(symbol, {})
        wr = self.get_win_rate(symbol)
        logger.debug(f"üìä Coin {symbol}: WR={wr:.1f}% | PnL=${pnl:+.2f} | Total=${stats.get('total_pnl', 0):.2f}")
    
    def get_win_rate(self, symbol: str) -> float:
        """Coin'in win rate'ini d√∂nd√ºr."""
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        if total < self.min_trades_for_stats:
            return 50.0  # Yeterli veri yok, n√∂tr
        wins = stats.get('wins', 0)
        return (wins / total) * 100
    
    def get_coin_penalty(self, symbol: str) -> int:
        """
        Coin performansƒ±na g√∂re sinyal puanƒ± cezasƒ± d√∂nd√ºr.
        D√º≈ü√ºk performanslƒ± coinler i√ßin 0-30 puan d√º≈ü√ºr√ºl√ºr.
        """
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        
        if total < self.min_trades_for_stats:
            return 0  # Yeterli veri yok
        
        win_rate = self.get_win_rate(symbol)
        avg_pnl = stats.get('total_pnl', 0) / total
        ks_rate = (stats.get('kill_switch_count', 0) / total) * 100
        
        penalty = 0
        
        # Win rate bazlƒ± ceza
        if win_rate < 25:
            penalty += 20
        elif win_rate < 35:
            penalty += 10
        elif win_rate < 45:
            penalty += 5
        
        # Avg PnL bazlƒ± ceza
        if avg_pnl < -10:
            penalty += 15
        elif avg_pnl < -5:
            penalty += 10
        elif avg_pnl < 0:
            penalty += 5
        
        # Kill switch rate bazlƒ± ceza
        if ks_rate > 40:
            penalty += 15
        elif ks_rate > 25:
            penalty += 10
        elif ks_rate > 15:
            penalty += 5
        
        return min(penalty, 50)  # Max 50 puan ceza
    
    def is_coin_blocked(self, symbol: str) -> bool:
        """Coin'in bloklanƒ±p bloklanmadƒ±ƒüƒ±nƒ± kontrol et."""
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        
        if total < self.min_trades_for_stats:
            return False
        
        win_rate = self.get_win_rate(symbol)
        ks_count = stats.get('kill_switch_count', 0)
        total_pnl = stats.get('total_pnl', 0)
        
        total_invested = stats.get('total_invested', 0)
        trades = stats.get('trades', [])
        
        # Kriter 1: Herhangi bir pozisyonda yatƒ±rƒ±lan MARGIN'ƒ± kaybettiyse blokla
        # Margin = size_usd / leverage (ger√ßek yatƒ±rƒ±lan para)
        # √ñrn: $100 margin, -$100 veya daha fazla zarar ‚Üí blokla
        for trade in trades:
            trade_size = trade.get('size_usd', 100)
            trade_leverage = trade.get('leverage', 10)
            trade_margin = trade_size / trade_leverage if trade_leverage > 0 else trade_size
            trade_pnl = trade.get('pnl', 0)
            # Margin kaybƒ± >= margin boyutu (100%+ kayƒ±p)
            if trade_pnl < 0 and abs(trade_pnl) >= trade_margin:
                return True
        
        # Kriter 2: Win rate √ßok d√º≈ü√ºk
        if win_rate < self.block_threshold_wr:
            return True
        
        # Kriter 3: √áok fazla kill switch
        if ks_count >= 5 and (ks_count / total) > 0.4:  # %40+ KS rate
            return True
        
        return False
    
    def get_worst_performers(self, limit: int = 10) -> list:
        """En k√∂t√º performanslƒ± coinleri d√∂nd√ºr."""
        performers = []
        for symbol, stats in self.coin_stats.items():
            total = stats.get('total_trades', 0)
            if total < self.min_trades_for_stats:
                continue
            
            win_rate = self.get_win_rate(symbol)
            avg_pnl = stats.get('total_pnl', 0) / total
            
            performers.append({
                'symbol': symbol,
                'win_rate': round(win_rate, 1),
                'avg_pnl': round(avg_pnl, 2),
                'total_pnl': round(stats.get('total_pnl', 0), 2),
                'trades': total,
                'ks_count': stats.get('kill_switch_count', 0),
                'penalty': self.get_coin_penalty(symbol)
            })
        
        # Total PnL'e g√∂re sƒ±rala (en k√∂t√ºden en iyiye)
        performers.sort(key=lambda x: x['total_pnl'])
        return performers[:limit]
    
    def get_best_performers(self, limit: int = 10) -> list:
        """En iyi performanslƒ± coinleri d√∂nd√ºr."""
        performers = []
        for symbol, stats in self.coin_stats.items():
            total = stats.get('total_trades', 0)
            if total < self.min_trades_for_stats:
                continue
            
            win_rate = self.get_win_rate(symbol)
            avg_pnl = stats.get('total_pnl', 0) / total
            
            performers.append({
                'symbol': symbol,
                'win_rate': round(win_rate, 1),
                'avg_pnl': round(avg_pnl, 2),
                'total_pnl': round(stats.get('total_pnl', 0), 2),
                'trades': total,
                'ks_count': stats.get('kill_switch_count', 0)
            })
        
        # Total PnL'e g√∂re sƒ±rala (en iyiden en k√∂t√ºye)
        performers.sort(key=lambda x: x['total_pnl'], reverse=True)
        return performers[:limit]
    
    def get_stats_for_optimizer(self) -> dict:
        """AI optimizer i√ßin coin istatistiklerini d√∂nd√ºr."""
        worst = self.get_worst_performers(5)
        best = self.get_best_performers(5)
        
        blocked_coins = [s for s in self.coin_stats.keys() if self.is_coin_blocked(s)]
        
        return {
            'worst_performers': worst,
            'best_performers': best,
            'blocked_coins': blocked_coins,
            'total_coins_tracked': len(self.coin_stats)
        }
    
    def get_all_stats(self) -> dict:
        """T√ºm coin istatistiklerini d√∂nd√ºr."""
        return {
            'coins': len(self.coin_stats),
            'worst_performers': self.get_worst_performers(10),
            'best_performers': self.get_best_performers(10),
            'blocked_coins': [s for s in self.coin_stats.keys() if self.is_coin_blocked(s)]
        }


# Global CoinPerformanceTracker instance
coin_performance_tracker = CoinPerformanceTracker()

# ============================================================================
# PHASE 36: ORDER BOOK IMBALANCE DETECTOR
# ============================================================================

class OrderBookImbalanceDetector:
    """
    Detects order book imbalance (OBI) to identify buying/selling pressure.
    
    Formula: OBI = (Bid_Qty - Ask_Qty) / (Bid_Qty + Ask_Qty)
    - OBI > 0.3: Strong buying pressure ‚Üí LONG boost
    - OBI < -0.3: Strong selling pressure ‚Üí SHORT boost
    """
    
    def __init__(self, threshold: float = 0.3, depth_levels: int = 5):
        self.threshold = threshold  # OBI threshold for signals
        self.depth_levels = depth_levels  # How many levels to analyze
        self.obi_cache = {}  # symbol -> {obi, timestamp}
        self.cache_ttl = 5  # Cache for 5 seconds
        logger.info(f"üìä OrderBookImbalanceDetector initialized: threshold={threshold}, depth={depth_levels}")
    
    async def fetch_depth(self, symbol: str) -> dict:
        """Fetch L2 depth data from Binance."""
        try:
            import aiohttp
            # Convert symbol format (BTCUSDT -> BTCUSDT)
            formatted = symbol.replace('/', '')
            url = f"https://fapi.binance.com/fapi/v1/depth?symbol={formatted}&limit=20"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=2) as resp:
                    if resp.status == 200:
                        return await resp.json()
            return {}
        except Exception as e:
            logger.debug(f"Depth fetch error for {symbol}: {e}")
            return {}
    
    def calculate_obi(self, bids: list, asks: list) -> float:
        """
        Calculate Order Book Imbalance.
        
        Args:
            bids: List of [price, quantity] for bids
            asks: List of [price, quantity] for asks
            
        Returns:
            OBI value between -1 and 1
        """
        try:
            # Sum top N levels
            bid_qty = sum(float(b[1]) for b in bids[:self.depth_levels]) if bids else 0
            ask_qty = sum(float(a[1]) for a in asks[:self.depth_levels]) if asks else 0
            
            total = bid_qty + ask_qty
            if total == 0:
                return 0.0
            
            obi = (bid_qty - ask_qty) / total
            return round(obi, 4)
            
        except Exception as e:
            logger.debug(f"OBI calculation error: {e}")
            return 0.0
    
    async def get_obi(self, symbol: str) -> float:
        """Get OBI for symbol (with caching)."""
        now = datetime.now().timestamp()
        
        # Check cache
        if symbol in self.obi_cache:
            cached = self.obi_cache[symbol]
            if now - cached['timestamp'] < self.cache_ttl:
                return cached['obi']
        
        # Fetch fresh data
        depth = await self.fetch_depth(symbol)
        if not depth:
            return self.obi_cache.get(symbol, {}).get('obi', 0.0)
        
        bids = depth.get('bids', [])
        asks = depth.get('asks', [])
        obi = self.calculate_obi(bids, asks)
        
        # Update cache
        self.obi_cache[symbol] = {
            'obi': obi,
            'timestamp': now,
            'bid_qty': sum(float(b[1]) for b in bids[:self.depth_levels]) if bids else 0,
            'ask_qty': sum(float(a[1]) for a in asks[:self.depth_levels]) if asks else 0,
            # Phase 212: USD depth for Thin Book Guard
            'total_bid_usd': sum(float(b[0]) * float(b[1]) for b in bids[:self.depth_levels]) if bids else 0,
            'total_ask_usd': sum(float(a[0]) * float(a[1]) for a in asks[:self.depth_levels]) if asks else 0,
        }
        
        return obi
    
    def get_signal_boost(self, symbol: str, action: str) -> tuple:
        """
        Get score boost based on OBI alignment with signal direction.
        
        Returns:
            (boost_points: int, reason: str)
        """
        cached = self.obi_cache.get(symbol, {})
        obi = cached.get('obi', 0)
        
        if abs(obi) < self.threshold:
            return (0, "OBI neutral")
        
        # Strong buying pressure
        if obi > self.threshold:
            if action == "LONG":
                return (15, f"OBI aligned +{obi:.2f}")
            elif action == "SHORT":
                return (-10, f"OBI opposing +{obi:.2f}")
        
        # Strong selling pressure
        elif obi < -self.threshold:
            if action == "SHORT":
                return (15, f"OBI aligned {obi:.2f}")
            elif action == "LONG":
                return (-10, f"OBI opposing {obi:.2f}")
        
        return (0, "OBI neutral")
    
    def get_status(self) -> dict:
        """Get OBI detector status for debugging."""
        return {
            "cached_symbols": len(self.obi_cache),
            "threshold": self.threshold,
            "depth_levels": self.depth_levels,
            "top_imbalances": sorted(
                [(s, d['obi']) for s, d in self.obi_cache.items()],
                key=lambda x: abs(x[1]),
                reverse=True
            )[:10]
        }


# Global OBI Detector instance
obi_detector = OrderBookImbalanceDetector()


# Legacy function for backwards compatibility
def calculate_imbalance(bids: list, asks: list) -> float:
    """
    Calculate order book imbalance (legacy wrapper).
    Positive = Bullish, Negative = Bearish
    """
    return obi_detector.calculate_obi(bids, asks) * 100  # Return as percentage


# ============================================================================
# MARKET REGIME DETERMINATION
# ============================================================================

def get_market_regime(hurst: float) -> str:
    """Determine market regime based on Hurst Exponent."""
    if hurst > 0.55:
        return "TREND TAKƒ∞Bƒ∞"
    elif hurst < 0.45:
        return "ORTALAMAYA D√ñN√ú≈û"
    else:
        return "RASTGELE Y√úR√úY√ú≈û"



# ============================================================================
# VWAP CALCULATION
# ============================================================================

def calculate_vwap(closes: list, volumes: list, prices: list) -> float:
    """
    Calculate Volume Weighted Average Price (VWAP).
    VWAP = Sum(Price * Volume) / Sum(Volume)
    """
    if not volumes or not prices:
        return closes[-1] if closes else 0.0
    
    try:
        # Use typical price for VWAP (High + Low + Close) / 3 if available, else Close
        # Here we use passed prices (closes or typical)
        # FORCE SLICING MATCH
        min_len = min(len(prices), len(volumes))
        if min_len == 0: return 0.0
        
        prices_arr = np.array(prices[-min_len:])
        volumes_arr = np.array(volumes[-min_len:])
        
        # Calculate for the window
        vwap = np.sum(prices_arr * volumes_arr) / np.sum(volumes_arr)
        return float(vwap)
    except Exception as e:
        logger.warning(f"VWAP calc error: {e}")
        return float(closes[-1])

# ============================================================================
# ADAPTIVE THRESHOLD (ATR-BASED)
# ============================================================================

def calculate_adaptive_threshold(base_threshold: float, atr: float, price: float, hurst: float = 0.5) -> float:
    """
    Adjust Z-Score threshold based on volatility (ATR) AND Hurst exponent.
    
    Hurst-based adjustment (Phase 128):
    - Hurst < 0.4 (Mean Reverting) -> Lower threshold (easier to enter, MR strategy)
    - Hurst = 0.5 (Random Walk) -> No change
    - Hurst > 0.6 (Trending) -> Higher threshold (harder to enter, need stronger signal)
    
    ATR-based adjustment:
    - High ATR -> Higher threshold (need bigger move in volatile markets)
    - Low ATR -> Lower threshold (smaller moves are significant)
    """
    if price == 0: return base_threshold
    
    threshold = base_threshold
    
    # 1. Hurst Factor (Phase 184) - NARROWED RANGE for more signals
    # Linear interpolation: H=0.2 ‚Üí 0.8x factor, H=0.5 ‚Üí 1.0x, H=0.8 ‚Üí 1.2x
    # Narrower range (was 0.6x-1.4x) so hurst doesn't over-inflate threshold
    hurst_factor = 1.0 + (hurst - 0.5) * 0.67
    
    # Clamp factor to narrower bounds (0.8x to 1.2x)
    hurst_factor = max(0.8, min(1.2, hurst_factor))
    
    threshold *= hurst_factor
    
    # 2. ATR Factor (existing logic)
    atr_pct = (atr / price) * 100
    
    # Phase 184: Reduced ATR inflation (was 1.2x ‚Üí 1.1x)
    if atr_pct > 2.0:  # High volatility
        threshold *= 1.1  # 10% harder (was 20%)
    elif atr_pct < 0.5:  # Low volatility
        threshold *= 0.85  # 15% easier
    
    return threshold

# ============================================================================
# SIGNAL GENERATOR (4-Layer Logic)
# ============================================================================

class SignalGenerator:
    """
    4-Layer signal generation based on DEVELOPER_HANDBOOK.
    
    Layer 1: Hurst Regime Filter
    Layer 2: Z-Score Threshold
    Layer 3: Liquidation Cascade
    Layer 4: Order Book Confirmation
    """
    
    def __init__(self):
        self.last_signal_time: float = 0
        self.min_signal_interval: float = 15.0  # RELAXED: 30s -> 15s for more signals
        self.liquidation_threshold: float = 100000  # $100k for cascade detection
        self.recent_liquidations: deque = deque(maxlen=50)
        self.leverage: int = 10 # Default Leverage
        logger.info(f"SignalGenerator Initialized (RELAXED). Leverage: {self.leverage}")
        
    def check_liquidation_cascade(self) -> tuple[bool, float]:
        """
        Check if there's a liquidation cascade.
        Returns (is_cascade, total_volume)
        """
        now = datetime.now().timestamp()
        # Look at liquidations in the last 30 seconds
        recent = [liq for liq in self.recent_liquidations 
                  if now - liq['timestamp'] < 30]
        
        if not recent:
            return False, 0
            
        total_volume = sum(liq['amount'] for liq in recent)
        is_cascade = total_volume > self.liquidation_threshold
        
        return is_cascade, total_volume
    
    def add_liquidation(self, side: str, amount: float, price: float):
        """Add a liquidation event."""
        self.recent_liquidations.append({
            'side': side,
            'amount': amount,
            'price': price,
            'timestamp': datetime.now().timestamp()
        })
    
    def generate_signal(
        self,
        hurst: float,
        zscore: float,
        imbalance: float,
        price: float,
        atr: float,
        vwap_zscore: float = 0.0,
        htf_trend: str = "NEUTRAL",
        leverage: int = 10,
        basis_pct: float = 0.0,
        whale_zscore: float = 0.0,
        nearest_fvg: Optional[Dict] = None,
        breakout: Optional[str] = None,
        spread_pct: float = 0.05, # Phase 13
        volatility_ratio: float = 1.0, # Phase 13
        coin_profile: Optional[Dict] = None,  # Phase 28: Dynamic coin profile
        symbol: str = "BTCUSDT",  # Symbol for liquidation cascade lookup
        rsi: float = 50.0,  # RSI value (0-100)
        volume_ratio: float = 1.0,  # Current volume / avg volume
        sweep_result: Optional[Dict] = None,  # Liquidity sweep detection result
        coin_stats: Optional[Dict] = None,  # Coin-specific stats for dynamic thresholds
        coin_daily_trend: str = "NEUTRAL",  # Coin's own daily trend
        volume_24h: float = 0.0,  # Phase 123: 24h Volume for liquidity check
        adx: float = 25.0,  # ADX value for trend strength
        adx_trend: str = "NEUTRAL",  # Trend direction: BULLISH/BEARISH/NEUTRAL
        is_volume_spike: bool = False,  # Volume breakout detection
        market_regime: str = "RANGING",  # Phase 156: Market regime from MarketRegimeDetector
        ob_imbalance_trend: float = 0.0,  # Phase 156: Short-term order book imbalance trend
        funding_rate: float = 0.0,  # Phase 157: Funding rate for contrarian scoring
        coin_wr_penalty: int = 0,  # Phase 157: Coin WR penalty from trade pattern analysis
        side_wr_penalty: int = 0,  # Phase 157: Side WR penalty from trade pattern analysis
        enhanced_indicators: Optional[Dict] = None,  # Phase 193: MACD, BB, StochRSI, EMA cross
        fib_context: Optional[Dict] = None,  # Phase FIB: Fibonacci retracement context
    ) -> Optional[Dict[str, Any]]:
        """
        Generate signal based on 13 Layers of confluence (SMC + Breakouts + RSI + Volume + Sweep).
        Uses coin_profile for dynamic threshold and minimum score.
        """
        now = datetime.now().timestamp()
        
        # PHASE 102: Debug signal generation attempts (log every 100th)
        if not hasattr(self, '_attempt_count'):
            self._attempt_count = 0
        self._attempt_count += 1
        
        # Check minimum interval
        if now - self.last_signal_time < self.min_signal_interval:
            return None
        
        # ===================================================================
        # SAAT BAZLI Fƒ∞LTRE KALDIRILDI (Phase 101)
        # Kullanƒ±cƒ± talebiyle 7/24 sinyal √ºretimi aktif
        # Risk: D√º≈ü√ºk likidite saatlerinde spread y√ºksek olabilir
        # ===================================================================

        

        # Phase 28: Dynamic threshold from coin profile
        # Phase 152 FIX: User's min_confidence_score is always the floor
        user_min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 65
        # Phase 224D: Apply regime offset to min_score
        try:
            user_min_score = market_regime_manager.get_adjusted_min_score(user_min_score)
            user_min_score = max(40, min(95, user_min_score))  # Clamp to sane range
        except Exception:
            pass
        
        if coin_profile:
            base_threshold = coin_profile.get('optimal_threshold', 1.6)
            # Phase 152: coin_profile min_score cannot go below user's setting
            coin_min = coin_profile.get('min_score', 55)
            min_score_required = max(coin_min, user_min_score)
            is_backtest = coin_profile.get('is_backtest', False)
            logger.debug(f"Using coin profile: threshold={base_threshold}, min_score={min_score_required} (coin={coin_min}, user={user_min_score})")
        else:
            base_threshold = 1.5
            min_score_required = user_min_score
            is_backtest = False
        
        # Leverage Scaling:
        # 10x = 1.0x factor (No change)
        # 20x = 1.1x factor
        # 50x = 1.4x factor (+40% stricter)
        leverage_factor = 1.0 + max(0, (leverage - 10) / 100)
        
        # In backtest mode, skip adaptive threshold to allow more signals
        if is_backtest:
            effective_threshold = base_threshold
        else:
            # Phase 128: Pass hurst to calculate_adaptive_threshold for per-coin dynamic threshold
            adaptive_threshold = calculate_adaptive_threshold(base_threshold, atr, price, hurst)
            effective_threshold = adaptive_threshold * leverage_factor
        
        # Phase 120: Log AFTER effective_threshold is calculated
        if self._attempt_count % 100 == 1:
            exceeds = "‚úÖ PASS" if abs(zscore) > effective_threshold else "‚ùå FAIL"
            logger.info(f"üî¨ SIGNAL_CHECK #{self._attempt_count}: {symbol} H={hurst:.2f} Z={zscore:.2f} eff_thresh={effective_threshold:.2f} {exceeds}")
        
        # 2. CONFIDENCE SCORING SYSTEM (0-100)
        score = 0
        reasons = []
        
        # =====================================================================
        # PHASE 108: SIMPLIFIED MEAN REVERSION SIGNAL DIRECTION
        # Z-Score is designed for mean reversion - always use contrarian logic:
        # - zscore > +threshold (overbought) ‚Üí SHORT (price will revert down)
        # - zscore < -threshold (oversold) ‚Üí LONG (price will revert up)
        # Hurst is used for SCORING only, not direction determination.
        # =====================================================================
        
        signal_side = None
        
        # Simple mean reversion logic (contrarian)
        if abs(zscore) > effective_threshold:
            if zscore > effective_threshold:
                signal_side = "SHORT"
                reasons.append(f"Z(+{zscore:.1f})")
            else:  # zscore < -effective_threshold
                signal_side = "LONG"
                reasons.append(f"Z({zscore:.1f})")
            
            # Phase 152: Base score 50 ‚Äî Z-Score g√º√ßl√º sinyal, 1 aligned katman yeterli
            score += 50
            
            # Phase 152: Hurst etkisi artƒ±k SADECE threshold'da (calculate_adaptive_threshold)
            # Scoring'deki √ßifte etki kaldƒ±rƒ±ldƒ± ‚Äî tutarlƒ±lƒ±k i√ßin
            if hurst < 0.45:
                reasons.append(f"H_MR({hurst:.2f})")  # Log only, no score change
        else:
            return None  # Z-Score not extreme enough
        
        if signal_side is None:
            return None
        
        # =====================================================================
        # Phase 212: STRONG_TREND_FILTER kaldƒ±rƒ±ldƒ± (ADX>40)
        # REGIME_VETO (ADX>30 + Hurst>0.55) aynƒ± i≈üi daha hassas yapƒ±yor.
        # ADX>40 filtresi hi√ß tetiklenmiyordu √ß√ºnk√º REGIME_VETO daha √∂nce yakalƒ±yordu.
        # ADX trend alignment bonusu korundu.
        # =====================================================================
        if adx > 30 and adx_trend != "NEUTRAL":
            # ADX trend alignment bonus (sadece y√∂n uyumlu sinyallere)
            if (adx_trend == "BULLISH" and signal_side == "LONG") or \
               (adx_trend == "BEARISH" and signal_side == "SHORT"):
                score += 5
                reasons.append(f"ADX_ALIGN({adx:.0f})")
        
        # Volume spike warning (for breakout detection)
        if is_volume_spike:
            # Volume spike during strong trend = breakout confirmation
            if adx > 25:
                score += 5  # Trend + volume spike = strong continuation
                reasons.append(f"VOL_SPIKE(trend)")
            else:
                # Volume spike without clear trend - could be reversal or manipulation
                logger.info(f"üìä VOLUME_SPIKE: {symbol} vol_ratio={volume_ratio:.1f}x without strong trend")
        
        # Phase 128: TRACE LOG - every signal that passes Z-Score threshold
        logger.info(f"üéØ Z_PASS: {symbol} {signal_side} Z={zscore:.2f} H={hurst:.2f} score={score}")
        
        # =====================================================================
        # Phase 212: SPIKE PROTECTION (Pump-Dump Guard)
        # Fiyat ATR'nin 10x'i kadar hareket ettiyse pump-dump riski y√ºksek.
        # Z-Score ge√ßmi≈üe baktƒ±ƒüƒ± i√ßin spike sonrasƒ± "ucuz" g√∂rebilir.
        # ATR normalden 10x+ fark = a≈üƒ±rƒ± hareket, sinyal verme.
        # =====================================================================
        if atr > 0:
            # Z-Score excess + ATR combination: if zscore is extreme AND volatility spike
            spike_ratio = abs(zscore) * (price * 0.01 / atr) if atr > 0 else 0
            # If the price move is so extreme that ATR-normalized Z is >15, it's a pump-dump
            if abs(zscore) > 4.0 and volume_ratio > 3.0:
                logger.info(f"üö® SPIKE_GUARD: {symbol} {signal_side} BLOCKED | Z={zscore:.2f} Vol={volume_ratio:.1f}x | Pump-dump risk")
                return None
        
        # Bonus based on Z-Score strength (0-10 pts extra)
        zscore_excess = abs(zscore) - effective_threshold
        zscore_bonus = min(10, int(zscore_excess * 5))  # Each 0.2 above threshold = +1 pt
        score += zscore_bonus
        
        # Log signal direction determination
        logger.debug(f"Phase 108: {symbol} H={hurst:.2f} Z={zscore:.2f} ‚Üí {signal_side}")
            
        # Layer 2: Order Book Imbalance (Confirmation) - Max 20 pts
        # Graduated scoring based on imbalance strength
        ob_aligned = False
        ob_score = 0
        if signal_side == "LONG" and imbalance > 0:
            if imbalance >= 10:
                ob_score = 20  # Strong buying pressure
            elif imbalance >= 5:
                ob_score = 15  # Good buying pressure
            elif imbalance >= 2:
                ob_score = 10  # Moderate buying pressure
            if ob_score > 0:
                score += ob_score
                ob_aligned = True
                reasons.append(f"OB(+{imbalance:.1f}%={ob_score}p)")
        elif signal_side == "SHORT" and imbalance < 0:
            if imbalance <= -10:
                ob_score = 20  # Strong selling pressure
            elif imbalance <= -5:
                ob_score = 15  # Good selling pressure
            elif imbalance <= -2:
                ob_score = 10  # Moderate selling pressure
            if ob_score > 0:
                score += ob_score
                ob_aligned = True
                reasons.append(f"OB({imbalance:.1f}%={ob_score}p)")
            
        # Layer 3: VWAP Z-Score (Mean Reversion Check) - Max 20 pts
        # RELAXED: 1.0 -> 0.7 threshold for easier confirmation
        vwap_aligned = False
        if signal_side == "LONG" and vwap_zscore < -0.7:
            score += 20
            vwap_aligned = True
            reasons.append(f"VWAP({vwap_zscore:.1f})")
        elif signal_side == "SHORT" and vwap_zscore > 0.7:
            score += 20
            vwap_aligned = True
            reasons.append(f"VWAP({vwap_zscore:.1f})")
            
        # Layer 4: Coin Daily Trend (Max 15 pts)
        # Phase 152: COIN-ONLY ‚Äî BTC kontrol√º should_allow_signal'da yapƒ±lƒ±yor (√ßifte filtre fixlendi)
        # Sadece coin'in kendi daily trend'ine g√∂re skor
        mtf_score = 0
        if signal_side == "LONG":
            if coin_daily_trend == "STRONG_BULLISH":
                mtf_score = 15
            elif coin_daily_trend == "BULLISH":
                mtf_score = 10
            elif coin_daily_trend == "NEUTRAL":
                mtf_score = 0
            elif coin_daily_trend == "BEARISH":
                mtf_score = -10
            elif coin_daily_trend == "STRONG_BEARISH":
                mtf_score = -20  # G√º√ßl√º penalty ama VETO deƒüil
        else: # SHORT
            if coin_daily_trend == "STRONG_BEARISH":
                mtf_score = 15
            elif coin_daily_trend == "BEARISH":
                mtf_score = 10
            elif coin_daily_trend == "NEUTRAL":
                mtf_score = 0
            elif coin_daily_trend == "BULLISH":
                mtf_score = -10
            elif coin_daily_trend == "STRONG_BULLISH":
                mtf_score = -20  # G√º√ßl√º penalty ama VETO deƒüil
            
        score += mtf_score
        reasons.append(f"COIN_TREND({coin_daily_trend}={mtf_score})")
        
        # Layer 5: Liquidation Cascade (Bonus) - Max 15 pts
        # Uses real-time liquidation stream from Binance
        liq_score, liq_reason = liquidation_tracker.get_cascade_score(symbol if symbol else 'BTCUSDT', signal_side)
        if liq_score > 0:
            score += liq_score
            reasons.append(liq_reason)

        # Layer 6: Spot-Futures Basis (Sentiment) - Max 10 pts
        # Contango (Basis > 0) favors Longs, Backwardation favors Shorts
        # Threshold: 0.02% (2 bps)
        if signal_side == "LONG" and basis_pct > 0.02:
            score += 10
            reasons.append(f"Basis(+{basis_pct:.2f}%)")
        elif signal_side == "SHORT" and basis_pct < -0.02:
            score += 10
            reasons.append(f"Basis({basis_pct:.2f}%)")

        # Layer 7: Whale Sentiment (Real-Time AggTrades) - Max 15 pts
        if signal_side == "LONG" and whale_zscore > 2.0:
            score += 15
            reasons.append(f"WhaleBuy(Z:{whale_zscore:.1f})")
        elif signal_side == "SHORT" and whale_zscore < -2.0:
            score += 15
            reasons.append(f"WhaleSell(Z:{whale_zscore:.1f})")

        # Layer 8: SMC Fair Value Gaps (Magnets/Filters) - Max +/- 20 pts
        if nearest_fvg:
            fvg_type = nearest_fvg['type'] # BULLISH or BEARISH
            # Distance check (is price INSIDE or very close?)
            # Top/Bottom are price levels.
            # If LONG and FVG is BEARISH (Resistance) and we are close below it -> DANGER
            # If LONG and FVG is BULLISH (Support) and we are close above it -> SUPPORT
            
            # Simple Logic: Check Type compatibility
            # Bullish FVG supports LONGs. Bearish FVG supports SHORTs.
            
            if signal_side == "LONG":
                if fvg_type == "BULLISH":
                    score += 10
                    reasons.append("SMC(Support)")
                elif fvg_type == "BEARISH":
                     # HITTING RESISTANCE?
                     # Only if we are below it and close.
                     # Simplified: Just penalize fighting the magnet type
                     score -= 20
                     reasons.append("SMC(Resistance!)")
                     
            elif signal_side == "SHORT":
                if fvg_type == "BEARISH":
                    score += 10
                    reasons.append("SMC(Resistance)")
                elif fvg_type == "BULLISH":
                    score -= 20
                    reasons.append("SMC(Support!)")
                    
        # Layer 9: Dynamic S/R Breakout (Trend Following) - Phase 11
        # If Breakout Signal exists AND Hurst > 0.5 (Trend Regime)
        if breakout:
             if hurst > 0.5:
                 if breakout == "BREAKOUT_LONG" and signal_side == "LONG":
                     score += 25
                     reasons.append("BREAKOUT(Trend)")
                 elif breakout == "BREAKOUT_SHORT" and signal_side == "SHORT":
                     score += 25
                     reasons.append("BREAKDOWN(Trend)")
             elif hurst < 0.4:
                 # Mean Reversion Regime: Breakouts are often Fakeouts!
                 # Or actually, if Z-Score says LONG (Oversold) but we have breakdown...
                 # It's mixed signals.
                 score -= 10
                 reasons.append("FakeoutRisk")

        # =====================================================================
        # PHASE 136: BONUS-ONLY SCORING LAYERS
        # SADECE BONUS verir, asla penalty vermez - sinyal akƒ±≈üƒ±nƒ± bozmaz
        # =====================================================================
        
        # Layer 10: RSI Momentum Bonus (+5/+8)
        # LONG + oversold = bonus, SHORT + overbought = bonus
        if signal_side == "LONG" and rsi < 35:
            rsi_bonus = 8 if rsi < 25 else 5
            score += rsi_bonus
            reasons.append(f"RSI_OS({rsi:.0f})+{rsi_bonus}")
        elif signal_side == "SHORT" and rsi > 65:
            rsi_bonus = 8 if rsi > 75 else 5
            score += rsi_bonus
            reasons.append(f"RSI_OB({rsi:.0f})+{rsi_bonus}")
        
        # Layer 11: Volume Spike Bonus (+5/+8)
        # volume_ratio is passed as parameter (default=1.0)
        if volume_ratio >= 1.5:
            vol_bonus = 8 if volume_ratio >= 2.0 else 5
            score += vol_bonus
            reasons.append(f"VOL({volume_ratio:.1f}x)+{vol_bonus}")
        
        # Layer 12: SMT Divergence Bonus (+10)
        # Uses existing smt_divergence_detector.last_divergence (no new API call)
        try:
            smt_div_bonus = smt_divergence_detector.last_divergence
            if smt_div_bonus and smt_div_bonus.get('divergence_type'):
                smt_type = smt_div_bonus['divergence_type']
                smt_age = datetime.now().timestamp() - smt_divergence_detector.divergence_time
                if smt_age < 300:  # Son 5 dakika
                    if smt_type == "BULLISH" and signal_side == "LONG":
                        score += 10
                        reasons.append("SMT_BULL+10")
                    elif smt_type == "BEARISH" and signal_side == "SHORT":
                        score += 10
                        reasons.append("SMT_BEAR+10")
        except Exception:
            pass  # SMT detector not ready
        
        # Layer 13: VWAP Sweet Zone Bonus (+5)
        # vwap_zscore is passed as parameter (default=0.0)
        if vwap_zscore != 0:
            vwap_dev = abs(vwap_zscore)
            # Sweet spot: 0.5-2.0 sigma away from VWAP (ideal mean reversion)
            if 0.5 <= vwap_dev <= 2.0:
                score += 5
                reasons.append(f"VWAP_ZONE({vwap_dev:.1f}œÉ)+5")
        
        # =====================================================================
        # PHASE 156: LAYER 16 ‚Äî ORDER BOOK IMBALANCE TREND (Short-term Flow)
        # Son 5 dakika bid/ask imbalance trend'i ‚Äî alƒ±cƒ±/satƒ±cƒ± baskƒ±sƒ±nƒ± √∂l√ßer
        # =====================================================================
        if abs(ob_imbalance_trend) > 2.0:
            if signal_side == "LONG" and ob_imbalance_trend > 2.0:
                ib_bonus = 8 if ob_imbalance_trend > 5.0 else 5
                score += ib_bonus
                reasons.append(f"IB_TREND(+{ob_imbalance_trend:.1f})+{ib_bonus}")
            elif signal_side == "SHORT" and ob_imbalance_trend < -2.0:
                ib_bonus = 8 if ob_imbalance_trend < -5.0 else 5
                score += ib_bonus
                reasons.append(f"IB_TREND({ob_imbalance_trend:.1f})+{ib_bonus}")
            elif signal_side == "LONG" and ob_imbalance_trend < -5.0:
                score -= 5
                reasons.append(f"IB_CONTRA({ob_imbalance_trend:.1f})-5")
            elif signal_side == "SHORT" and ob_imbalance_trend > 5.0:
                score -= 5
                reasons.append(f"IB_CONTRA({ob_imbalance_trend:.1f})-5")
        
        # =====================================================================
        # PHASE 157: LAYER 17 ‚Äî FUNDING RATE CONTRARIAN SCORING
        # Funding rate'e g√∂re contrarian bonus/penalty/veto
        # =====================================================================
        if funding_rate != 0:
            fr_adj, fr_reason, fr_veto = funding_oi_tracker.get_funding_signal(symbol, signal_side)
            if fr_veto:
                logger.info(f"üö´ FUNDING_VETO: {symbol} {signal_side} ‚Äî {fr_reason}")
                return None
            if fr_adj != 0:
                score += fr_adj
                reasons.append(f"{fr_reason}{'+' if fr_adj > 0 else ''}{fr_adj}")
        
        # =====================================================================
        # PHASE 157: LAYER 18 ‚Äî TRADE PATTERN PENALTY/BONUS
        # Kapanmƒ±≈ü trade analizi ‚Äî d√º≈ü√ºk WR coin/side'a penalty
        # =====================================================================
        if coin_wr_penalty != 0:
            score += coin_wr_penalty
            reasons.append(f"COIN_WR({coin_wr_penalty:+d})")
        # Side penalty ‚Äî calculated here where signal_side is known
        actual_side_penalty = trade_pattern_analyzer.get_side_penalty(signal_side)
        if actual_side_penalty != 0:
            score += actual_side_penalty
            reasons.append(f"SIDE_WR({actual_side_penalty:+d})")
        
        # Layer 14: POC Proximity Bonus (+5/+8)
        # coin_profile is passed as parameter (default=None)
        if coin_profile and coin_profile.get('poc', 0) > 0:
            poc = coin_profile['poc']
            poc_dist_pct = abs(price - poc) / poc * 100
            if poc_dist_pct < 2.0:
                score += 8
                reasons.append(f"POC_NEAR({poc_dist_pct:.1f}%)+8")
            elif poc_dist_pct < 5.0:
                score += 5
                reasons.append(f"POC_zone({poc_dist_pct:.1f}%)+5")
        
        # =====================================================================
        # PHASE 193: ENHANCED INDICATOR SCORING LAYERS (pandas-ta powered)
        # BONUS-ONLY ‚Äî Sadece destekleyici skor, asla VETO veya penalty deƒüil
        # =====================================================================
        if enhanced_indicators:
            ei = enhanced_indicators
            
            # Layer 19: MACD Momentum Confirmation (+5/+8)
            # MACD histogram sinyal y√∂n√ºn√º onaylƒ±yorsa bonus
            macd_hist = ei.get('macd_histogram', 0)
            macd_cross = ei.get('macd_signal_cross', 'NEUTRAL')
            if signal_side == "LONG":
                if macd_cross == 'BULLISH':
                    score += 8
                    reasons.append("MACD_CROSS_BULL+8")
                elif macd_hist > 0:
                    score += 5
                    reasons.append(f"MACD_POS+5")
            elif signal_side == "SHORT":
                if macd_cross == 'BEARISH':
                    score += 8
                    reasons.append("MACD_CROSS_BEAR+8")
                elif macd_hist < 0:
                    score += 5
                    reasons.append(f"MACD_NEG+5")
            
            # Layer 20: Bollinger Bands Position Confirmation (+5/+8)
            # LONG + fiyat alt BB'de = d√º≈ü√ºk fiyat desteƒüi, SHORT + fiyat √ºst BB'de
            bb_pos = ei.get('bb_position', 0)
            if signal_side == "LONG" and bb_pos < -0.5:
                bb_bonus = 8 if bb_pos < -0.8 else 5
                score += bb_bonus
                reasons.append(f"BB_LOW({bb_pos:.2f})+{bb_bonus}")
            elif signal_side == "SHORT" and bb_pos > 0.5:
                bb_bonus = 8 if bb_pos > 0.8 else 5
                score += bb_bonus
                reasons.append(f"BB_HIGH({bb_pos:.2f})+{bb_bonus}")
            
            # Layer 21: Stochastic RSI Confirmation (+5/+8)
            # StochRSI crossover + extreme zone = g√º√ßl√º momentum sinyali
            stoch_k = ei.get('stoch_rsi_k', 50)
            stoch_cross = ei.get('stoch_rsi_cross', 'NEUTRAL')
            if signal_side == "LONG":
                if stoch_cross == 'BULLISH':
                    score += 8
                    reasons.append(f"SRSI_BULL({stoch_k:.0f})+8")
                elif stoch_k < 20:
                    score += 5
                    reasons.append(f"SRSI_OS({stoch_k:.0f})+5")
            elif signal_side == "SHORT":
                if stoch_cross == 'BEARISH':
                    score += 8
                    reasons.append(f"SRSI_BEAR({stoch_k:.0f})+8")
                elif stoch_k > 80:
                    score += 5
                    reasons.append(f"SRSI_OB({stoch_k:.0f})+5")
            
            # Layer 22: EMA Crossover Trend Confirmation (+5)
            # EMA(8) x EMA(21) ‚Äî kƒ±sa vadeli trend y√∂n√º
            ema_cross = ei.get('ema_cross', 'NEUTRAL')
            if signal_side == "LONG" and ema_cross == 'BULLISH':
                score += 5
                reasons.append("EMA_BULL+5")
            elif signal_side == "SHORT" and ema_cross == 'BEARISH':
                score += 5
                reasons.append("EMA_BEAR+5")
        
        # =====================================================================
        # PHASE FIB: FIBONACCI ZONE CONFLUENCE (Layer 23, max +12)
        # Price in Fibonacci retracement zone ‚Üí score bonus
        # =====================================================================
        if FIB_ENABLED and FIB_SCORE_ENABLED and fib_context:
            fib_bonus = fib_context.get('fib_score_bonus', 0)
            if fib_bonus > 0:
                score += fib_bonus
                fib_level = fib_context.get('fib_level', '?')
                fib_conf = fib_context.get('confluence', [])
                conf_str = '+' + '+'.join(fib_conf) if fib_conf else ''
                reasons.append(f"Fib({fib_level},+{fib_bonus}{conf_str})")
            elif fib_context.get('skip_reason'):
                reasons.append(f"FibSkip({fib_context['skip_reason']})")
        
        # =====================================================================
        # PHASE 137: ADX + HURST REGIME DETECTION
        # SADECE BONUS - VETO YOK (Phase 133/134/135'teki hatayƒ± √∂nlemek i√ßin)
        # =====================================================================
        
        # Layer 15: ADX + Hurst Regime Bonus
        # Phase 152: ADX artƒ±k fonksiyon parametresi olarak alƒ±nƒ±yor (L10455)
        # Override kaldƒ±rƒ±ldƒ± ‚Äî ger√ßek ADX deƒüeri kullanƒ±lƒ±r
        
        if adx < 20 and hurst < 0.45:
            # Strong range regime - ideal for mean reversion
            score += 10
            reasons.append(f"RANGE({adx:.0f},{hurst:.2f})+10")
        elif adx > 25 and hurst > 0.55:
            # Trend regime - only warning, NO VETO
            reasons.append(f"TREND_WARN({adx:.0f},{hurst:.2f})")
        
        # =====================================================================
        # PHASE 156: REGIME-SIGNAL VETO FILTER
        # Trend rejiminde kar≈üƒ± y√∂nl√º mean-reversion sinyallerini veto et
        # VOLATILE rejimde min_score'u artƒ±r
        # =====================================================================
        
        # Veto 1: Coin-level trend regime (ADX + Hurst)
        # ADX > 30 VE Hurst > 0.55 ‚Üí g√º√ßl√º trend, MR sinyali riskli
        is_coin_trending = adx > 30 and hurst > 0.55
        
        if is_coin_trending:
            # Trend y√∂n√ºne kar≈üƒ± sinyal = VETO
            if adx_trend == "BULLISH" and signal_side == "SHORT":
                logger.info(f"üö´ REGIME_VETO: {symbol} SHORT rejected ‚Äî coin in BULLISH trend (ADX={adx:.0f}, H={hurst:.2f})")
                return None
            elif adx_trend == "BEARISH" and signal_side == "LONG":
                logger.info(f"üö´ REGIME_VETO: {symbol} LONG rejected ‚Äî coin in BEARISH trend (ADX={adx:.0f}, H={hurst:.2f})")
                return None
        
        # Veto 2: Macro VOLATILE rejimde daha y√ºksek conviction iste
        if market_regime == "VOLATILE":
            volatile_boost = int(min_score_required * 0.15)  # %15 artƒ±r
            min_score_required += volatile_boost
            reasons.append(f"VOL_STRICT(+{volatile_boost})")
            if score < min_score_required:
                logger.info(f"üö´ VOLATILE_VETO: {symbol} {signal_side} score={score} < volatile_min={min_score_required}")
                return None
        
        # =====================================================================
        # Phase 212: BTC TREND GUARD kaldƒ±rƒ±ldƒ±
        # BTC kontrol√º sadece process_signal_for_paper_trading() i√ßinde
        # btc_filter.should_allow_signal() √ºzerinden yapƒ±lƒ±yor.
        # √áift penalty sorununu giderir.
        # =====================================================================
        
        # =====================================================================
        # PHASE 193: STOPLOSS FREQUENCY GUARD CHECK
        # =====================================================================
        if stoploss_frequency_guard.is_locked(symbol):
            lock_reason = stoploss_frequency_guard.get_lock_reason(symbol)
            logger.info(f"üõë SL_GUARD: {symbol} {signal_side} rejected ‚Äî {lock_reason}")
            return None
        
        # =====================================================================
        # PHASE 48: KILL SWITCH FAULT PENALTY + BLOCK
        # =====================================================================
        # Check if coin is BLOCKED (kill switch within last 24h)
        if kill_switch_fault_tracker.is_blocked(symbol):
            logger.info(f"üö´ BLOCKED: {symbol} had kill switch within {kill_switch_fault_tracker.block_hours}h - signal rejected")
            return None
        
        # Apply penalty for coins that have previously triggered kill switch
        ks_penalty = kill_switch_fault_tracker.get_penalty(symbol)
        if ks_penalty < 0:
            score += ks_penalty  # ks_penalty is already negative
            reasons.append(f"KS_FAULT({ks_penalty}p)")
            logger.info(f"üìã Kill Switch Penalty applied to {symbol}: {ks_penalty} points (new score: {score})")
        
        # =====================================================================
        # A≈ûAMA 1: Mƒ∞Nƒ∞MUM SKOR KONTROL√ú
        # =====================================================================
        # Sadece Z-Score, OB, VWAP, MTF (veto i√ßin), Liq Cascade, Basis, Whale, FVG, Breakout skorlarƒ± kullanƒ±ldƒ±
        
        # Phase 137 DEBUG: Trace log to confirm signals reach this point
        logger.info(f"üìç PRE_SCORE: {symbol} {signal_side} score={score} min={min_score_required} | reasons: {','.join(reasons[:4])}")
        
        if score < min_score_required:
            # Debug log for signal rejection (every 50th to avoid spam)
            if hasattr(self, '_reject_count'):
                self._reject_count += 1
            else:
                self._reject_count = 1
            # Phase 137 FIX: Log every 10th rejection instead of 50th for better visibility
            if self._reject_count % 10 == 1:
                logger.info(f"üìä SCORE_LOW: {symbol} {signal_side} score={score} < min={min_score_required} | Z={zscore:.2f} H={hurst:.2f} | reasons: {', '.join(reasons[:5])}")
            return None
        
        # Phase 128: TRACE LOG - score check passed
        logger.info(f"‚úÖ SCORE_PASS: {symbol} {signal_side} score={score} >= min={min_score_required}")
        
        # =====================================================================
        # PHASE EQG: ENTRY QUALITY GATE
        # 3 ko≈üuldan en az 2'si ge√ßmeli, yoksa low-quality entry
        # A: Volume (volume_ratio >= 1.25 VEYA is_volume_spike)
        # B: OB Direction (imbalance/ob_trend sinyalle uyumlu)
        # C: Liquidity (24h vol >= $1.5M VE spread <= 0.20%)
        # =====================================================================
        eq_pass_count = 0
        eq_reasons = []
        entry_quality_pass = True  # Default: pass
        
        if ENTRY_QUALITY_GATE_ENABLED:
            # Ko≈üul A: Volume ba≈ülangƒ±cƒ±
            cond_a = volume_ratio >= EQ_MIN_VOLUME_RATIO or is_volume_spike
            if cond_a:
                eq_pass_count += 1
                eq_reasons.append(f"A:Vol({volume_ratio:.1f}x)")
            
            # Ko≈üul B: OB y√∂n baskƒ±sƒ±
            cond_b = False
            if signal_side == "LONG":
                cond_b = imbalance >= EQ_MIN_IMBALANCE or ob_imbalance_trend >= EQ_MIN_OB_TREND
            elif signal_side == "SHORT":
                cond_b = imbalance <= -EQ_MIN_IMBALANCE or ob_imbalance_trend <= -EQ_MIN_OB_TREND
            if cond_b:
                eq_pass_count += 1
                eq_reasons.append(f"B:OB(imb={imbalance:.0f},tr={ob_imbalance_trend:.1f})")
            
            # Ko≈üul C: Likidite yeterli
            cond_c = volume_24h >= EQ_MIN_VOLUME_24H and spread_pct <= EQ_MAX_SPREAD
            if cond_c:
                eq_pass_count += 1
                eq_reasons.append(f"C:Liq(${volume_24h/1e6:.1f}M,sp={spread_pct:.2f}%)")
            
            # Gate kararƒ±: en az 2/3 ge√ßmeli
            if eq_pass_count < 2:
                entry_quality_pass = False
                fail_detail = f"EQ_GATE_FAIL({eq_pass_count}/3: {','.join(eq_reasons) or 'none'})"
                
                if ENTRY_QUALITY_MODE == 'hard':
                    logger.info(f"üö´ {fail_detail}: {symbol} {signal_side} score={score} | vol={volume_ratio:.1f}x imb={imbalance:.0f} ob_tr={ob_imbalance_trend:.1f} vol24h=${volume_24h/1e6:.1f}M sp={spread_pct:.2f}%")
                    return None
                else:  # soft mode
                    score -= 15
                    reasons.append(fail_detail)
                    logger.info(f"‚ö†Ô∏è {fail_detail}: {symbol} {signal_side} score-=15 ‚Üí {score}")
            else:
                reasons.append(f"EQ_PASS({eq_pass_count}/3)")
                if eq_pass_count == 3:
                    reasons.append("EQ_STRONG")
        
        # =====================================================================
        # A≈ûAMA 2: KONFƒ∞RMASYON Fƒ∞LTRELERƒ∞ (Skor Vermez, Sadece Kontrol Eder)
        # Coin istatistiklerine g√∂re dinamik e≈üikler kullanƒ±lƒ±r
        # =====================================================================
        confirmation_passed = True
        confirmation_fails = []
        
        # ===================================================================
        # Phase 110: COIN_TREND sadece pozisyon boyutunu etkiler
        # Sinyal √ºretiminde hi√ß etkisi yok - coin_daily_trend sinyale eklenir
        # Position sizing a≈üamasƒ±nda kullanƒ±lƒ±r
        # ===================================================================
        # coin_daily_trend sinyale ekleniyor (a≈üaƒüƒ±da), burada i≈ülem yok
        
        # Dinamik e≈üikler hesapla (coin_stats varsa kullan, yoksa varsayƒ±lan)
        if coin_stats and coin_stats.get('sample_count', 0) >= 10:
            # Volume dinamik e≈üik: ortalama - 1 * std (minimum kabul edilen)
            vol_threshold = max(0.3, coin_stats['volume_avg'] - coin_stats['volume_std'])
            reasons.append(f"DynTH(V:{vol_threshold:.1f}x)")
        else:
            # Varsayƒ±lan e≈üikler (yeterli veri yok)
            vol_threshold = 0.5
        
        # ===================================================================
        # Phase 111: RSI KONTROL√ú KALDIRILDI
        # Mean reversion sisteminde RSI extreme'leri beklenen durum.
        # Z-Score zaten fiyat sapmasƒ±nƒ± √∂l√ß√ºyor - RSI gereksiz.
        # ===================================================================
        
        # Konfirmasyon 2: Volume/Liquidity Kontrol√º (Phase 123 + Phase EQG)
        # Phase EQG: 24h volume threshold artƒ±k EQ_MIN_VOLUME_24H ile kontrol ediliyor
        # Ama ek g√ºvenlik olarak √ßok d√º≈ü√ºk hacim kontrol√º kalƒ±yor
        min_volume = 500_000  # $500K min 24h volume (hard floor)
        
        if volume_24h < min_volume:
            confirmation_passed = False
            confirmation_fails.append(f"LOW_LIQ(24h_Vol=${volume_24h/1_000_000:.1f}M < $0.5M)")
        
        # Phase EQG: Volume ratio kontrol√º tekrar aktif
        if volume_ratio < vol_threshold:
            confirmation_passed = False
            confirmation_fails.append(f"LOW_VOL({volume_ratio:.1f}x<{vol_threshold:.1f})")
        
        # Konfirmasyon 3: Hurst Regime Kontrol√º (SADECE UYARI - VETO DEƒûƒ∞L)
        if hurst > 0.65:
            reasons.append(f"HURST_WARN({hurst:.2f}>0.65)")
        
        # Konfirmasyon 4: Liquidity Sweep Kontrol√º
        # Ters y√∂nde sweep varsa pozisyon a√ßma
        if sweep_result and sweep_result.get('sweep_type'):
            sweep_type = sweep_result['sweep_type']
            if sweep_type == 'BULLISH' and signal_side == 'SHORT':
                confirmation_passed = False
                confirmation_fails.append("SWEEP_CONTRA(BULL)")
            elif sweep_type == 'BEARISH' and signal_side == 'LONG':
                confirmation_passed = False
                confirmation_fails.append("SWEEP_CONTRA(BEAR)")
            else:
                # Aynƒ± y√∂nde sweep = bonus log (sinyal g√º√ßlendi)
                reasons.append(f"Sweep({sweep_type})")
        
        # Konfirmasyon 5: SMT Divergence Kontrol√º
        # Ters y√∂nde divergence varsa dikkatli ol (uyarƒ±, veto deƒüil)
        smt_div = smt_divergence_detector.last_divergence
        if smt_div and smt_div.get('divergence_type'):
            div_type = smt_div['divergence_type']
            age = datetime.now().timestamp() - smt_divergence_detector.divergence_time
            if age < 300:  # Son 5 dakika
                if div_type == 'BULLISH' and signal_side == 'SHORT':
                    # Uyarƒ± - veto deƒüil ama log
                    reasons.append("SMT_WARN(BULL)")
                elif div_type == 'BEARISH' and signal_side == 'LONG':
                    reasons.append("SMT_WARN(BEAR)")
                else:
                    # Aynƒ± y√∂nde = teyit
                    reasons.append(f"SMT({div_type})")
        
        # Konfirmasyon ba≈üarƒ±sƒ±z mƒ±?
        if not confirmation_passed:
            logger.info(f"üö´ CONF_FAIL: {symbol} {signal_side} score={score} failed: {', '.join(confirmation_fails)}")
            return None
        
        # T√ºm konfirmasyonlar ge√ßti - devam et
        
        # =====================================================================
        # PHASE 99: UNIFIED DYNAMIC LEVERAGE (All Factors Combined)
        # Combines: Spread + Price + Volatility + Balance Protection
        # This is the SINGLE source of truth for leverage (UI + Binance)
        # =====================================================================
        
        import math
        
        # Get spread-adjusted parameters (includes leverage, SL/TP multipliers, pullback)
        # Get volatility-adjusted parameters (includes leverage, SL/TP multipliers, pullback)
        # Calculate actual volatility_pct from ATR and price
        if price > 0 and atr > 0:
            volatility_pct = (atr / price) * 100
        else:
            volatility_pct = 15.0  # Default to mid-range if unknown
        spread_params = get_volatility_adjusted_params(volatility_pct, atr, price, spread_pct)
        
        # Base leverage from Spread level (low spread = high leverage)
        # Phase 152: price_factor get_volatility_adjusted_params'da hesaplanƒ±yor (√ßifte hesaplama fixlendi)
        base_leverage = spread_params['leverage']
        
        # 1. VOLATILITY FACTOR: High ATR = lower leverage
        # ATR as % of price: <10% = 1.0, 10-20% = 0.8, 20-30% = 0.6, 30-50% = 0.4, 50%+ = 0.3
        volatility_pct = (atr / price * 100) if price > 0 and atr > 0 else 10.0
        if volatility_pct <= 10.0:
            volatility_factor = 1.0   # Low volatility - no reduction
        elif volatility_pct <= 20.0:
            volatility_factor = 0.8   # Normal volatility
        elif volatility_pct <= 30.0:
            volatility_factor = 0.6   # High volatility
        elif volatility_pct <= 50.0:
            volatility_factor = 0.4   # Very high volatility
        else:
            volatility_factor = 0.3   # Extreme volatility
        
        # 2. BALANCE PROTECTION FACTOR
        leverage_mult = balance_protector.calculate_leverage_multiplier(
            balance_protector.peak_balance
        )
        
        # COMBINED LEVERAGE: base √ó volatility √ó balance_protection √ó user_multiplier
        # Phase 152: price_factor kaldƒ±rƒ±ldƒ± ‚Äî get_volatility_adjusted_params zaten uyguluyor
        # Phase 216: User-controlled leverage multiplier from settings
        user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        final_leverage = int(round(base_leverage * volatility_factor * leverage_mult * user_lev_mult))
        
        # Ensure leverage bounds (3-75x)
        final_leverage = max(3, min(75, final_leverage))
        
        # Log if any factor reduced leverage significantly
        if volatility_factor < 0.9 or leverage_mult < 0.9 or user_lev_mult != 1.0:
            logger.info(f"üìä Unified Leverage: base={base_leverage}x √ó vol={volatility_factor:.2f} √ó bal={leverage_mult:.2f} √ó user={user_lev_mult:.1f} ‚Üí {final_leverage}x | {symbol} @ ${price:.6f} (ATR:{volatility_pct:.1f}%)")
        
        # Use spread-based SL/TP multipliers (override regime-based)
        atr_sl = spread_params['sl_multiplier']
        atr_tp = spread_params['tp_multiplier']
        trail_mult = spread_params['trail_multiplier']
        
        # Adjust based on Hurst regime (fine-tuning)
        if hurst < 0.45:  # Strong Mean Reversion
            atr_tp *= 1.2  # Wider TP for mean reversion
            trail_act = atr * 1.0
        elif hurst > 0.55:  # Trending
            atr_tp *= 1.3  # Even wider TP for trends
            trail_act = atr * 1.5
        else:
            trail_act = atr * 1.2
        
        # Phase 13: Volatility Adjustments (keep existing logic)
        if volatility_ratio > 1.5:
            atr_sl *= 1.2
            atr_tp *= 1.5
            reasons.append(f"VolExp({volatility_ratio:.1f}x)")
        elif volatility_ratio < 0.8:
            atr_tp *= 0.8
            reasons.append("LowVol")
        
        # Spread Protection Buffer
        spread_buffer = 0.0
        if spread_pct > 0.1:
            spread_buffer = price * (spread_pct / 100)
            reasons.append(f"SpreadProt({spread_pct:.2f}%)")
        
        # =====================================================================
        # PHASE 160: ATR+SPREAD PULLBACK (replaces old spread-only pullback)
        # Pullback = (ATR% √ó pullback_factor) + (Spread% √ó 0.5)
        # ATR% = coin's natural volatility ‚Üí scales pullback depth
        # Spread% = liquidity buffer ‚Üí slippage protection
        # =====================================================================
        
        # ATR as percentage of price
        atr_pct = (atr / price) if price > 0 else 0  # e.g., 0.075 for 7.5%
        
        # Pullback = ATR component + Spread component
        pullback_factor = 0.4  # Use 40% of ATR as pullback base
        spread_factor = 0.5    # Use 50% of spread as slippage buffer
        pullback_pct = (atr_pct * pullback_factor) + (spread_pct / 100 * spread_factor)
        
        # Additional pullback for extreme volatility
        if volatility_ratio > 2.0:
            pullback_pct += 0.005  # +0.5%
        
        # Limit pullback to max 10% (ATR-based can go higher than old spread-based)
        pullback_pct = min(0.10, pullback_pct)
        
        # =====================================================================
        # PHASE 152: MOMENTUM ENTRY ‚Äî G√º√ßl√º trend'de pullback bypass
        # ADX > 30 (g√º√ßl√º trend) + Hurst > 0.55 (trending rejim) + 
        # Coin daily trend aligned ‚Üí Direkt market entry, pullback yok
        # =====================================================================
        strong_momentum = (
            adx > 30 and
            hurst > 0.55 and
            (
                (signal_side == "LONG" and coin_daily_trend in ["BULLISH", "STRONG_BULLISH"]) or
                (signal_side == "SHORT" and coin_daily_trend in ["BEARISH", "STRONG_BEARISH"])
            )
        )
        
        if strong_momentum:
            original_pullback = pullback_pct
            pullback_pct = 0.0  # Market entry ‚Äî no pullback
            reasons.append(f"‚ö° MOMENTUM_ENTRY(ADX={adx:.0f},H={hurst:.2f})")
            logger.info(f"‚ö° MOMENTUM ENTRY: {symbol} {signal_side} ‚Äî pullback {original_pullback*100:.1f}%‚Üí0% | ADX={adx:.1f} H={hurst:.2f} trend={coin_daily_trend}")
        elif ENTRY_QUALITY_GATE_ENABLED and eq_pass_count == 3:
            # PHASE EQG: STRONG QUALITY PULLBACK REDUCTION
            # 3/3 kalite ko≈üulu ge√ßtiyse ‚Üí daha erken giri≈ü (trend ba≈ülangƒ±cƒ±nƒ± yakala)
            original_pb = pullback_pct
            pullback_pct *= 0.75
            reasons.append(f"EQ_EARLY(pb {original_pb*100:.1f}%‚Üí{pullback_pct*100:.1f}%)")
        
        if signal_side == "LONG":
            atr_entry = price * (1 - pullback_pct)
        else:
            atr_entry = price * (1 + pullback_pct)
        
        # =====================================================================
        # PHASE FIB: FIBONACCI ENTRY BLEND
        # Blend ATR-based entry with Fibonacci entry (alpha=0.35)
        # strong_momentum ‚Üí bypass (market entry), fib kapalƒ±
        # deviation > max_dev ‚Üí fallback to ATR entry
        # Phase EQG: EQ_STRONG durumunda Fib deviation limiti geni≈ületilir (1.0% ‚Üí 1.5%)
        # =====================================================================
        ideal_entry = atr_entry  # Default: ATR-based entry
        fib_blend_applied = False
        max_dev = 1.5 if (ENTRY_QUALITY_GATE_ENABLED and eq_pass_count == 3) else FIB_MAX_ENTRY_DEV_PCT
        
        if not strong_momentum and FIB_ENABLED and FIB_ENTRY_ENABLED and fib_context:
            fib_entry = fib_context.get('fib_entry', 0)
            if fib_entry > 0 and fib_context.get('fib_active'):
                dev_pct = abs(fib_entry - atr_entry) / price * 100 if price > 0 else 999
                if dev_pct <= max_dev:
                    alpha = FIB_BLEND_ALPHA
                    ideal_entry = atr_entry * (1 - alpha) + fib_entry * alpha
                    fib_blend_applied = True
                    reasons.append(f"FibBlend(a={alpha})")
                    logger.info(f"üìê FIB ENTRY: {symbol} {signal_side} atr_entry={atr_entry:.6f} fib_entry={fib_entry:.6f} ‚Üí blend={ideal_entry:.6f} (dev={dev_pct:.2f}% max={max_dev:.1f}%)")
                else:
                    reasons.append(f"FibSkip(too_far,{dev_pct:.1f}%)")
        
        if signal_side == "LONG":
            sl = ideal_entry - (atr * atr_sl) - spread_buffer
            tp = ideal_entry + (atr * atr_tp)
            trail_activation = ideal_entry + trail_act
            trail_dist = atr * trail_mult
        else:
            sl = ideal_entry + (atr * atr_sl) + spread_buffer
            tp = ideal_entry - (atr * atr_tp)
            trail_activation = ideal_entry - trail_act
            trail_dist = atr * trail_mult
        
        # =====================================================================
        # PHASE 29: BALANCE-PROTECTED SIZE MULTIPLIER
        # =====================================================================
        
        # Base size from score
        size_mult = 1.0
        if score >= 90: size_mult = 1.5
        elif score < 80: size_mult = 0.8
        
        # Apply BalanceProtector adjustment
        balance_size_mult = balance_protector.calculate_position_size_multiplier(
            balance_protector.peak_balance
        )
        size_mult *= balance_size_mult
        
        # =====================================================================
        # PHASE 110: TREND-BASED POSITION SIZE REDUCTION
        # Trend kar≈üƒ±tƒ± trade'lerde pozisyon boyutunu azalt
        # =====================================================================
        trend_size_reduction = 1.0  # Default no reduction
        if coin_daily_trend == "STRONG_BEARISH" and signal_side == "LONG":
            trend_size_reduction = 0.7  # 30% smaller position
            reasons.append("üìâ TrendConflict(-30%)")
        elif coin_daily_trend == "STRONG_BULLISH" and signal_side == "SHORT":
            trend_size_reduction = 0.7  # 30% smaller position
            reasons.append("üìà TrendConflict(-30%)")
        elif coin_daily_trend == "BEARISH" and signal_side == "LONG":
            trend_size_reduction = 0.85  # 15% smaller position
            reasons.append("üìâ trend_conflict(-15%)")
        elif coin_daily_trend == "BULLISH" and signal_side == "SHORT":
            trend_size_reduction = 0.85  # 15% smaller position
            reasons.append("üìà trend_conflict(-15%)")
        
        size_mult *= trend_size_reduction
        
        self.last_signal_time = now
        
        # Log spread level and leverage with ATR% for debugging
        reasons.append(f"Spread({spread_params['level']})")
        reasons.append(f"Lev({final_leverage}x)")
        
        # Debug: Log the actual ATR% value and what level it maps to
        logger.info(f"üìä Signal {signal_side}: Spread%={spread_pct:.2f}% PB%={pullback_pct*100:.2f}% (ATR:{atr_pct*100:.1f}%+Spread:{spread_pct:.2f}%) ‚Üí Level={spread_params['level']} ‚Üí Lev={base_leverage}x (after BalProt: {final_leverage}x)")  # Phase 223: label was ATR% but value was spread_pct
        
        # Phase 127: Log successful signal generation for tracing
        logger.info(f"‚úÖ SIGNAL_GEN: {symbol} {signal_side} score={score} lev={final_leverage}x entry=${ideal_entry:.4f} PB={pullback_pct*100:.2f}%")
        
        return {
            'action': signal_side,
            'price': price,        # Signal price
            'entryPrice': ideal_entry, # Pending Order Price
            'sl': sl,
            'tp': tp,
            'trailActivation': trail_activation,
            'trailDistance': trail_dist,
            'reason': ", ".join(reasons),
            'timestamp': now,
            'confidenceScore': score,
            'sizeMultiplier': size_mult,
            'leverage': final_leverage,  # Phase 29: Dynamic leverage
            'spreadLevel': spread_params['level'],
            'pullbackPct': round(pullback_pct * 100, 2),  # Phase 160: ATR+Spread based
            'atrPct': round(atr_pct * 100, 2),  # Phase 160: Raw ATR% for bounce calc
            'coinDailyTrend': coin_daily_trend,  # Phase 110: For position sizing
            'trendSizeReduction': trend_size_reduction,  # Phase 110: Applied reduction
            # Phase 153: ADX and Hurst for dynamic bounce confirmation
            'adx': adx,
            'hurst': hurst,
            'spreadPct': spread_pct,  # Phase 228: Real bid-ask spread for dynamic trail
            'volatility_pct': atr_pct * 100,  # Phase 228: Volatility for dynamic trail
            # Phase FIB: Fibonacci telemetry
            'fibActive': fib_context.get('fib_active', False) if fib_context else False,
            'fibLevel': fib_context.get('fib_level') if fib_context else None,
            'fibBonus': fib_context.get('fib_score_bonus', 0) if fib_context else 0,
            'fibEntry': fib_context.get('fib_entry', 0) if fib_context else 0,
            'atrEntry': atr_entry,
            'fibBlendAlpha': FIB_BLEND_ALPHA if fib_blend_applied else 0,
            # Phase EQG: Entry Quality telemetry
            'volumeRatio': round(volume_ratio, 2),
            'isVolumeSpike': is_volume_spike,
            'imbalancePct': round(imbalance, 1),
            'obImbalanceTrend': round(ob_imbalance_trend, 1),
            'entryQualityPass': entry_quality_pass,
            'entryQualityReasons': eq_reasons,
        }


# ============================================================================
# BINANCE DATA STREAMER
# ============================================================================


# WhaleDetector removed ‚Äî WhaleTracker (L4412) is the active implementation
# See project_analysis.md #5 for details

class PaperTradingEngine:
    """
    Simulates trading execution on the backend (Server-Side).
    Persists state to JSON to survive restarts.
    """
    def __init__(self, state_file: str = None):
        # Use persistent volume path on Fly.io, fallback to local for development
        if state_file is None:
            if os.path.exists("/data"):
                state_file = "/data/paper_trading_state.json"
                logger.info("üìÅ Using persistent volume: /data/paper_trading_state.json")
            else:
                state_file = "paper_trading_state.json"
                logger.info("üìÅ Using local storage: paper_trading_state.json")
        self.state_file = state_file
        self.balance = 10000.0
        self.initial_balance = 10000.0
        self.positions = []
        self.trades = []
        self.equity_curve = [{"time": int(datetime.now().timestamp() * 1000), "balance": 10000.0, "drawdown": 0.0}]
        self.stats = {
            "totalTrades": 0, "winningTrades": 0, "losingTrades": 0, "winRate": 0.0,
            "totalPnl": 0.0, "maxDrawdown": 0.0, "profitFactor": 0.0
        }
        self.enabled = True  # Phase 16: Auto-trade toggle
        # Phase 17: Cloud Trading Settings
        self.symbol = "SOLUSDT"
        self.leverage = 10
        self.risk_per_trade = 0.02  # 2%
        # Phase 18: Full Trading Parameters
        self.sl_atr = 15  # 1.5x ATR ‚Äî tighter SL for better R:R
        self.tp_atr = 30  # 3.0x ATR ‚Äî wider TP for better R:R
        self.trail_activation_atr = 1.5
        self.trail_distance_atr = 1.5  # Phase 222: 1.0‚Üí1.5 (trail %80 loss rate fix)
        self.sl_multiplier = 2.0  # ATR multiplier for SL (used in sync loop)
        self.tp_multiplier = 3.0  # ATR multiplier for TP (used in sync loop)
        # Phase 22: Multi-position config
        self.max_positions = 50  # Allow up to 50 positions
        self.allow_hedging = True  # Allow LONG + SHORT simultaneously
        # Algorithm sensitivity settings (can be adjusted via API)
        self.z_score_threshold = 1.6  # Min Z-Score for signal
        # Phase 50: Dynamic Min Score Range
        self.min_score_low = 60   # Minimum possible score (aggressive mode)
        self.min_score_high = 90  # Maximum possible score (defensive mode)
        self.min_confidence_score = 68  # Current effective min score (dynamically calculated)
        # Phase 36: Entry/Exit tightness settings
        self.entry_tightness = 1.8  # 0.5-15.0: Pullback multiplier (Gev≈üek/Loose mode)
        self.exit_tightness = 1.2   # 0.5-15.0: SL/TP multiplier
        # Phase 200: Counter-signal adaptive exit tightness cache TTL
        self.counter_signal_ttl = 900  # 15 minutes
        # Phase 19: Server-side persistent logs
        self.logs = []
        # Phase 20: Advanced Risk Management Config
        self.max_position_age_hours = 24
        self.daily_drawdown_limit = 5.0  # %5 g√ºnl√ºk kayƒ±p limiti
        self.emergency_sl_pct = 3.5   # Phase 212: %5‚Üí%3.5 (10x lev = %35 margin max kayƒ±p)
        self.current_spread_pct = 0.05  # Will be updated from WebSocket
        self.daily_start_balance = 10000.0
        # Phase 217: Portfolio-level drawdown protection
        self.portfolio_max_unrealized_loss_pct = 15.0  # Toplam a√ßƒ±k pozisyon max kayƒ±p %
        # Phase 217: Save state throttle
        self._last_save_time = 0
        self.leverage_multiplier = 1.0  # Phase 217: User-adjustable leverage multiplier (0.3-3.0)
        # Phase 34: Pending Orders System
        self.pending_orders = []  # List of pending limit orders waiting for pullback
        self.pending_order_timeout_seconds = 1800  # 30 minutes to fill or cancel
        # Pipeline metrics for fill rate observability
        self.pipeline_metrics = {
            'pending_created': 0, 'signal_confirmed': 0, 'pending_expired': 0,
            'stale_dropped': 0, 'trail_entry_start': 0, 'trail_entry_ok': 0,
            'trail_entry_fail': 0, 'trail_entry_timeout': 0, 'market_fallback': 0,
            'signal_missed': 0, 'spread_rejected': 0, 'drift_rejected': 0, 'filled': 0,
            'fallback_on_fail': 0, 'fallback_on_expire': 0
        }
        
        # =========================================================================
        # COIN BLACKLIST SYSTEM
        # Automatically blocks coins that consistently cause losses
        # =========================================================================
        self.coin_blacklist = {}  # symbol -> {until: timestamp, reason: str, losses: int}
        self.coin_stats = {}  # symbol -> {wins: int, losses: int, consecutive_losses: int, last_trade_time: float}
        self.blacklist_threshold = 2  # Consecutive losses to trigger blacklist
        self.blacklist_duration_hours = 2  # Hours to keep coin blacklisted
        
        # Phase 224A: MAE/MFE Diagnostics + Signal EV
        self.score_band_stats = {}  # {"60-70": {wins, losses, total_win, total_loss, avg_win, avg_loss}}
        self.last_signal_per_coin = {}  # {symbol: {side, time}} for flip detection
        
        # Phase 60: AI Optimizer Toggle - kapalƒ±yken dinamik hesaplamalar yapƒ±lmaz
        self.ai_optimizer_enabled = False  # Default: OFF - manuel ayarlar ge√ßerli
        
        self.load_state()
        self.add_log("üöÄ Paper Trading Engine ba≈ülatƒ±ldƒ±")
    
    def get_today_pnl(self) -> dict:
        """
        Calculate today's PnL based on Turkey timezone (UTC+3).
        Returns dict with todayPnl (dollar) and todayPnlPercent.
        """
        # pytz imported globally
        
        # Turkey timezone (UTC+3)
        turkey_tz = pytz.timezone('Europe/Istanbul')
        now_turkey = datetime.now(turkey_tz)
        
        # Start of today in Turkey time
        today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_ms = int(today_start.timestamp() * 1000)
        
        # Sum PnL of trades closed today
        today_pnl = 0.0
        today_trades_count = 0
        
        for trade in self.trades:
            close_time = trade.get('closeTime', 0)
            if close_time >= today_start_ms:
                today_pnl += trade.get('pnl', 0)
                today_trades_count += 1
        
        # Calculate percent based on start of day balance
        # We store dayStartBalance or use initial if not set
        day_start_balance = getattr(self, 'day_start_balance', 10000.0)
        if day_start_balance <= 0:
            day_start_balance = 10000.0
        
        today_pnl_percent = (today_pnl / day_start_balance) * 100 if day_start_balance > 0 else 0
        
        return {
            'todayPnl': round(today_pnl, 2),
            'todayPnlPercent': round(today_pnl_percent, 2),
            'todayTradesCount': today_trades_count
        }
    
    def calculate_dynamic_min_score(self) -> int:
        """
        Phase 50: Dinamik Minimum Skor Hesaplama
        Son 10 trade'in win rate'ine g√∂re min_score_low ve min_score_high arasƒ±nda skor belirler.
        
        Phase 60: AI Optimizer kapalƒ±yken bu hesaplama ATLANIR.
        Kullanƒ±cƒ±nƒ±n Settings Modal'dan ayarladƒ±ƒüƒ± deƒüerler ge√ßerli olur.
        
        Win Rate < 40% ‚Üí min_score_high (defansif mod)
        Win Rate > 60% ‚Üí min_score_low (agresif mod)
        Win Rate 40-60% ‚Üí orta deƒüer (normal mod)
        """
        # Phase 60: AI Optimizer kapalƒ±ysa dinamik hesaplama yapma
        if not self.ai_optimizer_enabled:
            return self.min_confidence_score  # Manuel ayarƒ± koru
        
        # Son 10 trade'i al
        recent_trades = self.trades[-10:] if len(self.trades) >= 10 else self.trades
        
        if len(recent_trades) < 5:
            # Yeterli veri yok, orta deƒüer kullan
            mid_score = (self.min_score_low + self.min_score_high) // 2
            self.min_confidence_score = mid_score
            return mid_score
        
        # Win rate hesapla
        wins = sum(1 for t in recent_trades if t.get('pnl', 0) > 0)
        win_rate = wins / len(recent_trades)
        
        # Dinamik skor hesapla
        # Win Rate 0% ‚Üí max score (70)
        # Win Rate 50% ‚Üí mid score (60) 
        # Win Rate 100% ‚Üí min score (50)
        score_range = self.min_score_high - self.min_score_low  # 70 - 50 = 20
        
        # win_rate arttƒ±k√ßa skor D√ú≈ûER (daha agresif)
        dynamic_score = self.min_score_high - int(win_rate * score_range)
        
        # Aralƒ±k i√ßinde kal
        dynamic_score = max(self.min_score_low, min(self.min_score_high, dynamic_score))
        
        # G√ºncelle ve logla
        old_score = self.min_confidence_score
        self.min_confidence_score = dynamic_score
        
        if old_score != dynamic_score:
            mode = "üõ°Ô∏è Defansif" if dynamic_score >= 65 else ("‚öîÔ∏è Agresif" if dynamic_score <= 55 else "‚öñÔ∏è Normal")
            logger.info(f"üìä Dynamic Min Score: {old_score} ‚Üí {dynamic_score} | WR: {win_rate*100:.0f}% | Mode: {mode}")
            self.add_log(f"üìä Min Skor: {dynamic_score} ({mode}, WR:{win_rate*100:.0f}%)")
        
        return dynamic_score
    
    # =========================================================================
    # Phase 224B: EV-Based Signal Filter
    # =========================================================================
    def calculate_signal_ev(self, signal: dict) -> float:
        """
        Phase 224B: Expected Value hesaplama.
        EV = p(win) * avg_win - (1-p) * |avg_loss|
        Skor bandƒ±na g√∂re historik win rate kullanƒ±r.
        Returns: EV value (positive = profitable, negative = avoid)
        """
        score = signal.get('confidenceScore', 0)
        
        # Skor bandƒ±: 50-60, 60-70, 70-80, 80-90, 90-100
        band = min(90, max(50, (score // 10) * 10))
        band_key = f"{band}-{band + 10}"
        
        hist = self.score_band_stats.get(band_key, {})
        total = hist.get('wins', 0) + hist.get('losses', 0)
        
        if total < 5:
            # Yetersiz veri ‚Üí EV tahmini: score'u PnL √∂l√ßeƒüine d√∂n√º≈üt√ºr
            # avg_win/avg_loss tipik ~0.01-0.05 USDT/margin aralƒ±ƒüƒ±nda
            return (score - 60) * 0.005  # 60 skor = 0 EV, 80 skor = 0.1 EV
        
        p_win = hist['wins'] / total
        avg_win = hist.get('avg_win', 0)
        avg_loss = abs(hist.get('avg_loss', 0))
        
        ev = p_win * avg_win - (1 - p_win) * avg_loss
        return ev
    
    def update_score_band_stats(self, signal_score: int, pnl: float):
        """Phase 224B: Trade kapanƒ±nca skor bandƒ± istatistiƒüini g√ºncelle."""
        band = min(90, max(50, (signal_score // 10) * 10))
        band_key = f"{band}-{band + 10}"
        
        if band_key not in self.score_band_stats:
            self.score_band_stats[band_key] = {
                'wins': 0, 'losses': 0,
                'total_win': 0.0, 'total_loss': 0.0,
                'avg_win': 0.0, 'avg_loss': 0.0
            }
        
        stats = self.score_band_stats[band_key]
        if pnl > 0:
            stats['wins'] += 1
            stats['total_win'] += pnl
        else:
            stats['losses'] += 1
            stats['total_loss'] += pnl
        
        stats['avg_win'] = stats['total_win'] / max(1, stats['wins'])
        stats['avg_loss'] = stats['total_loss'] / max(1, stats['losses'])
    
    def get_dynamic_risk_per_trade(self) -> float:
        """
        Son 5 trade'in performansƒ±na g√∂re risk y√ºzdesini dinamik ayarla.
        4+ win: %4 (agresif), 2-3 win: %3 (standart), 0-1 win: %2 (koruyucu)
        """
        if len(self.trades) < 5:
            return self.risk_per_trade  # Yeterli veri yok, varsayƒ±lan kullan
        
        # Son 5 trade'i al
        last_5 = self.trades[-5:]
        wins = sum(1 for t in last_5 if t.get('pnl', 0) > 0)
        
        if wins >= 4:
            # Kazanma serisi: agresif
            return 0.04  # %4
        elif wins >= 2:
            # Normal: standart
            return 0.03  # %3
        else:
            # Kaybetme serisi: koruyucu
            return 0.02  # %2
    
    def add_log(self, message: str):
        """Add a timestamped log entry (persisted to state and SQLite)."""
        # Use Turkey timezone
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_now = datetime.now(turkey_tz)
        timestamp = turkey_now.strftime("%H:%M:%S")
        ts = int(turkey_now.timestamp() * 1000)
        entry = {"time": timestamp, "message": message, "ts": ts}
        self.logs.append(entry)
        self.logs = self.logs[-100:]  # Keep last 100 logs in memory
        logger.info(f"[PaperTrading] {message}")
        
        # Save to SQLite (async, non-blocking)
        try:
            safe_create_task(sqlite_manager.add_log(timestamp, message, ts))
        except Exception:
            pass  # Ignore if event loop not running
    
    # =========================================================================
    # COIN BLACKLIST SYSTEM METHODS
    # =========================================================================
    
    def is_coin_blacklisted(self, symbol: str) -> bool:
        """Check if a coin is currently blacklisted."""
        if symbol not in self.coin_blacklist:
            return False
        
        blacklist_entry = self.coin_blacklist[symbol]
        until_time = blacklist_entry.get('until', 0)
        
        if datetime.now().timestamp() > until_time:
            # Blacklist expired, remove it
            del self.coin_blacklist[symbol]
            self.add_log(f"‚úÖ {symbol} blacklist'ten √ßƒ±karƒ±ldƒ± (s√ºre doldu)")
            return False
        
        return True
    
    def add_to_blacklist(self, symbol: str, reason: str, losses: int):
        """Add a coin to the blacklist."""
        until_time = datetime.now().timestamp() + (self.blacklist_duration_hours * 3600)
        self.coin_blacklist[symbol] = {
            'until': until_time,
            'reason': reason,
            'losses': losses,
            'added_at': datetime.now().isoformat()
        }
        self.add_log(f"üö´ {symbol} BLACKLIST'e eklendi: {reason} ({self.blacklist_duration_hours}h)")
        logger.warning(f"Coin blacklisted: {symbol} - {reason}")
    
    def update_coin_stats(self, symbol: str, is_win: bool, pnl: float):
        """Update coin statistics after a trade closes."""
        if symbol not in self.coin_stats:
            self.coin_stats[symbol] = {
                'wins': 0,
                'losses': 0,
                'consecutive_losses': 0,
                'consecutive_wins': 0,
                'total_pnl': 0.0,
                'last_trade_time': 0
            }
        
        stats = self.coin_stats[symbol]
        stats['last_trade_time'] = datetime.now().timestamp()
        stats['total_pnl'] += pnl
        
        if is_win:
            stats['wins'] += 1
            stats['consecutive_wins'] += 1
            stats['consecutive_losses'] = 0  # Reset loss streak
        else:
            stats['losses'] += 1
            stats['consecutive_losses'] += 1
            stats['consecutive_wins'] = 0  # Reset win streak
            
            # Check if should blacklist
            if stats['consecutive_losses'] >= self.blacklist_threshold:
                reason = f"{stats['consecutive_losses']} ardƒ±≈üƒ±k zarar"
                self.add_to_blacklist(symbol, reason, stats['consecutive_losses'])
                # Reset consecutive after blacklist
                stats['consecutive_losses'] = 0
    
    def clean_expired_blacklist(self):
        """Remove expired entries from blacklist."""
        now = datetime.now().timestamp()
        expired = [s for s, data in self.coin_blacklist.items() if now > data.get('until', 0)]
        for symbol in expired:
            del self.coin_blacklist[symbol]
            self.add_log(f"‚úÖ {symbol} blacklist s√ºresi doldu")
    
    def get_blacklist_info(self) -> dict:
        """Get current blacklist status for API/UI."""
        self.clean_expired_blacklist()
        return {
            'blacklisted_coins': list(self.coin_blacklist.keys()),
            'count': len(self.coin_blacklist),
            'details': self.coin_blacklist
        }

    # =========================================================================
    # PHASE 200: ADAPTIVE EXIT TIGHTNESS (Counter-Signal)
    # Per-position exit_tightness based on opposing signals
    # =========================================================================
    
    def get_effective_exit_tightness(self, pos: dict) -> float:
        """Get per-position exit_tightness with counter-signal modifier.
        
        If an opposing signal was recently received for this coin,
        the modifier reduces exit_tightness ‚Üí tighter exits.
        If no opposing signal or modifier expired, returns global exit_tightness.
        """
        modifier = pos.get('counter_signal_modifier', 1.0)
        cs_time = pos.get('counter_signal_time', 0)
        
        # Expire modifier after TTL (15 minutes)
        if modifier < 1.0 and cs_time > 0:
            now_ts = datetime.now().timestamp()
            if now_ts - cs_time > self.counter_signal_ttl:
                # Expired ‚Äî reset to global
                pos['counter_signal_modifier'] = 1.0
                modifier = 1.0
        
        return self.exit_tightness * modifier
    
    # =========================================================================
    # DYNAMIC ATR MULTIPLIER
    # Adjusts SL/TP based on current volatility conditions
    # =========================================================================
    
    def calculate_dynamic_atr_multiplier(self, atr: float, price: float, lookback_atr: float = None) -> float:
        """
        Calculate a dynamic multiplier for ATR-based SL/TP.
        
        Logic:
        - Normal volatility (ATR ~1% of price): multiplier = 1.0
        - High volatility (ATR >2% of price): multiplier = 1.3-1.5 (wider SL/TP)
        - Low volatility (ATR <0.5% of price): multiplier = 0.7-0.8 (tighter SL/TP)
        
        Returns: float between 0.7 and 1.5
        """
        if price <= 0 or atr <= 0:
            return 1.0
        
        # Calculate ATR as percentage of price
        atr_pct = (atr / price) * 100
        
        # Define volatility bands
        LOW_VOL_THRESHOLD = 0.5   # <0.5% = low volatility
        NORMAL_VOL = 1.0          # ~1% = normal
        HIGH_VOL_THRESHOLD = 2.0  # >2% = high volatility
        
        if atr_pct < LOW_VOL_THRESHOLD:
            # Low volatility: tighten SL/TP (0.7-0.9)
            multiplier = 0.7 + (atr_pct / LOW_VOL_THRESHOLD) * 0.2
        elif atr_pct > HIGH_VOL_THRESHOLD:
            # High volatility: widen SL/TP (1.2-1.5)
            excess_vol = min(atr_pct - HIGH_VOL_THRESHOLD, 3.0)  # Cap at 5%
            multiplier = 1.2 + (excess_vol / 3.0) * 0.3
        else:
            # Normal volatility: scale linearly (0.9-1.2)
            normalized = (atr_pct - LOW_VOL_THRESHOLD) / (HIGH_VOL_THRESHOLD - LOW_VOL_THRESHOLD)
            multiplier = 0.9 + normalized * 0.3
        
        return round(min(1.5, max(0.7, multiplier)), 2)

    # =========================================================================
    # PHASE 30: KELLY CRITERION POSITION SIZING
    # =========================================================================
    
    def calculate_kelly_fraction(self) -> float:
        """
        Kelly Criterion ile optimal pozisyon boyutu hesapla.
        Kelly% = W - [(1-W) / R]
        W = Win rate (son 20 trade)
        R = Average Win / Average Loss
        
        Half-Kelly kullanƒ±lƒ±r (g√ºvenlik i√ßin).
        Returns: %1-%5 arasƒ± risk oranƒ±
        """
        # Minimum trade sayƒ±sƒ±na ula≈ümadƒ±ysa default kullan
        if len(self.trades) < 10:
            return self.risk_per_trade  # Default %2
        
        # Son 20 trade'i al
        recent_trades = self.trades[-20:]
        
        wins = [t for t in recent_trades if t.get('pnl', 0) > 0]
        losses = [t for t in recent_trades if t.get('pnl', 0) < 0]
        
        if not wins or not losses:
            return self.risk_per_trade
        
        # Win rate hesapla
        win_rate = len(wins) / len(recent_trades)
        
        # Ortalama kazan√ß ve kayƒ±p
        avg_win = np.mean([t['pnl'] for t in wins])
        avg_loss = abs(np.mean([t['pnl'] for t in losses]))
        
        if avg_loss <= 0:
            return self.risk_per_trade
        
        # Win/Loss ratio
        R = avg_win / avg_loss
        
        # Kelly form√ºl√º
        kelly = win_rate - ((1 - win_rate) / R)
        
        # Half-Kelly (daha g√ºvenli)
        half_kelly = kelly * 0.5
        
        # Sƒ±nƒ±rla: %1 - %5 arasƒ±
        final_risk = max(0.01, min(0.05, half_kelly))
        
        logger.debug(f"Kelly Calculation: WR={win_rate:.2f}, R={R:.2f}, Kelly={kelly:.3f}, Final={final_risk:.3f}")
        
        return final_risk
    
    def get_kelly_stats(self) -> dict:
        """Kelly hesaplama istatistikleri."""
        if len(self.trades) < 10:
            return {"status": "insufficient_data", "trades_needed": 10 - len(self.trades)}
        
        recent = self.trades[-20:]
        wins = [t for t in recent if t.get('pnl', 0) > 0]
        losses = [t for t in recent if t.get('pnl', 0) < 0]
        
        win_rate = len(wins) / len(recent) if recent else 0
        avg_win = np.mean([t['pnl'] for t in wins]) if wins else 0
        avg_loss = abs(np.mean([t['pnl'] for t in losses])) if losses else 1
        
        return {
            "status": "active",
            "sample_size": len(recent),
            "win_rate": round(win_rate * 100, 1),
            "avg_win": round(avg_win, 2),
            "avg_loss": round(avg_loss, 2),
            "win_loss_ratio": round(avg_win / avg_loss if avg_loss > 0 else 0, 2),
            "kelly_fraction": round(self.calculate_kelly_fraction() * 100, 2)
        }
    
    # =========================================================================
    # ASYNC OPEN_POSITION FOR AUTO-TRADING
    # =========================================================================
    
    async def open_position(self, side: str, price: float, atr: float, signal: dict, symbol: str = None):
        """
        Open a new position for auto-trading from background scanner.
        
        Args:
            side: 'LONG' or 'SHORT'
            price: Current price
            atr: Average True Range value
            signal: Signal dict with optional parameters
            symbol: Symbol to trade (defaults to self.symbol)
        """
        if not self.enabled:
            self.add_log(f"‚è∏Ô∏è Auto-trade kapalƒ±, i≈ülem yapƒ±lmadƒ±")
            return None
        
        # Phase 191: Paper pozisyon a√ßmayƒ± engelle ‚Äî sadece live
        if not live_binance_trader.enabled:
            logger.debug(f"üìÑ Paper trade skipped: {side} {symbol if symbol else self.symbol} (live only mode)")
            return None
        
        # Use provided symbol or default
        trade_symbol = symbol if symbol else self.symbol
        
        # BLACKLIST CHECK: Skip coins that consistently cause losses
        if self.is_coin_blacklisted(trade_symbol):
            logger.debug(f"Skipping {trade_symbol} - blacklisted")
            return None
        
        # Check position + pending order limits
        total_exposure = len(self.positions) + len(self.pending_orders)
        if total_exposure >= self.max_positions:
            logger.info(f"üö´ OPEN_POS SKIP: Max exposure reached ({total_exposure}/{self.max_positions})")
            return None  # Silently skip to avoid log spam
        
        # Phase 217: Direction exposure limit ‚Äî max %70 aynƒ± y√∂nde (count-based)
        long_count = sum(1 for p in self.positions if p.get('side') == 'LONG')
        short_count = sum(1 for p in self.positions if p.get('side') == 'SHORT')
        max_same_direction = max(3, self.max_positions * 70 // 100)
        if side == 'LONG' and long_count >= max_same_direction:
            logger.info(f"üö´ DIRECTION LIMIT: {long_count} LONG a√ßƒ±k (max {max_same_direction})")
            return None
        if side == 'SHORT' and short_count >= max_same_direction:
            logger.info(f"üö´ DIRECTION LIMIT: {short_count} SHORT a√ßƒ±k (max {max_same_direction})")
            return None
        
        # Phase 219: USDT-based directional exposure limit ‚Äî max %40 of balance per direction
        # Prevents overexposure to one direction. Uses margin (sizeUsd/leverage) as actual capital at risk.
        MAX_DIRECTION_EXPOSURE_PCT = 0.40  # 40% of wallet balance per direction
        same_dir_margin = sum(
            p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
            for p in self.positions if p.get('side') == side
        )
        # Also count pending orders for same direction
        same_dir_margin += sum(
            p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
            for p in self.pending_orders if p.get('side') == side
        )
        max_dir_exposure = self.balance * MAX_DIRECTION_EXPOSURE_PCT
        if same_dir_margin >= max_dir_exposure:
            logger.info(f"üö´ DIRECTION EXPOSURE: {side} margin ${same_dir_margin:.2f} >= ${max_dir_exposure:.2f} ({MAX_DIRECTION_EXPOSURE_PCT*100:.0f}% of ${self.balance:.2f})")
            return None
        
        # =========================================================================
        # PHASE 33: POSITION SCALING LOGIC
        # =========================================================================
        # Count entries for this specific coin and direction (positions + pending)
        same_coin_same_dir_pos = [p for p in self.positions if p.get('symbol') == trade_symbol and p.get('side') == side]
        same_coin_same_dir_pend = [p for p in self.pending_orders if p.get('symbol') == trade_symbol and p.get('side') == side]
        
        if len(same_coin_same_dir_pos) + len(same_coin_same_dir_pend) >= 3:
            logger.info(f"üö´ OPEN_POS SKIP: Scale-in limit reached for {trade_symbol} {side}")
            return None  # Silently skip scale-in limit
        
        # Check for existing pending order for same symbol (avoid duplicate pending)
        existing_pending = [p for p in self.pending_orders if p.get('symbol') == trade_symbol]
        if existing_pending:
            logger.info(f"üö´ OPEN_POS SKIP: Pending order already exists for {trade_symbol}")
            return None  # Already have pending order for this symbol
        
        # Check if we already have opposite position in same coin (hedging check)
        same_coin_opposite = [p for p in self.positions if p.get('symbol') == trade_symbol and p.get('side') != side]
        if same_coin_opposite and not self.allow_hedging:
            logger.info(f"üö´ OPEN_POS SKIP: Hedging disabled, opposite pos exists for {trade_symbol}")
            return None
        
        # ATR fallback
        if atr <= 0:
            atr = price * 0.01
        
        # =========================================================================
        # PHASE 34: PENDING ORDER SYSTEM (PULLBACK ENTRY)
        # =========================================================================
        # Create a pending order that waits for price to reach pullback level
        
        # Get pullback entry price from signal and apply entry_tightness
        if signal and 'entryPrice' in signal:
            base_pullback_pct = signal.get('pullbackPct', 0)
            # Apply entry_tightness: HIGHER = WIDER pullback (more distance from signal price)
            # Formula: multiply by sqrt(entry_tightness) for smooth scaling
            import math
            et_mult = math.sqrt(max(0.5, self.entry_tightness))  # sqrt smoothing: 2.6‚Üí1.6, 1.0‚Üí1.0
            adjusted_pullback_pct = base_pullback_pct * et_mult
            
            # Recalculate entry price with adjusted pullback
            if side == 'LONG':
                entry_price = price * (1 - adjusted_pullback_pct / 100)
            else:
                entry_price = price * (1 + adjusted_pullback_pct / 100)
            pullback_pct = adjusted_pullback_pct
        else:
            # No pullback, use current price
            entry_price = price
            pullback_pct = 0
        
        # Get spread-adjusted parameters from signal
        spread_level = signal.get('spreadLevel', 'normal') if signal else 'normal'
        
        # Use leverage from signal (spread-adjusted) or calculate
        if signal and 'leverage' in signal:
            adjusted_leverage = signal['leverage']
        else:
            session_adjusted_leverage = session_manager.adjust_leverage(self.leverage)
            leverage_mult = balance_protector.calculate_leverage_multiplier(self.balance)
            user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
            adjusted_leverage = int(session_adjusted_leverage * leverage_mult * user_lev_mult)
            adjusted_leverage = max(3, min(75, adjusted_leverage))
        
        # Phase 230B: Override leverage cap (BTC counter-trend protection)
        if signal and signal.get('overrideLeverageCap'):
            cap = signal['overrideLeverageCap']
            if adjusted_leverage > cap:
                logger.info(f"üí™ OVERRIDE LEV CAP: {self.symbol} {adjusted_leverage}x ‚Üí {cap}x")
                adjusted_leverage = cap
        
        # DYNAMIC POSITION SIZING: Son 5 trade performansƒ±na g√∂re risk ayarla
        dynamic_risk = self.get_dynamic_risk_per_trade()
        session_risk = session_manager.adjust_risk(dynamic_risk)
        size_mult = signal.get('sizeMultiplier', 1.0) if signal else 1.0
        
        # Phase 143: Apply Strong Trend size reduction
        strong_trend_size_mult = signal.get('strong_trend_size_mult', 1.0) if signal else 1.0
        size_mult = size_mult * strong_trend_size_mult
        if strong_trend_size_mult < 1.0:
            logger.info(f"üìâ STRONG_TREND SIZE: {strong_trend_size_mult:.0%} multiplier applied ‚Üí size_mult={size_mult:.2f}")
        elif strong_trend_size_mult > 1.0:
            logger.info(f"üöÄ TREND_MODE SIZE: {strong_trend_size_mult:.0%} multiplier applied ‚Üí size_mult={size_mult:.2f}")
        
        # Calculate SL/TP based on pullback entry price
        # Apply exit_tightness: lower = quicker exit (smaller SL/TP), higher = hold longer (bigger SL/TP)
        # DYNAMIC ATR MULTIPLIER: Adjust based on current volatility
        dynamic_atr_mult = self.calculate_dynamic_atr_multiplier(atr, price)
        
        # Phase 202: Trend Mode ‚Äî wider params for strong trend pro-trend signals
        is_trend_mode = signal.get('trend_mode', False) if signal else False
        if is_trend_mode:
            # Trend Mode: let winners run with wider params
            tm_sl_mult = 1.33    # SL 33% wider (1.5x ‚Üí 2.0x ATR effective)
            tm_tp_mult = 1.67    # TP 67% wider (3.0x ‚Üí 5.0x ATR effective)
            tm_trail_act_mult = 1.67  # Trail activation 67% wider (1.5x ‚Üí 2.5x effective)
            tm_trail_dist_mult = 1.50  # Trail distance 50% wider (1.0x ‚Üí 1.5x effective)
            logger.warning(f"üöÄ TREND_MODE PARAMS: {side} {trade_symbol} | TP√ó{tm_tp_mult:.2f} Trail√ó{tm_trail_act_mult:.2f} SL√ó{tm_sl_mult:.2f}")
        else:
            tm_sl_mult = 1.0
            tm_tp_mult = 1.0
            tm_trail_act_mult = 1.0
            tm_trail_dist_mult = 1.0
        
        adjusted_sl_atr = (self.sl_atr / 10) * self.exit_tightness * dynamic_atr_mult * tm_sl_mult
        adjusted_tp_atr = (self.tp_atr / 10) * self.exit_tightness * dynamic_atr_mult * tm_tp_mult
        
        # Use dynamic trail params from signal if available (Cloud Scanner + WebSocket parity)
        if signal and 'dynamic_trail_activation' in signal:
            # Use per-coin dynamic trail params
            base_trail_activation_atr = signal['dynamic_trail_activation']
            base_trail_distance_atr = signal['dynamic_trail_distance']
        else:
            # Fallback to global defaults
            base_trail_activation_atr = self.trail_activation_atr
            base_trail_distance_atr = self.trail_distance_atr
        
        adjusted_trail_activation_atr = base_trail_activation_atr * self.exit_tightness * dynamic_atr_mult * tm_trail_act_mult
        adjusted_trail_distance_atr = base_trail_distance_atr * self.exit_tightness * dynamic_atr_mult * tm_trail_dist_mult
        
        # Phase 224D G5: Apply regime profile multipliers
        try:
            regime_profile = market_regime_manager.get_profile()
            tuning_recs = getattr(self, '_tuning_recs', {})
            
            # Regime multipliers
            r_tp_mult = regime_profile.get('tp_mult', 1.0)
            r_sl_mult = regime_profile.get('sl_mult', 1.0)
            r_trail_mult = regime_profile.get('trail_distance_mult', 1.0)
            
            # PostTradeTracker tuning overrides (if available)
            if tuning_recs.get('tp_mult'):
                r_tp_mult *= tuning_recs['tp_mult']
            if tuning_recs.get('trail_distance_mult'):
                r_trail_mult *= tuning_recs['trail_distance_mult']
            
            adjusted_sl_atr *= r_sl_mult
            adjusted_tp_atr *= r_tp_mult
            adjusted_trail_activation_atr *= r_trail_mult
            adjusted_trail_distance_atr *= r_trail_mult
            
            if r_tp_mult != 1.0 or r_sl_mult != 1.0 or r_trail_mult != 1.0:
                logger.info(f"üé≠ REGIME_PARAMS: {trade_symbol} | TP√ó{r_tp_mult:.2f} SL√ó{r_sl_mult:.2f} Trail√ó{r_trail_mult:.2f} regime={market_regime_manager.current_regime}")
        except Exception as rp_err:
            logger.debug(f"Regime profile params error: {rp_err}")
        
        if side == 'LONG':
            sl = max(entry_price * 0.01, entry_price - (atr * adjusted_sl_atr))
            tp = entry_price + (atr * adjusted_tp_atr)
            trail_activation = entry_price + (atr * adjusted_trail_activation_atr)
        else:
            sl = entry_price + (atr * adjusted_sl_atr)
            tp = max(entry_price * 0.01, entry_price - (atr * adjusted_tp_atr))
            trail_activation = max(entry_price * 0.01, entry_price - (atr * adjusted_trail_activation_atr))
        
        trail_distance = atr * adjusted_trail_distance_atr
        
        # Position sizing
        risk_amount = self.balance * session_risk * size_mult
        position_size_usd = risk_amount * adjusted_leverage
        
        # Apply MTF size modifier (bonus: 1.1 = +10%, penalty: 0.8 = -20%)
        mtf_size_modifier = signal.get('mtf_size_modifier', 1.0) if signal else 1.0
        position_size_usd = position_size_usd * mtf_size_modifier
        
        position_size = position_size_usd / entry_price
        
        # Create pending order
        # Signal Confirmation: Phase 224B adaptive delay ‚Äî ATR/spread/skora g√∂re 1-8dk
        atr_pct_confirm = (atr / price * 100) if price > 0 else 2.0
        conf_score = signal.get('confidenceScore', 0) if signal else 0
        
        # Base wait: ATR-based
        if atr_pct_confirm > 5.0:
            base_wait_min = 2       # Y√ºksek volatilite ‚Üí kƒ±sa bekle
        elif atr_pct_confirm > 2.0:
            base_wait_min = 4       # Normal
        else:
            base_wait_min = 6       # D√º≈ü√ºk volatilite ‚Üí uzun bekle
        
        # Score adjustment: y√ºksek skor ‚Üí daha az bekleme
        if conf_score >= 85:
            base_wait_min = max(1, base_wait_min - 2)
        elif conf_score >= 70:
            base_wait_min = max(2, base_wait_min - 1)
        
        # Spread adjustment: y√ºksek spread ‚Üí daha uzun bekle
        if spread_level in ('High', 'Very High'):
            base_wait_min += 2
        elif spread_level in ('Extreme', 'Ultra'):
            base_wait_min += 4
        
        signal_confirmation_delay_seconds = base_wait_min * 60
        
        # Phase 224D: Regime-based confirmation multiplier
        try:
            regime_profile = market_regime_manager.get_profile()
            confirm_mult = regime_profile.get('confirmation_mult', 1.0)
            signal_confirmation_delay_seconds = int(signal_confirmation_delay_seconds * confirm_mult)
            signal_confirmation_delay_seconds = max(60, min(600, signal_confirmation_delay_seconds))  # 1-10dk cap
        except Exception:
            pass
        
        # Phase 155: AI Optimizer ‚Äî snapshot settings at trade open time
        settings_snapshot = {
            'entry_tightness': self.entry_tightness,
            'z_score_threshold': self.z_score_threshold,
            'min_score_low': self.min_score_low,
            'min_score_high': self.min_score_high,
            'max_positions': self.max_positions,
            'market_regime': market_regime_detector.current_regime if 'market_regime_detector' in dir() or True else 'UNKNOWN',
        }
        try:
            settings_snapshot['market_regime'] = market_regime_detector.current_regime
        except:
            settings_snapshot['market_regime'] = 'UNKNOWN'
        # Phase 211: OBI depth settings
        settings_snapshot['obi_threshold_veto'] = 0.6
        settings_snapshot['obi_threshold_penalty'] = 0.3
        settings_snapshot['obi_penalty_points'] = 15
        try:
            obi_cached = obi_detector.obi_cache.get(trade_symbol, {})
            settings_snapshot['obi_value_at_entry'] = round(obi_cached.get('obi', 0), 4)
        except:
            settings_snapshot['obi_value_at_entry'] = 0
        
        pending_order = {
            "id": f"PO_{int(datetime.now().timestamp())}_{side}_{trade_symbol}",
            "symbol": trade_symbol,
            "side": side,
            "signalPrice": price,  # Price when signal was generated
            "entryPrice": entry_price,  # Pullback price to wait for
            "pullbackPct": pullback_pct,
            "size": position_size,
            "sizeUsd": position_size_usd,
            "stopLoss": sl,
            "takeProfit": tp,
            "trailActivation": trail_activation,
            "trailDistance": trail_distance,
            "leverage": adjusted_leverage,
            "spreadLevel": spread_level,
            # Phase 49: Additional data for analysis
            "signalScore": signal.get('confidenceScore', 0) if signal else 0,
            "mtfScore": signal.get('mtf_score', 0) if signal else 0,
            "zScore": signal.get('zscore', 0) if signal else 0,
            "createdAt": int(datetime.now().timestamp() * 1000),
            "confirmAfter": int((datetime.now().timestamp() + signal_confirmation_delay_seconds) * 1000),  # 5 dakika sonra aktif
            "expiresAt": int((datetime.now().timestamp() + self.pending_order_timeout_seconds) * 1000),
            "atr": atr,
            "confirmed": False,  # Hen√ºz konfirme edilmedi
            # Phase 153: ADX and Hurst for dynamic bounce threshold
            "adx": signal.get('adx', 0) if signal else 0,
            "hurst": signal.get('hurst', 0.5) if signal else 0.5,
            # Dynamic trail params (per-coin)
            "dynamic_trail_activation": signal.get('dynamic_trail_activation', self.trail_activation_atr) if signal else self.trail_activation_atr,
            "dynamic_trail_distance": signal.get('dynamic_trail_distance', self.trail_distance_atr) if signal else self.trail_distance_atr,
            # Dynamic trail activation threshold data
            "volatility_pct": (atr / price * 100) if price > 0 else 2.0,
            "spreadPct": signal.get('spreadPct', 0.05) if signal else 0.05,
            "volumeRatio": signal.get('volumeRatio', 1.0) if signal else 1.0,
            # Phase 202: Trend Mode flag
            "trend_mode": is_trend_mode,
            # Phase 155: AI Optimizer settings snapshot
            "settingsSnapshot": settings_snapshot,
            # Phase 224D3: CanaryMode A/B test flag
            "is_canary": canary_mode.should_use_canary(f"PO_{int(datetime.now().timestamp())}_{side}_{trade_symbol}"),
        }
        
        self.pending_orders.append(pending_order)
        self.pipeline_metrics['pending_created'] += 1
        self.add_log(f"üìã PENDING: {side} {trade_symbol} | ${price:.4f} ‚Üí ${entry_price:.4f} ({pullback_pct}% pullback) | Spread: {spread_level}")
        logger.info(f"üìã PENDING ORDER: {side} {trade_symbol} @ {entry_price} (pullback {pullback_pct}% from {price}, spread={spread_level})")
        
        return pending_order
    
    async def check_pending_orders(self, opportunities: list):
        """Check all pending orders against current prices and execute or expire them."""
        current_time = int(datetime.now().timestamp() * 1000)
        # High-score signals get market fallback on hard exits to improve fill rate.
        MARKET_FALLBACK_MIN_SCORE = 80
        # Stale logic tuned softer to avoid dropping still-valid candidates too early.
        STALE_THRESHOLD_UNCONFIRMED_MIN = 15
        STALE_THRESHOLD_CONFIRMED_MIN = 30
        STALE_GRACE_MIN = 5
        STALE_PENALTY_PER_MIN = 1
        STALE_MIN_SCORE_BUFFER = 5
        
        for order in list(self.pending_orders):
            symbol = order.get('symbol', '')
            side = order.get('side', '')
            entry_price = order.get('entryPrice', 0)
            expires_at = order.get('expiresAt', 0)
            
            # Find current price for this symbol (also used by expiry fallback)
            current_price = None
            for opp in opportunities:
                if opp.get('symbol') == symbol:
                    current_price = opp.get('price', 0)
                    break
            
            # Check expiration first (with high-score market fallback for confirmed signals)
            if current_time > expires_at:
                signal_score = order.get('signalScore', 0)
                is_confirmed = order.get('confirmed', False)
                if is_confirmed and signal_score >= MARKET_FALLBACK_MIN_SCORE and current_price and current_price > 0:
                    self.pipeline_metrics['market_fallback'] += 1
                    self.pipeline_metrics['fallback_on_expire'] += 1
                    self.add_log(f"üî• MARKET FALLBACK: {side} {symbol} score={signal_score} ‚Üí pending expired, filling at market")
                    logger.info(f"üî• MARKET FALLBACK(EXPIRE): {side} {symbol} score={signal_score} age_expired ‚Üí market fill")
                    await self.execute_pending_order(order, current_price, force_market=True)
                    continue
                if order in self.pending_orders:
                    self.pending_orders.remove(order)
                self.pipeline_metrics['pending_expired'] += 1
                self.add_log(f"‚è∞ PENDING EXPIRED: {side} {symbol} @ ${entry_price:.4f} (30dk timeout)")
                logger.info(f"Pending order expired: {order['id']}")
                continue
            
            # Phase 224B: Stale Signal Penalty ‚Äî skor zamanla d√º≈üer
            created_at = order.get('createdAt', current_time)
            pending_age_min = (current_time - created_at) / 60000
            is_confirmed = order.get('confirmed', False)
            stale_threshold_min = STALE_THRESHOLD_CONFIRMED_MIN if is_confirmed else STALE_THRESHOLD_UNCONFIRMED_MIN
            if pending_age_min > stale_threshold_min:
                stale_penalty = min(20, int((pending_age_min - stale_threshold_min) * STALE_PENALTY_PER_MIN))
                original_score = order.get('signalScore', 70)
                stale_floor = max(40, self.min_confidence_score - STALE_MIN_SCORE_BUFFER)
                adjusted_score = max(stale_floor, original_score - stale_penalty)
                if pending_age_min > (stale_threshold_min + STALE_GRACE_MIN) and adjusted_score < self.min_confidence_score:
                    self.pending_orders.remove(order)
                    self.pipeline_metrics['stale_dropped'] += 1
                    self.add_log(f"‚è≥ STALE_SIGNAL: {side} {symbol} removed (score {original_score}‚Üí{adjusted_score} < min {self.min_confidence_score}, age={pending_age_min:.0f}min)")
                    logger.info(f"‚è≥ STALE_SIGNAL: {order['id']} removed (age={pending_age_min:.0f}min, stale_thresh={stale_threshold_min}min+{STALE_GRACE_MIN}min, score {original_score}‚Üí{adjusted_score})")
                    continue
            
            if not current_price or current_price <= 0:
                continue
            
            # ===================================================================
            # SIGNAL CONFIRMATION: 5 dakika bekleme
            # Sinyal geldiƒüinde hemen execute etme, trend doƒürulanmasƒ±nƒ± bekle
            # ===================================================================
            confirm_after = order.get('confirmAfter', 0)
            is_confirmed = order.get('confirmed', False)
            
            if not is_confirmed:
                if current_time < confirm_after:
                    # Hen√ºz konfirmasyon s√ºresi dolmadƒ± - fiyat hala doƒüru y√∂nde mi kontrol et
                    signal_price = order.get('signalPrice', entry_price)
                    
                    # FIX #3: Signal Invalidation Logic Corrected
                    # LONG sinyal: Eƒüer fiyat √áOK FAZLA D√ú≈ûT√úYSE (entry'i ge√ßip gitti), sinyal ge√ßersiz
                    # SHORT sinyal: Eƒüer fiyat √áOK FAZLA Y√úKSELDƒ∞YSE (entry'i ge√ßip gitti), sinyal ge√ßersiz
                    # Threshold: Entry fiyatƒ±nƒ±n %3 √∂tesine ge√ßerse iptal
                    
                    if side == 'LONG':
                        # LONG i√ßin: Fiyat entry'den %3 daha a≈üaƒüƒ± d√º≈üt√ºyse ‚Üí sinyal ka√ßƒ±rƒ±ldƒ±
                        price_drop_pct = (signal_price - current_price) / signal_price * 100
                        if price_drop_pct > 3.0:  # Fiyat %3'den fazla d√º≈üt√º - entry ka√ßƒ±rƒ±ldƒ±
                            self.pending_orders.remove(order)
                            self.pipeline_metrics['signal_missed'] += 1
                            self.add_log(f"‚ùå SIGNAL MISSED: {side} {symbol} - fiyat entry'den √ßok uzakla≈ütƒ± (-{price_drop_pct:.1f}%)")
                            logger.info(f"Signal missed: {order['id']} - price dropped too far below entry")
                            continue
                    else:  # SHORT
                        # SHORT i√ßin: Fiyat entry'den %3 daha yukarƒ± √ßƒ±ktƒ±ysa ‚Üí sinyal ka√ßƒ±rƒ±ldƒ±
                        price_rise_pct = (current_price - signal_price) / signal_price * 100
                        if price_rise_pct > 3.0:  # Fiyat %3'den fazla y√ºkseldi - entry ka√ßƒ±rƒ±ldƒ±
                            self.pending_orders.remove(order)
                            self.pipeline_metrics['signal_missed'] += 1
                            self.add_log(f"‚ùå SIGNAL MISSED: {side} {symbol} - fiyat entry'den √ßok uzakla≈ütƒ± (+{price_rise_pct:.1f}%)")
                            logger.info(f"Signal missed: {order['id']} - price rose too far above entry")
                            continue
                    
                    # Beklemeye devam et
                    remaining_secs = (confirm_after - current_time) / 1000
                    if remaining_secs > 0 and remaining_secs % 60 < 5:  # Her dakika log
                        logger.debug(f"Waiting for confirmation: {symbol} {side} - {remaining_secs:.0f}s remaining")
                    continue
                else:
                    # Konfirmasyon s√ºresi doldu - sinyali onayla
                    order['confirmed'] = True
                    self.pipeline_metrics['signal_confirmed'] += 1
                    self.add_log(f"‚úÖ SIGNAL CONFIRMED: {side} {symbol} @ ${current_price:.4f} (5dk bekleme tamamlandƒ±)")
                    logger.info(f"Signal confirmed after 5min wait: {order['id']}")
            
            # =================================================================
            # Phase 175: TRAILING ENTRY (mirrors Trailing Take Profit logic)
            # Instead of bounce+volume+trending, simply track bottom/peak
            # and trigger when price reverses by trail_entry_distance.
            # Same concept as trail TP but inverted for entries.
            # =================================================================
            trailing_entry_active = order.get('trailingEntryActive', False)
            atr = order.get('atr', entry_price * 0.01)
            
            if not trailing_entry_active:
                # Step 1: Check if price reached pullback entry level
                reached_entry = False
                if side == 'LONG' and current_price <= entry_price:
                    reached_entry = True
                elif side == 'SHORT' and current_price >= entry_price:
                    reached_entry = True
                
                if reached_entry:
                    # Start trailing entry ‚Äî track the extreme price
                    order['trailingEntryActive'] = True
                    self.pipeline_metrics['trail_entry_start'] += 1
                    order['trailEntryStartTime'] = current_time
                    # Initialize extreme price (bottom for LONG, peak for SHORT)
                    order['extremePrice'] = current_price
                    
                    # Calculate trail_entry_distance using COIN-SPECIFIC dynamic trail params
                    # The order already carries dynamic_trail_distance from get_dynamic_trail_params()
                    # which accounts for volatility, hurst, price, and spread.
                    # Trail entry = 30-60% of exit trail distance (trend-adjusted)
                    order_hurst = order.get('hurst', 0.5)
                    dynamic_trail_dist = order.get('dynamic_trail_distance', None)
                    
                    if dynamic_trail_dist is not None and dynamic_trail_dist > 0:
                        # Use coin-specific trail distance from dynamic params
                        # Trending coins: tighter entry trail (30%) ‚Üí enter quickly on small bounce
                        # Mean-reverting: wider entry trail (60%) ‚Üí wait for clear reversal
                        hurst_s = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                        entry_trail_ratio = 0.60 - hurst_s * 0.30  # 0.30 (trending) to 0.60 (mean-reverting)
                        trail_entry_dist = atr * dynamic_trail_dist * entry_trail_ratio
                    else:
                        # Fallback: use ATR-based calculation with wider factor
                        order_adx = order.get('adx', 0)
                        adx_s = min(1.0, max(0.0, (order_adx - 15) / 45))
                        hurst_s = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                        trend_s = adx_s * 0.6 + hurst_s * 0.4
                        # 0.30 - 0.50 ATR (was 0.05-0.10 ‚Äî 6x increase)
                        trail_factor = 0.50 - trend_s * 0.20
                        trail_entry_dist = atr * trail_factor
                    
                    order['trailEntryDistance'] = trail_entry_dist
                    
                    trail_pct = (trail_entry_dist / entry_price * 100) if entry_price > 0 else 0
                    # Phase 223: Fixed NameError ‚Äî et_mult, spread_trail_mult, order_spread were undefined in this scope
                    self.add_log(f"üìç TRAIL ENTRY: {side} {symbol} @ ${current_price:.6f} | Reversal‚â•{trail_pct:.2f}%")
                    logger.info(f"üìç TRAIL ENTRY START: {side} {symbol} entry=${entry_price:.6f} extreme=${current_price:.6f} trail_dist={trail_pct:.2f}% et={self.entry_tightness}")
            else:
                # Step 2: Trailing entry active ‚Äî track extreme and check reversal
                # This mirrors Trail TP: track peakPrice, trigger when price drops by trail_distance
                # Here: track bottomPrice (LONG) or peakPrice (SHORT), trigger on reversal
                
                trail_entry_distance = order.get('trailEntryDistance', atr * 0.08)
                extreme_price = order.get('extremePrice', current_price)
                trail_start = order.get('trailEntryStartTime', current_time)
                trail_timeout_ms = 15 * 60 * 1000  # 15 minute timeout
                
                # Cancel distance: how far from entry before giving up
                order_adx = order.get('adx', 0)
                order_hurst = order.get('hurst', 0.5)
                adx_strength = min(1.0, max(0.0, (order_adx - 15) / 45))
                hurst_strength = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                trend_strength = adx_strength * 0.6 + hurst_strength * 0.4
                base_cancel = 0.7 + trend_strength * 0.8
                cancel_distance = atr * base_cancel
                
                elapsed_ms = current_time - trail_start
                elapsed_secs = elapsed_ms / 1000
                
                if side == 'LONG':
                    # Track bottom price (like trail TP tracks peak)
                    if current_price < extreme_price:
                        order['extremePrice'] = current_price
                        extreme_price = current_price
                    
                    # Reversal confirmed: price rose from bottom by trail_entry_distance
                    if current_price >= extreme_price + trail_entry_distance:
                        reversal_pct = ((current_price - extreme_price) / extreme_price * 100) if extreme_price > 0 else 0
                        self.add_log(f"‚úÖ TRAIL ENTRY OK: {side} {symbol} @ ${current_price:.6f} | Bottom=${extreme_price:.6f} +{reversal_pct:.2f}% ({elapsed_secs:.0f}s)")
                        logger.info(f"‚úÖ TRAIL ENTRY CONFIRMED: {side} {symbol} price=${current_price:.6f} bottom=${extreme_price:.6f} reversal={reversal_pct:.2f}%")
                        self.pipeline_metrics['trail_entry_ok'] += 1
                        await self.execute_pending_order(order, current_price)
                        continue
                    
                    # Cancel: dropped too far below entry
                    if current_price < entry_price - cancel_distance:
                        signal_score = order.get('signalScore', 0)
                        if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                            self.pipeline_metrics['market_fallback'] += 1
                            self.pipeline_metrics['fallback_on_fail'] += 1
                            self.add_log(f"üî• MARKET FALLBACK: {side} {symbol} score={signal_score} ‚Üí trail fail, filling at market")
                            logger.info(f"üî• MARKET FALLBACK(FAIL): {side} {symbol} score={signal_score} dropped too far ‚Üí market fill")
                            await self.execute_pending_order(order, current_price, force_market=True)
                            continue
                        if order in self.pending_orders:
                            self.pending_orders.remove(order)
                        self.pipeline_metrics['trail_entry_fail'] += 1
                        self.add_log(f"‚ùå TRAIL ENTRY FAIL: {side} {symbol} d√º≈ü√º≈ü devam (${current_price:.6f})")
                        logger.info(f"‚ùå TRAIL ENTRY CANCEL: {side} {symbol} dropped {((entry_price-current_price)/atr):.1f}√óATR below entry")
                        continue
                
                else:  # SHORT
                    # Track peak price (like trail TP tracks peak for short)
                    if current_price > extreme_price:
                        order['extremePrice'] = current_price
                        extreme_price = current_price
                    
                    # Reversal confirmed: price dropped from peak by trail_entry_distance
                    if current_price <= extreme_price - trail_entry_distance:
                        reversal_pct = ((extreme_price - current_price) / extreme_price * 100) if extreme_price > 0 else 0
                        self.add_log(f"‚úÖ TRAIL ENTRY OK: {side} {symbol} @ ${current_price:.6f} | Peak=${extreme_price:.6f} -{reversal_pct:.2f}% ({elapsed_secs:.0f}s)")
                        logger.info(f"‚úÖ TRAIL ENTRY CONFIRMED: {side} {symbol} price=${current_price:.6f} peak=${extreme_price:.6f} reversal={reversal_pct:.2f}%")
                        self.pipeline_metrics['trail_entry_ok'] += 1
                        await self.execute_pending_order(order, current_price)
                        continue
                    
                    # Cancel: rose too far above entry
                    if current_price > entry_price + cancel_distance:
                        signal_score = order.get('signalScore', 0)
                        if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                            self.pipeline_metrics['market_fallback'] += 1
                            self.pipeline_metrics['fallback_on_fail'] += 1
                            self.add_log(f"üî• MARKET FALLBACK: {side} {symbol} score={signal_score} ‚Üí trail fail, filling at market")
                            logger.info(f"üî• MARKET FALLBACK(FAIL): {side} {symbol} score={signal_score} rose too far ‚Üí market fill")
                            await self.execute_pending_order(order, current_price, force_market=True)
                            continue
                        if order in self.pending_orders:
                            self.pending_orders.remove(order)
                        self.pipeline_metrics['trail_entry_fail'] += 1
                        self.add_log(f"‚ùå TRAIL ENTRY FAIL: {side} {symbol} y√ºkseli≈ü devam (${current_price:.6f})")
                        logger.info(f"‚ùå TRAIL ENTRY CANCEL: {side} {symbol} rose {((current_price-entry_price)/atr):.1f}√óATR above entry")
                        continue
                
                # Timeout check
                if elapsed_ms > trail_timeout_ms:
                    # Fix 2: Strong signals get market fallback instead of timeout
                    signal_score = order.get('signalScore', 0)
                    if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                        self.pipeline_metrics['market_fallback'] += 1
                        self.add_log(f"üî• MARKET FALLBACK: {side} {symbol} score={signal_score} ‚Üí trail timeout, filling at market")
                        logger.info(f"üî• MARKET FALLBACK: {side} {symbol} score={signal_score} trail_timeout={elapsed_secs:.0f}s ‚Üí market fill")
                        await self.execute_pending_order(order, current_price, force_market=True)
                        continue
                    # Normal timeout
                    self.pending_orders.remove(order)
                    self.pipeline_metrics['trail_entry_timeout'] += 1
                    self.add_log(f"‚è∞ TRAIL ENTRY TIMEOUT: {side} {symbol} (15dk reversal olmadƒ±, score={signal_score})")
                    logger.info(f"‚è∞ TRAIL ENTRY TIMEOUT: {side} {symbol} after {elapsed_secs:.0f}s score={signal_score}")
                    continue
                
                # Periodic log (every ~30s)
                trail_pct = (trail_entry_distance / entry_price * 100) if entry_price > 0 else 0
                if elapsed_secs > 0 and int(elapsed_secs) % 30 < 4:
                    logger.debug(f"üìç TRAIL ENTRY WAIT: {side} {symbol} {elapsed_secs:.0f}s | price=${current_price:.6f} extreme=${extreme_price:.6f} dist={trail_pct:.2f}%")
    
    async def execute_pending_order(self, order: dict, fill_price: float, force_market: bool = False):
        """Execute a pending order at the fill price.
        Args:
            force_market: If True, bypass spread/drift guards (used by market fallback).
        """
        # Remove from pending
        if order in self.pending_orders:
            self.pending_orders.remove(order)
        
        # Phase 55: Check if already have position in this coin
        symbol = order.get('symbol', '')
        existing_position = next((p for p in self.positions if p['symbol'] == symbol), None)
        if existing_position:
            self.add_log(f"‚ö†Ô∏è {symbol}'de zaten pozisyon var, yeni order iptal edildi")
            logger.info(f"‚ö†Ô∏è SKIP ORDER: {symbol} already has open position")
            return  # Don't create duplicate position
        
        
        # Recalculate SL/TP based on actual fill price
        # Apply exit_tightness for faster/slower exits
        atr = order.get('atr', fill_price * 0.01)
        side = order['side']
        
        # FIX #2: Dynamic ATR Multiplier (parity with open_position)
        dynamic_atr_mult = self.calculate_dynamic_atr_multiplier(atr, fill_price)
        
        # Phase 202: Trend Mode wider params
        is_trend_mode = order.get('trend_mode', False)
        if is_trend_mode:
            tm_sl_mult = 1.33
            tm_tp_mult = 1.67
            tm_trail_act_mult = 1.67
            tm_trail_dist_mult = 1.50
            logger.warning(f"üöÄ TREND_MODE EXEC: {side} {symbol} | wider TP/Trail/SL")
        else:
            tm_sl_mult = 1.0
            tm_tp_mult = 1.0
            tm_trail_act_mult = 1.0
            tm_trail_dist_mult = 1.0
        
        adjusted_sl_atr = (self.sl_atr / 10) * self.exit_tightness * dynamic_atr_mult * tm_sl_mult
        adjusted_tp_atr = (self.tp_atr / 10) * self.exit_tightness * dynamic_atr_mult * tm_tp_mult
        
        # Use dynamic trail params from order if available (Cloud Scanner + WebSocket parity)
        if 'dynamic_trail_activation' in order:
            base_trail_activation_atr = order['dynamic_trail_activation']
            base_trail_distance_atr = order['dynamic_trail_distance']
        else:
            base_trail_activation_atr = self.trail_activation_atr
            base_trail_distance_atr = self.trail_distance_atr
        
        adjusted_trail_activation_atr = base_trail_activation_atr * self.exit_tightness * dynamic_atr_mult * tm_trail_act_mult
        adjusted_trail_distance_atr = base_trail_distance_atr * self.exit_tightness * dynamic_atr_mult * tm_trail_dist_mult
        
        if side == 'LONG':
            sl = max(fill_price * 0.01, fill_price - (atr * adjusted_sl_atr))
            tp = fill_price + (atr * adjusted_tp_atr)
            trail_activation = fill_price + (atr * adjusted_trail_activation_atr)
        else:
            sl = fill_price + (atr * adjusted_sl_atr)
            tp = max(fill_price * 0.01, fill_price - (atr * adjusted_tp_atr))
            trail_activation = max(fill_price * 0.01, fill_price - (atr * adjusted_trail_activation_atr))
        
        trail_distance = atr * adjusted_trail_distance_atr
        
        # Phase 224D3: Apply CanaryMode parameter overrides for canary positions
        try:
            if order.get('is_canary', False) and canary_mode.enabled:
                base_params = {'sl': sl, 'tp': tp, 'trail_activation': trail_activation, 'trail_distance': trail_distance}
                canary_result = canary_mode.get_params(order.get('id', ''), base_params)
                # Apply canary multipliers if present
                if 'tp_mult' in canary_mode.canary_params:
                    tp_m = canary_mode.canary_params['tp_mult']
                    if side == 'LONG':
                        tp = fill_price + (tp - fill_price) * tp_m
                    else:
                        tp = fill_price - (fill_price - tp) * tp_m
                if 'sl_mult' in canary_mode.canary_params:
                    sl_m = canary_mode.canary_params['sl_mult']
                    if side == 'LONG':
                        sl = fill_price - (fill_price - sl) * sl_m
                    else:
                        sl = fill_price + (sl - fill_price) * sl_m
                if 'trail_mult' in canary_mode.canary_params:
                    tr_m = canary_mode.canary_params['trail_mult']
                    trail_distance *= tr_m
                logger.info(f"üê§ CANARY: {symbol} {side} | overrides applied: {canary_mode.canary_params}")
        except Exception as canary_err:
            logger.debug(f"CanaryMode params error: {canary_err}")
        
        # Create actual position
        new_position = {
            "id": order['id'].replace('PO_', 'POS_'),
            "symbol": order['symbol'],
            "side": order['side'],
            "entryPrice": fill_price,
            "size": order['size'],
            "sizeUsd": order['sizeUsd'],
            "contracts": order['size'],  # Phase 223b: needed for partial TP
            "stopLoss": sl,
            "takeProfit": tp,
            "trailingStop": sl,
            "trailActivation": trail_activation,
            "trailDistance": trail_distance,
            "isTrailingActive": False,
            "unrealizedPnl": 0.0,
            "unrealizedPnlPercent": 0.0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": order['leverage'],
            "spreadLevel": order['spreadLevel'],
            "pullbackPct": order.get('pullbackPct', 1.0),  # Adverse exit kontrol√º i√ßin
            # Phase 49: Carry forward analysis data from pending order
            "signalScore": order.get('signalScore', 0),
            "mtfScore": order.get('mtfScore', 0),
            "zScore": order.get('zScore', 0),
            # Phase 202: Trend Mode flag for stepped SL
            "trend_mode": is_trend_mode,
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": 0.0,
            "mfe_pct": 0.0,
            "mae_price": fill_price,
            "mfe_price": fill_price,
            "decision_trace": [],
            # Phase 224D3: CanaryMode flag propagated from pending order
            "is_canary": order.get('is_canary', False),
            # Dynamic trail activation threshold data (propagated from pending order)
            "volatility_pct": order.get('volatility_pct', (order.get('atr', fill_price * 0.02) / fill_price * 100) if fill_price > 0 else 2.0),
            "spreadPct": order.get('spreadPct', 0.05),
            "volumeRatio": order.get('volumeRatio', 1.0),
        }
        
        # =====================================================================
        # LIVE TRADING: Send order to Binance before creating local position
        # Phase 186: Limit entry + pre-trade spread filter
        # =====================================================================
        if live_binance_trader.enabled and live_binance_trader.trading_mode == 'live' and not force_market:
            try:
                # Phase 186 Feature C: Pre-trade spread filter
                ccxt_sym = f"{symbol[:-4]}/USDT:USDT"
                try:
                    pre_ticker = await live_binance_trader.exchange.fetch_ticker(ccxt_sym)
                    pre_bid = pre_ticker.get('bid', 0)
                    pre_ask = pre_ticker.get('ask', 0)
                    pre_mid = (pre_bid + pre_ask) / 2 if pre_bid and pre_ask else 0
                    pre_spread = ((pre_ask - pre_bid) / pre_mid * 100) if pre_mid > 0 else 0
                    
                    ENTRY_SPREAD_LIMIT = 0.3  # Max 0.3% spread for entry
                    if pre_spread > ENTRY_SPREAD_LIMIT:
                        logger.warning(f"üö´ SPREAD_FILTER: Rejecting {side} {symbol} entry ‚Äî spread={pre_spread:.3f}% > {ENTRY_SPREAD_LIMIT}% (bid=${pre_bid:.6f} ask=${pre_ask:.6f})")
                        self.add_log(f"üö´ SPREAD FILTER: {symbol} entry skipped (spread {pre_spread:.2f}% too wide)")
                        self.pipeline_metrics['spread_rejected'] += 1
                        # Return order to pending for retry
                        if order not in self.pending_orders:
                            self.pending_orders.append(order)
                        return
                except Exception as sf_err:
                    logger.debug(f"Spread filter check error: {sf_err}")
                    # Continue with entry if spread check fails
                
                # ===== Phase 201: Pre-Entry Price Drift Check =====
                # Compare signal price vs current price ‚Äî reject if drifted too much
                try:
                    signal_price = order.get('signalPrice', 0)
                    # Use pre_ticker from spread filter if available, otherwise fetch fresh
                    try:
                        current_price = pre_ticker.get('last', fill_price)
                    except NameError:
                        current_price = fill_price
                    if signal_price > 0 and current_price > 0:
                        MAX_PRICE_DRIFT_PCT = 1.5  # Max 1.5% drift since signal
                        price_drift_pct = abs(current_price - signal_price) / signal_price * 100
                        if price_drift_pct > MAX_PRICE_DRIFT_PCT:
                            logger.warning(f"üö´ SLIPPAGE_GUARD: {side} {symbol} REJECTED ‚Äî price drifted {price_drift_pct:.2f}% since signal (signal=${signal_price:.6f} ‚Üí now=${current_price:.6f})")
                            self.add_log(f"üö´ SLIPPAGE GUARD: {symbol} price drifted {price_drift_pct:.1f}% since signal")
                            self.pipeline_metrics['drift_rejected'] += 1
                            # Don't retry ‚Äî signal is stale
                            return
                        else:
                            logger.debug(f"‚úÖ DRIFT_CHECK: {symbol} drift={price_drift_pct:.2f}% OK (max {MAX_PRICE_DRIFT_PCT}%)")
                except Exception as drift_err:
                    logger.debug(f"Price drift check error: {drift_err}")
                
                logger.info(f"üî¥ LIVE ORDER: Sending {side} {symbol} to Binance (LIMIT entry)...")
                
                # Phase 186 Feature B: Use limit entry with market fallback
                result = await live_binance_trader.place_limit_entry_order(
                    symbol=symbol,
                    side=side,
                    size_usd=order['sizeUsd'],
                    leverage=order['leverage']
                )
                
                if result:
                    # ===== Phase 201: Post-Fill Max Slippage Rejection =====
                    fill_slippage = abs(result.get('slippage_pct', 0))
                    MAX_FILL_SLIPPAGE_PCT = 0.5  # Max 0.5% fill slippage
                    if fill_slippage > MAX_FILL_SLIPPAGE_PCT:
                        logger.warning(f"üö´ SLIPPAGE_GUARD: {side} {symbol} fill slippage {fill_slippage:.3f}% > max {MAX_FILL_SLIPPAGE_PCT}% ‚Äî CLOSING immediately")
                        self.add_log(f"üö´ SLIPPAGE REJECT: {symbol} closed (fill slip {fill_slippage:.2f}%)")
                        try:
                            await live_binance_trader.close_position(
                                symbol=symbol,
                                side=side,
                                amount=result.get('amount', order['size'])
                            )
                        except Exception as close_err:
                            logger.error(f"‚ùå Slippage rejection close failed: {close_err}")
                        return  # Don't create local position
                    
                    new_position['binance_order_id'] = result.get('id')
                    actual_fill = result.get('price', fill_price)
                    new_position['binance_fill_price'] = actual_fill
                    new_position['isLive'] = True
                    new_position['entry_method'] = result.get('entry_method', 'MARKET')
                    new_position['entry_slippage'] = result.get('slippage_pct', 0)
                    new_position['entry_spread'] = result.get('spread_pct', 0)
                    logger.info(f"‚úÖ BINANCE ORDER SUCCESS: {result.get('id')} | method={result.get('entry_method', 'MARKET')} | slippage={fill_slippage:.3f}%")
                    
                    # Phase 186: Update entryPrice + SL/TP if actual fill differs
                    if abs(actual_fill - fill_price) / fill_price > 0.001:
                        new_position['entryPrice'] = actual_fill
                        # Recalculate SL/TP with actual fill
                        if side == 'LONG':
                            new_position['stopLoss'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_sl_atr))
                            new_position['takeProfit'] = actual_fill + (atr * adjusted_tp_atr)
                            new_position['trailActivation'] = actual_fill + (atr * adjusted_trail_activation_atr)
                            new_position['trailingStop'] = new_position['stopLoss']
                        else:
                            new_position['stopLoss'] = actual_fill + (atr * adjusted_sl_atr)
                            new_position['takeProfit'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_tp_atr))
                            new_position['trailActivation'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_trail_activation_atr))
                            new_position['trailingStop'] = new_position['stopLoss']
                        logger.info(f"üìê SL/TP RECALC: {symbol} fill=${actual_fill:.6f} vs expected=${fill_price:.6f} ‚Üí SL=${new_position['stopLoss']:.6f} TP=${new_position['takeProfit']:.6f}")
                else:
                    logger.error(f"‚ùå BINANCE ORDER FAILED - skipping position creation")
                    self.add_log(f"‚ùå BINANCE HATASI: {side} {symbol} - Emir g√∂nderilemedi (yetersiz bakiye veya symbol hatasƒ±)")
                    return  # Don't create position if Binance order failed
                    
            except Exception as e:
                error_msg = str(e)[:80]  # Truncate long error messages
                logger.error(f"‚ùå LIVE ORDER ERROR: {e}")
                self.add_log(f"‚ùå BINANCE HATASI: {side} {symbol} - {error_msg}")
                return  # Don't create position if there was an error
        elif force_market and live_binance_trader.enabled and live_binance_trader.trading_mode == 'live':
            # Force market: bypass spread/drift guards, send direct market order
            try:
                logger.info(f"üî• FORCE MARKET ORDER: Sending {side} {symbol} to Binance (MARKET, no spread/drift check)...")
                result = await live_binance_trader.place_market_order(
                    symbol=symbol,
                    side=side,
                    size_usd=order['sizeUsd'],
                    leverage=order['leverage']
                )
                if result:
                    new_position['binance_order_id'] = result.get('id')
                    actual_fill = result.get('price', fill_price)
                    new_position['binance_fill_price'] = actual_fill
                    new_position['isLive'] = True
                    new_position['entry_method'] = 'MARKET_FALLBACK'
                    new_position['entry_slippage'] = result.get('slippage_pct', 0)
                    new_position['entry_spread'] = result.get('spread_pct', 0)
                    logger.info(f"‚úÖ FORCE MARKET SUCCESS: {result.get('id')} | slippage={abs(result.get('slippage_pct', 0)):.3f}%")
                    # Recalculate SL/TP with actual fill
                    if abs(actual_fill - fill_price) / fill_price > 0.001:
                        new_position['entryPrice'] = actual_fill
                        if side == 'LONG':
                            new_position['stopLoss'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_sl_atr))
                            new_position['takeProfit'] = actual_fill + (atr * adjusted_tp_atr)
                            new_position['trailActivation'] = actual_fill + (atr * adjusted_trail_activation_atr)
                            new_position['trailingStop'] = new_position['stopLoss']
                        else:
                            new_position['stopLoss'] = actual_fill + (atr * adjusted_sl_atr)
                            new_position['takeProfit'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_tp_atr))
                            new_position['trailActivation'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_trail_activation_atr))
                            new_position['trailingStop'] = new_position['stopLoss']
                else:
                    logger.error(f"‚ùå FORCE MARKET FAILED - skipping position creation")
                    self.add_log(f"‚ùå MARKET FALLBACK HATASI: {side} {symbol} - Emir g√∂nderilemedi")
                    return
            except Exception as e:
                logger.error(f"‚ùå FORCE MARKET ERROR: {e}")
                self.add_log(f"‚ùå MARKET FALLBACK HATASI: {side} {symbol} - {str(e)[:80]}")
                return
        
        # Paper Trading: Initial Margin = Position Size / Leverage
        # Kaldƒ±ra√ßlƒ± i≈ülemde sadece teminat miktarƒ± bakiyeden d√º≈ü√ºl√ºr
        leverage = new_position.get('leverage', 10)
        initial_margin = new_position['sizeUsd'] / leverage
        new_position['initialMargin'] = initial_margin  # Store for close calculation
        
        # Live trading'de bakiyeyi d√º≈ü√ºrme - Binance zaten d√º≈ü√ºrd√º
        if not live_binance_trader.enabled:
            self.balance -= initial_margin
        
        self.positions.append(new_position)
        self.pipeline_metrics['filled'] += 1
        
        # Save to SQLite for persistent openTime tracking
        try:
            await db_manager.save_open_position(new_position)
            logger.info(f"üìÇ Position saved to SQLite: {symbol} openTime={new_position.get('openTime')}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to save position to SQLite: {e}")
        
        # Calculate how much better than signal price we got
        signal_price = order.get('signalPrice', fill_price)
        if side == 'LONG':
            improvement = ((signal_price - fill_price) / signal_price) * 100
        else:
            improvement = ((fill_price - signal_price) / signal_price) * 100
        
        live_tag = "üî¥ LIVE" if live_binance_trader.enabled else "üìÑ PAPER"
        self.add_log(f"‚úÖ {live_tag} FILLED: {side} {order['symbol']} @ ${fill_price:.4f} | Improvement: {improvement:.2f}% | Lev: {order['leverage']}x")
        self.save_state()
        logger.info(f"‚úÖ {live_tag} FILLED: {side} {order['symbol']} @ {fill_price} (improvement: {improvement:.2f}%)")
    
    # =========================================================================
    # PHASE 20: ADVANCED RISK MANAGEMENT METHODS
    # =========================================================================
    
    def get_dynamic_trail_distance(self, atr: float, roi_pct: float = 0) -> float:
        """
        Calculate trail distance based on current spread and ROI.
        Phase 59: ROI-based dynamic trail - more profit = wider trail
        """
        spread = self.current_spread_pct
        
        # Base trail distance from spread
        if spread < 0.05:
            base_trail = atr * 0.5  # Tight trailing for low spread
        elif spread < 0.15:
            base_trail = atr * 1.0  # Normal trailing
        else:
            base_trail = atr * (1.0 + spread)  # Wide trailing scales with spread
        
        # Phase 59: ROI-based multiplier - k√¢r arttƒ±k√ßa trail geni≈üler
        if roi_pct >= 50:
            roi_mult = 2.0  # Very profitable, give lots of room
        elif roi_pct >= 25:
            roi_mult = 1.5  # Good profit, moderate room
        elif roi_pct >= 10:
            roi_mult = 1.2  # Small profit, slightly more room
        else:
            roi_mult = 1.0  # Standard trail
        
        return base_trail * roi_mult
    
    def update_progressive_sl(self, pos: dict, current_price: float, atr: float):
        """Move SL progressively as position goes into profit.
        
        Thresholds are multiplied by exit_tightness:
        - Lower exit_tightness (0.3-0.5) = earlier SL moves
        - Higher exit_tightness (1.5-2.0) = later SL moves
        """
        entry = pos['entryPrice']
        
        # Apply exit_tightness to thresholds - lower = earlier activation
        t = self.get_effective_exit_tightness(pos)
        
        if pos['side'] == 'LONG':
            profit_atr = (current_price - entry) / atr if atr > 0 else 0
            
            # Thresholds scaled by exit_tightness
            if profit_atr >= 2.5 * t:
                new_sl = entry + (2.0 * atr)  # Lock in 2 ATR profit
            elif profit_atr >= 2.0 * t:
                new_sl = entry + (1.5 * atr)  # Lock in 1.5 ATR profit
            elif profit_atr >= 1.5 * t:
                new_sl = entry + (1.0 * atr)  # Lock in 1 ATR profit
            elif profit_atr >= 1.0 * t:
                new_sl = entry + (0.5 * atr)  # Lock in 0.5 ATR profit
            elif profit_atr >= 0.25 * t:
                new_sl = entry  # Breakeven (daha erken koruma)
            else:
                return False  # No change
                
            if new_sl > pos['stopLoss']:
                old_sl = pos['stopLoss']
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl  # Also update trailing stop
                self.add_log(f"üìà PROGRESSIVE SL: ${old_sl:.6f} ‚Üí ${new_sl:.6f} (+{profit_atr:.1f} ATR)")
                return True
                
        elif pos['side'] == 'SHORT':
            profit_atr = (entry - current_price) / atr if atr > 0 else 0
            
            # Thresholds scaled by exit_tightness
            if profit_atr >= 2.5 * t:
                new_sl = entry - (2.0 * atr)
            elif profit_atr >= 2.0 * t:
                new_sl = entry - (1.5 * atr)
            elif profit_atr >= 1.5 * t:
                new_sl = entry - (1.0 * atr)
            elif profit_atr >= 1.0 * t:
                new_sl = entry - (0.5 * atr)
            elif profit_atr >= 0.25 * t:
                new_sl = entry  # Breakeven (daha erken koruma)
            else:
                return False
                
            if new_sl < pos['stopLoss']:
                old_sl = pos['stopLoss']
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl  # Also update trailing stop
                self.add_log(f"üìà PROGRESSIVE SL: ${old_sl:.6f} ‚Üí ${new_sl:.6f} (+{profit_atr:.1f} ATR)")
                return True
        
        return False
    
    def check_loss_recovery(self, pos: dict, current_price: float, atr: float) -> bool:
        """If in loss and recovering, trail to minimize loss."""
        entry = pos['entryPrice']
        
        if pos['side'] == 'LONG':
            loss_pct = ((entry - current_price) / entry) * 100 if entry > 0 else 0
            
            # Only if in loss (>1%) and price is recovering
            if loss_pct > 1:
                if 'recovery_low' not in pos:
                    pos['recovery_low'] = current_price
                elif current_price < pos['recovery_low']:
                    pos['recovery_low'] = current_price
                    
                # If price bounced from low by 0.3 ATR
                if current_price > pos['recovery_low'] + (atr * 0.3):
                    if not pos.get('recovery_mode', False):
                        pos['recovery_mode'] = True
                        pos['recovery_sl'] = current_price - (atr * 0.3)
                        self.add_log(f"üîÑ RECOVERY MODE: Zarar minimizasyonu aktif @ ${current_price:.6f}")
                    else:
                        new_recovery_sl = current_price - (atr * 0.3)
                        if new_recovery_sl > pos.get('recovery_sl', 0):
                            pos['recovery_sl'] = new_recovery_sl
                            
                    # Check recovery SL hit
                    if current_price <= pos['recovery_sl']:
                        self.close_position(pos, current_price, 'RECOVERY_EXIT')
                        return True
                        
        elif pos['side'] == 'SHORT':
            loss_pct = ((current_price - entry) / entry) * 100 if entry > 0 else 0
            
            if loss_pct > 1:  # %1 kayƒ±pta recovery mode (daha erken m√ºdahale)
                if 'recovery_high' not in pos:
                    pos['recovery_high'] = current_price
                elif current_price > pos['recovery_high']:
                    pos['recovery_high'] = current_price
                    
                if current_price < pos['recovery_high'] - (atr * 0.3):
                    if not pos.get('recovery_mode', False):
                        pos['recovery_mode'] = True
                        pos['recovery_sl'] = current_price + (atr * 0.3)
                        self.add_log(f"üîÑ RECOVERY MODE: Zarar minimizasyonu aktif @ ${current_price:.6f}")
                    else:
                        new_recovery_sl = current_price + (atr * 0.3)
                        if new_recovery_sl < pos.get('recovery_sl', float('inf')):
                            pos['recovery_sl'] = new_recovery_sl
                            
                    if current_price >= pos['recovery_sl']:
                        self.close_position(pos, current_price, 'RECOVERY_EXIT')
                        return True
        
        return False
    
    def check_time_based_exit(self, pos: dict, current_price: float, atr: float = None) -> bool:
        """Gradually liquidate positions that are open too long - close on bounces."""
        open_time = pos.get('openTime', 0)
        age_ms = int(datetime.now().timestamp() * 1000) - open_time
        age_hours = age_ms / (1000 * 60 * 60)
        
        if atr is None:
            atr = current_price * 0.01
        
        # exit_tightness ile √∂l√ßeklendir: y√ºksek = daha uzun tutma s√ºresi
        et = self.get_effective_exit_tightness(pos)
        adjusted_max_age = self.max_position_age_hours * et
        adjusted_hard_limit = 48 * et
        bounce_mult = 0.3 * et  # Bounce threshold: y√ºksek = daha geni≈ü
        
        # After adjusted max age, start gradual liquidation
        if age_hours > adjusted_max_age:
            # Mark position for gradual exit if not already
            if not pos.get('gradual_exit_mode', False):
                pos['gradual_exit_mode'] = True
                pos['gradual_exit_start'] = current_price
                self.add_log(f"‚è∞ ZAMAN A≈ûIMI: {age_hours:.1f}h > {adjusted_max_age:.1f}h (x{et:.1f}) - A≈üamalƒ± tasfiye")
            
            # For LONG: Close on bounces (price goes up then comes back)
            if pos['side'] == 'LONG':
                if 'gradual_high' not in pos:
                    pos['gradual_high'] = current_price
                elif current_price > pos['gradual_high']:
                    pos['gradual_high'] = current_price
                
                # If price dropped from high by bounce_mult * ATR, close position
                if pos['gradual_high'] - current_price >= atr * bounce_mult:
                    self.add_log(f"üìâ BOUNCED EXIT: A≈üamalƒ± tasfiye tamamlandƒ±")
                    pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_GRADUAL', 'roi': round(((current_price - pos['entryPrice']) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                    self.close_position(pos, current_price, 'TIME_GRADUAL')
                    return True
                    
            # For SHORT: Close when price dips then comes back
            elif pos['side'] == 'SHORT':
                if 'gradual_low' not in pos:
                    pos['gradual_low'] = current_price
                elif current_price < pos['gradual_low']:
                    pos['gradual_low'] = current_price
                
                # If price rose from low by bounce_mult * ATR, close position
                if current_price - pos['gradual_low'] >= atr * bounce_mult:
                    self.add_log(f"üìà BOUNCED EXIT: A≈üamalƒ± tasfiye tamamlandƒ±")
                    pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_GRADUAL', 'roi': round(((pos['entryPrice'] - current_price) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                    self.close_position(pos, current_price, 'TIME_GRADUAL')
                    return True
            
            # Hard limit: force close regardless
            if age_hours > adjusted_hard_limit:
                self.add_log(f"üÜò {adjusted_hard_limit:.0f}h+ SAAT: Zorunlu √ßƒ±kƒ±≈ü (x{et:.1f})")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_FORCE', 'roi': round(((current_price - pos['entryPrice']) / pos['entryPrice'] * 100) if pos.get('side') == 'LONG' and pos['entryPrice'] > 0 else ((pos['entryPrice'] - current_price) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                self.close_position(pos, current_price, 'TIME_FORCE')
                return True
                
        return False
    
    def check_emergency_sl(self, pos: dict, current_price: float) -> bool:
        """Hard limit for maximum loss per position.
        
        Dynamic threshold: max(base_emergency_pct, actual_sl_distance * 1.5) * exit_tightness
        This ensures Emergency SL never triggers BEFORE normal SL on high-vol coins.
        exit_tightness scales the threshold: higher = more patient, lower = quicker exit.
        """
        entry = pos['entryPrice']
        
        if pos['side'] == 'LONG':
            loss_pct = ((entry - current_price) / entry) * 100 if entry > 0 else 0
        else:
            loss_pct = ((current_price - entry) / entry) * 100 if entry > 0 else 0
        
        # Dynamic emergency threshold: never tighter than the position's own SL
        sl_price = pos.get('stopLoss', 0)
        if sl_price > 0 and entry > 0:
            actual_sl_distance_pct = abs(entry - sl_price) / entry * 100
            effective_emergency_pct = max(self.emergency_sl_pct, actual_sl_distance_pct * 1.5)
        else:
            effective_emergency_pct = self.emergency_sl_pct
        
        # Apply exit_tightness: higher = wider emergency threshold (more patient)
        et = self.get_effective_exit_tightness(pos)
        effective_emergency_pct = effective_emergency_pct * et
        
        # Cap at 10% * exit_tightness to prevent runaway losses
        effective_emergency_pct = min(effective_emergency_pct, 10.0 * et)
            
        if loss_pct >= effective_emergency_pct:
            self.add_log(f"üÜò ACƒ∞L √áIKI≈û: %{loss_pct:.1f} kayƒ±p (e≈üik: %{effective_emergency_pct:.1f}, x{et:.1f})")
            self.close_position(pos, current_price, 'EMERGENCY_SL')
            return True
        return False
    
    def check_portfolio_drawdown(self) -> bool:
        """Phase 217: T√ºm a√ßƒ±k pozisyonlarƒ±n toplam unrealized kaybƒ±nƒ± kontrol et."""
        if not self.positions:
            return False
        
        total_unrealized = sum(p.get('unrealizedPnl', 0) for p in self.positions)
        
        if self.balance <= 0:
            return False
        
        loss_pct = (total_unrealized / self.balance) * 100
        
        if loss_pct < -self.portfolio_max_unrealized_loss_pct:
            # En k√∂t√º pozisyondan ba≈ülayarak kapat
            sorted_positions = sorted(
                self.positions,
                key=lambda p: p.get('unrealizedPnl', 0)
            )
            
            # En k√∂t√º %50'sini kapat
            close_count = max(1, len(sorted_positions) // 2)
            for pos in sorted_positions[:close_count]:
                current_price = pos.get('currentPrice', pos.get('entryPrice', 0))
                self.close_position(pos, current_price, 'PORTFOLIO_DRAWDOWN')
            
            self.add_log(
                f"üö® PORTF√ñY KORUMA: Toplam kayƒ±p %{abs(loss_pct):.1f} "
                f"(limit: %{self.portfolio_max_unrealized_loss_pct}), "
                f"{close_count} pozisyon kapatƒ±ldƒ±"
            )
            return True
        return False
    
    def check_adverse_position_exit(self, pos: dict, current_price: float, atr: float = None) -> bool:
        """
        4 saat boyunca terste kalan pozisyonlarƒ± kontrol et.
        
        Kapatma kriterleri:
        1. Pozisyon 4+ saat terste (giri≈ü fiyatƒ±nƒ±n ters tarafƒ±nda)
        2. Fiyat, pullback seviyesinden daha fazla d√º≈ümemi≈üse kapat
        
        Bu sayede:
        - D√∂nmeyecek pozisyonlardan erken √ßƒ±kƒ±lƒ±r
        - Daha fazla d√º≈ümemi≈üse zarar minimize edilir
        """
        open_time = pos.get('openTime', 0)
        age_ms = int(datetime.now().timestamp() * 1000) - open_time
        age_hours = age_ms / (1000 * 60 * 60)
        
        # exit_tightness ile √∂l√ßeklendir: y√ºksek = daha sabƒ±rlƒ± (4h * 2.7 = 10.8h)
        et = self.get_effective_exit_tightness(pos)
        adverse_hours = 4 * et
        if age_hours < adverse_hours:
            return False
        
        entry = pos['entryPrice']
        # exit_tightness ile pullback geni≈ület: y√ºksek = daha geni≈ü tolerans
        pullback_pct = pos.get('pullbackPct', 1.0) * et
        
        if pos['side'] == 'LONG':
            # Terste mi? (fiyat entry'nin altƒ±nda)
            if current_price >= entry:
                return False  # K√¢rda, kontrol etme
            
            # Pullback threshold: entry'den ne kadar a≈üaƒüƒ± d√º≈üebilir
            pullback_threshold = entry * (1 - pullback_pct / 100)
            
            # Fiyat pullback threshold'unun √ºst√ºndeyse (√ßok fazla d√º≈ümediyse) kapat
            if current_price >= pullback_threshold:
                loss_pct = ((entry - current_price) / entry) * 100
                self.add_log(f"‚è∞ ADVERSE EXIT: {pos['symbol']} {age_hours:.1f}h terste | Zarar: %{loss_pct:.2f}")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'ADVERSE_TIME', 'roi': round(-loss_pct, 1)})
                self.close_position(pos, current_price, 'ADVERSE_TIME_EXIT')
                return True
                
        elif pos['side'] == 'SHORT':
            # Terste mi? (fiyat entry'nin √ºst√ºnde)
            if current_price <= entry:
                return False  # K√¢rda, kontrol etme
            
            # Pullback threshold: entry'den ne kadar yukarƒ± √ßƒ±kabilir
            pullback_threshold = entry * (1 + pullback_pct / 100)
            
            # Fiyat pullback threshold'unun altƒ±ndaysa (√ßok fazla y√ºkselmemi≈üse) kapat
            if current_price <= pullback_threshold:
                loss_pct = ((current_price - entry) / entry) * 100
                self.add_log(f"‚è∞ ADVERSE EXIT: {pos['symbol']} {age_hours:.1f}h terste | Zarar: %{loss_pct:.2f}")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'ADVERSE_TIME', 'roi': round(-loss_pct, 1)})
                self.close_position(pos, current_price, 'ADVERSE_TIME_EXIT')
                return True
        
        return False

    
    def check_daily_drawdown(self) -> bool:
        """Pause trading if daily loss exceeds limit."""
        # Phase 60: Use Turkey timezone (UTC+3) for consistency with get_today_pnl
        # pytz imported globally
        turkey_tz = pytz.timezone('Europe/Istanbul')
        now_turkey = datetime.now(turkey_tz)
        today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_ms = int(today_start.timestamp() * 1000)
        
        today_trades = [t for t in self.trades if t.get('closeTime', 0) >= today_start_ms]
        daily_pnl = sum(t.get('pnl', 0) for t in today_trades)
        daily_pnl_pct = (daily_pnl / self.balance) * 100 if self.balance > 0 else 0
        
        if daily_pnl_pct < -self.daily_drawdown_limit:
            if self.enabled:
                self.enabled = False
                self.add_log(f"üö® G√úNL√úK Lƒ∞Mƒ∞T: %{abs(daily_pnl_pct):.1f} kayƒ±p, trading durduruldu")
                self.save_state()
            return True
        return False
        
        
    def load_state(self):
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    data = json.load(f)
                    self.balance = data.get('balance', 10000.0)
                    self.positions = data.get('positions', [])
                    self.trades = data.get('trades', [])
                    self.equity_curve = data.get('equity_curve', [])
                    self.stats = data.get('stats', self.stats)
                    self.enabled = data.get('enabled', True)
                    # Phase 17: Load settings
                    self.symbol = data.get('symbol', 'SOLUSDT')
                    self.leverage = data.get('leverage', 10)
                    self.risk_per_trade = data.get('risk_per_trade', 0.02)
                    # Phase 18: Load full trading parameters
                    self.sl_atr = data.get('sl_atr', 15)  # Default: 15 (1.5x ATR)
                    self.tp_atr = data.get('tp_atr', 30)  # Default: 30 (3.0x ATR)
                    self.trail_activation_atr = data.get('trail_activation_atr', 1.5)
                    self.trail_distance_atr = data.get('trail_distance_atr', 1.0)
                    self.max_positions = data.get('max_positions', 50)  # Default: 50
                    # Phase 32: Load algorithm sensitivity settings
                    self.z_score_threshold = data.get('z_score_threshold', 1.6)  # Default: 1.6
                    self.min_confidence_score = data.get('min_confidence_score', 68)  # Default: 68
                    # Phase 50: Dynamic Min Score Range
                    self.min_score_low = data.get('min_score_low', 60)  # Default: 60
                    self.min_score_high = data.get('min_score_high', 90)  # Default: 90
                    # Phase 36: Load entry/exit tightness
                    self.entry_tightness = data.get('entry_tightness', 1.8)  # Default: Gev≈üek
                    self.exit_tightness = data.get('exit_tightness', 1.2)  # Default: 1.2x
                    # Phase 57: Load Kill Switch settings
                    if 'kill_switch_first_reduction' in data:
                        daily_kill_switch.first_reduction_pct = data.get('kill_switch_first_reduction', -100)
                    if 'kill_switch_full_close' in data:
                        daily_kill_switch.full_close_pct = data.get('kill_switch_full_close', -150)
                    # Phase 60: Load AI Optimizer state
                    self.ai_optimizer_enabled = data.get('ai_optimizer_enabled', False)
                    # Phase 217: Load leverage multiplier + daily_start_balance
                    self.leverage_multiplier = data.get('leverage_multiplier', 1.0)
                    self.daily_start_balance = data.get('daily_start_balance', self.balance)
                    # Sync with parameter_optimizer
                    try:
                        parameter_optimizer.enabled = self.ai_optimizer_enabled
                    except:
                        pass
                    # Phase 19: Load logs
                    self.logs = data.get('logs', [])
                    logger.info(f"Loaded Paper Trading: ${self.balance:.2f} | {self.symbol} | {self.leverage}x | SL:{self.sl_atr} TP:{self.tp_atr} | KS:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}")
                    
                    # Phase 48: Load kill switch faults from trade history
                    kill_switch_fault_tracker.load_from_trade_history(self.trades)
                    # Phase 59: Load coin performance stats from trade history
                    coin_performance_tracker.load_from_trade_history(self.trades)
                    # Phase 224B: Load EV signal filter state
                    self.score_band_stats = data.get('score_band_stats', {})
                    self.last_signal_per_coin = data.get('last_signal_per_coin', {})
                    # Pipeline metrics persistence
                    saved_metrics = data.get('pipeline_metrics', {})
                    if saved_metrics:
                        self.pipeline_metrics.update(saved_metrics)
            except Exception as e:
                logger.error(f"Failed to load state: {e}")
                
    def save_state(self, force: bool = False):
        # Phase 217: Save state throttle ‚Äî max 1 save per 2 seconds (unless force=True)
        now = datetime.now().timestamp()
        if not force and now - self._last_save_time < 2.0:
            return
        self._last_save_time = now
        try:
            data = {
                "balance": self.balance,
                "positions": self.positions,
                "trades": self.trades,
                "equity_curve": self.equity_curve[-500:],
                "stats": self.stats,
                "enabled": self.enabled,
                # Phase 17: Save settings
                "symbol": self.symbol,
                "leverage": self.leverage,
                "risk_per_trade": self.risk_per_trade,
                # Phase 18: Save full trading parameters
                "sl_atr": self.sl_atr,
                "tp_atr": self.tp_atr,
                "trail_activation_atr": self.trail_activation_atr,
                "trail_distance_atr": self.trail_distance_atr,
                "max_positions": self.max_positions,
                # Phase 32: Save algorithm sensitivity settings
                "z_score_threshold": self.z_score_threshold,
                "min_confidence_score": self.min_confidence_score,
                # Phase 50: Dynamic Min Score Range
                "min_score_low": self.min_score_low,
                "min_score_high": self.min_score_high,
                # Phase 36: Save entry/exit tightness
                "entry_tightness": self.entry_tightness,
                "exit_tightness": self.exit_tightness,
                # Phase 57: Kill Switch settings
                "kill_switch_first_reduction": daily_kill_switch.first_reduction_pct,
                "kill_switch_full_close": daily_kill_switch.full_close_pct,
                # Phase 60: AI Optimizer state
                "ai_optimizer_enabled": self.ai_optimizer_enabled,
                # Phase 217: Leverage multiplier + daily_start_balance
                "leverage_multiplier": getattr(self, 'leverage_multiplier', 1.0),
                "daily_start_balance": self.daily_start_balance,
                # Phase 19: Save logs
                "logs": self.logs[-100:],
                # Phase 224B: EV signal filter state
                "score_band_stats": self.score_band_stats,
                "last_signal_per_coin": self.last_signal_per_coin,
                "pipeline_metrics": self.pipeline_metrics,
            }
            with open(self.state_file, 'w') as f:
                json.dump(data, f)
        except Exception as e:
            logger.error(f"Failed to save state: {e}")

    def reset(self):
        """Reset paper trading to initial state.
        In live mode, preserves Binance balance instead of hardcoding 10000.
        """
        # Live modda Binance balance'ƒ±nƒ± koru, paper modda 10000 kullan
        if live_binance_trader.enabled and hasattr(self, 'balance') and self.balance > 0:
            reset_balance = self.balance  # Keep current Binance balance
            logger.info(f"üîÑ Reset: Keeping live balance ${reset_balance:.2f}")
        else:
            reset_balance = 10000.0
        
        self.balance = reset_balance
        self.initial_balance = reset_balance
        self.positions = []
        self.trades = []
        self.equity_curve = [{"time": int(datetime.now().timestamp() * 1000), "balance": reset_balance, "drawdown": 0.0}]
        self.stats = {
            "totalTrades": 0, "winningTrades": 0, "losingTrades": 0, "winRate": 0.0,
            "totalPnl": 0.0, "maxDrawdown": 0.0, "profitFactor": 0.0
        }
        # Phase 32: Clear old logs on reset
        self.logs = []
        # Clear pending orders
        self.pending_orders = []
        # Reset pipeline metrics
        for key in self.pipeline_metrics:
            self.pipeline_metrics[key] = 0
        self.save_state()
        logger.info("üîÑ Paper Trading Reset to $10,000")

    def close_position_by_id(self, position_id: str, current_price: float) -> bool:
        """Close a specific position by ID."""
        pos = next((p for p in self.positions if p['id'] == position_id), None)
        if not pos:
            return False
        self.close_position(pos, current_price, 'MANUAL')
        return True

    def on_signal(self, signal: Dict, current_price: float):
        # Phase 19: Log signal received
        action = signal.get('action', 'UNKNOWN')
        self.add_log(f"üì° Sƒ∞NYAL ALINDI: {action} @ ${current_price:.6f}")
        
        # Phase 16: Check if auto-trade is enabled
        if not self.enabled:
            self.add_log(f"‚è∏Ô∏è Auto-trade kapalƒ±, i≈ülem yapƒ±lmadƒ±")
            return
        
        # Phase 22: Multi-position and hedging logic
        action = signal.get('action', 'UNKNOWN')
        
        # Check total position limit
        if len(self.positions) >= self.max_positions:
            self.add_log(f"‚ö†Ô∏è Max pozisyon limiti ({self.max_positions}), yeni i≈ülem yapƒ±lmadƒ±")
            return
        
        # PHASE 33: Position scaling is handled in open_position method
        # This method is mainly for opposite signal exit logic
        
        # =====================================================================
        # PHASE 29: ENHANCED OPPOSITE SIGNAL EXIT - BALANCE PROTECTION FOCUS
        # =====================================================================
        
        opposite_positions = [p for p in self.positions if p.get('side') != action]
        
        # ATR for calculations (fallback to 1% of price)
        atr_estimate = current_price * 0.01
        
        for pos in opposite_positions:
            entry = pos.get('entryPrice', current_price)
            
            # Calculate PnL percentage
            if pos['side'] == 'LONG':
                pnl_pct = ((current_price - entry) / entry) * 100
            else:
                pnl_pct = ((entry - current_price) / entry) * 100
            
            # 1. PROFITABLE: Close immediately to lock profit
            if pnl_pct > 0.5:  # At least 0.5% profit
                self.add_log(f"üîÑ Sƒ∞NYAL TERSƒ∞NE D√ñND√ú: {pos['side']} %{pnl_pct:.1f} karlƒ± kapatƒ±lƒ±yor!")
                self.close_position(pos, current_price, 'SIGNAL_REVERSAL_PROFIT')
                continue
            
            # 2. SMALL LOSS (-2% to 0.5%): Activate breakeven trailing
            elif pnl_pct > -2:
                if not pos.get('breakeven_mode', False):
                    pos['breakeven_mode'] = True
                    pos['isTrailingActive'] = True
                    # Set tight trailing to try to close at breakeven or minimal loss
                    if pos['side'] == 'LONG':
                        pos['trailingStop'] = current_price - (atr_estimate * 0.3)
                        pos['trailDistance'] = atr_estimate * 0.3
                    else:
                        pos['trailingStop'] = current_price + (atr_estimate * 0.3)
                        pos['trailDistance'] = atr_estimate * 0.3
                    self.add_log(f"üõ°Ô∏è BREAKEVEN MODE: {pos['side']} %{pnl_pct:.1f} - Sƒ±kƒ± trailing aktif")
            
            # 3. LARGER LOSS (< -2%): Recovery mode with emergency SL
            else:
                if not pos.get('recovery_mode', False):
                    pos['recovery_mode'] = True
                    pos['isTrailingActive'] = True
                    # Set emergency stop loss to prevent further losses
                    if pos['side'] == 'LONG':
                        # Set SL at current price minus small buffer (accept the loss)
                        emergency_sl = current_price - (atr_estimate * 0.5)
                        pos['stopLoss'] = max(pos.get('stopLoss', 0), emergency_sl)
                    else:
                        emergency_sl = current_price + (atr_estimate * 0.5)
                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), emergency_sl)
                    self.add_log(f"üÜò RECOVERY MODE: {pos['side']} %{pnl_pct:.1f} - Emergency SL aktif @ {pos['stopLoss']:.6f}")

        # If hedging is disabled, check for opposite direction (Check again as some might have closed above)
        if not self.allow_hedging:
            remaining_opposite = [p for p in self.positions if p.get('side') != action]
            if len(remaining_opposite) > 0:
                self.add_log(f"‚ö†Ô∏è Hedging kapalƒ±, zaten ters pozisyon var")
                return

        # =====================================================================
        # PHASE 29: BALANCE-PROTECTED POSITION SIZING
        # PHASE 30: KELLY CRITERION + SESSION MANAGER
        # =====================================================================
        
        # Update BalanceProtector with current balance
        balance_protector.update_peak(self.balance)
        
        # Get leverage from signal (spread-based dynamic leverage)
        leverage = signal.get('leverage', self.leverage)
        
        # Phase 30: Apply SessionManager leverage adjustment
        session_adjusted_leverage = session_manager.adjust_leverage(leverage)
        
        # Apply BalanceProtector leverage multiplier
        leverage_mult = balance_protector.calculate_leverage_multiplier(self.balance)
        user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        adjusted_leverage = int(session_adjusted_leverage * leverage_mult * user_lev_mult)
        adjusted_leverage = max(3, min(75, adjusted_leverage))
        
        # Phase 230B: Override leverage cap (BTC counter-trend protection)
        if signal.get('overrideLeverageCap'):
            cap = signal['overrideLeverageCap']
            if adjusted_leverage > cap:
                logger.info(f"üí™ OVERRIDE LEV CAP: {symbol} {adjusted_leverage}x ‚Üí {cap}x")
                adjusted_leverage = cap
        
        # Get size multiplier from signal and BalanceProtector
        signal_size_mult = signal.get('sizeMultiplier', 1.0)
        balance_size_mult = balance_protector.calculate_position_size_multiplier(self.balance)
        final_size_mult = signal_size_mult * balance_size_mult
        
        # Check if we should reduce risk
        if balance_protector.should_reduce_risk(self.balance):
            final_size_mult *= 0.5  # Additional 50% reduction
            self.add_log(f"‚ö†Ô∏è DRAWDOWN KORUMASI: Pozisyon boyutu azaltƒ±ldƒ±")
        
        # Phase 30: Kelly Criterion position sizing
        kelly_risk = self.calculate_kelly_fraction()
        session_risk = session_manager.adjust_risk(kelly_risk)
        
        # Position Sizing with Kelly
        risk_amount = self.balance * session_risk * final_size_mult
        position_size_usd = risk_amount * adjusted_leverage
        position_size = position_size_usd / current_price
        
        # Log session info
        session_info = session_manager.get_session_info()
        self.add_log(f"üìç Session: {session_info['name_tr']} | Kelly: {kelly_risk*100:.1f}% | Lev: {adjusted_leverage}x")
        
        new_position = {
            "id": f"{int(datetime.now().timestamp())}_{signal['action']}",
            "symbol": self.symbol,
            "side": signal['action'],
            "entryPrice": current_price,
            "size": position_size,
            "sizeUsd": position_size_usd,
            "contracts": position_size,  # Phase 223b: needed for partial TP
            "stopLoss": signal['sl'],
            "takeProfit": signal['tp'],
            "trailingStop": signal['sl'],
            "trailActivation": signal['trailActivation'],
            "trailDistance": signal['trailDistance'],
            "isTrailingActive": False,
            "unrealizedPnl": 0.0,
            "unrealizedPnlPercent": 0.0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": adjusted_leverage,  # Phase 29: Store leverage
            "spreadLevel": signal.get('spreadLevel', 'normal'),  # Phase 29: Store spread level
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": 0.0,
            "mfe_pct": 0.0,
            "mae_price": current_price,
            "mfe_price": current_price,
            "decision_trace": [],
        }
        
        # Paper Trading: Initial Margin = Position Size / Leverage
        # Kaldƒ±ra√ßlƒ± i≈ülemde sadece teminat miktarƒ± bakiyeden d√º≈ü√ºl√ºr
        initial_margin = new_position['sizeUsd'] / adjusted_leverage
        new_position['initialMargin'] = initial_margin  # Store for close calculation
        self.balance -= initial_margin
        
        self.positions.append(new_position)
        
        # Save to SQLite for persistent openTime tracking
        try:
            asyncio.create_task(db_manager.save_open_position(new_position))
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to save position to SQLite: {e}")
        
        self.add_log(f"üöÄ POZƒ∞SYON A√áILDI: {signal['action']} {self.symbol} @ ${current_price:.4f} | {adjusted_leverage}x | SL:${signal['sl']:.4f} TP:${signal['tp']:.4f}")
        self.save_state()
        logger.info(f"üöÄ OPEN POSITION: {signal['action']} {self.symbol} @ {current_price} | {adjusted_leverage}x | Size: ${position_size_usd:.2f}")

    def update(self, current_price: float, atr: float = None):
        """Update positions with Phase 20 Advanced Risk Management."""
        # Phase 20: Check daily drawdown first
        if self.check_daily_drawdown():
            return
        # Phase 217: Check portfolio-level drawdown
        if self.check_portfolio_drawdown():
            return
        
        # Calculate ATR-like value from position if not provided
        if atr is None:
            atr = current_price * 0.01  # Fallback: 1% of price as ATR estimate
        
        for pos in list(self.positions):
            # Skip if already closed by another check
            if pos not in self.positions:
                continue
            
            # Phase 190: Use per-position price (from fast loop WebSocket / Binance sync updates)
            current_price = pos.get('currentPrice', pos.get('markPrice', current_price))
            atr = pos.get('atr', current_price * 0.01)
            
            # Phase 212: Entry-based Emergency SL DEVRE DI≈ûI
            # Trail-based Emergency SL (pre-guard, %1) zaten flash crash koruyor.
            # Entry-based versiyon volatile coin'lerde erken kapanmaya neden oluyordu.
            # Kalan korumalar: Trail Emergency SL, Normal SL, Adverse Exit, Time Exit, Daily Drawdown
            # if self.check_emergency_sl(pos, current_price):
            #     continue
            
            # Phase 210: Flash Trade Guard ‚Äî minimum 60s hold time
            MIN_HOLD_SECONDS_PT = 60
            open_time_ms_pt = pos.get('openTime', 0)
            if open_time_ms_pt > 0:
                hold_duration_pt = datetime.now().timestamp() - (open_time_ms_pt / 1000)
                if hold_duration_pt < MIN_HOLD_SECONDS_PT:
                    continue  # Skip remaining exit checks ‚Äî too early
                
            # Calc PnL
            if pos['side'] == 'LONG':
                pnl = (current_price - pos['entryPrice']) * pos['size']
            else:
                pnl = (pos['entryPrice'] - current_price) * pos['size']
            
            pnl_percent = (pnl / pos['sizeUsd']) * 100 * pos.get('leverage', 10) if pos.get('sizeUsd', 0) > 0 else 0
            
            pos['unrealizedPnl'] = pnl
            pos['unrealizedPnlPercent'] = pnl_percent
            
            # Phase 224A: MAE/MFE update
            if pnl_percent < pos.get('mae_pct', 0):
                pos['mae_pct'] = pnl_percent
                pos['mae_price'] = current_price
            if pnl_percent > pos.get('mfe_pct', 0):
                pos['mfe_pct'] = pnl_percent
                pos['mfe_price'] = current_price
            
            # Phase 217: Estimate funding fee cost
            open_time_ms = pos.get('openTime', 0)
            if open_time_ms > 0:
                age_hours = (datetime.now().timestamp() * 1000 - open_time_ms) / (1000 * 60 * 60)
                funding_periods = int(age_hours / 8)  # Her 8 saatte bir funding
                if funding_periods > 0:
                    symbol = pos.get('symbol', '')
                    rate = funding_oi_tracker.funding_rates.get(symbol, 0.0001) if 'funding_oi_tracker' in globals() else 0.0001
                    size_usd = pos.get('sizeUsd', 0)
                    pos['estimatedFundingCost'] = round(size_usd * abs(rate) * funding_periods, 4)
            
            # ===== PHASE 20: RISK MANAGEMENT PRIORITY ===== 
            
            # 1.5. Adverse Position Exit (4h terste kalan pozisyonlar)
            if self.check_adverse_position_exit(pos, current_price, atr):
                continue
            
            # 2. Time-based exit (gradual liquidation)
            if self.check_time_based_exit(pos, current_price, atr):
                continue
            
            # 3. Progressive SL (move SL to lock profits)
            self.update_progressive_sl(pos, current_price, atr)
            
            # 4. Loss Recovery Mode
            # DISABLED: Paper-only check_loss_recovery had a too-aggressive -1% threshold
            # that bypassed normal SL. All positions (paper + live) now use 
            # LossRecoveryTrailManager with spread-based thresholds (-3% to -7%)
            
            # ===== ORIGINAL TRAILING LOGIC (spread-aware + ROI-aware) =====
            
            # Phase 59: Calculate ROI for dynamic trail
            roi_pct = pos.get('unrealizedPnlPercent', 0)
            if roi_pct == 0:
                # Calculate if not cached
                entry = pos.get('entryPrice', 0)
                if entry > 0:
                    if pos['side'] == 'LONG':
                        roi_pct = ((current_price - entry) / entry) * 100 * pos.get('leverage', 1)
                    else:
                        roi_pct = ((entry - current_price) / entry) * 100 * pos.get('leverage', 1)
            
            # Get dynamic trail distance based on spread AND ROI
            dynamic_trail = self.get_dynamic_trail_distance(atr, roi_pct)
            
            # ================================================================
            # Phase 144: ROI-Based Trail Activation (with leverage + exit_tightness)
            # ================================================================
            # Phase 151: Spread-based trail activation ROI
            # Low volatility coins ‚Üí earlier activation, high volatility ‚Üí later
            spread_activation_map = {
                'Very Low': 2.0,   # BTC/ETH ‚Äî low vol, early trail
                'Low':      3.0,
                'Normal':   4.0,
                'High':     6.0,   # High spread = later trail
                'Very High': 8.0,  # Meme ‚Äî very volatile, late trail
                'Extreme':  12.0,  # Hyper-volatile
                'Ultra':    16.0   # Extreme edge cases
            }
            base_activation_roi = spread_activation_map.get(pos.get('spreadLevel', pos.get('spread_level', 'Normal')), 4.0)  # Phase 223c
            # Phase 218: Trail threshold must account for leverage ‚Äî otherwise tiny price moves
            # on high leverage (e.g. 0.42% on 20x = 8.5% ROI) falsely trigger trail
            pos_leverage = pos.get('leverage', 10)
            activation_threshold = base_activation_roi * self.get_effective_exit_tightness(pos) * pos_leverage
            
            if pos['side'] == 'LONG':
                # LONG: ROI must be >= threshold (positive ROI)
                if roi_pct >= activation_threshold:
                    if not pos['isTrailingActive']:
                        self.add_log(f"üîÑ TRAIL AKTƒ∞F: {pos['symbol']} LONG ROI={roi_pct:.1f}% >= {activation_threshold:.1f}%")
                    pos['isTrailingActive'] = True
                
                if pos['isTrailingActive']:
                    new_sl = current_price - dynamic_trail
                    if new_sl > pos['trailingStop']:
                        pos['trailingStop'] = new_sl
                        pos['stopLoss'] = new_sl
                
                # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                if 'slConfirmCount' not in pos:
                    pos['slConfirmCount'] = 0
                if 'slBreachStartTime' not in pos:
                    pos['slBreachStartTime'] = 0
                
                now_ts = datetime.now().timestamp()
                if current_price <= pos['stopLoss']:
                    if pos['slConfirmCount'] == 0:
                        pos['slBreachStartTime'] = now_ts
                    pos['slConfirmCount'] += 1
                    breach_duration = now_ts - pos['slBreachStartTime']
                    if pos['slConfirmCount'] >= 5 and breach_duration >= 15:
                        # ROI negatifse SL'den kapanmƒ±≈ü ‚Äî trailing aktif olsa bile etiket SL_HIT
                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive') and roi_pct >= 0) else 'SL_HIT'
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': reason, 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, reason)
                else:
                    if pos['slConfirmCount'] > 0:
                        self.add_log(f"‚ö° Spike bypassed: {pos['symbol']} LONG | {pos['slConfirmCount']} ticks")
                    pos['slConfirmCount'] = 0
                    pos['slBreachStartTime'] = 0
                    if current_price >= pos['takeProfit']:
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TP_HIT', 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, 'TP_HIT')
                    
            elif pos['side'] == 'SHORT':
                # SHORT: ROI must be >= threshold (positive ROI means price went down)
                if roi_pct >= activation_threshold:
                    if not pos['isTrailingActive']:
                        self.add_log(f"üîÑ TRAIL AKTƒ∞F: {pos['symbol']} SHORT ROI={roi_pct:.1f}% >= {activation_threshold:.1f}%")
                    pos['isTrailingActive'] = True
                    
                if pos['isTrailingActive']:
                    new_sl = current_price + dynamic_trail
                    if new_sl < pos['trailingStop']:
                        pos['trailingStop'] = new_sl
                        pos['stopLoss'] = new_sl
                
                # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                if 'slConfirmCount' not in pos:
                    pos['slConfirmCount'] = 0
                if 'slBreachStartTime' not in pos:
                    pos['slBreachStartTime'] = 0
                
                now_ts = datetime.now().timestamp()
                if current_price >= pos['stopLoss']:
                    if pos['slConfirmCount'] == 0:
                        pos['slBreachStartTime'] = now_ts
                    pos['slConfirmCount'] += 1
                    breach_duration = now_ts - pos['slBreachStartTime']
                    if pos['slConfirmCount'] >= 5 and breach_duration >= 15:
                        # ROI negatifse SL'den kapanmƒ±≈ü ‚Äî trailing aktif olsa bile etiket SL_HIT
                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive') and roi_pct >= 0) else 'SL_HIT'
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': reason, 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, reason)
                else:
                    if pos['slConfirmCount'] > 0:
                        self.add_log(f"‚ö° Spike bypassed: {pos['symbol']} SHORT | {pos['slConfirmCount']} ticks")
                    pos['slConfirmCount'] = 0
                    pos['slBreachStartTime'] = 0
                    if current_price <= pos['takeProfit']:
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TP_HIT', 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, 'TP_HIT')

    def _format_detailed_reason(self, reason: str, pos: Dict, exit_price: float, pnl_percent: float) -> str:
        """
        Phase 138: Format detailed close reason for trade history.
        
        Returns a human-readable reason with specific trigger details.
        """
        symbol = pos.get('symbol', 'UNKNOWN')
        entry_price = pos.get('entryPrice', 0)
        sl = pos.get('stopLoss', 0)
        tp = pos.get('takeProfit', 0)
        trailing_stop = pos.get('trailingStop', 0)
        peak_price = pos.get('peakPrice', pos.get('entryPrice', 0))
        
        # Calculate distance percentages
        if entry_price > 0:
            exit_vs_entry_pct = ((exit_price - entry_price) / entry_price) * 100
            if pos.get('side') == 'SHORT':
                exit_vs_entry_pct = -exit_vs_entry_pct
        else:
            exit_vs_entry_pct = 0
        
        reason_map = {
            # Stop Loss variants
            'SL': f"üî¥ SL: Stop Loss Fiyatƒ± A≈üƒ±ldƒ± ({pnl_percent:+.1f}%)",
            'SL_HIT': f"üî¥ SL: Stop Loss Tetiklendi @ ${exit_price:.4f} ({pnl_percent:+.1f}%)",
            'EMERGENCY_SL': f"üö® EMERGENCY: Acil Stop Loss ({pnl_percent:+.1f}%)",
            
            # Take Profit variants
            'TP': f"üü¢ TP: Take Profit Hedefi ({pnl_percent:+.1f}%)",
            'TP_HIT': f"üü¢ TP: Take Profit Tetiklendi @ ${exit_price:.4f} ({pnl_percent:+.1f}%)",
            
            # Trailing Stop
            'TRAIL': f"üìà TRAIL: Trailing Stop ({pnl_percent:+.1f}%, peak'ten √ßekilme)",
            'TRAIL_EXIT': f"üìà TRAIL: Trailing Stop √áƒ±kƒ±≈üƒ± ({pnl_percent:+.1f}%)",
            'TRAILING_STOP': f"üìà TRAIL: Trailing Stop Tetiklendi ({pnl_percent:+.1f}%)",
            
            # Kill Switch
            'KILL_SWITCH_FULL': f"‚ö†Ô∏è KILL: Kill Switch Tam Kapatma ({pnl_percent:+.1f}%)",
            'KILL_SWITCH_PARTIAL': f"‚ö†Ô∏è KILL: Kill Switch Kƒ±smi (%50, {pnl_percent:+.1f}%)",
            
            # Time-based
            'TIME_REDUCE_4H': f"‚è∞ TIME: 4 Saat Kuralƒ± (-10%, {pnl_percent:+.1f}%)",
            'TIME_REDUCE_8H': f"‚è∞ TIME: 8 Saat Kuralƒ± (-10%, {pnl_percent:+.1f}%)",
            'TIME_GRADUAL': f"‚è∞ TIME: Kademeli Zaman √áƒ±kƒ±≈üƒ± ({pnl_percent:+.1f}%)",
            'TIME_FORCE': f"‚è∞ TIME: Zorunlu Zaman √áƒ±kƒ±≈üƒ± ({pnl_percent:+.1f}%)",
            
            # Recovery & Adverse
            'RECOVERY_EXIT': f"üîÑ RECOVERY: Toparlanma √áƒ±kƒ±≈üƒ± ({pnl_percent:+.1f}%)",
            'ADVERSE_TIME_EXIT': f"‚ö° ADVERSE: Olumsuz Zaman √áƒ±kƒ±≈üƒ± ({pnl_percent:+.1f}%)",
            
            # Manual
            'MANUAL': f"üë§ MANUAL: Manuel Kapatma ({pnl_percent:+.1f}%)",
            
            # Signal Reversal
            'SIGNAL_REVERSAL_PROFIT': f"üîÑ REVERSAL: Sinyal Deƒüi≈üimi Karlƒ± √áƒ±kƒ±≈ü ({pnl_percent:+.1f}%)",
            
            # Phase 214: Failed Continuation
            'FAILED_CONTINUATION': f"üîÑ FAILED_CONT: Kalƒ±cƒ±lƒ±k Saƒülanamadƒ± ‚Äî {pos.get('fc_failed_count', 0)} ba≈üarƒ±sƒ±z deneme ({pnl_percent:+.1f}%)",
            
            # Phase 217: Portfolio Drawdown
            'PORTFOLIO_DRAWDOWN': f"üö® PORTF√ñY: Toplam kayƒ±p limiti a≈üƒ±ldƒ± ({pnl_percent:+.1f}%)",
        }
        
        return reason_map.get(reason, f"üìã {reason} ({pnl_percent:+.1f}%)")

    def close_position(self, pos: Dict, exit_price: float, reason: str):
        """
        Close a position and record it in trade history.
        For live trading, also schedules async Binance close.
        """
        # Phase 232: Idempotent guard ‚Äî prevent double close
        if pos not in self.positions:
            logger.warning(f"‚ö†Ô∏è IDEMPOTENT_GUARD: {pos.get('symbol')} already removed from positions, skipping close")
            return None
        if pos.get('_closing'):
            logger.warning(f"‚ö†Ô∏è IDEMPOTENT_GUARD: {pos.get('symbol')} already closing, skipping")
            return None
        pos['_closing'] = True
        
        # Calculate PnL
        if pos['side'] == 'LONG':
            pnl = (exit_price - pos['entryPrice']) * pos['size']
        else:
            pnl = (pos['entryPrice'] - exit_price) * pos['size']
        
        # Paper Trading: Pozisyon kapandƒ±ƒüƒ±nda Initial Margin + PnL bakiyeye eklenir
        initial_margin = pos.get('initialMargin', pos.get('sizeUsd', 0) / pos.get('leverage', 10))
        
        # Live trading'de bakiye Binance'den senkronize edilir
        if not live_binance_trader.enabled:
            self.balance += initial_margin + pnl
        
        # Remove from positions list
        if pos in self.positions:
            self.positions.remove(pos)
        
        # Update SQLite: mark position as CLOSED with close_time
        try:
            pos_id = pos.get('id', '')
            pos_symbol = pos.get('symbol', '')
            asyncio.create_task(db_manager.close_position_in_db(pos_id, pos_symbol))
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to close position in SQLite: {e}")
        
        # Record trade
        trade = {
            "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
            "symbol": pos.get('symbol', 'UNKNOWN'),
            "side": pos.get('side', 'LONG'),
            "entryPrice": pos.get('entryPrice', 0),
            "exitPrice": exit_price,
            "size": pos.get('size', 0),
            "sizeUsd": pos.get('sizeUsd', 0),
            "pnl": pnl,
            "pnlPercent": (pnl / pos.get('sizeUsd', 1)) * 100 * pos.get('leverage', 10) if pos.get('sizeUsd', 0) > 0 else 0,
            "margin": initial_margin,
            "roi": (pnl / initial_margin * 100) if initial_margin > 0 else 0,
            "openTime": pos.get('openTime', 0),
            "closeTime": int(datetime.now().timestamp() * 1000),
            "reason": reason,
            "leverage": pos.get('leverage', 10),
            "isLive": pos.get('isLive', False),
            "signalScore": pos.get('signalScore', 0),
            "mtfScore": pos.get('mtfScore', 0),
            "zScore": pos.get('zScore', 0),
            "spreadLevel": pos.get('spreadLevel', 'unknown'),
            "stopLoss": pos.get('stopLoss', 0),
            "takeProfit": pos.get('takeProfit', 0),
            "trailActivation": pos.get('trailActivation', 0),
            "trailingStop": pos.get('trailingStop', 0),
            "isTrailingActive": pos.get('isTrailingActive', False),
            "atr": pos.get('atr', 0),
            "slMultiplier": pos.get('slMultiplier', 0),
            "tpMultiplier": pos.get('tpMultiplier', 0),
            # Phase 155: AI Optimizer settings snapshot from open time
            "settingsSnapshot": pos.get('settingsSnapshot', {}),
            # Phase 186: Execution quality + complete position data
            "entry_method": pos.get('entry_method', 'MARKET'),
            "entry_slippage": pos.get('entry_slippage', 0),
            "entry_spread": pos.get('entry_spread', 0),
            "binance_fill_price": pos.get('binance_fill_price', 0),
            "binance_order_id": pos.get('binance_order_id', ''),
            "hurst": pos.get('hurst', 0.5),
            "adx": pos.get('adx', 0),
            "pullbackPct": pos.get('pullbackPct', 0),
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": round(pos.get('mae_pct', 0), 2),
            "mfe_pct": round(pos.get('mfe_pct', 0), 2),
            "decision_trace": pos.get('decision_trace', [])[-5:],
            # Phase 232: Canonical reason + legacy closeReason
            "closeReason": reason,
            # Phase 232: Close metrics snapshot
            "close_metrics_json": json.dumps({
                'entry': pos.get('entryPrice', 0),
                'exit': exit_price,
                'stopLoss': pos.get('stopLoss', 0),
                'takeProfit': pos.get('takeProfit', 0),
                'trailingStop': pos.get('trailingStop', 0),
                'atr': pos.get('atr', 0),
                'leverage': pos.get('leverage', 10),
                'price_move_pct': round(abs(exit_price - pos.get('entryPrice', 0)) / pos.get('entryPrice', 1) * 100, 4) if pos.get('entryPrice', 0) > 0 else 0,
                'roi_pct': round((pnl / initial_margin * 100), 2) if initial_margin > 0 else 0,
                'spreadLevel': pos.get('spreadLevel', 'unknown'),
                'isTrailingActive': pos.get('isTrailingActive', False),
            }),
        }
        
        # =====================================================================
        # PHASE 193: POST-CLOSE HOOKS (SL Guard, FreqAI, Hyperopt)
        # =====================================================================
        try:
            # 1. StoplossFrequencyGuard: Record SL exits
            if reason in ('SL_HIT', 'EMERGENCY_SL'):
                stoploss_frequency_guard.record_stoploss(
                    symbol=pos.get('symbol', 'UNKNOWN'),
                    reason=reason
                )
            
            # 2. FreqAI: Record trade features for ML training
            if freqai_model and freqai_model.enabled:
                ml_features = {
                    'zscore': pos.get('zScore', 0),
                    'hurst': pos.get('hurst', 0.5),
                    'rsi': pos.get('rsi', 50),
                    'adx': pos.get('adx', 25),
                    'volume_ratio': pos.get('volumeRatio', 1.0),
                    'bb_position': pos.get('bbPosition', 0),
                    'macd_histogram': pos.get('macdHistogram', 0),
                    'stoch_rsi_k': pos.get('stochRsiK', 50),
                    'ema_cross_bullish': 1.0 if pos.get('emaCross') == 'BULLISH' else 0.0,
                    'vwap_zscore': pos.get('vwapZscore', 0),
                    'spread_pct': pos.get('spreadPct', 0),
                    'funding_rate': pos.get('fundingRate', 0),
                    'imbalance': pos.get('imbalance', 0),
                    'signal_score': pos.get('signalScore', 0),
                    'leverage': pos.get('leverage', 10),
                    'atr_pct': (pos.get('atr', 0) / pos.get('entryPrice', 1)) * 100 if pos.get('entryPrice', 0) > 0 else 0,
                }
                freqai_model.record_trade(ml_features, pnl > 0)
            
            # 3. Hyperopt: Record trade data for parameter optimization
            if hhq_hyperoptimizer and hhq_hyperoptimizer.enabled:
                hhq_hyperoptimizer.record_trade(trade)
                if hhq_hyperoptimizer.should_auto_optimize():
                    asyncio.create_task(hhq_hyperoptimizer.optimize())
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Phase 193 post-close hook error: {e}")
        
        # Phase 138: LIVE positions - store reason for Binance sync, DON'T write trade yet
        # Binance sync will detect the close and write trade with this reason
        symbol = pos.get('symbol', 'UNKNOWN')
        is_live = pos.get('isLive', False)
        
        if is_live:
            # Store detailed reason for Binance sync to use
            leverage = pos.get('leverage', 10)
            size_usd = pos.get('sizeUsd', 0)
            margin = size_usd / leverage if leverage > 0 and size_usd > 0 else 0
            roi = (pnl / margin * 100) if margin > 0 else 0  # Leveraged ROI
            
            detailed_reason = self._format_detailed_reason(reason, pos, exit_price, roi)
            
            pending_close_reasons[symbol] = {
                "reason": detailed_reason,
                "original_reason": reason,
                "pnl": pnl,
                "exitPrice": exit_price,
                "timestamp": int(datetime.now().timestamp() * 1000),
                "trade_data": trade,  # Full trade data for Binance sync to use
                "entry_order_id": pos.get('binance_order_id', ''),  # Phase 229
            }
            logger.info(f"üìã PENDING REASON SET: {symbol} = {detailed_reason}")
            
            # Phase 187: Save to position_closes with ALL settings data
            try:
                close_data = {
                    'symbol': symbol,
                    'side': pos.get('side', 'LONG'),
                    'reason': detailed_reason,
                    'original_reason': reason,
                    'entryPrice': pos.get('entryPrice', 0),
                    'exitPrice': exit_price,
                    'pnl': pnl,
                    'leverage': leverage,
                    'sizeUsd': size_usd,
                    'margin': margin,
                    'roi': roi,
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    # Phase 187: Complete settings + execution data
                    'stopLoss': pos.get('stopLoss', 0),
                    'takeProfit': pos.get('takeProfit', 0),
                    'atr': pos.get('atr', 0),
                    'trailingStop': pos.get('trailingStop', 0),
                    'trailActivation': pos.get('trailActivation', 0),
                    'settingsSnapshot': pos.get('settingsSnapshot', {}),
                    'entry_method': pos.get('entry_method', 'MARKET'),
                    'entry_slippage': pos.get('entry_slippage', 0),
                    'entry_spread': pos.get('entry_spread', 0),
                    'signalScore': pos.get('signalScore', 0),
                    'spreadLevel': pos.get('spreadLevel', 'unknown'),
                    'binance_fill_price': pos.get('binance_fill_price', 0),
                    'hurst': pos.get('hurst', 0.5),
                    'trade_id': trade.get('id', ''),
                    # Phase 224A
                    'mae_pct': round(pos.get('mae_pct', 0), 2),
                    'mfe_pct': round(pos.get('mfe_pct', 0), 2),
                    # Phase 224A: Decision trace
                    'decision_trace': json.dumps(pos.get('decision_trace', [])[-10:]),
                    # Phase 229: Order ID-based matching
                    'entry_order_id': pos.get('binance_order_id', ''),
                }
                safe_create_task(sqlite_manager.save_position_close(close_data))
            except Exception as e:
                logger.debug(f"SQLite position close save error: {e}")
            
            # Phase 187: ALSO save LIVE trades to trades table!
            # Previously only position_closes got the data, trades table was skipped
            try:
                safe_create_task(sqlite_manager.save_trade(trade))
                logger.info(f"üíæ LIVE trade saved to trades table: {symbol} PnL={pnl:.4f}")
            except Exception as e:
                logger.debug(f"SQLite LIVE trade save error: {e}")
            
            # Still append to in-memory trades for frontend
            self.trades.append(trade)
        else:
            # PAPER positions: write trade history as normal
            self.trades.append(trade)
            
            # Save trade to SQLite (async, non-blocking)
            try:
                safe_create_task(sqlite_manager.save_trade(trade))
            except Exception as e:
                logger.debug(f"SQLite save error: {e}")
        
        # Update Stats (for both LIVE and PAPER)
        self.stats['totalTrades'] += 1
        self.stats['totalPnl'] += pnl
        if pnl > 0: 
            self.stats['winningTrades'] += 1
        else: 
            self.stats['losingTrades'] += 1
        
        # Update coin-specific stats for blacklist system
        symbol = pos.get('symbol', 'UNKNOWN')
        is_win = pnl > 0
        self.update_coin_stats(symbol, is_win, pnl)
        
        # Phase 224B: Update score band statistics for EV calculation
        signal_score = pos.get('signalScore', 0)
        if signal_score > 0:
            self.update_score_band_stats(signal_score, pnl)
        
        # Phase 224C: Record exit in ExitArbitrator
        try:
            roi_arb = (pnl / max(0.01, pos.get('initialMargin', 1))) * 100
            exit_arbitrator.record_exit(
                symbol=symbol,
                reason=reason,
                roi=roi_arb,
                pnl=pnl,
                decision_trace=pos.get('decision_trace', [])
            )
        except Exception as ea_err:
            logger.debug(f"ExitArbitrator error: {ea_err}")
        
        # Phase 224D3: Record result in CanaryMode (use stored flag)
        try:
            canary_mode.record_result(pos.get('id', ''), pnl, is_canary=pos.get('is_canary', False))
        except Exception as cm_err:
            logger.debug(f"CanaryMode error: {cm_err}")
        
        # Log position close
        live_tag = "üî¥ LIVE" if pos.get('isLive', False) else "üìÑ PAPER"
        emoji = "‚úÖ" if pnl > 0 else "‚ùå"
        self.add_log(f"{emoji} {live_tag} KAPANDI [{reason}]: {pos.get('side', 'UNKNOWN')} @ ${exit_price:.4f} | PnL: ${pnl:.2f}")
        self.save_state(force=True)  # Critical: position close MUST be persisted
        logger.info(f"‚úÖ {live_tag} CLOSE: {reason} PnL: {pnl:.2f}")
        
        # =====================================================================
        # LIVE TRADING: Schedule close on Binance (fire-and-forget)
        # =====================================================================
        if live_binance_trader.enabled and pos.get('isLive', False):
            symbol = pos.get('symbol', '')
            side = pos.get('side', 'LONG')
            # Phase 141: Use contracts with size fallback for consistency with Binance API
            amount = pos.get('contracts', pos.get('size', 0))
            
            logger.info(f"üî¥ LIVE CLOSE: Scheduling {side} {symbol} close on Binance...")
            
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.ensure_future(self._close_on_binance(symbol, side, amount))
                else:
                    loop.run_until_complete(self._close_on_binance(symbol, side, amount))
            except RuntimeError:
                asyncio.run(self._close_on_binance(symbol, side, amount))
            
            # Phase 157: Schedule Binance trade history fetch after close
            ui_state_cache.trigger_trade_fetch(delay_seconds=3)
        
        # Phase 52: Post-trade tracking for 24h analysis
        try:
            post_trade_tracker.start_tracking(trade)
        except Exception as e:
            logger.debug(f"Post-trade tracking error: {e}")
        
        # Phase 54: Record score components for analysis
        try:
            components = {
                'zScore': pos.get('zScore', 0),
                'signalScore': pos.get('signalScore', 0),
                'mtfScore': pos.get('mtfScore', 0),
                'spreadLevel': pos.get('spreadLevel', 'medium'),
                'hurst': pos.get('hurst', 0.5),
                'imbalance': pos.get('imbalance', 0),
            }
            score_component_analyzer.record_trade(trade, components)
        except Exception as e:
            logger.debug(f"Score component record error: {e}")
        
        # Phase 59: Record coin performance for learning
        try:
            coin_performance_tracker.record_trade(pos.get('symbol', ''), pnl, reason)
        except Exception as e:
            logger.debug(f"Coin performance record error: {e}")
    
    async def _close_on_binance(self, symbol: str, side: str, amount: float):
        """Helper to close position on Binance asynchronously.
        Phase 87: Now fetches actual Binance position size to prevent partial closes.
        """
        try:
            # Phase 87: Get ACTUAL position size from Binance (not paper trader)
            # This fixes the BULLA bug where paper size (57) != Binance size (60)
            binance_positions = await live_binance_trader.get_positions()
            actual_amount = amount  # fallback to paper amount
            
            for pos in binance_positions:
                if pos.get('symbol') == symbol:
                    actual_amount = pos.get('size', amount)
                    if abs(actual_amount - amount) > 0.001:
                        logger.warning(f"‚ö†Ô∏è Size mismatch: Paper={amount:.4f}, Binance={actual_amount:.4f} - using Binance size")
                    break
            
            result = await live_binance_trader.close_position(symbol, side, actual_amount)
            if result:
                close_order_id = str(result.get('id', ''))
                logger.info(f"‚úÖ BINANCE CLOSE SUCCESS: {symbol} | Size: {actual_amount:.4f} | OrderID: {close_order_id[:12]}")
                
                # Phase 229: Save close_order_id to pending_close_reasons + SQLite
                if close_order_id and symbol in pending_close_reasons:
                    pending_close_reasons[symbol]['close_order_id'] = close_order_id
                if close_order_id:
                    safe_create_task(sqlite_manager.update_close_order_id(symbol, close_order_id))
            else:
                logger.error(f"‚ùå BINANCE CLOSE FAILED for {symbol}")
        except Exception as e:
            logger.error(f"‚ùå LIVE CLOSE ERROR: {e}")



class SmartMoneyAnalyzer:
    """
    Analyzes Price Action for Smart Money Concepts (SMC).
    Focus: Fair Value Gaps (FVG) and Market Structure (BOS).
    """
    def __init__(self, window_size: int = 50):
        self.window_size = window_size
        self.fvgs = [] # List of {'top': float, 'bottom': float, 'type': 'BULL'|'BEAR', 'mitigated': bool, 'timestamp': int}
        self.structure = "NEUTRAL"
        
    def detect_fvg(self, highs: list, lows: list, closes: list, times: list):
        """
        Detects FVGs from the last 3 candles.
        Bullish FVG: Low[0] > High[2] (Gap Up)
        Bearish FVG: High[0] < Low[2] (Gap Down)
        """
        if len(highs) < 3: return
        
        # Bullish FVG
        # Previous 2 candles (idx -2) High vs Current candle (idx 0) Low
        # Wait, usually detection is confirmed after candle close. 
        # So we look at indices -1 (just closed), -2, -3.
        
        # Using [Current, Prev, PrevPrev] convention where -1 is latest closed
        # Indices: -1 (Latest), -2 (Middle), -3 (Oldest)
        
        # Bullish FVG: Low[-1] > High[-3]
        if lows[-1] > highs[-3]:
            gap_size = lows[-1] - highs[-3]
            # Filter tiny gaps (must be > 0.05% of price to be relevant)
            if gap_size > (closes[-1] * 0.0005):
                self.fvgs.append({
                    'top': lows[-1],
                    'bottom': highs[-3],
                    'type': 'BULLISH',
                    'mitigated': False,
                    'timestamp': times[-1]
                })

        # Bearish FVG: High[-1] < Low[-3]
        if highs[-1] < lows[-3]:
            gap_size = lows[-3] - highs[-1]
            if gap_size > (closes[-1] * 0.0005):
                self.fvgs.append({
                    'top': lows[-3],
                    'bottom': highs[-1],
                    'type': 'BEARISH',
                    'mitigated': False,
                    'timestamp': times[-1]
                })
                
        # Cleanup and Check Mitigation
        self.cleanup_mitigated(highs[-1], lows[-1])
        
    def cleanup_mitigated(self, current_high: float, current_low: float):
        # A FVG is mitigated if price trades completely through it.
        # Actually, often just touching it ("filling" it) counts.
        # Strict: If price closes beyond it? NO, usually if wick fills it.
        
        for fvg in self.fvgs:
            if fvg['mitigated']: continue
            
            if fvg['type'] == 'BULLISH':
                # Price drops below the bottom of the bullish gap
                if current_low < fvg['bottom']:
                    fvg['mitigated'] = True
            elif fvg['type'] == 'BEARISH':
                # Price rises above the top of the bearish gap
                if current_high > fvg['top']:
                    fvg['mitigated'] = True
        
        # Keep only last 10 unmitigated FVGs to avoid clutter
        unmitigated = [f for f in self.fvgs if not f['mitigated']]
        self.fvgs = unmitigated[-10:]
        
    def get_nearest_fvg(self, current_price: float) -> Optional[Dict]:
        """Finds nearest unmitigated FVG to current price (Magnet)."""
        if not self.fvgs: return None
        
        # Determine direction
        nearest = None
        min_dist = float('inf')
        
        for fvg in self.fvgs:
            # Distance from center of FVG
            center = (fvg['top'] + fvg['bottom']) / 2
            dist = abs(current_price - center)
            if dist < min_dist:
                min_dist = dist
                nearest = fvg
                
        return nearest

class PivotAnalyzer:
    """
    detects Dynamic Support & Resistance using Pivot Points.
    Port of LuxAlgo 'Support and Resistance Levels with Breaks'.
    """
    def __init__(self, left_bars: int = 15, right_bars: int = 15):
        self.left_bars = left_bars
        self.right_bars = right_bars
        self.resistances = deque(maxlen=5) # Store last 5 active resistance levels
        self.supports = deque(maxlen=5)    # Store last 5 active support levels
        self.last_clean_time = 0
        
    def update(self, highs: list, lows: list, times: list):
        """
        Check for NEW pivot points.
        A pivot is confirmed when we have 'right_bars' of data after it.
        So we specifically look at the candle at index -(right_bars + 1).
        """
        window = self.left_bars + self.right_bars + 1
        if len(highs) < window: return

        # Index of the potential pivot (start counting from end)
        # If we have 100 candles, right_bars=15.
        # We look at index -16.
        pivot_idx = -(self.right_bars + 1)
        
        # --- Check Pivot High ---
        # Get window of highs centered on pivot_idx
        # Slicing in Python is tricky with negative indices.
        # Simplest: Convert to full list indices if possible or use relative slices carefully.
        # Let's say pivot_idx is -16. Window starts at -31, ends at -1 (exclusive of current unmatched?) No.
        # range: [pivot_idx - left_bars : pivot_idx + right_bars + 1]
        
        # Safety check for slice bounds
        if abs(pivot_idx - self.left_bars) > len(highs): return
        
        candidate_high = highs[pivot_idx]
        
        # Check if it's the max in the window
        # Note: highs[pivot_idx] is single value.
        # We need to slice around it.
        start_i = pivot_idx - self.left_bars
        end_i = pivot_idx + self.right_bars + 1 # Slice end is exclusive
        
        # In negative indexing:
        # if pivot_idx = -16, right=15, left=15.
        # start = -31. end = 0? No, end = -16 + 15 + 1 = 0! which means up to the end.
        
        if end_i == 0:
            window_highs = highs[start_i:]
            window_lows = lows[start_i:]
        else:
            window_highs = highs[start_i:end_i]
            window_lows = lows[start_i:end_i]

        if len(window_highs) == window and candidate_high == max(window_highs):
            # FOUND RESISTANCE
            # Avoid duplicates: Check if we haven't added this one yet
            pivot_time = times[pivot_idx]
            if not any(r['timestamp'] == pivot_time for r in self.resistances):
                self.resistances.append({
                    'price': candidate_high,
                    'timestamp': pivot_time,
                    'broken': False
                })

        # --- Check Pivot Low ---
        candidate_low = lows[pivot_idx]
        if len(window_lows) == window and candidate_low == min(window_lows):
            # FOUND SUPPORT
            pivot_time = times[pivot_idx]
            if not any(s['timestamp'] == pivot_time for s in self.supports):
                self.supports.append({
                    'price': candidate_low,
                    'timestamp': pivot_time,
                    'broken': False
                })

    def check_breakout(self, close: float, open_price: float, volume_osc: float, vol_thresh: float = 20.0) -> Optional[str]:
        """
        Check if current PRICE breaks any active level with VOLUME.
        """
        # 1. Check Resistance Break (Bullish)
        # Condition: Close > Res AND Open < Res (Clean crossover) AND VolOsc > Thresh
        # Or simply Close > Res is enough?
        # Script says: crossover(close, highUsePivot) AND osc > volumeThresh
        
        for res in self.resistances:
            if not res['broken']:
                # Basic crossover check: Current Close > Res (and maybe prev close < Res?)
                # For simplicity, we just check if we are ABOVE it now.
                # But breakout implies 'just happened'.
                # We'll rely on the caller to provide 'just happened' context or just state "ABOVE RESISTANCE".
                # Actually, strictly for Signal Generation, we want the MOMENT.
                if close > res['price'] and open_price < res['price']: # Candle pierced it
                    if volume_osc > vol_thresh:
                        return "BREAKOUT_LONG"
        
        # 2. Check Support Break (Bearish)
        for sup in self.supports:
            if not sup['broken']:
                if close < sup['price'] and open_price > sup['price']:
                    if volume_osc > vol_thresh:
                        return "BREAKOUT_SHORT"
                        
        return None

def calculate_volume_osc(volumes: list, short_len: int = 5, long_len: int = 10) -> float:
    if len(volumes) < long_len: return 0.0
    
    # Simple EMA manual calc or use numpy convolve?
    # Or pandas ewm if we had pandas.
    # We can do simple smoothing.
    
    # Using np.mean for simplicity? No, EMA is crucial for speed.
    # Let's approximate EMA using latest values if we don't want full history.
    # But we have full history in 'volumes'.
    
    # Vectorized EMA with numpy?
    # Simple implementation:
    v = np.array(volumes)
    
    def ema(data, window):
        alpha = 2 / (window + 1)
        # Very standardized EMA implementation
        weights = (1 - alpha) ** np.arange(len(data))[::-1]
        weights /= weights.sum()
        return np.sum(data * weights) # This is Weighted Moving Average, close enough for short windows?
        # Actually EMA is recursive.
        
    # Better: Use simple SMA for now if EMA is too heavy?
    # User specifically asked for EMA logic.
    # Let's write a proper iterative EMA helper for the last value.
    
    def get_last_ema(data, N):
        alpha = 2 / (N + 1)
        ema = data[0]
        for val in data[1:]:
            ema = alpha * val + (1 - alpha) * ema
        return ema
        
    short_ema = get_last_ema(volumes, short_len)
    long_ema = get_last_ema(volumes, long_len)
    
    if long_ema == 0: return 0.0
    
    return 100 * (short_ema - long_ema) / long_ema

class BinanceStreamer:
    """
    Handles Binance data streaming and analysis.
    Uses WebSocket streams for real-time data (no rate limits).
    """
    
    def __init__(self, symbol: str = "BTC/USDT"):
        self.symbol = symbol
        self.raw_symbol = symbol.replace("/", "")  # BTCUSDT for WebSocket
        self.exchange: Optional[ccxt_async.binance] = None
        self.prices: deque = deque(maxlen=500)
        self.highs: deque = deque(maxlen=500)
        self.lows: deque = deque(maxlen=500)
        self.closes: deque = deque(maxlen=500)
        self.volumes: deque = deque(maxlen=500)
        self.spreads: deque = deque(maxlen=500)
        self.last_price: float = 0.0
        self.running: bool = False
        self.last_htf_trend: str = "NEUTRAL"
        self.signal_generator = SignalGenerator()
        self.pending_liquidation: Optional[Dict] = None
        
        # WebSocket stream state (real-time, no rate limits)
        self.ws_ticker: Dict = {}
        self.ws_spot_ticker: Dict = {} # SPOT Monitoring
        self.ws_order_book: Dict = {'bids': [], 'asks': []}
        
        # Phase 13: Volatility History
        self.atr_history: deque = deque(maxlen=200) # Store ATR values for VR calculation
        self.ws_connected: bool = False
        
        # Whale Hunter
        self.whale_detector = WhaleDetector(threshold_usd=100000.0) # $100k Threshold
        
        # SMC Analyzer (Phase 10)
        self.smc_analyzer = SmartMoneyAnalyzer()
        
        # Pivot Analyzer (Phase 11)
        self.pivot_analyzer = PivotAnalyzer(left_bars=15, right_bars=15)
        
        # Phase 15: Cloud Paper Trading Engine (Use global instance for REST API access)
        # Note: global_paper_trader is defined later, set in connect()
        self.paper_trader = None  # Will be set to global_paper_trader in connect()
        
        # Phase 28: Dynamic Coin Profile
        self.coin_profile = None  # Will be loaded in connect()
        
        logger.info(f"‚òÅÔ∏è Cloud Paper Trading Active.")
    
    async def update_coin_profile(self):
        """Load or update coin profile for dynamic parameter optimization."""
        try:
            if self.exchange:
                self.coin_profile = await coin_profiler.get_or_update(self.symbol, self.exchange)
                logger.info(f"üìä Coin profile loaded: {self.symbol} | Threshold: {self.coin_profile.get('optimal_threshold', 1.6)}")
            else:
                logger.warning("Exchange not connected, using default profile")
                self.coin_profile = coin_profiler._get_default_profile(self.symbol)
        except Exception as e:
            logger.error(f"Failed to load coin profile: {e}")
            self.coin_profile = coin_profiler._get_default_profile(self.symbol)

    async def connect(self):
        """Initialize CCXT exchange connection and WebSocket streams."""
        self.running = True
        self.exchange = ccxt_async.binance({
            'enableRateLimit': True,
            'options': {
                'defaultType': 'future',
            }
        })
        logger.info(f"Connected to Binance for {self.symbol}")
        
        # Start WebSocket streams in background
        asyncio.create_task(self.start_combined_stream())
        asyncio.create_task(self.start_liquidation_stream())
        asyncio.create_task(self.start_spot_stream()) # Phase 7: Spot
        asyncio.create_task(self.start_agg_trade_stream()) # Phase 9: Whale Hunter
        asyncio.create_task(self.monitor_htf_trend())
        
                
    async def start_agg_trade_stream(self):
        """Streams real-time Aggregated Trades for Whale Detection."""
        ws_url = f"wss://stream.binance.com:9443/ws/{self.symbol.lower().replace('/', '')}@aggTrade"
        while self.running:
            try:
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    while self.running:
                        msg = await ws.recv()
                        data = json.loads(msg)
                        # Process AggTrade
                        # e: event type, E: event time, p: price, q: quantity, m: is_buyer_maker
                        self.whale_detector.process_trade(
                            price=float(data['p']),
                            quantity=float(data['q']),
                            is_buyer_maker=data['m'],
                            timestamp=data['E']
                        )
            except Exception as e:
                logger.error(f"AggTrade Stream Error: {e}")
                await asyncio.sleep(5)

    async def monitor_htf_trend(self):
        """Periodically update 4H trend context."""
        while self.running:
            try:
                trend = await self.fetch_htf_trend()
                self.last_htf_trend = trend
                logger.info(f"HTF Trend Updated: {trend}")
                await asyncio.sleep(300) # Update every 5 minutes
            except Exception as e:
                logger.error(f"HTF Monitor error: {e}")
                await asyncio.sleep(60)

    async def start_spot_stream(self):
        """Connect to Binance SPOT WebSocket for Basis Monitoring."""
        symbol_lower = self.raw_symbol.lower()
        # Spot Stream URL
        ws_url = f"wss://stream.binance.com:9443/ws/{symbol_lower}@ticker"
        
        while self.running:
            try:
                # 20s Ping Interval (New Requirement Jan 2026)
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    logger.info(f"Connected to SPOT Stream: {symbol_lower}")
                    
                    while self.running:
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=30.0)
                            data = json.loads(msg)
                            
                            # Raw Stream Data for Ticker
                            if 'c' in data:
                                self.ws_spot_ticker = {
                                    'last': float(data.get('c', 0)),
                                    'volume': float(data.get('v', 0))
                                }
                        except asyncio.TimeoutError:
                            continue
                        except Exception as e:
                            logger.warning(f"Spot stream error: {e}")
                            break
            except Exception as e:
                logger.error(f"Spot Socket error: {e}")
                if self.running:
                    await asyncio.sleep(5)

    async def start_combined_stream(self):
        """Connect to Binance combined WebSocket for ticker + order book."""
        symbol_lower = self.raw_symbol.lower()
        # Combined stream: ticker + depth (20 levels, 100ms updates)
        ws_url = f"wss://fstream.binance.com/stream?streams={symbol_lower}@ticker/{symbol_lower}@depth20@100ms"
        
        while self.running:
            try:
                # 20s Ping Interval (Resilience Update)
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    logger.info(f"Connected to Binance WebSocket streams: {symbol_lower}")
                    self.ws_connected = True
                    
                    while self.running:
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=30.0)
                            data = json.loads(msg)
                            
                            if 'stream' in data and 'data' in data:
                                stream_name = data['stream']
                                stream_data = data['data']
                                
                                if '@ticker' in stream_name:
                                    # Update ticker data
                                    self.ws_ticker = {
                                        'last': float(stream_data.get('c', 0)),
                                        'open': float(stream_data.get('o', 0)), # Needed for breakout
                                        'high': float(stream_data.get('h', 0)),
                                        'low': float(stream_data.get('l', 0)),
                                        'volume': float(stream_data.get('v', 0)),
                                    }
                                elif '@depth' in stream_name:
                                    # Update order book data
                                    self.ws_order_book = {
                                        'bids': [[float(b[0]), float(b[1])] for b in stream_data.get('b', [])],
                                        'asks': [[float(a[0]), float(a[1])] for a in stream_data.get('a', [])],
                                    }
                        except asyncio.TimeoutError:
                            continue
                        except Exception as e:
                            logger.warning(f"Stream message error: {e}")
                            break
                            
            except Exception as e:
                logger.error(f"WebSocket stream error: {e}")
                self.ws_connected = False
                if self.running:
                    await asyncio.sleep(5)  # Reconnect delay
        
    async def disconnect(self):
        """Close exchange connection."""
        self.running = False
        if self.exchange:
            await self.exchange.close()
            logger.info("Disconnected from Binance")

    async def switch_symbol(self, new_symbol: str):
        """Switch the active symbol and restart streams."""
        if self.symbol == new_symbol:
            return

        logger.info(f"üîÑ Switching symbol from {self.symbol} to {new_symbol}")

        # 1. Stop current streams
        await self.disconnect()

        # 2. Update symbol state
        self.symbol = new_symbol
        self.raw_symbol = new_symbol.replace("/", "")

        # 3. Clear data buffers
        self.prices.clear()
        self.highs.clear()
        self.lows.clear()
        self.closes.clear()
        self.volumes.clear()
        self.spreads.clear()
        self.ws_order_book = {'bids': [], 'asks': []}

        # 4. Restart connection
        # connect() will set running=True
        await self.connect()
            
    async def start_liquidation_stream(self):
        """Connect to Binance Futures liquidation WebSocket."""
        symbol_lower = self.raw_symbol.lower()
        ws_url = f"wss://fstream.binance.com/ws/{symbol_lower}@forceOrder"
        
        try:
            async with websockets.connect(ws_url) as ws:
                logger.info(f"Connected to Binance Liquidation Stream: {symbol_lower}")
                self.liquidation_ws = ws
                
                while self.running:
                    try:
                        msg = await asyncio.wait_for(ws.recv(), timeout=1.0)
                        data = json.loads(msg)
                        
                        if 'o' in data:
                            liq_data = data['o']
                            side = liq_data.get('S', 'UNKNOWN')
                            qty = float(liq_data.get('q', 0))
                            price = float(liq_data.get('p', 0))
                            amount_usd = qty * price
                            
                            # Add to signal generator
                            self.signal_generator.add_liquidation(side, amount_usd, price)
                            
                            # Store pending liquidation for next update
                            self.pending_liquidation = {
                                'side': 'SATIM' if side == 'SELL' else 'ALIM',
                                'amount': amount_usd,
                                'price': price,
                                'isCascade': amount_usd > 100000
                            }
                            
                            logger.info(f"üî• Liquidation: {side} ${amount_usd:,.0f} @ {price}")
                            
                    except asyncio.TimeoutError:
                        continue
                    except Exception as e:
                        logger.warning(f"Liquidation stream error: {e}")
                        await asyncio.sleep(1)
                        
        except Exception as e:
            logger.error(f"Failed to connect to liquidation stream: {e}")
            
    async def fetch_ticker(self) -> dict:
        """Fetch current ticker data."""
        try:
            ticker = await self.exchange.fetch_ticker(self.symbol)
            return ticker
        except Exception as e:
            logger.error(f"Ticker fetch error: {e}")
            return {}
            
    async def fetch_order_book(self, limit: int = 20) -> dict:
        """Fetch order book data."""
        try:
            order_book = await self.exchange.fetch_order_book(self.symbol, limit)
            return order_book
        except Exception as e:
            logger.error(f"Order book fetch error: {e}")
            return {'bids': [], 'asks': []}
    
    async def fetch_ohlcv(self) -> list:
        """Fetch recent OHLCV for ATR calculation."""
        try:
            ohlcv = await self.exchange.fetch_ohlcv(self.symbol, '1m', limit=100)
            return ohlcv
        except Exception as e:
            logger.error(f"OHLCV fetch error: {e}")
            return []
            
    def update_price(self, price: float, high: float = None, low: float = None, volume: float = 0):
        """Update price history."""
        self.prices.append(price)
        self.volumes.append(volume)
        
        if high:
            self.highs.append(high)
        else:
            self.highs.append(price)
            
        if low:
            self.lows.append(low)
        else:
            self.lows.append(price)
            
        self.closes.append(price)
        
        # Spread calculation
        if len(self.prices) >= 20:
            ma = np.mean(list(self.prices)[-20:])
            spread = price - ma
            self.spreads.append(spread)
            
        self.last_price = price
        
        # SMC Detection (FVG)
        if len(self.closes) >= 5:
            self.smc_analyzer.detect_fvg(
                list(self.highs), 
                list(self.lows), 
                list(self.closes), 
                [int(datetime.now().timestamp()) for _ in range(len(self.closes))] # Simplified mock times
            )
        
        # Pivot Detection (Phase 11)
        if len(self.closes) >= 35:
             self.pivot_analyzer.update(
                list(self.highs), 
                list(self.lows), 
                [int(datetime.now().timestamp()) for _ in range(len(self.closes))]
             )
        # For simplicity, we run detection on every price update but it only looks at closed candles

        # Phase 15: Update Paper Trading (Check SL/TP)
        if hasattr(self, 'paper_trader') and self.paper_trader:
            # Phase 20: Pass ATR for risk management
            atr_value = self.atr if hasattr(self, 'atr') and self.atr > 0 else price * 0.01
            self.paper_trader.update(price, atr_value)

    def get_metrics(self) -> dict:
        """Calculate all metrics from current data."""
        prices_list = list(self.prices)
        spreads_list = list(self.spreads)
        highs_list = list(self.highs)
        lows_list = list(self.lows)
        closes_list = list(self.closes)
        volumes_list = list(self.volumes)
        
        # Ensure consistent lengths for VWAP calculation
        min_len = min(len(prices_list), len(closes_list), len(volumes_list))
        if min_len > 0:
            prices_list = prices_list[-min_len:]
            closes_list = closes_list[-min_len:]
            volumes_list = volumes_list[-min_len:]
        
        hurst = calculate_hurst(prices_list)
        zscore = calculate_zscore(spreads_list)
        spread = spreads_list[-1] if spreads_list else 0.0
        regime = get_market_regime(hurst)
        atr = calculate_atr(highs_list, lows_list, closes_list)
        
        # VWAP Z-Score
        vwap = calculate_vwap(closes_list, volumes_list, prices_list)
        std_dev = np.std(prices_list[-20:]) if len(prices_list) >= 20 else 1.0
        vwap_zscore = (prices_list[-1] - vwap) / std_dev if std_dev > 0 else 0
        
        # Volume Oscillator (Phase 11)
        vol_osc = calculate_volume_osc(volumes_list)
        
        # Phase 13: Volatility History & Ratio
        self.atr_history.append(atr)
        avg_atr = np.mean(self.atr_history) if len(self.atr_history) > 10 else atr
        volatility_ratio = atr / avg_atr if avg_atr > 0 else 1.0
        
        # Phase 13: Real-Time Spread % (Bid-Ask)
        spread_pct = 0.05 # Default safest
        if self.ws_order_book['bids'] and self.ws_order_book['asks']:
            best_bid = float(self.ws_order_book['bids'][0][0])
            best_ask = float(self.ws_order_book['asks'][0][0])
            if best_bid > 0:
                spread_val = best_ask - best_bid
                spread_pct = (spread_val / best_bid) * 100
        
        return {
            "hurst": round(hurst, 4),
            "regime": regime,
            "zScore": round(zscore, 4),
            "spread": round(spread, 4), # This is Close - SMA(20)
            "spreadPct": round(spread_pct, 4), # This is Bid-Ask Spread
            "atr": round(atr, 2),
            "volatilityRatio": round(volatility_ratio, 2),
            "vwap_zscore": round(vwap_zscore, 2),
            "vol_osc": round(vol_osc, 2)
        }

    async def fetch_htf_trend(self) -> str:
        """Fetch 4H RSI and Trend via REST API."""
        try:
            # Fetch last 50 4H candles
            if hasattr(self, 'exchange'):
                ohlcv = await self.exchange.fetch_ohlcv(self.symbol, '4h', limit=50)
                if not ohlcv: return "NEUTRAL"
                
                closes = np.array([float(x[4]) for x in ohlcv])
                
                # Calculate RSI
                delta = np.diff(closes)
                gain = (delta > 0) * delta
                loss = (delta < 0) * -delta
                
                avg_gain = np.mean(gain[-14:])
                avg_loss = np.mean(loss[-14:])
                
                if avg_loss == 0: return "BULLISH"
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
                
                # Determine Trend
                ma20 = np.mean(closes[-20:])
                current = closes[-1]
                
                if current > ma20:
                    if rsi > 70: return "STRONG_BULLISH"
                    return "BULLISH"
                else:
                    if rsi < 30: return "STRONG_BEARISH"
                    return "BEARISH"
            return "NEUTRAL"
        except Exception as e:
            logger.warning(f"HTF Trend error: {e}")
            return "NEUTRAL"


# ============================================================================
# WEBSOCKET ENDPOINT
# ============================================================================

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return JSONResponse({"status": "healthy", "timestamp": datetime.now().isoformat()})

@app.get("/server-ip")
async def server_ip():
    """Get server's outbound IP for Binance whitelisting."""
    import aiohttp
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("https://api.ipify.org?format=json", timeout=aiohttp.ClientTimeout(total=10)) as response:
                data = await response.json()
                return JSONResponse({"outbound_ip": data.get("ip"), "region": os.environ.get("FLY_REGION", "unknown")})
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

# Phase 16: Global Paper Trader for REST API access
global_paper_trader = PaperTradingEngine()

# Phase 138: Global dictionary to track close reasons for Binance sync
# When engine triggers SL/TP/Trail, reason is stored here instead of writing to trade history
# Binance sync will use this to set proper reason when detecting closed position
pending_close_reasons = {}  # {symbol: {"reason": str, "details": dict, "timestamp": int}}

# Phase 205: Last closed candle's close price per symbol
# Updated by scanner candle builder (5m) ‚Äî used for exit decisions instead of tick price
# This prevents false exits caused by intra-candle wicks/spikes
last_candle_close = {}  # {symbol: float}

@app.get("/paper-trading/status")
async def paper_trading_status():
    """Get current paper trading status - used for initial UI sync."""
    today_pnl_data = global_paper_trader.get_today_pnl()
    stats_with_today = {**global_paper_trader.stats, **today_pnl_data}
    return JSONResponse({
        "balance": global_paper_trader.balance,
        "positions": global_paper_trader.positions,
        "trades": global_paper_trader.trades,  # ALL trades (no limit)
        "stats": stats_with_today,
        "enabled": global_paper_trader.enabled,
        "logs": global_paper_trader.logs[-100:],  # Last 100 logs
        "equityCurve": global_paper_trader.equity_curve[-200:],  # Last 200 points
        "tradingMode": live_binance_trader.trading_mode,  # paper or live
        "liveEnabled": live_binance_trader.enabled,
        "pipelineMetrics": global_paper_trader.pipeline_metrics
    })


# ============================================================================
# LIVE TRADING ENDPOINTS
# ============================================================================

@app.get("/live-trading/status")
async def live_trading_status():
    """Get live trading status - Binance connection and positions."""
    
    # Check environment variable directly (not cached value from import time)
    env_trading_mode = os.environ.get('TRADING_MODE', 'paper')
    init_error = None
    
    # Auto-initialize if TRADING_MODE is live and exchange not yet created
    # Use same logic as test-connection: check exchange object, not enabled flag
    if env_trading_mode == 'live' and not live_binance_trader.exchange:
        live_binance_trader.trading_mode = env_trading_mode
        try:
            success = await live_binance_trader.initialize()
            if not success:
                init_error = getattr(live_binance_trader, 'last_error', 'Initialize returned False')
        except Exception as e:
            init_error = str(e)
            logger.error(f"Live trading init error: {e}")
    
    if not live_binance_trader.enabled:
        return JSONResponse({
            "enabled": False,
            "trading_mode": env_trading_mode,
            "message": "Live trading not enabled. Set TRADING_MODE=live to activate.",
            "init_error": init_error or getattr(live_binance_trader, 'last_error', None)
        })
    
    try:
        balance = await live_binance_trader.get_balance()
        positions = await live_binance_trader.get_positions()
        pnl_data = await live_binance_trader.get_pnl_from_binance()
        # Phase 187b: Trade history from SQLite (full data, no limit)
        # Previously: get_trade_history(limit=50, days_back=7) from Binance Income API
        # Now: all trades from SQLite with entry/exit prices, reasons, settings
        trades = await sqlite_manager.get_full_trade_history(limit=0)
        logger.info(f"Phase 187b: Got {len(trades)} trades from SQLite")
        
        return JSONResponse({
            "enabled": True,
            "trading_mode": "live",
            "balance": balance,
            "positions": positions,
            "position_count": len(positions),
            "last_sync": live_binance_trader.last_sync_time,
            "status": live_binance_trader.get_status(),
            # PnL data from Binance income history
            "todayPnl": pnl_data.get('todayPnl', 0),
            "todayPnlPercent": pnl_data.get('todayPnlPercent', 0),
            "totalPnl": pnl_data.get('totalPnl', 0),
            "totalPnlPercent": pnl_data.get('totalPnlPercent', 0),
            "todayTradesCount": pnl_data.get('todayTradesCount', 0),
            # Phase 187b: Full trade history from SQLite
            "trades": trades,
            "tradeCount": len(trades),
        })
    except Exception as e:
        return JSONResponse({
            "enabled": True,
            "trading_mode": "live",
            "error": str(e)
        }, status_code=500)


@app.post("/live-trading/emergency-close")
async def live_trading_emergency_close():
    """Emergency close all positions on Binance."""
    if not live_binance_trader.enabled:
        return JSONResponse({
            "success": False,
            "message": "Live trading not enabled"
        }, status_code=400)
    
    try:
        closed = await live_binance_trader.close_all_positions()
        return JSONResponse({
            "success": True,
            "closed_positions": len(closed),
            "details": closed
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


@app.post("/live-trading/test-connection")
async def live_trading_test_connection():
    """Test Binance API connection."""
    try:
        if not live_binance_trader.exchange:
            # Try to initialize
            success = await live_binance_trader.initialize()
            if not success:
                return JSONResponse({
                    "success": False,
                    "message": "Failed to initialize Binance connection"
                }, status_code=400)
        
        balance = await live_binance_trader.get_balance()
        return JSONResponse({
            "success": True,
            "message": "Binance connection successful!",
            "balance": balance
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.get("/live-trading/raw-positions")
async def live_trading_raw_positions():
    """Debug: Get raw positions from Binance API."""
    try:
        if not live_binance_trader.exchange:
            return JSONResponse({"error": "Exchange not initialized"}, status_code=400)
        
        # Get raw positions from Binance
        raw_positions = await live_binance_trader.exchange.fetch_positions()
        
        # Filter only positions with any activity
        active = []
        for p in raw_positions:
            contracts = float(p.get('contracts', 0))
            notional = float(p.get('notional', 0))
            if abs(contracts) > 0 or abs(notional) > 0:
                active.append({
                    'symbol': p.get('symbol'),
                    'contracts': contracts,
                    'notional': notional,
                    'entryPrice': p.get('entryPrice'),
                    'markPrice': p.get('markPrice'),
                    'side': p.get('side'),
                    'leverage': p.get('leverage'),
                    'unrealizedPnl': p.get('unrealizedPnl'),
                    'marginMode': p.get('marginMode'),
                    'raw_info': p.get('info', {})  # Include raw Binance response
                })
        
        return JSONResponse({
            "total_symbols": len(raw_positions),
            "active_positions": len(active),
            "positions": active
        })
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

@app.post("/paper-trading/reset")
async def paper_trading_reset():
    """Reset paper trading to initial state."""
    global_paper_trader.reset()
    return JSONResponse({"success": True, "message": "Paper trading reset to $10,000"})

@app.post("/paper-trading/toggle")
async def paper_trading_toggle():
    """Toggle auto-trading on/off."""
    global_paper_trader.enabled = not global_paper_trader.enabled
    global_paper_trader.save_state()
    status = "enabled" if global_paper_trader.enabled else "disabled"
    return JSONResponse({"success": True, "enabled": global_paper_trader.enabled, "message": f"Auto-trading {status}"})

# Phase 52: Optimizer endpoints
@app.post("/optimizer/toggle")
async def optimizer_toggle():
    """Toggle auto-optimizer on/off."""
    parameter_optimizer.enabled = not parameter_optimizer.enabled
    
    # Phase 60: Sync with paper_trader for dynamic calculations
    if global_paper_trader:
        global_paper_trader.ai_optimizer_enabled = parameter_optimizer.enabled
        global_paper_trader.save_state()
    
    status = "enabled" if parameter_optimizer.enabled else "disabled"
    logger.info(f"ü§ñ Auto-optimizer {status}")
    
    # Log mode change
    if global_paper_trader:
        if parameter_optimizer.enabled:
            global_paper_trader.add_log(f"ü§ñ AI Optimizer AKTƒ∞F - Dinamik ayarlar etkin")
        else:
            global_paper_trader.add_log(f"üë§ AI Optimizer KAPALI - Manuel ayarlar ge√ßerli")
    
    return JSONResponse({
        "success": True, 
        "enabled": parameter_optimizer.enabled, 
        "message": f"Auto-optimizer {status}"
    })

@app.get("/trade-analysis")
async def trade_analysis():
    """Phase 157: Trade pattern analysis + funding status."""
    analysis = trade_pattern_analyzer.last_analysis or {"status": "not_run"}
    funding = funding_oi_tracker.get_status()
    return {
        "tradeAnalysis": analysis,
        "funding": funding,
        "coinWr": {k: {"wr": v["wr"], "total": v["total"], "pnl": v.get("total_pnl", 0)} 
                   for k, v in trade_pattern_analyzer.coin_wr.items() if v.get("total", 0) >= 3},
        "hourWr": {str(k): {"wr": v["wr"], "total": v["total"]} 
                   for k, v in trade_pattern_analyzer.hour_wr.items()},
    }

@app.get("/optimizer/status")
async def optimizer_status():
    """Get optimizer status and analysis."""
    # Convert tracking dict to list for UI
    tracking_list = []
    try:
        for trade_id, data in post_trade_tracker.tracking.items():
            exit_time = data.get('exit_time')
            exit_time_str = None
            if exit_time:
                try:
                    exit_time_str = exit_time.isoformat() if hasattr(exit_time, 'isoformat') else str(exit_time)
                except:
                    exit_time_str = str(exit_time)
            
            tracking_list.append({
                'id': trade_id,
                'symbol': data.get('symbol', ''),
                'side': data.get('side', ''),
                'exitPrice': data.get('exit_price', 0),
                'exitTime': exit_time_str,
                'pnl': data.get('pnl', 0),
                'reason': data.get('reason', ''),
                'maxPriceAfter': data.get('max_price_after', 0),
                'minPriceAfter': data.get('min_price_after', 0),
                'priceSamples': data.get('price_samples', 0),
            })
    except Exception as e:
        logger.error(f"Error building tracking list: {e}")
    
    return JSONResponse({
        "enabled": parameter_optimizer.enabled,
        "lastOptimization": parameter_optimizer.last_optimization,
        "lastAnalysis": performance_analyzer.last_analysis,
        "postTradeStats": post_trade_tracker.get_stats(),
        "trackingCount": len(post_trade_tracker.tracking),
        "trackingList": tracking_list,
        "recentAnalyses": post_trade_tracker.analysis_results[-10:],
        "marketRegime": market_regime_detector.get_status(),
        "scoreAnalysis": score_component_analyzer.get_status()
    })

@app.post("/optimizer/run")
async def optimizer_run_now():
    """Manually trigger optimization analysis."""
    try:
        pt_stats = post_trade_tracker.get_stats()
        analysis = performance_analyzer.analyze(global_paper_trader.trades, pt_stats)
        
        if analysis:
            current_settings = {
                'z_score_threshold': global_paper_trader.z_score_threshold,
                'min_score_low': global_paper_trader.min_score_low,
                'min_score_high': global_paper_trader.min_score_high,
                'entry_tightness': global_paper_trader.entry_tightness,
                'max_positions': global_paper_trader.max_positions,
            }
            optimization = parameter_optimizer.optimize(analysis, current_settings)
            
            return JSONResponse({
                "success": True,
                "analysis": analysis,
                "optimization": optimization
            })
        
        return JSONResponse({"success": False, "message": "No trades to analyze"})
    except Exception as e:
        logger.error(f"Optimizer run error: {e}")
        return JSONResponse({"success": False, "message": str(e)})


# ============================================================================
# PHASE 59: PERFORMANCE DASHBOARD ENDPOINTS
# ============================================================================

@app.get("/performance/coins")
async def get_coin_performance():
    """Get coin-based performance statistics ‚Äî Binance verisi √∂ncelikli."""
    # Binance verisi varsa onu kullan
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=500)
        if binance_trades and len(binance_trades) >= 5:
            coin_stats = {}
            for t in binance_trades:
                sym = t.get('symbol', 'UNKNOWN').replace('USDT', '')
                if sym not in coin_stats:
                    coin_stats[sym] = {'wins': 0, 'losses': 0, 'total_pnl': 0, 'trades': 0}
                coin_stats[sym]['trades'] += 1
                pnl = t.get('pnl', 0)
                coin_stats[sym]['total_pnl'] += pnl
                if pnl > 0:
                    coin_stats[sym]['wins'] += 1
                else:
                    coin_stats[sym]['losses'] += 1
            
            # Calculate WR
            for sym, data in coin_stats.items():
                total = data['wins'] + data['losses']
                data['win_rate'] = round((data['wins'] / total * 100) if total > 0 else 0, 1)
                data['avg_pnl'] = round(data['total_pnl'] / data['trades'], 4) if data['trades'] > 0 else 0
                data['total_pnl'] = round(data['total_pnl'], 2)
            
            # Sort by total PnL
            best_coins = sorted(coin_stats.items(), key=lambda x: x[1]['total_pnl'], reverse=True)[:10]
            worst_coins = sorted(coin_stats.items(), key=lambda x: x[1]['total_pnl'])[:10]
            
            return JSONResponse({
                "success": True,
                "source": "binance",
                "bestCoins": [{"symbol": s, **d} for s, d in best_coins],
                "worstCoins": [{"symbol": s, **d} for s, d in worst_coins],
                "totalCoins": len(coin_stats),
                "totalTrades": len(binance_trades)
            })
    except Exception as e:
        logger.debug(f"Binance coin perf error: {e}")
    
    # Fallback to paper trader
    return JSONResponse({
        "success": True,
        "source": "paper",
        **coin_performance_tracker.get_all_stats()
    })

@app.get("/performance/daily")
async def get_daily_performance():
    """Get daily PnL data for charts ‚Äî Binance verisi √∂ncelikli."""
    import pytz
    turkey_tz = pytz.timezone('Europe/Istanbul')
    
    # Try Binance trades first
    trades = []
    source = "paper"
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=1000)
        if binance_trades and len(binance_trades) >= 5:
            trades = binance_trades
            source = "binance"
    except Exception as e:
        logger.debug(f"Binance daily perf error: {e}")
    
    # Fallback to paper trades
    if not trades:
        trades = global_paper_trader.trades
        source = "paper"
    
    # Group trades by day (using Turkey timezone)
    daily_pnl = {}
    for trade in trades:
        close_time = trade.get('closeTime', trade.get('close_time', 0))
        pnl = trade.get('pnl', 0)
        if close_time and close_time > 0:
            try:
                utc_dt = datetime.utcfromtimestamp(close_time / 1000).replace(tzinfo=pytz.UTC)
                turkey_dt = utc_dt.astimezone(turkey_tz)
                day = turkey_dt.strftime('%Y-%m-%d')
                if day not in daily_pnl:
                    daily_pnl[day] = {'pnl': 0, 'trades': 0, 'wins': 0}
                daily_pnl[day]['pnl'] += pnl
                daily_pnl[day]['trades'] += 1
                if pnl > 0:
                    daily_pnl[day]['wins'] += 1
            except:
                pass
    
    # Convert to list sorted by date
    daily_list = []
    for day, data in sorted(daily_pnl.items()):
        wr = (data['wins'] / data['trades'] * 100) if data['trades'] > 0 else 0
        daily_list.append({
            'date': day,
            'pnl': round(data['pnl'], 2),
            'trades': data['trades'],
            'winRate': round(wr, 1)
        })
    
    # Calculate cumulative PnL
    cumulative = 0
    for item in daily_list:
        cumulative += item['pnl']
        item['cumulative'] = round(cumulative, 2)
    
    return JSONResponse({
        "success": True,
        "source": source,
        "dailyPnl": daily_list[-30:],  # Last 30 days
        "totalDays": len(daily_list)
    })

@app.get("/performance/optimizer-history")
async def get_optimizer_history():
    """Get AI optimizer change history."""
    history = parameter_optimizer.optimization_history[-20:]  # Last 20
    return JSONResponse({
        "success": True,
        "history": history
    })

@app.get("/performance/summary")
async def get_performance_summary():
    """Get comprehensive performance summary ‚Äî Binance verisi √∂ncelikli."""
    
    # Try Binance trades first
    trades = []
    source = "paper"
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=1000)
        if binance_trades and len(binance_trades) >= 5:
            trades = binance_trades
            source = "binance"
    except Exception as e:
        logger.debug(f"Binance summary error: {e}")
    
    # Fallback to paper trades
    if not trades:
        trades = global_paper_trader.trades
        source = "paper"
    
    total_trades = len(trades)
    total_pnl = sum(t.get('pnl', 0) for t in trades)
    winning_trades = len([t for t in trades if t.get('pnl', 0) > 0])
    win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
    
    # Recent performance (last 7 days)
    week_ago = datetime.now().timestamp() * 1000 - (7 * 24 * 60 * 60 * 1000)
    recent_trades = [t for t in trades if t.get('closeTime', t.get('close_time', 0)) > week_ago]
    recent_pnl = sum(t.get('pnl', 0) for t in recent_trades)
    recent_wins = len([t for t in recent_trades if t.get('pnl', 0) > 0])
    recent_wr = (recent_wins / len(recent_trades) * 100) if recent_trades else 0
    
    # Close reason breakdown
    reason_stats = {}
    for t in trades:
        reason = t.get('reason', t.get('closeReason', 'UNKNOWN'))
        # Normalize reason
        if 'SL' in str(reason).upper() or 'STOP' in str(reason).upper():
            reason = 'SL_HIT'
        elif 'TP' in str(reason).upper() or 'TAKE' in str(reason).upper():
            reason = 'TP_HIT'
        elif 'TRAIL' in str(reason).upper():
            reason = 'TRAILING'
        elif 'BREAKEVEN' in str(reason).upper():
            reason = 'BREAKEVEN'
        elif 'TIME' in str(reason).upper():
            reason = 'TIME_EXIT'
        
        if reason not in reason_stats:
            reason_stats[reason] = {'count': 0, 'pnl': 0}
        reason_stats[reason]['count'] += 1
        reason_stats[reason]['pnl'] += t.get('pnl', 0)
    
    # Round reason PnL
    for r in reason_stats:
        reason_stats[r]['pnl'] = round(reason_stats[r]['pnl'], 2)
    
    # Average trade metrics
    avg_win = 0
    avg_loss = 0
    wins = [t.get('pnl', 0) for t in trades if t.get('pnl', 0) > 0]
    losses = [t.get('pnl', 0) for t in trades if t.get('pnl', 0) < 0]
    if wins:
        avg_win = sum(wins) / len(wins)
    if losses:
        avg_loss = sum(losses) / len(losses)
    profit_factor = abs(sum(wins) / sum(losses)) if losses and sum(losses) != 0 else 0
    
    # Get today's PnL from Binance income API (includes FUNDING_FEE + COMMISSION)
    binance_today_pnl = 0
    binance_today_pnl_pct = 0
    binance_total_pnl_income = 0
    try:
        if live_binance_trader.enabled:
            # Use cached PnL if available (updated every scan cycle)
            cached = getattr(live_binance_trader, 'cached_pnl', None)
            if cached:
                binance_today_pnl = cached.get('todayPnl', 0)
                binance_today_pnl_pct = cached.get('todayPnlPercent', 0)
                binance_total_pnl_income = cached.get('totalPnl', 0)
            else:
                # Fetch fresh if no cache
                pnl_data = await live_binance_trader.get_pnl_from_binance()
                binance_today_pnl = pnl_data.get('todayPnl', 0)
                binance_today_pnl_pct = pnl_data.get('todayPnlPercent', 0)
                binance_total_pnl_income = pnl_data.get('totalPnl', 0)
    except Exception as e:
        logger.debug(f"Binance today PnL fetch error: {e}")
    
    return JSONResponse({
        "success": True,
        "source": source,
        "totalPnl": round(total_pnl, 2),
        "totalTrades": total_trades,
        "winRate": round(win_rate, 1),
        "winningTrades": winning_trades,
        "losingTrades": total_trades - winning_trades,
        "recentPnl": round(recent_pnl, 2),
        "recentTrades": len(recent_trades),
        "recentWinRate": round(recent_wr, 1),
        "avgWin": round(avg_win, 4),
        "avgLoss": round(avg_loss, 4),
        "profitFactor": round(profit_factor, 2),
        "closeReasons": reason_stats,
        "coinStats": coin_performance_tracker.get_stats_for_optimizer(),
        "optimizerEnabled": parameter_optimizer.enabled,
        "lastOptimization": parameter_optimizer.last_optimization,
        "binanceTodayPnl": round(binance_today_pnl, 2),
        "binanceTodayPnlPct": round(binance_today_pnl_pct, 2),
        "binanceTotalPnlIncome": round(binance_total_pnl_income, 2)
    })

@app.post("/scanner/start")
async def scanner_start():
    """Start the background scanner."""
    global background_scanner_task

    task_alive = background_scanner_task is not None and not background_scanner_task.done()

    # Heal stale state: running flag true but task is dead
    if multi_coin_scanner.running and task_alive:
        return JSONResponse({"success": True, "running": True, "message": "Scanner already running"})

    multi_coin_scanner.running = True
    if not task_alive:
        background_scanner_task = asyncio.create_task(background_scanner_loop())
        logger.warning("üîÅ Scanner task auto-restarted via /scanner/start (stale running state healed)")

    logger.info("üöÄ Scanner started via API")
    return JSONResponse({"success": True, "running": True, "message": "Scanner started"})

@app.post("/scanner/stop")
async def scanner_stop():
    """Stop the background scanner."""
    multi_coin_scanner.running = False
    logger.info("üõë Scanner stopped via API")
    return JSONResponse({"success": True, "running": False, "message": "Scanner stopped"})

@app.get("/scanner/status")
async def scanner_status():
    """Get scanner running status."""
    global background_scanner_task
    task_alive = background_scanner_task is not None and not background_scanner_task.done()

    # Self-heal: if scanner marked running but task died, restart automatically.
    auto_restarted = False
    if multi_coin_scanner.running and not task_alive:
        background_scanner_task = asyncio.create_task(background_scanner_loop())
        task_alive = True
        auto_restarted = True
        logger.warning("üîÅ Scanner task auto-restarted via /scanner/status (detected dead task)")

    # Keep running flag consistent with actual task state (important for frontend WS bootstrap).
    if task_alive and not multi_coin_scanner.running:
        multi_coin_scanner.running = True
        logger.warning("üîÅ Scanner running flag healed via /scanner/status (task alive, flag was false)")

    cache_age = 0
    if ui_state_cache.last_update > 0:
        cache_age = int(max(0, datetime.now().timestamp() - ui_state_cache.last_update))

    effective_running = multi_coin_scanner.running or task_alive

    return JSONResponse({
        "running": effective_running,
        "runningFlag": multi_coin_scanner.running,
        "totalCoins": len(multi_coin_scanner.coins),
        "analyzedCoins": len(multi_coin_scanner.analyzers),
        "taskAlive": task_alive,
        "cacheInitialized": ui_state_cache._initialized,
        "cacheAgeSec": cache_age,
        "autoRestarted": auto_restarted
    })

# Phase 17: Settings endpoints
@app.get("/paper-trading/settings")
async def paper_trading_get_settings():
    """Get current cloud trading settings."""
    return JSONResponse({
        "symbol": global_paper_trader.symbol,
        "leverage": global_paper_trader.leverage,
        "riskPerTrade": global_paper_trader.risk_per_trade,
        "enabled": global_paper_trader.enabled,
        "balance": global_paper_trader.balance,
        "positions": global_paper_trader.positions,
        "stats": {**global_paper_trader.stats, **global_paper_trader.get_today_pnl()},
        "trades": global_paper_trader.trades[-50:],
        "equityCurve": global_paper_trader.equity_curve[-100:],
        "slAtr": global_paper_trader.sl_atr,
        "tpAtr": global_paper_trader.tp_atr,
        "trailActivationAtr": global_paper_trader.trail_activation_atr,
        "trailDistanceAtr": global_paper_trader.trail_distance_atr,
        "maxPositions": global_paper_trader.max_positions,
        # Algorithm sensitivity settings
        "zScoreThreshold": global_paper_trader.z_score_threshold,
        "minConfidenceScore": global_paper_trader.min_confidence_score,
        # Phase 50: Dynamic Min Score Range
        "minScoreLow": global_paper_trader.min_score_low,
        "minScoreHigh": global_paper_trader.min_score_high,
        # Phase 36: Entry/Exit tightness
        "entryTightness": global_paper_trader.entry_tightness,
        "exitTightness": global_paper_trader.exit_tightness,
        # Server-side logs
        "logs": global_paper_trader.logs[-50:],
        # Phase 52: Adaptive Trading System stats
        "optimizer": {
            "enabled": parameter_optimizer.enabled,
            "lastOptimization": parameter_optimizer.last_optimization,
            "postTradeStats": post_trade_tracker.get_stats(),
            "lastAnalysis": performance_analyzer.last_analysis,
        },
        # Phase 57: Kill Switch settings
        "killSwitchFirstReduction": daily_kill_switch.first_reduction_pct,
        "killSwitchFullClose": daily_kill_switch.full_close_pct,
        # Phase 216: Leverage multiplier
        "leverageMultiplier": getattr(global_paper_trader, 'leverage_multiplier', 1.0)
    })

@app.post("/paper-trading/settings")
async def paper_trading_update_settings(
    symbol: str = None, 
    leverage: int = None, 
    riskPerTrade: float = None,
    slAtr: float = None,
    tpAtr: float = None,
    trailActivationAtr: float = None,
    trailDistanceAtr: float = None,
    maxPositions: int = None,
    zScoreThreshold: float = None,
    minConfidenceScore: int = None,
    minScoreLow: int = None,
    minScoreHigh: int = None,
    entryTightness: float = None,
    exitTightness: float = None,
    killSwitchFirstReduction: float = None,
    killSwitchFullClose: float = None,
    leverageMultiplier: float = None
):
    """Update cloud trading settings."""
    if symbol:
        global_paper_trader.symbol = symbol
        # Switch Binance Streamer to new symbol
        # Assuming binance_streamer is the global instance variable
        if 'binance_streamer' in globals():
            await binance_streamer.switch_symbol(symbol)
        else:
             logger.warning("‚ö†Ô∏è binance_streamer global not found, stream not switched.")

    if leverage:
        global_paper_trader.leverage = leverage
    if riskPerTrade:
        global_paper_trader.risk_per_trade = riskPerTrade
    # Phase 18: Full trading parameters
    if slAtr is not None:
        global_paper_trader.sl_atr = slAtr
    if tpAtr is not None:
        global_paper_trader.tp_atr = tpAtr
    if trailActivationAtr is not None:
        global_paper_trader.trail_activation_atr = trailActivationAtr
    if trailDistanceAtr is not None:
        global_paper_trader.trail_distance_atr = trailDistanceAtr
    if maxPositions is not None:
        global_paper_trader.max_positions = maxPositions
    # Algorithm sensitivity settings
    if zScoreThreshold is not None:
        global_paper_trader.z_score_threshold = zScoreThreshold
    if minConfidenceScore is not None:
        global_paper_trader.min_confidence_score = minConfidenceScore
    # Phase 50: Dynamic Min Score Range
    if minScoreLow is not None:
        global_paper_trader.min_score_low = minScoreLow
    if minScoreHigh is not None:
        global_paper_trader.min_score_high = minScoreHigh
    # Phase 36: Entry/Exit tightness settings
    if entryTightness is not None:
        global_paper_trader.entry_tightness = entryTightness
    if exitTightness is not None:
        global_paper_trader.exit_tightness = exitTightness
    
    # Phase 57: Kill Switch settings
    if killSwitchFirstReduction is not None:
        daily_kill_switch.first_reduction_pct = killSwitchFirstReduction
        logger.info(f"üö® Kill Switch First Reduction updated: {killSwitchFirstReduction}%")
    if killSwitchFullClose is not None:
        daily_kill_switch.full_close_pct = killSwitchFullClose
        logger.info(f"üö® Kill Switch Full Close updated: {killSwitchFullClose}%")
    
    # Phase 216: Leverage multiplier
    if leverageMultiplier is not None:
        clamped = max(0.3, min(3.0, leverageMultiplier))
        old_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        global_paper_trader.leverage_multiplier = clamped
        logger.info(f"‚ö° Leverage Multiplier updated: {old_mult:.1f}x ‚Üí {clamped:.1f}x")
        # Fix P1: Clear pending orders with stale leverage when multiplier changes
        if abs(old_mult - clamped) > 0.01 and global_paper_trader.pending_orders:
            stale_count = len(global_paper_trader.pending_orders)
            global_paper_trader.pending_orders.clear()
            global_paper_trader.add_log(f"‚ö†Ô∏è SETTINGS_CHANGED_LEVERAGE_MULTIPLIER: {stale_count} pending orders cleared (lev {old_mult:.1f}x‚Üí{clamped:.1f}x)")
            logger.info(f"üóëÔ∏è Cleared {stale_count} pending orders due to leverage multiplier change")
    
    # Log settings change (simplified)
    global_paper_trader.add_log(f"‚öôÔ∏è Ayarlar g√ºncellendi: SL:{global_paper_trader.sl_atr} TP:{global_paper_trader.tp_atr} Z:{global_paper_trader.z_score_threshold} KS:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}")
    global_paper_trader.save_state()
    logger.info(f"Settings updated: MaxPositions:{global_paper_trader.max_positions} Z-Threshold:{global_paper_trader.z_score_threshold} KillSwitch:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}")
    
    # ====== PHASE 37: Update existing positions' TP/SL based on new exit_tightness ======
    updated_positions = 0
    for pos in global_paper_trader.positions:
        try:
            entry_price = pos.get('entryPrice', 0)
            if entry_price <= 0:
                continue
            
            # Use stored ATR or estimate from entry price (2% is typical ATR)
            atr = pos.get('atr', entry_price * 0.02)
            side = pos.get('side', '')
            
            # Recalculate TP/SL with new exit_tightness
            adjusted_sl_atr = (global_paper_trader.sl_atr / 10) * global_paper_trader.exit_tightness
            adjusted_tp_atr = (global_paper_trader.tp_atr / 10) * global_paper_trader.exit_tightness
            adjusted_trail_activation_atr = global_paper_trader.trail_activation_atr * global_paper_trader.exit_tightness
            adjusted_trail_distance_atr = global_paper_trader.trail_distance_atr * global_paper_trader.exit_tightness
            
            if side == 'LONG':
                new_sl = max(entry_price * 0.01, entry_price - (atr * adjusted_sl_atr))
                new_tp = entry_price + (atr * adjusted_tp_atr)
                new_trail_activation = entry_price + (atr * adjusted_trail_activation_atr)
            else:  # SHORT
                new_sl = entry_price + (atr * adjusted_sl_atr)
                new_tp = max(entry_price * 0.01, entry_price - (atr * adjusted_tp_atr))
                new_trail_activation = max(entry_price * 0.01, entry_price - (atr * adjusted_trail_activation_atr))
            
            new_trail_distance = atr * adjusted_trail_distance_atr
            
            # Only update if not already in trailing mode (to preserve trailing stop progress)
            if not pos.get('isTrailingActive', False):
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl
            
            pos['takeProfit'] = new_tp
            pos['trailActivation'] = new_trail_activation
            pos['trailDistance'] = new_trail_distance
            
            updated_positions += 1
            
        except Exception as e:
            logger.error(f"Error updating position {pos.get('symbol', '?')}: {e}")
    
    if updated_positions > 0:
        logger.info(f"üîÑ Updated TP/SL for {updated_positions} existing positions based on new exit_tightness: {global_paper_trader.exit_tightness}")
        global_paper_trader.add_log(f"üîÑ {updated_positions} pozisyonun TP/SL'si g√ºncellendi (Exit: {global_paper_trader.exit_tightness})")
        global_paper_trader.save_state()
    
    return JSONResponse({
        "success": True,
        "symbol": global_paper_trader.symbol,
        "leverage": global_paper_trader.leverage,
        "riskPerTrade": global_paper_trader.risk_per_trade,
        "slAtr": global_paper_trader.sl_atr,
        "tpAtr": global_paper_trader.tp_atr,
        "trailActivationAtr": global_paper_trader.trail_activation_atr,
        "trailDistanceAtr": global_paper_trader.trail_distance_atr,
        "maxPositions": global_paper_trader.max_positions,
        "zScoreThreshold": global_paper_trader.z_score_threshold,
        "minConfidenceScore": global_paper_trader.min_confidence_score,
        "entryTightness": global_paper_trader.entry_tightness,
        "exitTightness": global_paper_trader.exit_tightness,
        "killSwitchFirstReduction": daily_kill_switch.first_reduction_pct,
        "killSwitchFullClose": daily_kill_switch.full_close_pct,
        "updatedPositions": updated_positions
    })


# Phase 36: Market Order from Signal Card

# ============================================================================
# PHASE 193: NEW API ENDPOINTS (FreqAI, Hyperopt, StoplossGuard, WS Manager)
# ============================================================================

@app.get("/phase193/status")
async def phase193_status():
    """Get status of all Phase 193 modules."""
    return JSONResponse({
        "stoploss_guard": stoploss_frequency_guard.get_status(),
        "freqai": freqai_model.get_status() if freqai_model else {"enabled": False, "error": "not installed"},
        "hyperopt": hhq_hyperoptimizer.get_status() if hhq_hyperoptimizer else {"enabled": False, "error": "not installed"},
        "ws_manager": ccxt_ws_manager.get_status() if ccxt_ws_manager else {"enabled": False, "error": "not installed"},
        "pandas_ta": PANDAS_TA_AVAILABLE,
    })

@app.post("/phase193/stoploss-guard/settings")
async def phase193_sl_guard_settings(request: Request):
    """Update StoplossFrequencyGuard settings."""
    data = await request.json()
    stoploss_frequency_guard.update_settings(data)
    return JSONResponse(stoploss_frequency_guard.get_status())

@app.post("/phase193/freqai/retrain")
async def phase193_freqai_retrain():
    """Force FreqAI model retrain."""
    if not freqai_model:
        return JSONResponse({"error": "FreqAI not available"}, status_code=400)
    success = freqai_model.force_retrain()
    return JSONResponse({
        "success": success,
        "status": freqai_model.get_status()
    })

@app.post("/phase193/hyperopt/run")
async def phase193_hyperopt_run(request: Request):
    """Run hyperparameter optimization."""
    if not hhq_hyperoptimizer:
        return JSONResponse({"error": "Hyperopt not available"}, status_code=400)
    
    data = await request.json() if request.headers.get('content-type') == 'application/json' else {}
    n_trials = data.get('n_trials', 100)
    
    # Load trade data from paper trader if not already loaded
    if not hhq_hyperoptimizer.trade_data and 'global_paper_trader' in globals():
        hhq_hyperoptimizer.trade_data = list(global_paper_trader.trade_history)
    
    result = await hhq_hyperoptimizer.optimize(n_trials=n_trials)
    return JSONResponse(result)


@app.post("/paper-trading/market-order")
async def paper_trading_market_order(request: Request):
    """Open a market order from a signal card (manual entry)."""
    try:
        data = await request.json()
        symbol = data.get('symbol')
        side = data.get('side')  # LONG or SHORT
        price = float(data.get('price', 0))
        # Fix P0: Use signal leverage from UI (already includes multiplier)
        requested_lev = data.get('signalLeverage')
        
        if not symbol or not side or price <= 0:
            return JSONResponse({"success": False, "error": "Missing symbol, side, or price"}, status_code=400)
        
        # Check if we have room for more positions
        if len(global_paper_trader.positions) >= global_paper_trader.max_positions:
            return JSONResponse({"success": False, "error": f"Max positions ({global_paper_trader.max_positions}) reached"})
        
        # Phase 191: Paper market order engelle
        if not live_binance_trader.enabled:
            return JSONResponse({"success": False, "error": "Paper trading deaktif ‚Äî sadece live"}, status_code=400)
        
        # Get ATR from analyzer if available
        atr = price * 0.02  # Default 2% of price as fallback ATR
        if symbol in multi_coin_scanner.analyzers:
            analyzer = multi_coin_scanner.analyzers[symbol]
            if hasattr(analyzer.opportunity, 'atr') and analyzer.opportunity.atr > 0:
                atr = analyzer.opportunity.atr
        
        # Calculate position sizing
        balance = global_paper_trader.balance
        risk_amount = balance * global_paper_trader.risk_per_trade
        
        # Fix P0: Leverage pipeline ‚Äî priority: signalLeverage > base * multiplier
        base_lev = global_paper_trader.leverage
        user_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        if requested_lev and requested_lev > 0:
            leverage = max(3, min(75, int(requested_lev)))
        else:
            leverage = max(3, min(75, int(base_lev * user_mult)))
        
        # LEV_PIPE log for full traceability
        logger.info(f"üîß LEV_PIPE: signalLev={requested_lev} userMult={user_mult:.1f} baseLev={base_lev} ‚Üí orderLev={leverage}x | {side} {symbol}")
        
        # Fix P1: Set leverage on Binance ‚Äî abort if real failure
        if live_binance_trader.enabled:
            set_ok = await live_binance_trader.set_leverage(symbol, leverage)
            if not set_ok:
                return JSONResponse({"success": False, "error": f"Binance leverage set failed for {symbol} ‚Üí {leverage}x"}, status_code=500)
        
        # SL/TP based on ATR
        sl_distance = atr * (global_paper_trader.sl_atr / 10)
        tp_distance = atr * (global_paper_trader.tp_atr / 10)
        
        if side == 'LONG':
            sl = price - sl_distance
            tp = price + tp_distance
        else:
            sl = price + sl_distance
            tp = price - tp_distance
        
        # Position size
        if sl_distance > 0:
            size = risk_amount / sl_distance
        else:
            size = (balance * 0.1) / price  # 10% of balance fallback
        
        size_usd = size * price
        
        # Create position
        position = {
            "id": f"manual_{int(datetime.now().timestamp() * 1000)}",
            "symbol": symbol,
            "side": side,
            "entryPrice": price,
            "currentPrice": price,
            "size": size,
            "sizeUsd": size_usd,
            "stopLoss": sl,
            "takeProfit": tp,
            "trailingStop": 0,
            "trailActivation": price + (atr * global_paper_trader.trail_activation_atr) if side == 'LONG' else price - (atr * global_paper_trader.trail_activation_atr),
            "trailDistance": atr * global_paper_trader.trail_distance_atr,
            "isTrailingActive": False,
            "unrealizedPnl": 0,
            "unrealizedPnlPercent": 0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": leverage,
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
        }
        
        global_paper_trader.positions.append(position)
        global_paper_trader.add_log(f"üõí MARKET ORDER: {side} {symbol} @ ${price:.4f} | {leverage}x | SL: ${sl:.4f} | TP: ${tp:.4f}")
        global_paper_trader.save_state()
        
        logger.info(f"‚úÖ Market Order: {side} {symbol} @ {price} | finalLev={leverage}x")
        return JSONResponse({"success": True, "position": position})
        
    except Exception as e:
        logger.error(f"Market order error: {e}")
        return JSONResponse({"success": False, "error": str(e)}, status_code=500)


@app.post("/paper-trading/close/{position_id}")
async def paper_trading_close(position_id: str):
    """Close a specific position with real-time price."""
    try:
        # Find position by ID
        pos = next((p for p in global_paper_trader.positions if p['id'] == position_id), None)
        if not pos:
            logger.warning(f"Close position failed: position {position_id} not found. Active positions: {[p['id'] for p in global_paper_trader.positions]}")
            return JSONResponse({"success": False, "message": f"Pozisyon bulunamadƒ±: {position_id}"}, status_code=404)
        
        # Get current price - priority: 1) stored currentPrice 2) scanner opportunities 3) entryPrice fallback
        current_price = pos.get('currentPrice', 0)
        
        if not current_price or current_price <= 0:
            # Try to get from scanner opportunities
            symbol = pos.get('symbol', '')
            for opp in multi_coin_scanner.current_opportunities:
                if opp.get('symbol') == symbol:
                    current_price = opp.get('price', 0)
                    break
        
        if not current_price or current_price <= 0:
            # Final fallback to entry price
            current_price = pos.get('entryPrice', 0)
            logger.warning(f"Using entry price for close (no live price): {position_id}")
        
        if current_price <= 0:
            return JSONResponse({"success": False, "message": "G√ºncel fiyat alƒ±namadƒ±"}, status_code=500)
        
        # Close the position
        success = global_paper_trader.close_position_by_id(position_id, current_price)
        if success:
            return JSONResponse({"success": True, "message": f"Pozisyon kapatƒ±ldƒ± @ ${current_price:.6f}"})
        else:
            logger.error(f"close_position_by_id returned False for {position_id}")
            return JSONResponse({"success": False, "message": "Pozisyon kapatƒ±lamadƒ±"}, status_code=500)
            
    except Exception as e:
        logger.error(f"Error closing position {position_id}: {e}")
        return JSONResponse({"success": False, "message": f"Hata: {str(e)}"}, status_code=500)


# ============================================================================
# PHASE 31: MULTI-COIN SCANNER WEBSOCKET ENDPOINT
# ============================================================================


def _safe_json_default(obj):
    """Fallback serializer for numpy/pandas types that json.dumps can't handle."""
    if isinstance(obj, (np.bool_,)):
        return bool(obj)
    if isinstance(obj, (np.integer,)):
        return int(obj)
    if isinstance(obj, (np.floating,)):
        return float(obj)
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")

@app.websocket("/ws/scanner")
async def scanner_websocket_endpoint(websocket: WebSocket):
    """
    PHASE 98: Simplified WebSocket endpoint using UI State Cache.
    
    Reads from pre-populated cache instead of making fresh Binance API calls.
    Cache is updated every 3 seconds by background_scanner_loop.
    
    Benefits:
    - Instant connection (~0ms vs 3+ minutes before)
    - No Binance API rate limit impact from UI connections
    - All clients see consistent data
    """
    global background_scanner_task
    await websocket.accept()
    logger.info("üöÄ Phase 98: Scanner WebSocket connected - using cache")

    # Auto-heal on client connect: running=true but scanner task is dead.
    task_alive = background_scanner_task is not None and not background_scanner_task.done()
    if multi_coin_scanner.running and not task_alive:
        background_scanner_task = asyncio.create_task(background_scanner_loop())
        logger.warning("üîÅ Scanner task auto-restarted via /ws/scanner connect")
    
    full_state_interval = 2.0  # Full payload (opportunities + portfolio) cadence
    fast_tick_interval = 0.35  # Fast price ticks for active signals/positions
    last_full_state_sent = 0.0
    
    try:
        def build_warmup_state() -> dict:
            """Build non-empty fallback state while cache is warming up."""
            scanner_stats = multi_coin_scanner.get_scanner_stats() if 'multi_coin_scanner' in globals() else {}
            opps = ui_state_cache.opportunities or getattr(multi_coin_scanner, 'opportunities', []) or []
            min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
            long_count = sum(1 for o in opps if o.get('signalAction') == 'LONG' and o.get('signalScore', 0) >= min_score)
            short_count = sum(1 for o in opps if o.get('signalAction') == 'SHORT' and o.get('signalScore', 0) >= min_score)

            if live_binance_trader.enabled:
                positions = ui_state_cache.positions or global_paper_trader.positions
                balance = ui_state_cache.balance or (ui_state_cache.live_balance or {}).get('walletBalance', 0)
            else:
                positions = ui_state_cache.positions or global_paper_trader.positions
                balance = ui_state_cache.balance or global_paper_trader.balance

            trades = ui_state_cache.trades or global_paper_trader.trades

            return {
                "type": "scanner_update",
                "opportunities": opps,
                "stats": {
                    "totalCoins": scanner_stats.get('totalCoins', len(getattr(multi_coin_scanner, 'coins', []))),
                    "analyzedCoins": scanner_stats.get('analyzedCoins', len(getattr(multi_coin_scanner, 'analyzers', {}))),
                    "longSignals": long_count,
                    "shortSignals": short_count,
                    "activeSignals": long_count + short_count,
                    "lastUpdate": datetime.now().timestamp()
                },
                "portfolio": {
                    "balance": balance,
                    "positions": positions,
                    "trades": sorted(trades, key=lambda t: t.get('closeTime', 0), reverse=True),
                    "stats": {
                        **ui_state_cache.pnl_data,
                        "liveBalance": ui_state_cache.live_balance,
                        "winRate": 0,
                        "totalTrades": len(trades)
                    },
                    "logs": (ui_state_cache.logs or global_paper_trader.logs)[-100:],
                    "enabled": global_paper_trader.enabled
                },
                "tradingMode": "live" if live_binance_trader.enabled else "paper",
                "timestamp": datetime.now().timestamp(),
                "message": "Cache warming up (serving fallback scanner state)"
            }

        async def send_full_state():
            """Send scanner snapshot. Uses fallback state while cache initializes."""
            state = ui_state_cache.get_state() if ui_state_cache.is_ready() else build_warmup_state()
            await websocket.send_text(json.dumps(state, default=_safe_json_default))

        async def send_fast_price_tick():
            """Send lightweight fast price updates for active symbols only."""
            if not binance_ws_manager.tickers:
                return

            min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
            source_opps = ui_state_cache.opportunities or getattr(multi_coin_scanner, 'opportunities', []) or []
            signal_symbols = set()
            for opp in source_opps:
                if opp.get('signalAction') != 'NONE' and opp.get('signalScore', 0) >= min_score:
                    sym = opp.get('symbol')
                    if sym:
                        signal_symbols.add(sym)

            source_positions = ui_state_cache.positions or global_paper_trader.positions
            position_symbols = set()
            for pos in source_positions:
                sym = pos.get('symbol')
                if sym:
                    position_symbols.add(sym)

            tracked_symbols = signal_symbols.union(position_symbols)
            if not tracked_symbols:
                return

            tickers = binance_ws_manager.get_tickers(list(tracked_symbols))
            if not tickers:
                return

            all_prices = {}
            signal_prices = {}
            position_prices = {}
            for sym, tick in tickers.items():
                px = float(tick.get('last', 0) or 0)
                if px <= 0:
                    continue
                all_prices[sym] = px
                if sym in signal_symbols:
                    signal_prices[sym] = px
                if sym in position_symbols:
                    position_prices[sym] = px

            if not all_prices:
                return

            await websocket.send_text(json.dumps({
                "type": "price_tick",
                "prices": all_prices,
                "signalPrices": signal_prices,
                "positionPrices": position_prices,
                "timestamp": datetime.now().timestamp()
            }, default=_safe_json_default))

        # INSTANT: Send cached state immediately (no API calls!)
        await send_full_state()
        last_full_state_sent = datetime.now().timestamp()
        if ui_state_cache.is_ready():
            logger.info(f"üì¶ Phase 98: Sent cached state instantly ({len(ui_state_cache.opportunities)} opportunities)")
        else:
            logger.info("‚è≥ Phase 98: Cache not ready yet, sent empty state")
        
        # Stream fast ticks frequently + full state periodically.
        while True:
            await asyncio.sleep(fast_tick_interval)

            await send_fast_price_tick()

            now_ts = datetime.now().timestamp()
            if now_ts - last_full_state_sent >= full_state_interval:
                await send_full_state()
                last_full_state_sent = now_ts
            
    except WebSocketDisconnect:
        logger.info("Scanner WebSocket client disconnected")
    except Exception as e:
        if "close message" not in str(e).lower() and "disconnect" not in str(e).lower():
            logger.error(f"Scanner WebSocket error: {e}")
    finally:
        # Scanner continues running in background - we don't stop it here
        pass


@app.websocket("/ws/ui")
async def ui_websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for real-time UI updates.
    Broadcasts: signals, positions, prices, logs, kill switch events.
    """
    await ui_ws_manager.connect(websocket)
    
    try:
        # Phase 91: Send initial state with correct data source based on trading mode
        # Use Binance data for live mode, paper trader for paper mode
        
        if live_binance_trader.enabled:
            # Live mode: Get data from Binance
            try:
                initial_balance_data = await live_binance_trader.get_balance()
                initial_balance = initial_balance_data.get('walletBalance', 0)
                initial_live_balance = initial_balance_data
            except:
                initial_balance = 0
                initial_live_balance = None
            
            try:
                initial_positions = await live_binance_trader.get_positions()
            except:
                initial_positions = []
            
            # Get PnL data
            try:
                pnl_data = await live_binance_trader.get_pnl_from_binance()
            except:
                pnl_data = {'todayPnl': 0, 'todayPnlPercent': 0, 'totalPnl': 0, 'totalPnlPercent': 0}
            
            initial_state = {
                "balance": initial_balance,
                "positions": initial_positions,
                "pendingOrders": global_paper_trader.pending_orders,
                "enabled": global_paper_trader.enabled,
                "tradeCount": len(global_paper_trader.trades),
                "trades": global_paper_trader.trades,
                "opportunities": multi_coin_scanner.opportunities if multi_coin_scanner else [],
                # Phase 92: Include scanner stats with totalCoins
                "stats": {
                    "todayPnl": pnl_data.get('todayPnl', 0),
                    "todayPnlPercent": pnl_data.get('todayPnlPercent', 0),
                    "totalPnl": pnl_data.get('totalPnl', 0),
                    "totalPnlPercent": pnl_data.get('totalPnlPercent', 0),
                    "liveBalance": initial_live_balance,
                    # Scanner stats
                    "totalCoins": len(multi_coin_scanner.coins) if multi_coin_scanner and multi_coin_scanner.coins else 0,
                    "analyzedCoins": len(multi_coin_scanner.opportunities) if multi_coin_scanner else 0,
                    "longSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'LONG'),
                    "shortSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'SHORT')
                },
                "logs": global_paper_trader.logs[-100:] if hasattr(global_paper_trader, 'logs') else [],
                "tradingMode": "live"
            }
        else:
            # Paper mode: Use paper trader data
            pnl_data = global_paper_trader.get_today_pnl()
            initial_state = {
                "balance": global_paper_trader.balance,
                "positions": global_paper_trader.positions,
                "pendingOrders": global_paper_trader.pending_orders,
                "enabled": global_paper_trader.enabled,
                "tradeCount": len(global_paper_trader.trades),
                "trades": global_paper_trader.trades,
                "opportunities": multi_coin_scanner.opportunities if multi_coin_scanner else [],
                # Phase 92: Include scanner stats with totalCoins
                "stats": {
                    **global_paper_trader.stats,
                    **pnl_data,
                    # Scanner stats
                    "totalCoins": len(multi_coin_scanner.coins) if multi_coin_scanner and multi_coin_scanner.coins else 0,
                    "analyzedCoins": len(multi_coin_scanner.opportunities) if multi_coin_scanner else 0,
                    "longSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'LONG'),
                    "shortSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'SHORT')
                },
                "logs": global_paper_trader.logs[-100:] if hasattr(global_paper_trader, 'logs') else [],
                "tradingMode": "paper"
            }
        
        await websocket.send_json({"type": "INITIAL_STATE", "data": initial_state, "timestamp": int(datetime.now().timestamp() * 1000)})
        
        # Keep connection alive and handle incoming messages
        while True:
            try:
                # Wait for any message (ping/pong or commands)
                data = await asyncio.wait_for(websocket.receive_text(), timeout=30)
                
                # Handle ping
                if data == "ping":
                    await websocket.send_text("pong")
                    
            except asyncio.TimeoutError:
                # Send keepalive ping
                try:
                    await websocket.send_text("ping")
                except:
                    break
                    
    except WebSocketDisconnect:
        ui_ws_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"UI WebSocket error: {e}")
        ui_ws_manager.disconnect(websocket)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, symbol: str = None):
    """
    WebSocket endpoint for real-time data streaming.
    """
    await websocket.accept()
    
    # Phase 26 Fix: Prioritize Global Paper Trader Symbol
    # If symbol arg is "BTCUSDT" (default) or None, check if we have a persisted symbol
    active_symbol = symbol
    if not active_symbol or active_symbol == "BTCUSDT":
        if global_paper_trader.symbol and global_paper_trader.symbol != "SOLUSDT": # Avoid default if persisted is different
             active_symbol = global_paper_trader.symbol
        if not active_symbol:
             active_symbol = "BTCUSDT" # Ultimate fallback

    logger.info(f"Client connected. Active Symbol: {active_symbol} (Requested: {symbol}, Global: {global_paper_trader.symbol})")
    
    ccxt_symbol = active_symbol.replace("USDT", "/USDT")
    streamer = BinanceStreamer(ccxt_symbol)
    
    try:
        await streamer.connect()
        streamer.running = True
        streamer.paper_trader = global_paper_trader  # Phase 16: Use global instance
        
        # Phase 28: Load coin profile for dynamic optimization
        await streamer.update_coin_profile()
        
        # Fetch initial OHLCV for ATR (one-time REST call)
        try:
            ohlcv = await streamer.fetch_ohlcv()
            for candle in ohlcv:
                _, _, high, low, close, volume = candle
                streamer.update_price(close, high, low, volume)
        except Exception as e:
            logger.warning(f"Initial OHLCV fetch failed: {e}")
        
        # Wait for WebSocket stream to connect
        await asyncio.sleep(2)
        
        while streamer.running:
            try:
                # Use WebSocket stream data (no REST API calls = no rate limits!)
                ticker = streamer.ws_ticker
                spot_ticker = streamer.ws_spot_ticker
                order_book = streamer.ws_order_book
                
                if ticker and 'last' in ticker:
                    price = ticker['last']
                    high = ticker.get('high', price)
                    low = ticker.get('low', price)
                    volume = ticker.get('volume', 0)
                    streamer.update_price(price, high, low, volume)
                    
                    # Basis Calculation (Futures - Spot)
                    spot_price = spot_ticker.get('last', 0)
                    basis = 0.0
                    basis_pct = 0.0
                    if spot_price > 0:
                        basis = price - spot_price
                        basis_pct = (basis / spot_price) * 100
                    
                    metrics = streamer.get_metrics()
                    
                    # Format order book
                    bids = [
                        {"price": float(b[0]), "size": float(b[1]), "total": 0}
                        for b in order_book.get('bids', [])[:20]
                    ]
                    asks = [
                        {"price": float(a[0]), "size": float(a[1]), "total": 0}
                        for a in order_book.get('asks', [])[:20]
                    ]
                    
                    acc = 0
                    for b in bids:
                        acc += b['size']
                        b['total'] = acc
                    acc = 0
                    for a in asks:
                        acc += a['size']
                        a['total'] = acc
                    
                    imbalance = calculate_imbalance(
                        order_book.get('bids', []),
                        order_book.get('asks', [])
                    )
                    
                    
                    # Generate signal if conditions met
                    signal = None
                    try:
                        whale_z = streamer.whale_detector.get_zscore()
                        nearest_fvg = streamer.smc_analyzer.get_nearest_fvg(price) # Phase 10
                        
                        # Check Breakout (Phase 11)
                        open_price = ticker.get('open', price)
                        vol_osc = metrics.get('vol_osc', 0)
                        breakout = streamer.pivot_analyzer.check_breakout(price, open_price, vol_osc)
                        
                        # Phase FIB: Update MTF BEFORE generate_signal (so OHLCV cache is fresh)
                        ws_fib_context = None
                        if FIB_ENABLED:
                            try:
                                await mtf_confirmation.update_coin_trend(active_symbol, streamer.exchange)
                                # Build fib_context from cached MTF data
                                trend_data = mtf_confirmation.coin_trends.get(active_symbol, {})
                                if trend_data:
                                    # Determine signal_side from z-score direction
                                    # P2 fix: use direction, not hardcoded ¬±1.0 threshold
                                    z = metrics.get('zScore', 0)
                                    pre_side = 'LONG' if z < 0 else ('SHORT' if z > 0 else None)
                                    if pre_side:
                                        # P3 fix: get adx from trend_data (adx_4h), not metrics (has no adx)
                                        ws_adx = trend_data.get('adx_4h', 25)
                                        ws_fib_context = build_fib_context(
                                            signal_side=pre_side,
                                            price=price,
                                            atr=metrics['atr'],
                                            adx=ws_adx,
                                            hurst=metrics['hurst'],
                                            trend_data=trend_data
                                        )
                            except Exception as fib_err:
                                logger.debug(f"FIB context error: {fib_err}")
                        
                        signal = streamer.signal_generator.generate_signal(
                            hurst=metrics['hurst'],
                            zscore=metrics['zScore'],
                            imbalance=imbalance,
                            price=price,
                            atr=metrics['atr'],
                            vwap_zscore=metrics.get('vwap_zscore', 0),
                            htf_trend=getattr(streamer, 'last_htf_trend', "NEUTRAL"),
                            leverage=getattr(streamer.signal_generator, 'leverage', 10), # Safe access
                            basis_pct=basis_pct, # NEW: Spot-Futures Spread
                            whale_zscore=whale_z, # NEW: Whale Sentiment
                            nearest_fvg=nearest_fvg, # NEW: SMC Filter
                            breakout=breakout, # NEW: Phase 11 Breakout
                            spread_pct=metrics.get('spreadPct', 0.05), # Phase 13
                            volatility_ratio=metrics.get('volatilityRatio', 1.0), # Phase 13
                            coin_profile=streamer.coin_profile,  # Phase 28: Dynamic optimization
                            fib_context=ws_fib_context  # Phase FIB: Fibonacci context
                        )
                        
                        # =====================================================
                        # PHASE 63: Cloud Scanner Parity - Real MTF Confirmation
                        # Uses same algorithm as Cloud Scanner for consistency
                        # =====================================================
                        if signal:
                            action = signal['action']
                            atr = metrics['atr']
                            hurst = metrics['hurst']
                            spread_pct = metrics.get('spreadPct', 0.05)
                            
                            # Phase 230B: Add coin data for BTC filter multi-factor override
                            # Source: ws_ticker has 'percentage' (24h change) and 'quoteVolume' (24h USD volume)
                            signal['priceChange24h'] = ticker.get('percentage', 0)
                            signal['volume24h'] = ticker.get('quoteVolume', 0)
                            
                            # Update MTF trends using real OHLCV data (Cloud Scanner parity)
                            # NOTE: If FIB_ENABLED, this was already called above ‚Äî cache TTL prevents re-fetch
                            try:
                                await mtf_confirmation.update_coin_trend(active_symbol, streamer.exchange)
                            except Exception as mtf_update_err:
                                logger.warning(f"MTF trend update error: {mtf_update_err}")
                            
                            # Get MTF confirmation using Cloud Scanner's scoring system
                            mtf_result = mtf_confirmation.confirm_signal(active_symbol, action)
                            mtf_score = mtf_result.get('mtf_score', 0)
                            mtf_confirmed = mtf_result.get('confirmed', False)
                            score_modifier = mtf_result.get('score_modifier', 1.0)
                            
                            # Log MTF result (Cloud Scanner parity)
                            if score_modifier > 1.0:
                                logger.info(f"‚úÖ MTF BONUS: {action} {active_symbol} (skor: +{mtf_score}) - pozisyon +%10 b√ºy√ºk")
                            elif score_modifier < 1.0 and mtf_confirmed:
                                logger.info(f"‚ö†Ô∏è MTF PENALTY: {action} {active_symbol} (skor: {mtf_score}) - pozisyon -%20 k√º√ß√ºk")
                            
                            if not mtf_confirmed:
                                logger.info(f"üö´ MTF RED: {action} {active_symbol} (skor: {mtf_score}) - sinyal reddedildi")
                                signal = None
                            else:
                                # Add MTF size modifier to signal
                                signal['mtf_size_modifier'] = score_modifier
                                signal['mtf_score'] = mtf_score
                                
                                # =====================================================
                                # DYNAMIC LEVERAGE (Cloud Scanner Parity)
                                # Calculate leverage based on MTF + PRICE + SPREAD + VOLATILITY
                                # =====================================================
                                try:
                                    import math
                                    
                                    # Calculate TF count from scores (positive score = aligned)
                                    scores = mtf_result.get('scores', {'15m': 0, '1h': 0, '4h': 0, '1d': 0})
                                    tf_count = sum(1 for s in scores.values() if s > 0)
                                    
                                    # Base leverage from MTF agreement
                                    if tf_count >= 4:
                                        base_leverage = 100  # All 4 TFs aligned
                                    elif tf_count >= 3:
                                        base_leverage = 75   # 3 TFs aligned
                                    elif tf_count >= 2:
                                        base_leverage = 50   # 2 TFs aligned
                                    else:
                                        base_leverage = 25   # 0-1 TF aligned
                                    
                                    # PRICE FACTOR: Logarithmic reduction for low-price coins
                                    if price > 0:
                                        log_price = math.log10(max(price, 0.0001))
                                        price_factor = max(0.3, min(1.0, (log_price + 2) / 4))
                                    else:
                                        price_factor = 1.0
                                    
                                    # SPREAD FACTOR: High spread = lower leverage
                                    if spread_pct > 0:
                                        spread_factor = max(0.5, 1.0 - spread_pct * 2)
                                    else:
                                        spread_factor = 1.0
                                    
                                    # VOLATILITY FACTOR: High ATR = lower leverage
                                    volatility_pct = (atr / price * 100) if price > 0 and atr > 0 else 2.0
                                    if volatility_pct <= 2.0:
                                        volatility_factor = 1.0
                                    elif volatility_pct <= 4.0:
                                        volatility_factor = 0.8
                                    elif volatility_pct <= 6.0:
                                        volatility_factor = 0.6
                                    elif volatility_pct <= 10.0:
                                        volatility_factor = 0.4
                                    else:
                                        volatility_factor = 0.3
                                    
                                    # COMBINED LEVERAGE:
                                    # backend selector output (MTF+price+spread+volatility) √ó user multiplier (Settings modal)
                                    base_dynamic_leverage = base_leverage * price_factor * spread_factor * volatility_factor
                                    user_lev_mult = (
                                        getattr(global_paper_trader, 'leverage_multiplier', 1.0)
                                        if 'global_paper_trader' in globals() else 1.0
                                    )
                                    dynamic_leverage = int(round(base_dynamic_leverage * user_lev_mult))
                                    dynamic_leverage = max(3, min(75, dynamic_leverage))
                                    
                                    signal['leverage'] = dynamic_leverage
                                    signal['leverage_includes_user_mult'] = True
                                    signal['leverage_user_mult'] = round(user_lev_mult, 2)
                                    signal['baseLeverage'] = max(3, min(75, int(round(base_dynamic_leverage))))
                                    signal['tf_count'] = tf_count
                                    signal['price_factor'] = round(price_factor, 2)
                                    signal['spread_factor'] = round(spread_factor, 2)
                                    signal['volatility_factor'] = round(volatility_factor, 2)
                                    signal['volatility_pct'] = round(volatility_pct, 2)
                                    
                                    # Log if any factor reduced leverage
                                    if price_factor < 0.9 or spread_factor < 0.9 or volatility_factor < 0.9 or user_lev_mult != 1.0:
                                        logger.info(
                                            f"üìä Leverage: base={base_leverage}x √ó price={price_factor:.2f} √ó spread={spread_factor:.2f} √ó vol={volatility_factor:.2f} √ó user={user_lev_mult:.1f} "
                                            f"‚Üí {dynamic_leverage}x | {active_symbol} @ ${price:.6f} (ATR:{volatility_pct:.1f}%)"
                                        )
                                    else:
                                        logger.info(f"üìä Dynamic Leverage: {dynamic_leverage}x (TF:{tf_count}/3)")
                                except Exception as lev_err:
                                    logger.warning(f"Dynamic leverage error: {lev_err}")
                                    user_lev_mult = (
                                        getattr(global_paper_trader, 'leverage_multiplier', 1.0)
                                        if 'global_paper_trader' in globals() else 1.0
                                    )
                                    signal['leverage'] = max(3, min(75, int(round(25 * user_lev_mult))))
                                    signal['leverage_includes_user_mult'] = True
                                    signal['leverage_user_mult'] = round(user_lev_mult, 2)
                                
                                # =====================================================
                                # VOLUME PROFILE BOOST (Cloud Scanner Parity)
                                # Uses per-coin volume profiler
                                # =====================================================
                                try:
                                    # Get or create per-coin volume profiler
                                    if active_symbol not in coin_volume_profiles:
                                        coin_volume_profiles[active_symbol] = VolumeProfileAnalyzer()
                                    
                                    coin_vp = coin_volume_profiles[active_symbol]
                                    
                                    # Update volume profile if stale (every hour)
                                    if datetime.now().timestamp() - coin_vp.last_update > 3600:
                                        ohlcv_4h = await streamer.exchange.fetch_ohlcv(ccxt_symbol, '4h', limit=100)
                                        if ohlcv_4h:
                                            coin_vp.calculate_profile(ohlcv_4h)
                                            logger.debug(f"Updated VP for {active_symbol}: POC={coin_vp.poc:.6f}")
                                    
                                    # Get boost based on price proximity to key levels
                                    vp_boost = coin_vp.get_signal_boost(price, action)
                                    if vp_boost > 0:
                                        signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + vp_boost)
                                        signal['vp_boost'] = vp_boost
                                        logger.info(f"üìà VP BOOST: {active_symbol} +{vp_boost*100:.0f}% @ POC={coin_vp.poc:.6f}")
                                except Exception as vp_err:
                                    logger.warning(f"Volume Profile error: {vp_err}")
                                
                                # =====================================================
                                # DYNAMIC TRAIL PARAMETERS (Cloud Scanner Parity)
                                # Calculate trail_activation and trail_distance per-coin
                                # =====================================================
                                try:
                                    volatility_pct = signal.get('volatility_pct', (atr / price * 100) if price > 0 else 3.0)
                                    
                                    # Calculate dynamic trail params
                                    trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
                                        volatility_pct=volatility_pct,
                                        hurst=hurst,
                                        price=price,
                                        spread_pct=spread_pct,
                                        settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
                                        settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
                                    )
                                    
                                    signal['dynamic_trail_activation'] = trail_activation_atr
                                    signal['dynamic_trail_distance'] = trail_distance_atr
                                    signal['hurst'] = hurst
                                    signal['spreadPct'] = spread_pct
                                    
                                    # Log if significantly different from defaults (1.5, 1.0)
                                    if abs(trail_activation_atr - 1.5) > 0.3 or abs(trail_distance_atr - 1.0) > 0.2:
                                        logger.info(f"üéØ Dynamic Trail: act={trail_activation_atr}x, dist={trail_distance_atr}x | {active_symbol} (vol:{volatility_pct:.1f}%, hurst:{hurst:.2f})")
                                except Exception as trail_err:
                                    logger.debug(f"Dynamic trail params error: {trail_err}")
                                
                                # =====================================================
                                # BTC CORRELATION FILTER
                                # =====================================================
                                try:
                                    await btc_filter.update_btc_state(streamer.exchange)
                                    btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
                                        active_symbol, signal['action'],
                                        coin_change_pct=signal.get('priceChange24h', 0),
                                        volume_24h=signal.get('volume24h', 0),
                                        zscore=signal.get('zscore', 0),
                                        spread_pct=signal.get('spreadPct', 0)
                                    )
                                    
                                    if not btc_allowed:
                                        logger.info(f"BTC FILTER BLOCKED: {btc_reason}")
                                        signal = None
                                    elif btc_penalty != 0:
                                        signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 - btc_penalty)
                                        signal['btc_adjustment'] = btc_reason
                                        logger.info(f"BTC ADJUSTMENT: {btc_reason} | Size: {signal.get('sizeMultiplier', 1.0):.2f}x")
                                        # Phase 230B: Override risk caps
                                        if btc_filter.last_override:
                                            signal['overrideLeverageCap'] = 3
                                            signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), 0.5)
                                            logger.info(f"üí™ WS OVERRIDE CAPS: {active_symbol} | leverage‚â§3x, size‚â§0.5x")
                                except Exception as btc_err:
                                    logger.warning(f"BTC Filter error: {btc_err}")
                                
                                # Execute trade if signal still valid
                                if signal:
                                    trends = mtf_result.get('trends', {})
                                    logger.info(f"ü§ñ WS-Trade: {action} {active_symbol} @ ${price:.4f} | MTF:{mtf_score} | Lev:{signal.get('leverage', 50)}x | 15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}")
                                    
                                    try:
                                        if hasattr(streamer, 'paper_trader') and streamer.paper_trader:
                                            streamer.paper_trader.current_spread_pct = spread_pct
                                            streamer.paper_trader.on_signal(signal, price)
                                    except Exception as pt_err:
                                        logger.error(f"Paper Trading Error: {pt_err}")
                                    
                                    manager.last_signals[symbol] = signal
                                    logger.info(f"SIGNAL GENERATED: {signal['action']} @ {price}")

                    except Exception as e:
                        logger.error(f"Signal Generation Error: {e}")
                        # Ensure variables used below are at least defined if they fail
                        whale_z = 0
                        breakout = None
                    
                    # Use WhaleZ in metrics display if desired
                    metrics['whale_z'] = round(whale_z, 2)
                    
                    # Get pending liquidation
                    liquidation = streamer.pending_liquidation
                    streamer.pending_liquidation = None
                    
                    # Convert deques to lists for JSON serialization
                    active_supports = list(streamer.pivot_analyzer.supports)
                    active_resistances = list(streamer.pivot_analyzer.resistances)
                    
                    response = {
                        "type": "update",
                        "price": price,
                        "spotPrice": spot_price, # NEW
                        "basis": round(basis, 2), # NEW
                        "basisPercent": round(basis_pct, 4), # NEW
                        "metrics": metrics,
                        "orderBook": {
                            "bids": bids,
                            "asks": asks,
                            "imbalance": round(imbalance, 2)
                        },
                        "liquidation": liquidation,
                        "signal": signal,
                        "smc": { # NEW Phase 10
                            "fvgs": streamer.smc_analyzer.fvgs,
                            "structure": streamer.smc_analyzer.structure
                        },
                        "pivots": { # NEW Phase 11
                            "supports": active_supports,
                            "resistances": active_resistances,
                            "breakout": breakout
                        },
                        "portfolio": { # Phase 15: Cloud Portfolio
                            "balance": streamer.paper_trader.balance if hasattr(streamer, 'paper_trader') else 10000,
                            "positions": streamer.paper_trader.positions if hasattr(streamer, 'paper_trader') else [],
                            "stats": streamer.paper_trader.stats if hasattr(streamer, 'paper_trader') else {},
                            "equityCurve": streamer.paper_trader.equity_curve[-100:] if hasattr(streamer, 'paper_trader') else [],
                            # Phase 21: Live updates
                            "trades": streamer.paper_trader.trades[-20:] if hasattr(streamer, 'paper_trader') else [],
                            "logs": streamer.paper_trader.logs[-30:] if hasattr(streamer, 'paper_trader') else [],
                            "cloudSymbol": streamer.paper_trader.symbol if hasattr(streamer, 'paper_trader') else "UNKNOWN"
                        }
                    }
                    
                    await websocket.send_json(response)
                    
                await asyncio.sleep(1.0)  # Slow down main loop
                
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.error(f"Stream error: {e}")
                await asyncio.sleep(2)
                
    except WebSocketDisconnect:
        logger.info("Client disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await streamer.disconnect()


# ============================================================================
# BACKTEST ENGINE
# ============================================================================

from pydantic import BaseModel
from typing import List
import ccxt as ccxt_sync

class BacktestRequest(BaseModel):
    symbol: str = "BTCUSDT"
    timeframe: str = "1h"
    startDate: str = "2025-12-01"
    endDate: str = "2025-12-31"
    initialBalance: float = 10000
    leverage: int = 10
    riskPerTrade: float = 2

class BacktestTrade(BaseModel):
    id: str
    side: str
    entryPrice: float
    exitPrice: float
    entryTime: int
    exitTime: int
    pnl: float
    pnlPercent: float
    closeReason: str

class BacktestResult(BaseModel):
    trades: List[dict]
    equityCurve: List[dict]
    priceData: List[dict]
    stats: dict


def run_backtest_simulation(
    ohlcv_data: list,
    initial_balance: float,
    leverage: int,
    risk_per_trade: float
) -> tuple:
    """
    Run backtest simulation on historical OHLCV data.
    Returns (trades, equity_curve, stats)
    """
    trades = []
    equity_curve = []
    balance = initial_balance
    position = None
    pending_order = None
    
    # Data storage for calculations
    prices = []
    highs = []
    lows = []
    closes = []
    spreads = []
    
    peak_balance = initial_balance
    max_drawdown = 0
    
    for i, candle in enumerate(ohlcv_data):
        timestamp, open_p, high, low, close, volume = candle
        
        prices.append(close)
        highs.append(high)
        lows.append(low)
        closes.append(close)
        
        # 0. Check Pending Order (Limit Entry)
        if pending_order:
            # Expiry check (1 candle max wait ~ 1h, though user said 15m)
            # Since we only have 1H bars, if it doesn't fill in this candle (the one after signal), we cancel.
            if timestamp - pending_order['timestamp'] > 3600 * 2: # Give it 2 candles grace? No, strictly 1.
                 pending_order = None
            else:
                 # Try to fill
                 filled = False
                 if pending_order['side'] == 'LONG':
                     if low <= pending_order['entryPrice']:
                         filled = True
                 else: # SHORT
                     if high >= pending_order['entryPrice']:
                         filled = True
                 
                 if filled:
                     entry_price = pending_order['entryPrice']
                     risk_amt = balance * (risk_per_trade / 100)
                     size_usd = risk_amt * leverage * pending_order['sizeMultiplier']
                     size_token = size_usd / entry_price
                     
                     position = {
                        'side': pending_order['side'],
                        'entryPrice': entry_price,
                        'size': size_token,
                        'sizeUsd': size_usd,
                        'sl': pending_order['sl'],
                        'tp': pending_order['tp'],
                        'trailActivation': pending_order['trailActivation'],
                        'trailDistance': pending_order['trailDistance'],
                        'isTrailingActive': False,
                        'trailingStop': pending_order['sl'],
                        'entryTime': timestamp,
                        'slMoved': False, # For Breakeven Logic
                        'initialSL': pending_order['sl'],
                        'max_r': 0.0
                    }
                     pending_order = None # Consumed
        
        # Need at least 50 candles for calculations
        if len(prices) < 50:
            equity_curve.append({
                "time": timestamp,
                "balance": balance,
                "price": close
            })
            continue
        
        # Calculate spread
        ma = np.mean(prices[-20:])
        spread = close - ma
        spreads.append(spread)
        
        # Calculate metrics
        hurst = calculate_hurst(prices[-100:] if len(prices) >= 100 else prices)
        zscore = calculate_zscore(spreads) if len(spreads) >= 20 else 0
        atr = calculate_atr(highs[-30:], lows[-30:], closes[-30:])
        
        # Simulate order book imbalance (correlated with Z-Score for mean-reversion)
        # When Z-Score high (overbought), OB tends negative (selling pressure)
        np.random.seed(int(timestamp) % 10000)
        noise = np.random.uniform(-15, 15)
        imbalance = -zscore * 5 + noise  # Negative correlation with Z-Score
        imbalance = max(-40, min(40, imbalance))
        
        # Simulated Backtest Inputs for Parity
        # 1. VWAP Simulation
        # Since we have Volume in backtest data, we can calculate real VWAP
        # But our `prices` list doesn't store volume history in this simplified engine
        # So we'll use a simplified approximation or mock it.
        # Ideally we refactor engine to store volumes, but for now let's approximate:
        # If High Volume + Price Move -> VWAP confirms
        # For simulation parity, we'll use the Z-Score correlation method again
        # Negative correlation: Price High -> VWAP usually lags -> VWAP Z-Score High
        vwap_zscore = zscore * 0.8  # High correlation assumption
        
        # 2. HTF Trend Simulation
        # Taking 1H data, we can approximate 4H trend by looking at last 4 hours
        if len(prices) >= 4:
            p4 = prices[-4:]
            if p4[-1] > p4[0]: htf_trend = "BULLISH"
            else: htf_trend = "BEARISH"
        else:
            htf_trend = "NEUTRAL"
            
        # 3. Use REAL SignalGenerator (Parity)
        # We need to instantiate it once outside loop, but for now let's use a fresh one 
        # or better, pass one in. For simplicity in this function script:
        # We'll just instantiate. Note: state like 'last_signal_time' resets every loop if we do this
        # SO WE MUST instantiate outside loop.
        
        # ... Wait, we can't instantiate inside loop or state is lost.
        # Moving instantiation to top of function (done in next step logic if needed, 
        # but here we'll assume 'generator' is available or create a lightweight version)
        
        # Actually, let's just interpret the logic here to match EXACTLY or use the class.
        # Using the class is best.
        if 'generator' not in locals():
            generator = SignalGenerator()
            generator.min_signal_interval = 0 # Disable time check for backtest 1H candles
        
        # Phase 29: Simulate spread based on volatility
        # Higher volatility = higher spread (realistic simulation)
        volatility = atr / close * 100 if close > 0 else 1.0
        simulated_spread_pct = 0.02 + (volatility * 0.03)  # Base 0.02% + volatility adjustment
        simulated_spread_pct = min(0.5, simulated_spread_pct)  # Cap at 0.5%
        
        # Volatility ratio simulation
        volatility_ratio = volatility / 2.0 if volatility > 0 else 1.0  # Normalized to ~1.0
        
        # Create simulated coin profile for backtest
        # Phase 29: More aggressive parameters for DOGE backtest
        coin_profile = {
            'symbol': 'backtest',
            'optimal_threshold': 0.5,  # Very aggressive threshold for DOGE (Z > 0.5)
            'min_score': 40,  # Lower minimum for more signals in backtest
            'avg_atr_pct': volatility,
            'sl_atr': 2.0,
            'tp_atr': 3.0,
            'is_backtest': True  # Flag to skip adaptive threshold
        }
            
        signal_dict = generator.generate_signal(
            hurst=hurst,
            zscore=zscore,
            imbalance=imbalance,
            price=close,
            atr=atr,
            vwap_zscore=vwap_zscore,
            htf_trend=htf_trend,
            leverage=leverage,
            basis_pct=0.0,  # Backtest doesn't support Spot/Basis yet
            whale_zscore=0.0,  # Backtest doesn't support Whale Flow yet
            spread_pct=simulated_spread_pct,  # Phase 29: Spread simulation
            volatility_ratio=volatility_ratio,  # Phase 29: Volatility ratio
            coin_profile=coin_profile  # Phase 29: Coin profile
        )
        

        
        # Check existing position for SL/TP
        if position:
            if position['side'] == 'LONG':
                unrealized_pnl = (close - position['entryPrice']) * position['size']
                curr_pnl_pct = (unrealized_pnl / position['sizeUsd']) * 100 * leverage
                
                # 1. RESCUE MISSION (Stale Position)
                duration = timestamp - position['entryTime']
                if duration >= 3600 and unrealized_pnl < 0:
                     if high >= position['entryPrice']:
                         # Rescue!
                         exit_price = position['entryPrice']
                         pnl = 0
                         balance += pnl
                         trades.append({
                            'id': str(len(trades)), 'side': 'LONG', 'entryPrice': position['entryPrice'],
                            'exitPrice': exit_price, 'entryTime': position['entryTime'], 'exitTime': timestamp,
                            'pnl': 0, 'pnlPercent': 0, 'closeReason': 'RESCUE'
                         })
                         position = None
                         continue

                # 2. STEP TRAILING LOGIC (R-Based Risk Management)
                # Calculates R (Risk Unit) and trails Stop Loss based on profit milestones
                
                initial_risk = abs(position['entryPrice'] - position['initialSL'])
                if initial_risk == 0: initial_risk = position['entryPrice'] * 0.01 # Fallback to 1%

                # Calculate Max Price reached during this candle (Potential Max R)
                # Long: High, Short: Low
                if position['side'] == 'LONG':
                    # Check if SL hit first intra-candle?
                    # Worst case assumption: We check SL hit based on Low first (handled in Exits below)
                    # Here we update SL for NEXT candle based on High
                    current_r = (high - position['entryPrice']) / initial_risk
                else:
                    current_r = (position['entryPrice'] - low) / initial_risk

                # Update Max R Reached
                position['max_r'] = max(position.get('max_r', 0), current_r)
                
                # Apply Step Logic
                new_sl = position['sl']
                if position['side'] == 'LONG':
                    if position['max_r'] >= 4.0:
                        # Trail 2.5R locked (Trails 1.5R behind)
                        target_sl = position['entryPrice'] + (2.5 * initial_risk)
                        # Continuous trail above 4R: Entry + (MaxR - 1.5) * R
                        continuous_sl = position['entryPrice'] + (position['max_r'] - 1.5) * initial_risk
                        target_sl = max(target_sl, continuous_sl)
                        new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 3.0:
                         # Level 3: Lock 1.5R
                         target_sl = position['entryPrice'] + (1.5 * initial_risk)
                         new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 2.0:
                         # Level 2: Lock 0.5R
                         target_sl = position['entryPrice'] + (0.5 * initial_risk)
                         new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 1.0:
                         # Level 1: Breakeven
                         new_sl = max(new_sl, position['entryPrice'])
                else: # SHORT
                    if position['max_r'] >= 4.0:
                        target_sl = position['entryPrice'] - (2.5 * initial_risk)
                        continuous_sl = position['entryPrice'] - (position['max_r'] - 1.5) * initial_risk
                        target_sl = min(target_sl, continuous_sl)
                        new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 3.0:
                         target_sl = position['entryPrice'] - (1.5 * initial_risk)
                         new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 2.0:
                         target_sl = position['entryPrice'] - (0.5 * initial_risk)
                         new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 1.0:
                         new_sl = min(new_sl, position['entryPrice'])

                position['sl'] = new_sl
                # We disable 'trailingStop' logic from pending order to avoid conflict
                position['isTrailingActive'] = True # Mark as active so effective_sl uses this?
                # Actually below we use 'trailingStop' if 'isTrailingActive' is True.
                # Let's map 'sl' to 'trailingStop' seamlessly
                position['trailingStop'] = new_sl
                
                # Check exits
                effective_sl = position['trailingStop'] if position['isTrailingActive'] else position['sl']
                if low <= effective_sl:
                    exit_price = effective_sl
                    pnl = (exit_price - position['entryPrice']) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'LONG',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TRAILING' if position['isTrailingActive'] else 'SL'
                    })
                    position = None
                elif high >= position['tp']:
                    exit_price = position['tp']
                    pnl = (exit_price - position['entryPrice']) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'LONG',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TP'
                    })
                    position = None
                # Check scaling out (Simulated) - simplified for backtest
                
            else:  # SHORT
                unrealized_pnl = (position['entryPrice'] - close) * position['size']
                curr_pnl_pct = (unrealized_pnl / position['sizeUsd']) * 100 * leverage
                
                # 1. RESCUE MISSION
                duration = timestamp - position['entryTime']
                if duration >= 3600 and unrealized_pnl < 0:
                     if low <= position['entryPrice']:
                         exit_price = position['entryPrice']
                         pnl = 0
                         balance += pnl
                         trades.append({
                            'id': str(len(trades)), 'side': 'SHORT', 'entryPrice': position['entryPrice'],
                            'exitPrice': exit_price, 'entryTime': position['entryTime'], 'exitTime': timestamp,
                            'pnl': 0, 'pnlPercent': 0, 'closeReason': 'RESCUE'
                         })
                         position = None
                         continue

                # 2. BREAKEVEN
                if curr_pnl_pct > 0.5 and not position.get('slMoved', False):
                    position['sl'] = position['entryPrice']
                    position['slMoved'] = True

                if close <= position['trailActivation'] and not position['isTrailingActive']:
                    position['isTrailingActive'] = True
                    position['trailingStop'] = close + position['trailDistance']
                if position['isTrailingActive'] and close + position['trailDistance'] < position['trailingStop']:
                    position['trailingStop'] = close + position['trailDistance']
                
                effective_sl = position['trailingStop'] if position['isTrailingActive'] else position['sl']
                if high >= effective_sl:
                    exit_price = effective_sl
                    pnl = (position['entryPrice'] - exit_price) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'SHORT',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TRAILING' if position['isTrailingActive'] else 'SL'
                    })
                    position = None
                elif low <= position['tp']:
                    exit_price = position['tp']
                    pnl = (position['entryPrice'] - exit_price) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'SHORT',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TP'
                    })
                    position = None
        
        # Open entry if no position
        # Open entry if no position
        elif signal_dict:
            # SignalGenerator returned a valid signal!
            action = signal_dict['action']
            
            # Create PENDING ORDER (Wait for Pullback Limit)
            # SignalGenerator now returns 'entryPrice' which is the Limit price
            limit_price = signal_dict.get('entryPrice', close) # Fallback to close if missing
            
            pending_order = {
                'side': action,
                'entryPrice': limit_price,
                'sl': signal_dict['sl'],
                'tp': signal_dict['tp'],
                'trailActivation': signal_dict['trailActivation'],
                'trailDistance': signal_dict['trailDistance'],
                'sizeMultiplier': signal_dict.get('sizeMultiplier', 1.0),
                'timestamp': timestamp # Signal time
            }
            # Position will be created in NEXT loop iteration if Limit fills
        

        
        # Update peak and drawdown
        if balance > peak_balance:
            peak_balance = balance
        current_dd = ((peak_balance - balance) / peak_balance) * 100
        if current_dd > max_drawdown:
            max_drawdown = current_dd
        
        equity_curve.append({
            "time": timestamp,
            "balance": round(balance, 2),
            "price": close
        })
    
    # Close any remaining position at last price
    if position and ohlcv_data:
        last_close = ohlcv_data[-1][4]
        last_time = ohlcv_data[-1][0]
        if position['side'] == 'LONG':
            pnl = (last_close - position['entryPrice']) * position['size']
        else:
            pnl = (position['entryPrice'] - last_close) * position['size']
        balance += pnl
        trades.append({
            'id': str(len(trades)),
            'side': position['side'],
            'entryPrice': position['entryPrice'],
            'exitPrice': last_close,
            'entryTime': position['entryTime'],
            'exitTime': last_time,
            'pnl': round(pnl, 2),
            'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
            'closeReason': 'END'
        })
    
    # Calculate stats
    winning_trades = [t for t in trades if t['pnl'] > 0]
    losing_trades = [t for t in trades if t['pnl'] <= 0]
    total_wins = sum(t['pnl'] for t in winning_trades)
    total_losses = abs(sum(t['pnl'] for t in losing_trades))
    
    stats = {
        'totalTrades': len(trades),
        'winningTrades': len(winning_trades),
        'losingTrades': len(losing_trades),
        'winRate': round((len(winning_trades) / len(trades)) * 100, 2) if trades else 0,
        'totalPnl': round(balance - initial_balance, 2),
        'totalPnlPercent': round(((balance - initial_balance) / initial_balance) * 100, 2),
        'maxDrawdown': round(max_drawdown, 2),
        'profitFactor': round(total_wins / total_losses, 2) if total_losses > 0 else 999,
        'avgWin': round(total_wins / len(winning_trades), 2) if winning_trades else 0,
        'avgLoss': round(total_losses / len(losing_trades), 2) if losing_trades else 0,
        'finalBalance': round(balance, 2)
    }
    
    return trades, equity_curve, stats


@app.post("/backtest")
async def run_backtest(request: BacktestRequest):
    """
    Run backtest on historical data.
    """
    logger.info(f"Starting backtest for {request.symbol} from {request.startDate} to {request.endDate}")
    
    try:
        # Use synchronous CCXT for fetching historical data
        exchange = ccxt_sync.binance({
            'enableRateLimit': True,
            'options': {'defaultType': 'future'}
        })
        
        # Parse dates
        start_ts = int(datetime.strptime(request.startDate, "%Y-%m-%d").timestamp() * 1000)
        end_ts = int(datetime.strptime(request.endDate, "%Y-%m-%d").timestamp() * 1000)
        
        logger.info(f"Backtest Date Range: {request.startDate} ({start_ts}) to {request.endDate} ({end_ts})")
        
        # Fetch OHLCV data
        symbol = request.symbol.replace("USDT", "/USDT")
        all_ohlcv = []
        current_ts = start_ts
        
        while current_ts < end_ts:
            logger.info(f"Fetching from {current_ts}...")
            ohlcv = exchange.fetch_ohlcv(symbol, request.timeframe, since=current_ts, limit=1000)
            if not ohlcv:
                logger.warning("No data returned from fetch_ohlcv")
                break
            
            logger.info(f"Fetched {len(ohlcv)} candles. First: {ohlcv[0][0]}, Last: {ohlcv[-1][0]}")
            all_ohlcv.extend(ohlcv)
            current_ts = ohlcv[-1][0] + 1
            if len(ohlcv) < 1000:
                break
        
        # Filter to date range
        all_ohlcv = [c for c in all_ohlcv if start_ts <= c[0] <= end_ts]
        
        logger.info(f"Total candles after filter: {len(all_ohlcv)}")
        
        # Run simulation
        trades, equity_curve, stats = run_backtest_simulation(
            all_ohlcv,
            request.initialBalance,
            request.leverage,
            request.riskPerTrade
        )
        
        # Format price data for chart
        price_data = [
            {
                "time": c[0],
                "open": c[1],
                "high": c[2],
                "low": c[3],
                "close": c[4],
                "volume": c[5]
            }
            for c in all_ohlcv[::max(1, len(all_ohlcv)//500)]  # Limit to 500 points
        ]
        
        logger.info(f"Backtest complete: {stats['totalTrades']} trades, {stats['winRate']}% win rate")
        
        return {
            "trades": trades,
            "equityCurve": equity_curve[::max(1, len(equity_curve)//500)],
            "priceData": price_data,
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"Backtest error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("Starting HHQ-1 Quant Backend v2.0...")
    logger.info("WebSocket endpoint: ws://localhost:8000/ws?symbol=BTCUSDT")
    logger.info("Backtest endpoint: POST http://localhost:8000/backtest")
    logger.info("Health check: http://localhost:8000/health")
    logger.info("Features: ATR, Liquidation Stream, 4-Layer Signal, Backtest")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
