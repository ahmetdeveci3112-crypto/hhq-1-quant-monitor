"""
HHQ-1 Quant Monitor - Python Backend v2.0
==========================================
FastAPI WebSocket server for real-time algorithmic trading analysis.

Features:
- Binance WebSocket data streaming via CCXT
- Hurst Exponent calculation (R/S Analysis)
- Z-Score calculation for pairs trading
- ATR calculation for volatility-based risk management
- Order Book imbalance analysis
- Liquidation cascade detection
- 4-Layer signal generation
"""

import asyncio
import json
import logging
import math
import os
import time
import websockets
from collections import deque
from datetime import datetime, timedelta
from typing import Optional, Dict, Any

import ccxt.async_support as ccxt_async
import ccxt as ccxt_sync
import numpy as np
import pandas as pd
import pytz
from contextlib import asynccontextmanager
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Phase 193: pandas-ta for enhanced technical indicators
try:
    import pandas_ta as pta
    PANDAS_TA_AVAILABLE = True
    logger.info("âœ… pandas-ta loaded successfully")
except ImportError:
    PANDAS_TA_AVAILABLE = False
    logger.warning("âš ï¸ pandas-ta not installed, using manual TA calculations")

# Phase 193: Import new modules (graceful fallback)
try:
    from ccxt_ws_manager import ccxt_ws_manager
    logger.info("âœ… ccxt_ws_manager loaded")
except ImportError:
    ccxt_ws_manager = None
    logger.warning("âš ï¸ ccxt_ws_manager not available")

try:
    from freqai_adapter import freqai_model
    logger.info("âœ… freqai_adapter loaded")
except ImportError:
    freqai_model = None
    logger.warning("âš ï¸ freqai_adapter not available")

try:
    from hyperopt import hhq_hyperoptimizer
    logger.info("âœ… hyperopt loaded")
except ImportError:
    hhq_hyperoptimizer = None
    logger.warning("âš ï¸ hyperopt not available")

# ============================================================================
# SQLITE DATABASE MANAGER
# ============================================================================
import aiosqlite

class SQLiteManager:
    """
    Async SQLite database manager for persistent storage.
    Stores trades, settings, and logs in a SQLite database.
    """
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            if os.path.exists("/data"):
                db_path = "/data/trading.db"
                logger.info("ðŸ“ Using persistent SQLite: /data/trading.db")
            else:
                db_path = "trading.db"
                logger.info("ðŸ“ Using local SQLite: trading.db")
        self.db_path = db_path
        self._initialized = False
    
    async def init_db(self):
        """Initialize database tables."""
        if self._initialized:
            return
        
        async with aiosqlite.connect(self.db_path) as db:
            # Trades table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS trades (
                    id TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    exit_price REAL,
                    size REAL NOT NULL,
                    size_usd REAL NOT NULL,
                    pnl REAL,
                    pnl_percent REAL,
                    open_time INTEGER NOT NULL,
                    close_time INTEGER,
                    close_reason TEXT,
                    leverage INTEGER DEFAULT 10,
                    signal_score INTEGER DEFAULT 0,
                    mtf_score INTEGER DEFAULT 0,
                    z_score REAL DEFAULT 0,
                    spread_level TEXT DEFAULT 'unknown',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Settings table (key-value)
            await db.execute('''
                CREATE TABLE IF NOT EXISTS settings (
                    key TEXT PRIMARY KEY,
                    value TEXT NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Logs table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    time TEXT NOT NULL,
                    message TEXT NOT NULL,
                    ts INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Equity curve table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS equity_curve (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    time INTEGER NOT NULL,
                    balance REAL NOT NULL,
                    drawdown REAL NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Coin stats table (for blacklist system)
            await db.execute('''
                CREATE TABLE IF NOT EXISTS coin_stats (
                    symbol TEXT PRIMARY KEY,
                    wins INTEGER DEFAULT 0,
                    losses INTEGER DEFAULT 0,
                    consecutive_losses INTEGER DEFAULT 0,
                    consecutive_wins INTEGER DEFAULT 0,
                    total_pnl REAL DEFAULT 0,
                    last_trade_time REAL DEFAULT 0,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Signals table - ALL signals (accepted AND rejected) for performance analysis
            await db.execute('''
                CREATE TABLE IF NOT EXISTS signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    action TEXT NOT NULL,
                    price REAL NOT NULL,
                    zscore REAL,
                    hurst REAL,
                    atr REAL,
                    signal_score INTEGER,
                    htf_trend TEXT,
                    mtf_confirmed INTEGER,
                    mtf_reason TEXT,
                    blacklisted INTEGER DEFAULT 0,
                    accepted INTEGER DEFAULT 0,
                    reject_reason TEXT,
                    z_threshold REAL,
                    min_confidence REAL,
                    entry_tightness REAL,
                    exit_tightness REAL,
                    timestamp INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Open positions table - tracks positions while open
            await db.execute('''
                CREATE TABLE IF NOT EXISTS positions (
                    id TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    size REAL NOT NULL,
                    size_usd REAL NOT NULL,
                    stop_loss REAL,
                    take_profit REAL,
                    leverage INTEGER,
                    open_time INTEGER NOT NULL,
                    signal_score INTEGER,
                    zscore REAL,
                    hurst REAL,
                    atr REAL,
                    htf_trend TEXT,
                    status TEXT DEFAULT 'OPEN',
                    close_time INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Migrate: add close_time column if missing
            try:
                await db.execute('ALTER TABLE positions ADD COLUMN close_time INTEGER')
                logger.info("ðŸ“‚ Added close_time column to positions table")
            except:
                pass  # Column already exists
            
            # Binance trade history - her realized PnL income kaydÄ±
            await db.execute('''
                CREATE TABLE IF NOT EXISTS binance_trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    income_id TEXT UNIQUE,
                    symbol TEXT NOT NULL,
                    side TEXT,
                    entry_price REAL,
                    exit_price REAL,
                    pnl REAL NOT NULL,
                    pnl_percent REAL,
                    margin REAL,
                    leverage INTEGER,
                    size_usd REAL,
                    close_reason TEXT,
                    close_time INTEGER NOT NULL,
                    raw_data TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Position close events - her pozisyon kapatma kaydÄ±
            await db.execute('''
                CREATE TABLE IF NOT EXISTS position_closes (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    reason TEXT NOT NULL,
                    original_reason TEXT,
                    entry_price REAL,
                    exit_price REAL,
                    pnl REAL,
                    leverage INTEGER,
                    size_usd REAL,
                    margin REAL,
                    roi REAL,
                    timestamp INTEGER NOT NULL,
                    matched_to_income INTEGER DEFAULT 0,
                    mae_pct REAL DEFAULT 0,
                    mfe_pct REAL DEFAULT 0,
                    decision_trace TEXT DEFAULT '[]',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Leverage cache - pozisyon leverage bilgilerini sakla
            await db.execute('''
                CREATE TABLE IF NOT EXISTS leverage_cache (
                    symbol TEXT PRIMARY KEY,
                    leverage INTEGER NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Phase 154: Breakeven states - survive deploy/restart
            await db.execute('''
                CREATE TABLE IF NOT EXISTS breakeven_states (
                    state_key TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    side TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    activation_price REAL NOT NULL,
                    activation_time TEXT NOT NULL,
                    spread_level TEXT DEFAULT 'Normal',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await db.commit()
            
            # Phase 49: Migration - Add new columns to trades table if they don't exist
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN signal_score INTEGER DEFAULT 0')
            except:
                pass  # Column already exists
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN mtf_score INTEGER DEFAULT 0')
            except:
                pass
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN z_score REAL DEFAULT 0')
            except:
                pass
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN spread_level TEXT DEFAULT "unknown"')
            except:
                pass
            # Phase 155: AI Optimizer â€” settings snapshot per trade
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN settings_snapshot TEXT DEFAULT "{}"')
            except:
                pass
            
            # Phase 186: Comprehensive trade data persistence â€” all missing columns
            migration_columns = [
                ('stop_loss', 'REAL DEFAULT 0'),
                ('take_profit', 'REAL DEFAULT 0'),
                ('atr', 'REAL DEFAULT 0'),
                ('trailing_stop', 'REAL DEFAULT 0'),
                ('trail_activation', 'REAL DEFAULT 0'),
                ('is_trailing_active', 'INTEGER DEFAULT 0'),
                ('margin', 'REAL DEFAULT 0'),
                ('roi', 'REAL DEFAULT 0'),
                ('is_live', 'INTEGER DEFAULT 0'),
                ('entry_method', 'TEXT DEFAULT "MARKET"'),
                ('entry_slippage', 'REAL DEFAULT 0'),
                ('entry_spread', 'REAL DEFAULT 0'),
                ('binance_fill_price', 'REAL DEFAULT 0'),
                ('binance_order_id', 'TEXT'),
                ('hurst', 'REAL DEFAULT 0.5'),
                ('adx', 'REAL DEFAULT 0'),
                ('pullback_pct', 'REAL DEFAULT 0'),
                # Phase 232: Close metrics snapshot
                ('close_metrics_json', 'TEXT DEFAULT "{}"'),
            ]
            for col_name, col_type in migration_columns:
                try:
                    await db.execute(f'ALTER TABLE trades ADD COLUMN {col_name} {col_type}')
                except:
                    pass  # Column already exists
            
            # Phase 187: position_closes needs settings data too
            pc_migration_columns = [
                ('stop_loss', 'REAL DEFAULT 0'),
                ('take_profit', 'REAL DEFAULT 0'),
                ('atr', 'REAL DEFAULT 0'),
                ('trailing_stop', 'REAL DEFAULT 0'),
                ('trail_activation', 'REAL DEFAULT 0'),
                ('settings_snapshot', 'TEXT DEFAULT "{}"'),
                ('entry_method', 'TEXT DEFAULT "MARKET"'),
                ('entry_slippage', 'REAL DEFAULT 0'),
                ('entry_spread', 'REAL DEFAULT 0'),
                ('signal_score', 'INTEGER DEFAULT 0'),
                ('spread_level', 'TEXT DEFAULT "unknown"'),
                ('binance_fill_price', 'REAL DEFAULT 0'),
                ('hurst', 'REAL DEFAULT 0.5'),
                ('trade_id', 'TEXT'),
                # Phase 224A: Diagnostics columns
                ('mae_pct', 'REAL DEFAULT 0'),
                ('mfe_pct', 'REAL DEFAULT 0'),
                ('decision_trace', 'TEXT DEFAULT \"[]\"'),
                # Phase 229: Order ID-based trade matching
                ('entry_order_id', 'TEXT'),
                ('close_order_id', 'TEXT'),
            ]
            for col_name, col_type in pc_migration_columns:
                try:
                    await db.execute(f'ALTER TABLE position_closes ADD COLUMN {col_name} {col_type}')
                except:
                    pass
            
            # Phase 211: OBI depth filter columns
            obi_migration_columns = [
                ('obi_value', 'REAL DEFAULT 0'),  # signals table
            ]
            for col_name, col_type in obi_migration_columns:
                try:
                    await db.execute(f'ALTER TABLE signals ADD COLUMN {col_name} {col_type}')
                except:
                    pass
            # OBI value for trades table (saved in settings_snapshot JSON, but also as direct column)
            try:
                await db.execute('ALTER TABLE trades ADD COLUMN obi_value REAL DEFAULT 0')
            except:
                pass
            await db.commit()
            
            self._initialized = True
            logger.info("âœ… SQLite database initialized with all tables")
    
    async def save_setting(self, key: str, value: any):
        """Save a setting to database."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO settings (key, value, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
            ''', (key, json.dumps(value)))
            await db.commit()
    
    async def get_setting(self, key: str, default: any = None) -> any:
        """Get a setting from database."""
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute('SELECT value FROM settings WHERE key = ?', (key,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return json.loads(row[0])
                return default
    
    @staticmethod
    def _is_rich_value(val, field_type='numeric'):
        """Check if a value is 'rich' (non-default). Used by merge/upsert to prevent default values from overwriting."""
        if val is None:
            return False
        if field_type == 'numeric':
            return val != 0 and val != 0.0
        elif field_type == 'text':
            return val not in ('', 'unknown', 'MARKET', '{}', '[]')
        elif field_type == 'score':
            return val is not None and val > 0
        return val is not None

    async def save_trade(self, trade: dict):
        """Save a completed trade â€” Phase 239: Merge/upsert semantics.
        Default/empty values (0, 'unknown', '') will NOT overwrite existing rich data.
        Only richer values replace existing ones."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO trades 
                (id, symbol, side, entry_price, exit_price, size, size_usd, pnl, pnl_percent, 
                 open_time, close_time, close_reason, leverage, signal_score, mtf_score, z_score, 
                 spread_level, settings_snapshot,
                 stop_loss, take_profit, atr, trailing_stop, trail_activation, is_trailing_active,
                 margin, roi, is_live, entry_method, entry_slippage, entry_spread, 
                 binance_fill_price, binance_order_id, hurst, adx, pullback_pct, close_metrics_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(id) DO UPDATE SET
                  symbol = COALESCE(excluded.symbol, trades.symbol),
                  side = COALESCE(excluded.side, trades.side),
                  entry_price = CASE WHEN excluded.entry_price > 0 THEN excluded.entry_price ELSE trades.entry_price END,
                  exit_price = CASE WHEN excluded.exit_price > 0 THEN excluded.exit_price ELSE trades.exit_price END,
                  size = CASE WHEN excluded.size > 0 THEN excluded.size ELSE trades.size END,
                  size_usd = CASE WHEN excluded.size_usd > 0 THEN excluded.size_usd ELSE trades.size_usd END,
                  pnl = COALESCE(excluded.pnl, trades.pnl),
                  pnl_percent = CASE WHEN excluded.pnl_percent != 0 THEN excluded.pnl_percent ELSE trades.pnl_percent END,
                  open_time = CASE WHEN excluded.open_time > 0 THEN excluded.open_time ELSE trades.open_time END,
                  close_time = COALESCE(excluded.close_time, trades.close_time),
                  close_reason = CASE WHEN excluded.close_reason IS NOT NULL AND excluded.close_reason != 'Closed' AND excluded.close_reason != 'Synced from Binance' THEN excluded.close_reason ELSE COALESCE(trades.close_reason, excluded.close_reason) END,
                  leverage = CASE WHEN excluded.leverage > 0 AND excluded.leverage != 10 THEN excluded.leverage WHEN trades.leverage > 0 THEN trades.leverage ELSE excluded.leverage END,
                  signal_score = CASE WHEN excluded.signal_score > 0 THEN excluded.signal_score ELSE trades.signal_score END,
                  mtf_score = CASE WHEN excluded.mtf_score > 0 THEN excluded.mtf_score ELSE trades.mtf_score END,
                  z_score = CASE WHEN excluded.z_score != 0 THEN excluded.z_score ELSE trades.z_score END,
                  spread_level = CASE WHEN excluded.spread_level IS NOT NULL AND excluded.spread_level != 'unknown' THEN excluded.spread_level ELSE COALESCE(trades.spread_level, excluded.spread_level) END,
                  settings_snapshot = CASE WHEN excluded.settings_snapshot IS NOT NULL AND excluded.settings_snapshot != '{}' THEN excluded.settings_snapshot ELSE COALESCE(trades.settings_snapshot, excluded.settings_snapshot) END,
                  stop_loss = CASE WHEN excluded.stop_loss > 0 THEN excluded.stop_loss ELSE trades.stop_loss END,
                  take_profit = CASE WHEN excluded.take_profit > 0 THEN excluded.take_profit ELSE trades.take_profit END,
                  atr = CASE WHEN excluded.atr > 0 THEN excluded.atr ELSE trades.atr END,
                  trailing_stop = CASE WHEN excluded.trailing_stop > 0 THEN excluded.trailing_stop ELSE trades.trailing_stop END,
                  trail_activation = CASE WHEN excluded.trail_activation > 0 THEN excluded.trail_activation ELSE trades.trail_activation END,
                  is_trailing_active = CASE WHEN excluded.is_trailing_active > 0 THEN excluded.is_trailing_active ELSE trades.is_trailing_active END,
                  margin = CASE WHEN excluded.margin > 0 THEN excluded.margin ELSE trades.margin END,
                  roi = CASE WHEN excluded.roi != 0 THEN excluded.roi ELSE trades.roi END,
                  is_live = CASE WHEN excluded.is_live > 0 THEN excluded.is_live ELSE trades.is_live END,
                  entry_method = CASE WHEN excluded.entry_method IS NOT NULL AND excluded.entry_method != 'MARKET' THEN excluded.entry_method ELSE COALESCE(trades.entry_method, excluded.entry_method) END,
                  entry_slippage = CASE WHEN excluded.entry_slippage != 0 THEN excluded.entry_slippage ELSE trades.entry_slippage END,
                  entry_spread = CASE WHEN excluded.entry_spread != 0 THEN excluded.entry_spread ELSE trades.entry_spread END,
                  binance_fill_price = CASE WHEN excluded.binance_fill_price > 0 THEN excluded.binance_fill_price ELSE trades.binance_fill_price END,
                  binance_order_id = CASE WHEN excluded.binance_order_id IS NOT NULL AND excluded.binance_order_id != '' THEN excluded.binance_order_id ELSE COALESCE(trades.binance_order_id, excluded.binance_order_id) END,
                  hurst = CASE WHEN excluded.hurst != 0.5 AND excluded.hurst > 0 THEN excluded.hurst WHEN trades.hurst != 0.5 AND trades.hurst > 0 THEN trades.hurst ELSE excluded.hurst END,
                  adx = CASE WHEN excluded.adx > 0 THEN excluded.adx ELSE trades.adx END,
                  pullback_pct = CASE WHEN excluded.pullback_pct > 0 THEN excluded.pullback_pct ELSE trades.pullback_pct END,
                  close_metrics_json = CASE WHEN excluded.close_metrics_json IS NOT NULL AND excluded.close_metrics_json != '{}' THEN excluded.close_metrics_json ELSE COALESCE(trades.close_metrics_json, excluded.close_metrics_json) END
            ''', (
                trade.get('id'),
                trade.get('symbol'),
                trade.get('side'),
                trade.get('entryPrice'),
                trade.get('exitPrice'),
                trade.get('size', 0),
                trade.get('sizeUsd', 0),
                trade.get('pnl'),
                trade.get('pnlPercent', 0),
                trade.get('openTime', 0),
                trade.get('closeTime'),
                trade.get('reason', trade.get('closeReason')),
                trade.get('leverage', 10),
                trade.get('signalScore', 0),
                trade.get('mtfScore', 0),
                trade.get('zScore', 0),
                trade.get('spreadLevel', 'unknown'),
                json.dumps(trade.get('settingsSnapshot', {})),
                # Phase 186: New fields
                trade.get('stopLoss', 0),
                trade.get('takeProfit', 0),
                trade.get('atr', 0),
                trade.get('trailingStop', 0),
                trade.get('trailActivation', 0),
                1 if trade.get('isTrailingActive', False) else 0,
                trade.get('margin', 0),
                trade.get('roi', 0),
                1 if trade.get('isLive', False) else 0,
                trade.get('entry_method', 'MARKET'),
                trade.get('entry_slippage', 0),
                trade.get('entry_spread', 0),
                trade.get('binance_fill_price', 0),
                trade.get('binance_order_id', ''),
                trade.get('hurst', 0.5),
                trade.get('adx', 0),
                trade.get('pullbackPct', 0),
                trade.get('close_metrics_json', '{}'),
            ))
            await db.commit()
    
    async def get_recent_trades(self, limit: int = 50) -> list:
        """Get recent trades."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT * FROM trades ORDER BY close_time DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [dict(row) for row in rows]
    
    async def get_full_trade_history(self, limit: int = 0) -> list:
        """
        Phase 187b: Get ALL trades from SQLite with full data.
        Returns frontend-compatible format with all 35 fields.
        limit=0 means no limit (all trades).
        """
        try:
            async with aiosqlite.connect(self.db_path) as db:
                db.row_factory = aiosqlite.Row
                if limit > 0:
                    query = 'SELECT * FROM trades ORDER BY close_time DESC LIMIT ?'
                    params = (limit,)
                else:
                    query = 'SELECT * FROM trades ORDER BY close_time DESC'
                    params = ()
                
                async with db.execute(query, params) as cursor:
                    rows = await cursor.fetchall()
                    trades = []
                    for row in rows:
                        d = dict(row)
                        # Parse settings_snapshot from JSON string
                        try:
                            if d.get('settings_snapshot') and isinstance(d['settings_snapshot'], str):
                                d['settings_snapshot'] = json.loads(d['settings_snapshot'])
                        except:
                            d['settings_snapshot'] = {}
                        
                        # Frontend-compatible format
                        turkey_tz = pytz.timezone('Europe/Istanbul')
                        close_ts = d.get('close_time', 0)
                        if close_ts and close_ts > 0:
                            close_dt = datetime.fromtimestamp(close_ts / 1000, tz=turkey_tz)
                            time_str = close_dt.strftime('%H:%M')
                            date_str = close_dt.strftime('%d/%m')
                        else:
                            time_str = ''
                            date_str = ''
                        
                        pnl = d.get('pnl', 0) or 0
                        margin = d.get('margin', 0) or 0
                        roi = d.get('roi', 0) or 0
                        
                        trade = {
                            'id': d.get('id', ''),
                            'symbol': (d.get('symbol', '') or '').replace('USDT', ''),
                            'symbolFull': d.get('symbol', ''),
                            'side': d.get('side', 'LONG'),
                            'entryPrice': d.get('entry_price', 0) or 0,
                            'exitPrice': d.get('exit_price', 0) or 0,
                            'pnl': round(pnl, 4),
                            'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                            'pnlPercent': d.get('pnl_percent', 0) or 0,
                            'roi': round(roi, 2),
                            'margin': round(margin, 4),
                            'leverage': d.get('leverage', 10) or 10,
                            'sizeUsd': round(d.get('size_usd', 0) or 0, 2),
                            'closeTime': close_ts,
                            'openTime': d.get('open_time', 0) or 0,
                            'time': time_str,
                            'date': date_str,
                            'timestamp': close_ts,
                            'closeReason': d.get('close_reason', 'Closed') or 'Closed',
                            'reason': d.get('close_reason', 'Closed') or 'Closed',
                            'type': 'CLOSE',
                            # Phase 187b: Full data
                            'stopLoss': d.get('stop_loss', 0) or 0,
                            'takeProfit': d.get('take_profit', 0) or 0,
                            'atr': d.get('atr', 0) or 0,
                            'trailingStop': d.get('trailing_stop', 0) or 0,
                            'trailActivation': d.get('trail_activation', 0) or 0,
                            'isTrailingActive': bool(d.get('is_trailing_active', 0)),
                            'spreadLevel': d.get('spread_level', 'unknown'),
                            'signalScore': d.get('signal_score', 0) or 0,
                            'mtfScore': d.get('mtf_score', 0) or 0,
                            'zScore': d.get('z_score', 0) or 0,
                            'entryMethod': d.get('entry_method', 'MARKET'),
                            'entrySlippage': d.get('entry_slippage', 0) or 0,
                            'entrySpread': d.get('entry_spread', 0) or 0,
                            'binanceFillPrice': d.get('binance_fill_price', 0) or 0,
                            'isLive': bool(d.get('is_live', 0)),
                            'hurst': d.get('hurst', 0.5) or 0.5,
                            'settingsSnapshot': d.get('settings_snapshot', {}),
                            # Phase 232: Close metrics snapshot
                            'close_metrics_json': d.get('close_metrics_json', '{}'),
                        }
                        trades.append(trade)
                    
                    logger.info(f"ðŸ“Š SQLite trade history: returning {len(trades)} trades")
                    return trades
        except Exception as e:
            logger.error(f"get_full_trade_history error: {e}")
            return []
    
    async def add_log(self, time: str, message: str, ts: int):
        """Add a log entry."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO logs (time, message, ts) VALUES (?, ?, ?)
            ''', (time, message, ts))
            # Keep only last 500 logs
            await db.execute('''
                DELETE FROM logs WHERE id NOT IN (
                    SELECT id FROM logs ORDER BY id DESC LIMIT 500
                )
            ''')
            await db.commit()
    
    async def get_recent_logs(self, limit: int = 100) -> list:
        """Get recent logs."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT time, message, ts FROM logs ORDER BY id DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [{"time": row["time"], "message": row["message"], "ts": row["ts"]} for row in rows]
    
    async def save_equity_point(self, time: int, balance: float, drawdown: float):
        """Save an equity curve point."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO equity_curve (time, balance, drawdown) VALUES (?, ?, ?)
            ''', (time, balance, drawdown))
            # Keep only last 1000 points
            await db.execute('''
                DELETE FROM equity_curve WHERE id NOT IN (
                    SELECT id FROM equity_curve ORDER BY id DESC LIMIT 1000
                )
            ''')
            await db.commit()
    
    async def get_equity_curve(self, limit: int = 500) -> list:
        """Get equity curve data."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            async with db.execute('''
                SELECT time, balance, drawdown FROM equity_curve ORDER BY id DESC LIMIT ?
            ''', (limit,)) as cursor:
                rows = await cursor.fetchall()
                return [{"time": row["time"], "balance": row["balance"], "drawdown": row["drawdown"]} for row in reversed(rows)]
    
    async def save_signal(self, signal_data: dict):
        """Save a signal (accepted or rejected) for performance analysis."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO signals (
                    symbol, action, price, zscore, hurst, atr, signal_score,
                    htf_trend, mtf_confirmed, mtf_reason, blacklisted, accepted,
                    reject_reason, z_threshold, min_confidence, entry_tightness,
                    exit_tightness, timestamp, obi_value
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                signal_data.get('symbol'),
                signal_data.get('action'),
                signal_data.get('price', 0),
                signal_data.get('zscore', 0),
                signal_data.get('hurst', 0),
                signal_data.get('atr', 0),
                signal_data.get('signal_score', 0),
                signal_data.get('htf_trend', 'NEUTRAL'),
                1 if signal_data.get('mtf_confirmed', False) else 0,
                signal_data.get('mtf_reason', ''),
                1 if signal_data.get('blacklisted', False) else 0,
                1 if signal_data.get('accepted', False) else 0,
                signal_data.get('reject_reason', ''),
                signal_data.get('z_threshold', 0),
                signal_data.get('min_confidence', 0),
                signal_data.get('entry_tightness', 1.0),
                signal_data.get('exit_tightness', 1.0),
                signal_data.get('timestamp', int(datetime.now().timestamp() * 1000)),
                signal_data.get('obi_value', 0),  # Phase 211: OBI depth value
            ))
            await db.commit()
    
    async def save_open_position(self, pos: dict):
        """Save an open position to database."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO positions (
                    id, symbol, side, entry_price, size, size_usd,
                    stop_loss, take_profit, leverage, open_time,
                    signal_score, zscore, hurst, atr, htf_trend, status
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                pos.get('id'),
                pos.get('symbol'),
                pos.get('side'),
                pos.get('entryPrice'),
                pos.get('size', 0),
                pos.get('sizeUsd', 0),
                pos.get('stopLoss', 0),
                pos.get('takeProfit', 0),
                pos.get('leverage', 10),
                pos.get('openTime', 0),
                pos.get('signalScore', 0),
                pos.get('zscore', 0),
                pos.get('hurst', 0),
                pos.get('atr', 0),
                pos.get('htfTrend', 'NEUTRAL'),
                'OPEN'
            ))
            await db.commit()
    
    async def close_position_in_db(self, position_id: str, symbol: str = None):
        """Mark a position as closed in database with close_time."""
        close_time = int(datetime.now().timestamp() * 1000)
        async with aiosqlite.connect(self.db_path) as db:
            if position_id:
                await db.execute('''
                    UPDATE positions SET status = 'CLOSED', close_time = ? WHERE id = ?
                ''', (close_time, position_id))
            elif symbol:
                await db.execute('''
                    UPDATE positions SET status = 'CLOSED', close_time = ? 
                    WHERE symbol = ? AND status = 'OPEN'
                ''', (close_time, symbol))
            await db.commit()
            logger.info(f"ðŸ“‚ Position closed in DB: id={position_id} symbol={symbol}")
    
    async def get_position_open_time(self, symbol: str) -> int:
        """Get open_time for an active position by symbol from SQLite."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute(
                    "SELECT open_time FROM positions WHERE symbol=? AND status='OPEN' ORDER BY open_time DESC LIMIT 1",
                    (symbol,)
                )
                row = await cursor.fetchone()
                return row[0] if row else None
        except Exception as e:
            logger.warning(f"âš ï¸ get_position_open_time error for {symbol}: {e}")
            return None
    
    async def get_all_open_times(self) -> dict:
        """Get open_times for ALL active positions in one query. Returns {symbol: open_time_ms}."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute(
                    "SELECT symbol, open_time FROM positions WHERE status='OPEN'"
                )
                rows = await cursor.fetchall()
                return {row[0]: row[1] for row in rows}
        except Exception as e:
            logger.warning(f"âš ï¸ get_all_open_times error: {e}")
            return {}
    


    async def lookup_position_close_metadata(self, symbol: str, close_time: int, window_ms: int = 3600000) -> dict:
        """Phase 239: Lookup position_closes for metadata enrichment.
        Returns dict of metadata fields or empty dict if not found."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                db.row_factory = aiosqlite.Row
                async with db.execute('''
                    SELECT * FROM position_closes 
                    WHERE symbol = ? AND ABS(timestamp - ?) < ?
                    ORDER BY ABS(timestamp - ?) ASC LIMIT 1
                ''', (symbol, close_time, window_ms, close_time)) as cursor:
                    row = await cursor.fetchone()
                    if row:
                        return dict(row)
            return {}
        except Exception as e:
            logger.debug(f"lookup_position_close_metadata error: {e}")
            return {}

    async def get_trade_data_quality_24h(self) -> dict:
        """Phase 239: Get trade metadata quality stats for last 24 hours."""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cutoff_ms = int((datetime.now().timestamp() - 86400) * 1000)
                async with db.execute('''
                    SELECT 
                        COUNT(*) as total,
                        SUM(CASE WHEN pullback_pct = 0 OR pullback_pct IS NULL THEN 1 ELSE 0 END) as missing_pullback,
                        SUM(CASE WHEN signal_score = 0 OR signal_score IS NULL THEN 1 ELSE 0 END) as missing_score,
                        SUM(CASE WHEN spread_level = 'unknown' OR spread_level IS NULL THEN 1 ELSE 0 END) as missing_spread
                    FROM trades WHERE close_time > ?
                ''', (cutoff_ms,)) as cursor:
                    row = await cursor.fetchone()
                    if row:
                        total = row[0] or 0
                        missing_pb = row[1] or 0
                        missing_score = row[2] or 0
                        missing_spread = row[3] or 0
                        # Phase 239 fix: per-field average instead of max (prevents inflated coverage)
                        avg_missing = (missing_pb + missing_score + missing_spread) / 3.0
                        coverage = round(((total - avg_missing) / max(total, 1)) * 100, 1)
                        return {
                            'trades_total_24h': total,
                            'trades_missing_pullback_24h': missing_pb,
                            'trades_missing_score_24h': missing_score,
                            'trades_missing_spread_24h': missing_spread,
                            'trade_metadata_coverage_pct_24h': coverage,
                        }
            return {'trades_total_24h': 0, 'trade_metadata_coverage_pct_24h': 100.0}
        except Exception as e:
            logger.debug(f"get_trade_data_quality_24h error: {e}")
            return {'trades_total_24h': 0, 'trade_metadata_coverage_pct_24h': 0, 'error': str(e)}

    async def backfill_missing_metadata(self, hours_back: int = 48) -> int:
        """Phase 239: Backfill missing trade metadata from position_closes.
        Idempotent â€” only updates fields that are currently default/empty.
        Returns number of trades updated."""
        updated = 0
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cutoff_ms = int((datetime.now().timestamp() - hours_back * 3600) * 1000)
                db.row_factory = aiosqlite.Row
                # Find trades with missing metadata
                async with db.execute('''
                    SELECT id, symbol, close_time FROM trades 
                    WHERE close_time > ? AND (
                        (signal_score = 0 OR signal_score IS NULL) OR
                        (spread_level = 'unknown' OR spread_level IS NULL) OR
                        (pullback_pct = 0 OR pullback_pct IS NULL)
                    )
                ''', (cutoff_ms,)) as cursor:
                    rows = await cursor.fetchall()
                
                for row in rows:
                    trade_id = row['id']
                    symbol = row['symbol']
                    close_time = row['close_time'] or 0
                    
                    # Look up position_closes
                    pc = await self.lookup_position_close_metadata(symbol, close_time)
                    if not pc:
                        continue
                    
                    # Build SET clause only for fields that have richer data in position_closes
                    updates = []
                    params = []
                    if pc.get('signal_score', 0) > 0:
                        updates.append('signal_score = CASE WHEN signal_score = 0 OR signal_score IS NULL THEN ? ELSE signal_score END')
                        params.append(pc['signal_score'])
                    if pc.get('spread_level') and pc['spread_level'] != 'unknown':
                        updates.append("spread_level = CASE WHEN spread_level = 'unknown' OR spread_level IS NULL THEN ? ELSE spread_level END")
                        params.append(pc['spread_level'])
                    if pc.get('entry_price', 0) > 0:
                        updates.append('entry_price = CASE WHEN entry_price = 0 OR entry_price IS NULL THEN ? ELSE entry_price END')
                        params.append(pc['entry_price'])
                    if pc.get('exit_price', 0) > 0:
                        updates.append('exit_price = CASE WHEN exit_price = 0 OR exit_price IS NULL THEN ? ELSE exit_price END')
                        params.append(pc['exit_price'])
                    if pc.get('leverage', 0) > 0:
                        updates.append('leverage = CASE WHEN leverage = 0 OR leverage IS NULL THEN ? ELSE leverage END')
                        params.append(pc['leverage'])
                    if pc.get('hurst', 0.5) != 0.5 and pc.get('hurst', 0) > 0:
                        updates.append('hurst = CASE WHEN hurst = 0.5 OR hurst IS NULL THEN ? ELSE hurst END')
                        params.append(pc['hurst'])
                    if pc.get('stop_loss', 0) > 0:
                        updates.append('stop_loss = CASE WHEN stop_loss = 0 OR stop_loss IS NULL THEN ? ELSE stop_loss END')
                        params.append(pc['stop_loss'])
                    if pc.get('take_profit', 0) > 0:
                        updates.append('take_profit = CASE WHEN take_profit = 0 OR take_profit IS NULL THEN ? ELSE take_profit END')
                        params.append(pc['take_profit'])
                    if pc.get('atr', 0) > 0:
                        updates.append('atr = CASE WHEN atr = 0 OR atr IS NULL THEN ? ELSE atr END')
                        params.append(pc['atr'])
                    # Phase 239 fix: removed side backfill â€” risky on fuzzy time match
                    if pc.get('original_reason') and pc['original_reason'] != 'Closed':
                        updates.append("close_reason = CASE WHEN close_reason = 'Synced from Binance' OR close_reason = 'Closed' THEN ? ELSE close_reason END")
                        params.append(pc.get('reason', pc['original_reason']))
                    
                    if updates:
                        params.append(trade_id)
                        sql = f"UPDATE trades SET {', '.join(updates)} WHERE id = ?"
                        await db.execute(sql, params)
                        updated += 1
                
                if updated > 0:
                    await db.commit()
                    logger.info(f"ðŸ“Š BACKFILL: Updated metadata for {updated}/{len(rows)} trades from position_closes")
                
        except Exception as e:
            logger.error(f"backfill_missing_metadata error: {e}")
        return updated

    async def save_all_settings(self, settings: dict):
        """Save all settings to database."""
        async with aiosqlite.connect(self.db_path) as db:
            for key, value in settings.items():
                await db.execute('''
                    INSERT OR REPLACE INTO settings (key, value, updated_at)
                    VALUES (?, ?, CURRENT_TIMESTAMP)
                ''', (key, json.dumps(value)))
            await db.commit()
    
    async def save_position_close(self, close_data: dict):
        """Phase 187: Save position close with ALL trade data + settings."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO position_closes (
                    symbol, side, reason, original_reason, entry_price, exit_price,
                    pnl, leverage, size_usd, margin, roi, timestamp,
                    stop_loss, take_profit, atr, trailing_stop, trail_activation,
                    settings_snapshot, entry_method, entry_slippage, entry_spread,
                    signal_score, spread_level, binance_fill_price, hurst, trade_id,
                    mae_pct, mfe_pct, decision_trace,
                    entry_order_id, close_order_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                close_data.get('symbol'),
                close_data.get('side'),
                close_data.get('reason', 'Closed'),
                close_data.get('original_reason', 'Closed'),
                close_data.get('entryPrice', 0),
                close_data.get('exitPrice', 0),
                close_data.get('pnl', 0),
                close_data.get('leverage', 10),
                close_data.get('sizeUsd', 0),
                close_data.get('margin', 0),
                close_data.get('roi', 0),
                close_data.get('timestamp', int(datetime.now().timestamp() * 1000)),
                # Phase 187: Settings + execution data
                close_data.get('stopLoss', 0),
                close_data.get('takeProfit', 0),
                close_data.get('atr', 0),
                close_data.get('trailingStop', 0),
                close_data.get('trailActivation', 0),
                json.dumps(close_data.get('settingsSnapshot', {})),
                close_data.get('entry_method', 'MARKET'),
                close_data.get('entry_slippage', 0),
                close_data.get('entry_spread', 0),
                close_data.get('signalScore', 0),
                close_data.get('spreadLevel', 'unknown'),
                close_data.get('binance_fill_price', 0),
                close_data.get('hurst', 0.5),
                close_data.get('trade_id', ''),
                close_data.get('mae_pct', 0),
                close_data.get('mfe_pct', 0),
                close_data.get('decision_trace', '[]'),
                close_data.get('entry_order_id', ''),
                close_data.get('close_order_id', ''),
            ))
            await db.commit()
            logger.info(f"ðŸ’¾ Position close saved to SQLite: {close_data.get('symbol')} - {close_data.get('reason')} | entry_oid={close_data.get('entry_order_id', '')[:12]} close_oid={close_data.get('close_order_id', '')[:12]}")
    
    async def get_pending_close_reason(self, symbol: str, close_time: int, window_minutes: int = 30, close_order_id: str = None) -> dict:
        """Phase 229: Get pending close reason â€” order ID match first, timestamp fallback."""
        window_ms = window_minutes * 60 * 1000
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            
            # Step 0: Exact match by close_order_id (Phase 229)
            # Phase 229b: Added symbol filter to prevent cross-symbol mismatches
            if close_order_id:
                async with db.execute('''
                    SELECT * FROM position_closes 
                    WHERE symbol = ? AND close_order_id = ? AND close_order_id != ''
                    LIMIT 1
                ''', (symbol, close_order_id)) as cursor:
                    row = await cursor.fetchone()
                    if row:
                        logger.info(f"ðŸ†” ORDER ID MATCH: {symbol} close_oid={close_order_id[:12]}")
                        return dict(row)
            
            # Step 1: Try unmatched records by timestamp
            async with db.execute('''
                SELECT * FROM position_closes 
                WHERE symbol = ? AND matched_to_income = 0
                AND ABS(timestamp - ?) < ?
                ORDER BY ABS(timestamp - ?) ASC
                LIMIT 1
            ''', (symbol, close_time, window_ms, close_time)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return dict(row)
            
            # Step 2: Fallback â€” check ALL records (even matched ones)
            async with db.execute('''
                SELECT * FROM position_closes 
                WHERE symbol = ? AND ABS(timestamp - ?) < ?
                ORDER BY ABS(timestamp - ?) ASC
                LIMIT 1
            ''', (symbol, close_time, window_ms, close_time)) as cursor:
                row = await cursor.fetchone()
                if row:
                    logger.debug(f"ðŸ“‹ Fallback match for {symbol}: reason={dict(row).get('reason')}")
                    return dict(row)
            return None
    
    async def mark_close_matched(self, close_id: int):
        """Mark a position close as matched to Binance income."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                UPDATE position_closes SET matched_to_income = 1 WHERE id = ?
            ''', (close_id,))
            await db.commit()
    
    async def update_close_order_id(self, symbol: str, close_order_id: str):
        """Phase 229b: Update the most recent position_close with Binance close order ID.
        Uses timestamp window (last 5 min) to prevent wrong-row updates on rapid consecutive closes."""
        try:
            now_ms = int(datetime.now().timestamp() * 1000)
            window_ms = 5 * 60 * 1000  # 5 minutes
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute('''
                    UPDATE position_closes SET close_order_id = ?
                    WHERE symbol = ? AND (close_order_id IS NULL OR close_order_id = '')
                    AND timestamp > ? - ?
                    ORDER BY timestamp DESC LIMIT 1
                ''', (close_order_id, symbol, now_ms, window_ms))
                await db.commit()
                if cursor.rowcount > 0:
                    logger.info(f"ðŸ†” Close order ID saved: {symbol} = {close_order_id[:12]}")
                else:
                    logger.debug(f"ðŸ†” Close order ID no matching row: {symbol} = {close_order_id[:12]}")
        except Exception as e:
            logger.warning(f"âš ï¸ update_close_order_id error: {e}")
    
    async def save_binance_trade(self, trade_data: dict):
        """
        Phase 152: Save Binance trade with enrichment from position_closes.
        Before saving, try to match with position_closes for better close reason.
        """
        async with aiosqlite.connect(self.db_path) as db:
            symbol = trade_data.get('symbol')
            close_time = trade_data.get('closeTime', 0)
            close_reason = trade_data.get('closeReason', 'Closed')
            entry_price = trade_data.get('entryPrice', 0)
            exit_price = trade_data.get('exitPrice', 0)
            side = trade_data.get('side', 'LONG')
            leverage = trade_data.get('leverage', 1)
            size_usd = trade_data.get('sizeUsd', 0)
            
            # Phase 152: Enrich from position_closes if close_reason is generic
            if close_reason in ('Closed', 'Position closed on Binance', 'Historical (from Binance)'):
                try:
                    db.row_factory = aiosqlite.Row
                    async with db.execute('''
                        SELECT * FROM position_closes 
                        WHERE symbol = ? AND ABS(timestamp - ?) < 3600000
                        ORDER BY ABS(timestamp - ?) ASC LIMIT 1
                    ''', (symbol, close_time, close_time)) as cursor:
                        pc = await cursor.fetchone()
                        if pc:
                            close_reason = pc['original_reason'] or pc['reason'] or close_reason
                            if pc['entry_price'] and pc['entry_price'] > 0:
                                entry_price = pc['entry_price']
                            if pc['exit_price'] and pc['exit_price'] > 0:
                                exit_price = pc['exit_price']
                            if pc['side']:
                                side = pc['side']
                            if pc['leverage'] and pc['leverage'] > 0:
                                leverage = pc['leverage']
                            if pc['size_usd'] and pc['size_usd'] > 0:
                                size_usd = pc['size_usd']
                            logger.info(f"ðŸ“‹ Enriched trade {symbol} with close reason: {close_reason}")
                except Exception as e:
                    logger.debug(f"Enrichment lookup failed: {e}")
            
            await db.execute('''
                INSERT OR REPLACE INTO binance_trades (
                    income_id, symbol, side, entry_price, exit_price, pnl, pnl_percent,
                    margin, leverage, size_usd, close_reason, close_time, raw_data
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                trade_data.get('incomeId', str(close_time)),
                symbol,
                side,
                entry_price,
                exit_price,
                trade_data.get('pnl', 0),
                trade_data.get('roi', 0),
                trade_data.get('margin', 0),
                leverage,
                size_usd,
                close_reason,
                close_time,
                json.dumps(trade_data)
            ))
            await db.commit()
    
    async def get_binance_trades(self, limit: int = 200) -> list:
        """
        Phase 152: Get trades from SQLite with position_closes JOIN for enriched data.
        Reads directly from binance_trades columns + enriches with position_closes.
        """
        try:
            async with aiosqlite.connect(self.db_path) as db:
                db.row_factory = aiosqlite.Row
                
                # LEFT JOIN position_closes to get proper close reasons
                # Match by symbol + timestamp within 5 minute window
                async with db.execute('''
                    SELECT 
                        bt.symbol, bt.side, bt.entry_price, bt.exit_price, 
                        bt.pnl, bt.pnl_percent, bt.margin, bt.leverage, 
                        bt.size_usd, bt.close_reason, bt.close_time,
                        pc.reason AS pc_reason, pc.original_reason AS pc_original_reason,
                        pc.entry_price AS pc_entry, pc.exit_price AS pc_exit,
                        pc.side AS pc_side, pc.leverage AS pc_leverage,
                        pc.size_usd AS pc_size_usd, pc.margin AS pc_margin,
                        pc.roi AS pc_roi
                    FROM binance_trades bt
                    LEFT JOIN position_closes pc 
                        ON bt.symbol = pc.symbol 
                        AND ABS(bt.close_time - pc.timestamp) < 300000
                    ORDER BY bt.close_time DESC 
                    LIMIT ?
                ''', (limit,)) as cursor:
                    rows = await cursor.fetchall()
                    
                    trades = []
                    seen = set()  # Dedup by symbol+close_time
                    
                    for row in rows:
                        dedup_key = f"{row['symbol']}_{row['close_time']}"
                        if dedup_key in seen:
                            continue
                        seen.add(dedup_key)
                        
                        # Use position_closes data for enrichment (priority)
                        close_reason = row['close_reason'] or 'Closed'
                        reason_detail = close_reason
                        entry_price = row['entry_price'] or 0
                        exit_price = row['exit_price'] or 0
                        side = row['side'] or 'LONG'
                        leverage = row['leverage'] or 10
                        size_usd = row['size_usd'] or 0
                        margin = row['margin'] or 0
                        pnl = row['pnl'] or 0
                        roi = row['pnl_percent'] or 0
                        
                        # Enrich from position_closes if available
                        if row['pc_reason'] and row['pc_reason'] != 'Closed':
                            close_reason = row['pc_reason']
                            reason_detail = row['pc_original_reason'] or row['pc_reason']
                        if row['pc_entry'] and row['pc_entry'] > 0:
                            entry_price = row['pc_entry']
                        if row['pc_exit'] and row['pc_exit'] > 0:
                            exit_price = row['pc_exit']
                        if row['pc_side']:
                            side = row['pc_side']
                        if row['pc_leverage'] and row['pc_leverage'] > 0:
                            leverage = row['pc_leverage']
                        if row['pc_size_usd'] and row['pc_size_usd'] > 0:
                            size_usd = row['pc_size_usd']
                        if row['pc_margin'] and row['pc_margin'] > 0:
                            margin = row['pc_margin']
                        if row['pc_roi'] and row['pc_roi'] != 0:
                            roi = row['pc_roi']
                        
                        # Recalculate margin/roi if needed
                        if margin == 0 and size_usd > 0 and leverage > 0:
                            margin = size_usd / leverage
                        if roi == 0 and margin > 0 and pnl != 0:
                            roi = (pnl / margin * 100)
                        
                        close_time_ms = row['close_time'] or 0
                        try:
                            turkey_tz = pytz.timezone('Europe/Istanbul')
                            ct = datetime.fromtimestamp(close_time_ms / 1000, turkey_tz)
                            time_str = ct.strftime('%H:%M:%S')
                            date_str = ct.strftime('%m/%d')
                        except:
                            time_str = ''
                            date_str = ''
                        
                        trades.append({
                            'symbol': row['symbol'],
                            'side': side,
                            'entryPrice': round(entry_price, 8) if entry_price else 0,
                            'exitPrice': round(exit_price, 8) if exit_price else 0,
                            'pnl': round(pnl, 4),
                            'closeTime': close_time_ms,
                            'closeReason': close_reason,
                            'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                            'timestamp': close_time_ms,
                            'time': time_str,
                            'date': date_str,
                            'type': 'CLOSE',
                            'margin': round(margin, 4),
                            'leverage': leverage,
                            'sizeUsd': round(size_usd, 2),
                            'roi': round(roi, 2),
                            'reason': reason_detail
                        })
                    
                    return trades
        except Exception as e:
            logger.error(f"get_binance_trades error: {e}")
            return []
    
    async def save_leverage(self, symbol: str, leverage: int):
        """Cache leverage for a symbol."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO leverage_cache (symbol, leverage, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
            ''', (symbol, leverage))
            await db.commit()
    
    async def get_leverage(self, symbol: str) -> int:
        """Get cached leverage for a symbol."""
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute('''
                SELECT leverage FROM leverage_cache WHERE symbol = ?
            ''', (symbol,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    return row[0]
                return 10  # Default leverage
    
    # ================================================================
    # Phase 154: Breakeven State Persistence
    # ================================================================
    async def save_breakeven_state(self, state_key: str, symbol: str, side: str, 
                                    entry_price: float, activation_price: float,
                                    activation_time: str, spread_level: str = 'Normal'):
        """Save breakeven state to SQLite."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO breakeven_states 
                (state_key, symbol, side, entry_price, activation_price, activation_time, spread_level)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (state_key, symbol, side, entry_price, activation_price, activation_time, spread_level))
            await db.commit()
        logger.info(f"ðŸ’¾ Breakeven state saved: {state_key}")
    
    async def delete_breakeven_state(self, state_key: str):
        """Delete breakeven state from SQLite."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('DELETE FROM breakeven_states WHERE state_key = ?', (state_key,))
            await db.commit()
        logger.info(f"ðŸ—‘ï¸ Breakeven state deleted: {state_key}")
    
    async def load_breakeven_states(self) -> dict:
        """Load all breakeven states from SQLite."""
        states = {}
        try:
            async with aiosqlite.connect(self.db_path) as db:
                async with db.execute('SELECT state_key, symbol, side, entry_price, activation_price, activation_time, spread_level FROM breakeven_states') as cursor:
                    async for row in cursor:
                        states[row[0]] = {
                            'active': True,
                            'entry_price': row[3],
                            'activation_price': row[4],
                            'activation_time': row[5],
                            'spread_level': row[6]
                        }
            if states:
                logger.info(f"ðŸ“‚ Loaded {len(states)} breakeven states from SQLite: {list(states.keys())}")
        except Exception as e:
            logger.error(f"Failed to load breakeven states: {e}")
        return states

# Global SQLite manager
sqlite_manager = SQLiteManager()


def safe_create_task(coro, name="unnamed"):
    """Create an asyncio task with exception logging instead of silent swallowing."""
    task = asyncio.create_task(coro)
    def _handle_exception(t):
        if t.cancelled():
            return
        exc = t.exception()
        if exc:
            logger.error(f"ðŸ”¥ Background task '{name}' failed: {exc}")
    task.add_done_callback(_handle_exception)
    return task


# ============================================================================
# UI WEBSOCKET MANAGER - Real-time updates to UI clients
# ============================================================================

class UIWebSocketManager:
    """
    Manages WebSocket connections to UI clients.
    Broadcasts real-time events: signals, positions, prices, logs.
    """
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.last_broadcast = 0
        self.broadcast_interval = 0.5  # Min 500ms between price broadcasts
        logger.info("ðŸ”Œ UIWebSocketManager initialized")
    
    async def connect(self, websocket: WebSocket):
        """Accept new WebSocket connection."""
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"ðŸ”Œ UI WebSocket connected. Total clients: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        """Remove disconnected WebSocket."""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info(f"ðŸ”Œ UI WebSocket disconnected. Total clients: {len(self.active_connections)}")
    
    async def broadcast(self, event_type: str, data: dict):
        """Broadcast event to all connected UI clients."""
        if not self.active_connections:
            return
        
        message = {
            "type": event_type,
            "data": data,
            "timestamp": int(datetime.now().timestamp() * 1000)
        }
        
        # Remove dead connections
        dead = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception:
                dead.append(connection)
        
        for d in dead:
            self.disconnect(d)
    
    async def broadcast_signal(self, signal: dict):
        """Broadcast new signal event."""
        await self.broadcast("SIGNAL", signal)
    
    async def broadcast_position_opened(self, position: dict):
        """Broadcast position opened event."""
        await self.broadcast("POSITION_OPENED", position)
    
    async def broadcast_position_closed(self, trade: dict):
        """Broadcast position closed event."""
        await self.broadcast("POSITION_CLOSED", trade)
    
    async def broadcast_pending_order(self, order: dict):
        """Broadcast new pending order event."""
        await self.broadcast("PENDING_ORDER", order)
    
    async def broadcast_price_update(self, positions: list):
        """Broadcast position price updates (throttled)."""
        now = datetime.now().timestamp()
        if now - self.last_broadcast < self.broadcast_interval:
            return  # Throttle
        self.last_broadcast = now
        await self.broadcast("PRICE_UPDATE", {"positions": positions})
    
    async def broadcast_log(self, log: str):
        """Broadcast log message."""
        await self.broadcast("LOG", {"message": log})
    
    async def broadcast_kill_switch(self, actions: dict):
        """Broadcast kill switch event."""
        await self.broadcast("KILL_SWITCH", actions)



# Global UI WebSocket manager
ui_ws_manager = UIWebSocketManager()


# ============================================================================
# LIVE BINANCE TRADER - Real Order Execution
# ============================================================================

class LiveBinanceTrader:
    """
    Binance Futures gerÃ§ek emir ve pozisyon yÃ¶netimi.
    Pozisyonlar, bakiye, PnL Binance'den okunur - backend hesaplamaz.
    Backend sadece AL/SAT emirleri gÃ¶nderir.
    """
    
    def __init__(self):
        self.exchange = None
        self.enabled = False
        self.initialized = False
        self.last_error = None
        self.last_order_error = None
        self.last_balance = 0.0
        self.last_positions = []
        self.last_sync_time = 0
        self.trading_mode = os.environ.get('TRADING_MODE', 'paper')  # paper, live
         # Phase 146: Persistent trailing state for live positions
        # Key: symbol, Value: {isActive: bool, trailingStop: float, peakPrice: float}
        self.trailing_state = {}
        logger.info(f"ðŸ“Š LiveBinanceTrader initialized | Mode: {self.trading_mode}")
    
    async def initialize(self):
        """Binance baÄŸlantÄ±sÄ±nÄ± baÅŸlat."""
        self.last_error = None  # Reset error
        
        if self.trading_mode == 'paper':
            self.last_error = "trading_mode is paper, not live"
            logger.info("ðŸ“„ PAPER MODE: Binance connection skipped")
            return False
            
        api_key = os.environ.get('BINANCE_API_KEY')
        api_secret = os.environ.get('BINANCE_SECRET')
        
        if not api_key or not api_secret:
            self.last_error = f"Missing credentials: api_key={bool(api_key)}, secret={bool(api_secret)}"
            logger.error("âŒ BINANCE_API_KEY ve BINANCE_SECRET tanÄ±mlÄ± deÄŸil!")
            return False
        
        try:
            self.exchange = ccxt_async.binance({
                'apiKey': api_key,
                'secret': api_secret,
                'options': {'defaultType': 'future'},
                'enableRateLimit': True,
            })
            
            # BaÄŸlantÄ± testi - bakiye Ã§ek
            balance = await self.exchange.fetch_balance()
            self.last_balance = float((balance.get('USDT') or {}).get('free') or 0)
            
            logger.info(f"âœ… Binance Futures baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
            logger.info(f"ðŸ’° KullanÄ±labilir Bakiye: ${self.last_balance:.2f} USDT")
            
            self.enabled = True
            self.initialized = True
            
            return True
            
        except Exception as e:
            self.last_error = f"Binance connection error: {str(e)}"
            logger.error(f"âŒ Binance baÄŸlantÄ± hatasÄ±: {e}")
            self.exchange = None  # Reset exchange on error to allow retry
            self.enabled = False
            return False
    
    async def get_balance(self) -> dict:
        """Binance'den bakiye Ã§ek - Futures account iÃ§in doÄŸru alanlar."""
        if not self.enabled or not self.exchange:
            return {'walletBalance': 0, 'marginBalance': 0, 'availableBalance': 0, 'unrealizedPnl': 0, 'free': 0, 'used': 0, 'total': 0}
            
        try:
            balance = await self.exchange.fetch_balance()
            
            # Get raw Binance info for accurate Futures balance fields
            info = balance.get('info', {})
            
            # Binance Futures returns these in 'info':
            # totalWalletBalance: Wallet Balance (without unrealized PnL)
            # totalMarginBalance: Margin Balance (wallet + unrealized PnL)
            # totalUnrealizedProfit: Unrealized PnL
            # availableBalance: Available Balance for trading
            
            wallet_balance = float(info.get('totalWalletBalance', 0) or 0)
            margin_balance = float(info.get('totalMarginBalance', 0) or 0)
            unrealized_pnl = float(info.get('totalUnrealizedProfit', 0) or 0)
            available_balance = float(info.get('availableBalance', 0) or 0)
            
            # Fallback to USDT if raw info not available
            usdt = balance.get('USDT', {})
            if wallet_balance == 0:
                wallet_balance = float(usdt.get('total') or 0)
            if available_balance == 0:
                available_balance = float(usdt.get('free') or 0)
            
            result = {
                # Correct Binance Futures fields
                'walletBalance': wallet_balance,      # "Balance" in Binance UI
                'marginBalance': margin_balance,      # "Margin Balance" in Binance UI
                'availableBalance': available_balance, # Available for trading
                'unrealizedPnl': unrealized_pnl,      # "Unrealized PNL" in Binance UI
                # Legacy fields for compatibility
                'free': available_balance,
                'used': margin_balance - available_balance,
                'total': margin_balance
            }
            
            self.last_balance = margin_balance  # Use margin balance as total
            logger.info(f"Balance: wallet={wallet_balance:.2f}, margin={margin_balance:.2f}, available={available_balance:.2f}, unrealizedPnl={unrealized_pnl:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"Balance fetch error: {e}")
            return {'walletBalance': 0, 'marginBalance': 0, 'availableBalance': 0, 'unrealizedPnl': 0, 'free': 0, 'used': 0, 'total': self.last_balance}
    
    async def get_positions(self, fast: bool = False) -> list:
        """Binance'den aÃ§Ä±k pozisyonlarÄ± Ã§ek. fast=True skips expensive openTime lookup."""
        logger.info(f"get_positions called: enabled={self.enabled}, exchange={self.exchange is not None}")
        
        if not self.enabled or not self.exchange:
            logger.warning(f"get_positions early return: enabled={self.enabled}, exchange={self.exchange is not None}")
            return []
            
        try:
            # Use Binance fapiPrivateV2GetPositionRisk directly - fapiPrivateGetAccount returns 404
            raw_positions = None
            try:
                raw_positions = await self.exchange.fapiPrivateV2GetPositionRisk()
                logger.info(f"Binance API returned {len(raw_positions)} position entries")
            except Exception as e:
                logger.warning(f"Direct API failed ({e}), using CCXT fetch_positions")
                raw_positions = None
            
            if raw_positions:
                # Process direct Binance API response
                result = []
                skipped_symbols = []
                for p in raw_positions:
                    position_amt = float(p.get('positionAmt', 0) or 0)
                    symbol = p.get('symbol', '')
                    if abs(position_amt) > 0:
                        symbol = p.get('symbol', '')
                        side = 'LONG' if position_amt > 0 else 'SHORT'
                        entry_price = float(p.get('entryPrice', 0) or 0)
                        unrealized_pnl = float(p.get('unRealizedProfit', 0) or 0)
                        notional = abs(float(p.get('notional', 0) or 0))
                        leverage = int(p.get('leverage', 1) or 1)
                        position_margin = float(p.get('isolatedMargin', 0) or p.get('initialMargin', 0) or 0)
                        if position_margin == 0 and notional > 0 and leverage > 0:
                            position_margin = notional / leverage
                        
                        # Calculate PnL percentage
                        pnl_percent = (unrealized_pnl / position_margin * 100) if position_margin > 0 else 0
                        
                        # Read openTime from SQLite (single source of truth)
                        try:
                            db_ot = await db_manager.get_position_open_time(symbol)
                            open_time_val = db_ot if db_ot else int(p.get('updateTime', datetime.now().timestamp() * 1000))
                        except:
                            open_time_val = int(p.get('updateTime', datetime.now().timestamp() * 1000))
                        result.append({
                            'symbol': symbol,
                            'side': side,
                            'entryPrice': entry_price,
                            'sizeUsd': notional,
                            'unrealizedPnl': unrealized_pnl,
                            'pnlPercent': pnl_percent,
                            'leverage': leverage,
                            'initialMargin': position_margin,
                            'size': abs(position_amt),           # Phase 149: Fix missing size field
                            'contracts': abs(position_amt),
                            'markPrice': float(p.get('markPrice', entry_price) or entry_price),  # Phase 149: Add markPrice
                            'openTime': open_time_val
                        })
                    else:
                        # Track symbols with 0 positionAmt
                        if symbol.endswith('USDT'):
                            skipped_symbols.append(f"{symbol}:{position_amt}")
                            # Log detailed info for suspected missing positions
                            if any(x in symbol for x in ['HANA', 'BUSDT', 'FLOKI', 'PORTAL', 'MEGA']):
                                notional = float(p.get('notional', 0) or 0)
                                entry = float(p.get('entryPrice', 0) or 0)
                                pnl = float(p.get('unRealizedProfit', 0) or 0)
                                logger.warning(f"ðŸ” Suspected missing: {symbol} posAmt={position_amt} notional={notional} entry={entry} pnl={pnl}")
                
                # Log any skipped USDT symbols (these might be the missing ones)
                if skipped_symbols:
                    logger.info(f"âš ï¸ Skipped {len(skipped_symbols)} positions with positionAmt=0")
                
                # Log ALL active position symbols for debugging
                active_symbols = sorted([r['symbol'] for r in result])
                logger.info(f"ðŸ“‹ Active positions ({len(result)}): {', '.join(active_symbols)}")
                
                logger.info(f"get_positions returning {len(result)} active positions (direct API)")
                return sorted(result, key=lambda x: x.get('openTime', 0), reverse=True)
            
            # Fallback to CCXT if direct API failed
            positions = await self.exchange.fetch_positions()
            logger.info(f"fetch_positions returned {len(positions)} items from CCXT")
            result = []
            skipped_count = 0
            
            for p in positions:
                contracts = float(p.get('contracts') or 0)
                notional = float(p.get('notional') or 0)
                raw_info = p.get('info', {})
                raw_position_amt = float(raw_info.get('positionAmt', 0) or 0)
                
                # Check if position is active using multiple indicators
                # Some CCXT versions may not populate 'contracts' correctly
                is_active = abs(contracts) > 0 or abs(notional) > 0 or abs(raw_position_amt) > 0
                
                if is_active:
                    # CCXT symbol format: BTC/USDT:USDT -> BTCUSDT
                    symbol = p.get('symbol', '').replace('/USDT:USDT', 'USDT')
                    
                    
                    # Determine side correctly:
                    # 1. Check CCXT side field first
                    # 2. Fall back to raw Binance positionAmt (negative = SHORT)
                    ccxt_side = p.get('side', '').upper()
                    
                    if ccxt_side in ['LONG', 'SHORT']:
                        side = ccxt_side
                    elif raw_position_amt < 0:
                        side = 'SHORT'
                    elif raw_position_amt > 0:
                        side = 'LONG'
                    else:
                        # Fallback to contracts sign
                        side = 'LONG' if contracts > 0 else 'SHORT'
                    
                    logger.info(f"Found active position: {symbol} side={side} contracts={contracts} raw_amt={raw_position_amt}")
                    
                    notional = abs(float(p.get('notional') or 0))
                    position_margin = float(raw_info.get('positionInitialMargin', 0) or raw_info.get('initialMargin', 0) or 0)
                    
                    # Get raw leverage from Binance directly
                    raw_leverage = int(p.get('leverage') or raw_info.get('leverage') or 1)
                    
                    # Calculate leverage from notional/margin (for verification)
                    if position_margin > 0:
                        calculated_leverage = int(round(notional / position_margin))
                    else:
                        calculated_leverage = raw_leverage
                    
                    # Use raw Binance leverage instead of calculated (more accurate)
                    final_leverage = raw_leverage
                    
                    logger.info(f"  ðŸ“Š {symbol}: raw_lev={raw_leverage}x, calc_lev={calculated_leverage}x, margin=${position_margin:.2f}, notional=${notional:.2f}")
                    
                    # Calculate PnL percentage based on margin (ROI)
                    unrealized_pnl = float(p.get('unrealizedPnl') or 0)
                    if position_margin > 0:
                        pnl_percent = (unrealized_pnl / position_margin) * 100
                    else:
                        pnl_percent = float(p.get('percentage') or 0)
                    
                    # Get position open time from SQLite
                    open_time = int(datetime.now().timestamp() * 1000)  # Default to now
                    
                    # Read from SQLite positions table (single source of truth)
                    try:
                        db_open_time = await db_manager.get_position_open_time(symbol)
                        if db_open_time:
                            open_time = db_open_time
                    except Exception as e:
                        logger.warning(f"Could not get openTime from SQLite for {symbol}: {e}")
                    
                    # Phase 232: Use raw_position_amt when contracts==0
                    position_amount = abs(contracts) if abs(contracts) > 0 else abs(raw_position_amt)
                    entry_price = float(p.get('entryPrice') or 0)
                    mark_price = float(p.get('markPrice') or 0)
                    
                    # Phase 204: Use currentPrice from engine position (scanner/WS close price)
                    # instead of markPrice for exit decisions â€” markPrice can spike with wicks
                    engine_pos = None
                    if global_paper_trader:
                        for ep in global_paper_trader.positions:
                            if ep.get('symbol') == symbol:
                                engine_pos = ep
                                break
                    current_price = float(engine_pos.get('currentPrice', 0)) if engine_pos else 0
                    if current_price <= 0:
                        current_price = mark_price  # Fallback to markPrice if no engine price
                    
                    # ================================================================
                    # Phase 145: Calculate dynamic TP/SL/Trail for live positions
                    # ================================================================
                    # Use same formulas as paper trading
                    # Phase 221: Use same formula as open_position for consistency
                    sl_atr_mult = (global_paper_trader.sl_atr / 10) if global_paper_trader else 1.5
                    tp_atr_mult = (global_paper_trader.tp_atr / 10) if global_paper_trader else 3.0
                    trail_activation_atr = 1.5
                    trail_distance_atr = 1.0
                    exit_tightness = global_paper_trader.exit_tightness if global_paper_trader else 1.0
                    
                    # Estimate ATR as ~1.5% of price (typical for crypto)
                    estimated_atr = entry_price * 0.015
                    
                    # Phase 221: Apply exit_tightness + dynamic_atr_mult (was missing)
                    dyn_mult = global_paper_trader.calculate_dynamic_atr_multiplier(estimated_atr, entry_price) if global_paper_trader else 1.0
                    adjusted_sl_atr = sl_atr_mult * exit_tightness * dyn_mult
                    adjusted_tp_atr = tp_atr_mult * exit_tightness * dyn_mult
                    adjusted_trail_activation = trail_activation_atr * exit_tightness * dyn_mult
                    adjusted_trail_distance = trail_distance_atr * exit_tightness * dyn_mult
                    
                    # Calculate TP/SL based on side
                    if side == 'LONG':
                        sl = entry_price - (estimated_atr * adjusted_sl_atr)
                        tp = entry_price + (estimated_atr * adjusted_tp_atr)
                        trail_activation = entry_price + (estimated_atr * adjusted_trail_activation)
                    else:  # SHORT
                        sl = entry_price + (estimated_atr * adjusted_sl_atr)
                        tp = entry_price - (estimated_atr * adjusted_tp_atr)
                        trail_activation = entry_price - (estimated_atr * adjusted_trail_activation)
                    
                    trailing_stop = sl  # Initial trailing stop = SL
                    trail_distance = estimated_atr * adjusted_trail_distance
                    
                    # ================================================================
                    # Phase 146: Persistent Trailing State (server-side)
                    # ================================================================
                    # Get or create trailing state for this symbol
                    if symbol not in self.trailing_state:
                        self.trailing_state[symbol] = {
                            'isActive': False,
                            'trailingStop': sl,
                            'peakPrice': current_price,
                            'activatedAt': None,
                            'openTime': open_time  # Phase 232: for hold-time guard
                        }
                    
                    # Phase 205: Use candle close price for trail decisions
                    candle_close_price = last_candle_close.get(symbol, current_price)
                    
                    trail_state = self.trailing_state[symbol]
                    roi_pct = pnl_percent
                    # Phase 231j: Dual-condition â€” aligned with scanner/WS/backup/sync
                    # Phase 231l: Side-aware (not abs) â€” same as other paths
                    if side == 'LONG':
                        fb_price_move = ((current_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                    else:
                        fb_price_move = ((entry_price - current_price) / entry_price) * 100 if entry_price > 0 else 0
                    
                    # Phase 231h â†’ 238A: Dynamic breakeven prices
                    _fb_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP_FB')
                    be_long = entry_price * (1 + _fb_buf)
                    be_short = entry_price * (1 - _fb_buf)
                    
                    # Phase 231j: price_move >= 0.75 OR roi >= 5.0
                    if not trail_state['isActive'] and (fb_price_move >= 0.75 or roi_pct >= 5.0):
                        trail_state['isActive'] = True
                        trail_state['activatedAt'] = datetime.now().isoformat()
                        trail_state['peakPrice'] = current_price
                        logger.info(f"ðŸ”„ TRAIL+BE(fallback): {symbol} pm={fb_price_move:.2f}% roi={roi_pct:.1f}%")
                    
                    is_trailing_active = trail_state['isActive']
                    
                    # Update trailing stop if active
                    if is_trailing_active:
                        if side == 'LONG':
                            # Track peak price using candle close (Phase 205)
                            if candle_close_price > trail_state['peakPrice']:
                                trail_state['peakPrice'] = candle_close_price
                            trailing_stop = trail_state['peakPrice'] - trail_distance
                            # Phase 231h: Clamp â€” never below breakeven
                            trailing_stop = max(trailing_stop, be_long)
                            # Keep the highest trailing stop
                            if trailing_stop > trail_state['trailingStop']:
                                trail_state['trailingStop'] = trailing_stop
                                logger.debug(f"  ðŸ“ˆ {symbol} LONG trailing stop raised to ${trailing_stop:.6f}")
                        else:  # SHORT
                            # Track lowest price using candle close (Phase 205)
                            if candle_close_price < trail_state['peakPrice']:
                                trail_state['peakPrice'] = candle_close_price
                            trailing_stop = trail_state['peakPrice'] + trail_distance
                            # Phase 231h: Clamp â€” never above breakeven
                            trailing_stop = min(trailing_stop, be_short)
                            # Keep the lowest trailing stop for shorts
                            if trailing_stop < trail_state['trailingStop'] or trail_state['trailingStop'] == sl:
                                trail_state['trailingStop'] = trailing_stop
                                logger.debug(f"  ðŸ“‰ {symbol} SHORT trailing stop lowered to ${trailing_stop:.6f}")
                        
                        trailing_stop = trail_state['trailingStop']
                        
                        # ================================================================
                        # Phase 147: Check if trailing stop is HIT and close position
                        # ================================================================
                        # Phase 212: Emergency SL runs BEFORE Flash Trade Guard
                        # Flash crash korumasÄ± ilk 60 saniyede de aktif olmalÄ±
                        if engine_pos and check_emergency_sl_static(engine_pos, current_price, trailing_stop):
                            excess_pct = abs(current_price - trailing_stop) / entry_price * 100
                            close_reason = f"EMERGENCY_SL: price ${current_price:.6f} exceeded trail ${trailing_stop:.6f} by {excess_pct:.2f}%"
                            logger.warning(f"ðŸš¨ EMERGENCY SL (pre-guard): {symbol} {side} | {close_reason}")
                            should_close = True
                        else:
                            should_close = False
                            close_reason = ""
                        
                        if should_close:
                            # Emergency â€” skip Flash Trade Guard, close immediately
                            logger.warning(f"ðŸ”´ LIVE TRAIL EXIT: {symbol} {side} | {close_reason}")
                            if not hasattr(self, 'pending_closes'):
                                self.pending_closes = []
                            self.pending_closes.append({
                                'symbol': symbol,
                                'side': side,
                                'reason': close_reason,
                                'amount': position_amount,
                                'pnl_percent': pnl_percent,
                                # Phase 232b: Position snapshot for trade_data + DB persist
                                'pos_snapshot': {
                                    'entryPrice': entry_price,
                                    'exitPrice': current_price,
                                    'unrealizedPnl': unrealized_pnl,
                                    'leverage': calculated_leverage,
                                    'sizeUsd': notional,
                                    'margin': position_margin,
                                    'stopLoss': sl,
                                    'takeProfit': tp,
                                    'trailActivation': trail_activation,
                                    'trailingStop': trailing_stop,
                                    'isTrailingActive': is_trailing_active,
                                    'atr': estimated_atr,
                                    'spreadLevel': engine_pos.get('spreadLevel', 'unknown') if engine_pos else 'unknown',
                                    'signalScore': engine_pos.get('signalScore', 0) if engine_pos else 0,
                                    'openTime': engine_pos.get('openTime', 0) if engine_pos else 0,
                                    'binance_order_id': engine_pos.get('binance_order_id', '') if engine_pos else '',
                                    'hurst': engine_pos.get('hurst', 0.5) if engine_pos else 0.5,
                                },
                            })
                            continue
                        
                        # Phase 210: Flash Trade Guard â€” minimum 60s hold time
                        MIN_HOLD_SECONDS = 60
                        open_time_ms = trail_state.get('openTime', 0)
                        if open_time_ms > 0:
                            hold_duration = datetime.now().timestamp() - (open_time_ms / 1000)
                            if hold_duration < MIN_HOLD_SECONDS:
                                continue  # Skip trail exit check â€” too early
                        
                        should_close = False
                        close_reason = ""
                        
                        if side == 'LONG':
                            # LONG: candle close drops below trailing stop
                            if candle_close_price <= trailing_stop:
                                should_close = True
                                close_reason = f"TRAIL_EXIT: close ${candle_close_price:.6f} <= trail ${trailing_stop:.6f}"
                        else:  # SHORT
                            # SHORT: candle close rises above trailing stop
                            if candle_close_price >= trailing_stop:
                                should_close = True
                                close_reason = f"TRAIL_EXIT: close ${candle_close_price:.6f} >= trail ${trailing_stop:.6f}"
                        
                        # Phase 212: Duplicate Emergency SL removed â€” pre-guard version handles this
                        # (See L1527-1557 above)
                        if should_close:
                            logger.warning(f"ðŸ”´ LIVE TRAIL EXIT: {symbol} {side} | {close_reason}")
                            logger.warning(f"   ðŸ“Š ROI: {pnl_percent:.1f}% | PnL: ${unrealized_pnl:.2f}")
                            
                            # Queue for closing - don't close directly in get_positions to avoid blocking
                            if not hasattr(self, 'pending_closes'):
                                self.pending_closes = []
                            
                            self.pending_closes.append({
                                'symbol': symbol,
                                'side': side,
                                'amount': position_amount,
                                'reason': close_reason,
                                'timestamp': datetime.now().isoformat(),
                                # Phase 232b: Position snapshot for trade_data + DB persist
                                'pos_snapshot': {
                                    'entryPrice': entry_price,
                                    'exitPrice': candle_close_price,
                                    'unrealizedPnl': unrealized_pnl,
                                    'leverage': calculated_leverage,
                                    'sizeUsd': notional,
                                    'margin': position_margin,
                                    'stopLoss': sl,
                                    'takeProfit': tp,
                                    'trailActivation': trail_activation,
                                    'trailingStop': trailing_stop,
                                    'isTrailingActive': is_trailing_active,
                                    'atr': estimated_atr,
                                    'spreadLevel': engine_pos.get('spreadLevel', 'unknown') if engine_pos else 'unknown',
                                    'signalScore': engine_pos.get('signalScore', 0) if engine_pos else 0,
                                    'openTime': engine_pos.get('openTime', 0) if engine_pos else 0,
                                    'binance_order_id': engine_pos.get('binance_order_id', '') if engine_pos else '',
                                    'hurst': engine_pos.get('hurst', 0.5) if engine_pos else 0.5,
                                },
                            })
                            
                            # Clear trailing state after close triggered
                            del self.trailing_state[symbol]
                    
                    result.append({
                        'id': f"BIN_{symbol}_{int(datetime.now().timestamp())}",
                        'symbol': symbol,
                        'side': side,  # Use calculated side from CCXT/raw info
                        'size': position_amount,        # Internal usage
                        'contracts': position_amount,   # Phase 141: Binance-compatible field
                        'sizeUsd': notional,
                        'entryPrice': entry_price,
                        'markPrice': mark_price,
                        'unrealizedPnl': unrealized_pnl,
                        'unrealizedPnlPercent': pnl_percent,
                        'leverage': calculated_leverage,  # notional/margin - accurate for cross margin
                        'margin': position_margin,  # Add margin for UI
                        'liquidationPrice': float(p.get('liquidationPrice') or 0),
                        'marginType': p.get('marginMode', 'cross'),
                        'openTime': open_time,  # Actual position open time from trade history
                        'isLive': True,  # Mark as live position
                        # Phase 145: Dynamic TP/SL/Trail values
                        'stopLoss': sl,
                        'takeProfit': tp,
                        'trailActivation': trail_activation,
                        'trailingStop': trailing_stop,
                        'trailDistance': trail_distance,
                        'isTrailingActive': is_trailing_active,
                        'atr': estimated_atr
                    })
            
            # Phase 147: Process pending closes
            if hasattr(self, 'pending_closes') and self.pending_closes:
                for close_order in self.pending_closes:
                    logger.info(f"ðŸ”„ Processing pending close: {close_order['symbol']}")
                    # Note: This will be executed on next tick - positions will close async
                    asyncio.create_task(self._execute_pending_close(close_order))
                self.pending_closes = []
            
            logger.info(f"get_positions returning {len(result)} active positions")
            self.last_positions = result
            return result
            
        except Exception as e:
            logger.error(f"Positions fetch error: {e}")
            return self.last_positions
    
    async def set_leverage(self, symbol: str, leverage: int) -> bool:
        """KaldÄ±raÃ§ ayarla."""
        if not self.enabled or not self.exchange:
            return False
            
        try:
            ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
            await self.exchange.set_leverage(leverage, ccxt_symbol)
            logger.info(f"âš™ï¸ Leverage set: {symbol} -> {leverage}x")
            return True
        except Exception as e:
            err_str = str(e).lower()
            # "already set" / "No need to change" is benign â€” Binance returns error if same leverage
            if 'already' in err_str or 'no need' in err_str or 'not modified' in err_str:
                logger.info(f"âš™ï¸ Leverage already {leverage}x for {symbol} (OK)")
                return True
            logger.error(f"âŒ Leverage set FAILED for {symbol} -> {leverage}x: {e}")
            return False  # Real error â€” caller should abort order

    def _extract_exchange_error(self, error: Exception) -> str:
        """Normalize exchange error to a short, UI-safe message."""
        try:
            msg = str(error)
        except Exception:
            msg = repr(error)
        msg = (msg or "unknown_exchange_error").replace("\n", " ").strip()
        return msg[:220]

    def _normalize_order_amount(self, ccxt_symbol: str, price: float, target_usd: float, market: dict) -> tuple:
        """
        Normalize amount for Binance futures constraints.
        Returns: (amount, notional_usd, min_notional_usd)
        """
        safe_price = max(float(price or 0), 1e-12)
        amount = max(0.0, float(target_usd or 0) / safe_price)
        limits = (market or {}).get('limits', {})
        min_amount = float((limits.get('amount') or {}).get('min') or 0.0)
        min_cost = float((limits.get('cost') or {}).get('min') or 0.0)
        min_notional = max(5.0, min_cost)

        if min_amount > 0 and amount < min_amount:
            amount = min_amount
        if amount * safe_price < min_notional:
            amount = max(amount, min_notional / safe_price)

        try:
            amount = float(self.exchange.amount_to_precision(ccxt_symbol, amount))
        except Exception:
            pass

        if min_amount > 0 and amount < min_amount:
            amount = min_amount
            try:
                amount = float(self.exchange.amount_to_precision(ccxt_symbol, amount))
            except Exception:
                pass

        notional = amount * safe_price
        if notional < min_notional * 0.98:
            precision_info = (market or {}).get('precision') or {}
            amount_precision = precision_info.get('amount')
            if isinstance(amount_precision, int):
                step = 10 ** (-amount_precision)
                amount = math.ceil((min_notional / safe_price) / step) * step
                amount = round(amount, amount_precision)
                try:
                    amount = float(self.exchange.amount_to_precision(ccxt_symbol, amount))
                except Exception:
                    pass
                notional = amount * safe_price

        return amount, notional, min_notional
    
    async def place_market_order(self, symbol: str, side: str, size_usd: float, leverage: int) -> dict:
        """Market emir gÃ¶nder â€” Phase 186: with execution quality logging."""
        self.last_order_error = None
        if not self.enabled or not self.exchange:
            self.last_order_error = "live_trader_disabled"
            logger.error("âŒ LiveBinanceTrader not enabled, order rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            # KaldÄ±raÃ§ ayarla â€” abort if real failure
            set_ok = await self.set_leverage(symbol, leverage)
            if not set_ok:
                self.last_order_error = f"set_leverage_failed:{leverage}x"
                logger.error(f"âŒ Aborting market order {symbol}: leverage set to {leverage}x failed")
                return None
            
            # Phase 186: Capture pre-order book state
            ticker = await self.exchange.fetch_ticker(ccxt_symbol)
            price = ticker['last']
            best_bid = ticker.get('bid', price)
            best_ask = ticker.get('ask', price)
            mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else price
            spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0

            # Amount precision + min lot + min notional normalization
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            if not market:
                self.last_order_error = f"market_not_found:{ccxt_symbol}"
                logger.error(f"âŒ BINANCE ORDER FAILED: {side} {symbol} | Unknown market {ccxt_symbol}")
                return None
            amount, effective_notional, min_notional = self._normalize_order_amount(
                ccxt_symbol=ccxt_symbol,
                price=price,
                target_usd=size_usd,
                market=market,
            )
            if effective_notional < min_notional * 0.95 or amount <= 0:
                self.last_order_error = (
                    f"amount_too_small:notional={effective_notional:.3f}<min={min_notional:.3f}"
                )
                logger.error(
                    f"âŒ BINANCE ORDER FAILED: {side} {symbol} | "
                    f"invalid normalized amount={amount} notional={effective_notional:.3f} min={min_notional:.3f}"
                )
                return None
            
            send_time = datetime.now().timestamp()
            
            # Emir gÃ¶nder
            order_side = 'buy' if side == 'LONG' else 'sell'
            order = await self.exchange.create_market_order(
                ccxt_symbol,
                order_side,
                amount,
                params={'reduceOnly': False}
            )
            
            fill_time = datetime.now().timestamp()
            avg_fill = float(order.get('average') or price)
            fee_info = order.get('fee') or {}
            fee_cost = float(fee_info.get('cost') or 0)
            
            # Phase 186: Calculate slippage
            if side == 'LONG':
                reference = best_ask if best_ask else price
                slippage_pct = (avg_fill - reference) / reference * 100 if reference > 0 else 0
            else:
                reference = best_bid if best_bid else price
                slippage_pct = (reference - avg_fill) / reference * 100 if reference > 0 else 0
            
            latency_ms = (fill_time - send_time) * 1000
            
            logger.info(f"ðŸ“¤ BINANCE ORDER SENT: {side} {symbol}")
            logger.info(f"   ðŸ’µ Size: ${size_usd:.2f} | Effective: ${effective_notional:.2f} | Amount: {amount:.6f}")
            logger.info(f"   ðŸ“Š Leverage: {leverage}x | Price: ${price:.4f}")
            logger.info(f"   ðŸ†” Order ID: {order.get('id', 'N/A')}")
            logger.warning(f"ðŸ“Š EXEC_QUALITY: {side} {symbol} MARKET | bid=${(best_bid or 0.0):.6f} ask=${(best_ask or 0.0):.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | fee=${fee_cost:.4f} | {latency_ms:.0f}ms")
            
            return {
                'id': order.get('id'),
                'symbol': symbol,
                'side': side,
                'amount': amount,
                'price': avg_fill,  # Use actual fill price
                'cost': effective_notional,
                'status': order.get('status', 'filled'),
                'timestamp': int(datetime.now().timestamp() * 1000),
                'slippage_pct': slippage_pct,
                'spread_pct': spread_pct,
                'fee': fee_cost,
            }
            
        except Exception as e:
            self.last_order_error = self._extract_exchange_error(e)
            logger.error(f"âŒ BINANCE ORDER FAILED: {side} {symbol} | Error: {self.last_order_error}")
            return None
    
    async def place_limit_entry_order(self, symbol: str, side: str, size_usd: float, leverage: int) -> dict:
        """
        Phase 186: Limit entry with aggressive pricing + 3s timeout â†’ market fallback.
        LONG: limit at best_ask + 2 ticks (crosses spread slightly for fast fill)
        SHORT: limit at best_bid - 2 ticks
        """
        self.last_order_error = None
        if not self.enabled or not self.exchange:
            self.last_order_error = "live_trader_disabled"
            logger.error("âŒ LiveBinanceTrader not enabled, order rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            set_ok = await self.set_leverage(symbol, leverage)
            if not set_ok:
                self.last_order_error = f"set_leverage_failed:{leverage}x"
                logger.error(f"âŒ Aborting limit entry {symbol}: leverage set to {leverage}x failed")
                return None
            
            # Fetch ticker for pricing
            ticker = await self.exchange.fetch_ticker(ccxt_symbol)
            price = ticker['last']
            best_bid = ticker.get('bid', price)
            best_ask = ticker.get('ask', price)
            mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else price
            spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0
            
            # ===== Phase 201: Order Book Depth Check =====
            try:
                orderbook = await self.exchange.fetch_order_book(ccxt_symbol, 10)
                relevant_levels = orderbook['asks'][:10] if side == 'LONG' else orderbook['bids'][:10]
                available_liquidity_usd = sum(level[0] * level[1] for level in relevant_levels)
                
                MAX_BOOK_IMPACT_PCT = 0.20  # Max 20% of visible liquidity
                if available_liquidity_usd > 0 and size_usd > available_liquidity_usd * MAX_BOOK_IMPACT_PCT:
                    adjusted_size = available_liquidity_usd * 0.10  # Reduce to 10% of book
                    logger.warning(f"ðŸš« LIQUIDITY_GUARD: {symbol} size ${size_usd:.2f} > {MAX_BOOK_IMPACT_PCT*100:.0f}% of book (${available_liquidity_usd:.0f}) â†’ adjusted to ${adjusted_size:.2f}")
                    size_usd = max(adjusted_size, 5.0)  # Min $5 notional floor
                elif available_liquidity_usd > 0:
                    logger.debug(f"ðŸ“Š BOOK_DEPTH: {symbol} size=${size_usd:.2f} vs book=${available_liquidity_usd:.0f} ({size_usd/available_liquidity_usd*100:.1f}%)")
            except Exception as ob_err:
                logger.debug(f"Order book depth check error: {ob_err}")
            
            # Minimum lot size + precision + min notional
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            if not market:
                self.last_order_error = f"market_not_found:{ccxt_symbol}"
                logger.error(f"âŒ LIMIT ENTRY FAILED: {side} {symbol} | Unknown market {ccxt_symbol}")
                return None
            amount, effective_notional, min_notional = self._normalize_order_amount(
                ccxt_symbol=ccxt_symbol,
                price=price,
                target_usd=size_usd,
                market=market,
            )
            if effective_notional < min_notional * 0.95 or amount <= 0:
                self.last_order_error = (
                    f"amount_too_small:notional={effective_notional:.3f}<min={min_notional:.3f}"
                )
                logger.error(
                    f"âŒ LIMIT ENTRY FAILED: {side} {symbol} | "
                    f"invalid normalized amount={amount} notional={effective_notional:.3f} min={min_notional:.3f}"
                )
                return None
            tick_size = 0.0001  # Default
            # Get price tick size
            precision_info = market.get('precision') or {}
            tick_size = precision_info.get('price', 0.0001)
            if isinstance(tick_size, int):
                tick_size = 10 ** (-tick_size)  # ccxt sometimes returns precision as decimal places
            
            # Aggressive limit pricing: cross the spread slightly
            order_side = 'buy' if side == 'LONG' else 'sell'
            if side == 'LONG':
                limit_price = best_ask + (tick_size * 2)  # 2 ticks above ask
            else:
                limit_price = best_bid - (tick_size * 2)  # 2 ticks below bid
            
            limit_price = float(self.exchange.price_to_precision(ccxt_symbol, limit_price))
            amount = float(self.exchange.amount_to_precision(ccxt_symbol, amount))
            
            send_time = datetime.now().timestamp()
            
            # Send limit order (IOC would be better but GTC + cancel is more portable)
            order = await self.exchange.create_limit_order(
                ccxt_symbol,
                order_side,
                amount,
                limit_price,
                params={'reduceOnly': False, 'timeInForce': 'GTC'}
            )
            
            order_id = order.get('id')
            logger.info(f"ðŸ“¤ LIMIT ENTRY: {side} {symbol} @ ${limit_price:.6f} | Amount: {amount}")
            
            # Wait 3 seconds for fill
            await asyncio.sleep(3)
            
            # Check fill status
            order_check = await self.exchange.fetch_order(order_id, ccxt_symbol)
            status = order_check.get('status', 'unknown')
            filled = float(order_check.get('filled') or 0)
            remaining = float(order_check.get('remaining') or 0)
            avg_fill = float(order_check.get('average') or 0)
            
            fill_time = datetime.now().timestamp()
            latency_ms = (fill_time - send_time) * 1000
            
            if status == 'closed' and remaining <= 0:
                # Fully filled via limit! Best case â€” reduced slippage
                fee_info = order_check.get('fee') or {}
                fee_cost = float(fee_info.get('cost') or 0)
                
                if side == 'LONG':
                    slippage_pct = (avg_fill - best_ask) / best_ask * 100 if best_ask > 0 else 0
                else:
                    slippage_pct = (best_bid - avg_fill) / best_bid * 100 if best_bid > 0 else 0
                
                logger.warning(f"ðŸ“Š EXEC_QUALITY: {side} {symbol} LIMIT_FILLED | bid=${(best_bid or 0.0):.6f} ask=${(best_ask or 0.0):.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | {latency_ms:.0f}ms")
                
                return {
                    'id': order_id,
                    'symbol': symbol,
                    'side': side,
                    'amount': filled,
                    'price': avg_fill,
                    'cost': effective_notional,
                    'status': 'filled',
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    'slippage_pct': slippage_pct,
                    'spread_pct': spread_pct,
                    'fee': fee_cost,
                    'entry_method': 'LIMIT',
                }
            
            else:
                # Not fully filled â€” cancel remainder and market fallback
                if filled > 0:
                    logger.warning(f"âš ï¸ LIMIT_PARTIAL_ENTRY: {side} {symbol} filled={filled:.4f} remaining={remaining:.4f}")
                
                # Cancel unfilled portion
                try:
                    await self.exchange.cancel_order(order_id, ccxt_symbol)
                except:
                    pass  # May already be filled/cancelled
                
                if remaining > 0:
                    try:
                        remaining = float(self.exchange.amount_to_precision(ccxt_symbol, remaining))
                    except Exception:
                        pass
                    # Market fallback for unfilled portion
                    logger.warning(f"ðŸ”„ LIMITâ†’MARKET FALLBACK: {side} {symbol} | {remaining:.4f} unfilled â†’ market")
                    try:
                        fallback_order = await self.exchange.create_market_order(
                            ccxt_symbol,
                            order_side,
                            remaining,
                            params={'reduceOnly': False}
                        )
                        fallback_fill = float(fallback_order.get('average') or price)
                        
                        # Weighted average fill price
                        if filled > 0:
                            total_filled = filled + float(fallback_order.get('filled') or remaining)
                            avg_fill = (avg_fill * filled + fallback_fill * float(fallback_order.get('filled') or remaining)) / total_filled if total_filled > 0 else fallback_fill
                        else:
                            avg_fill = fallback_fill
                            
                    except Exception as fb_err:
                        self.last_order_error = self._extract_exchange_error(fb_err)
                        logger.error(f"âŒ MARKET FALLBACK FAILED: {side} {symbol} | {self.last_order_error}")
                        if filled <= 0:
                            return None  # Total failure
                        # If partially filled via limit, continue with what we have
                
                if side == 'LONG':
                    slippage_pct = (avg_fill - best_ask) / best_ask * 100 if best_ask > 0 else 0
                else:
                    slippage_pct = (best_bid - avg_fill) / best_bid * 100 if best_bid > 0 else 0
                
                logger.warning(f"ðŸ“Š EXEC_QUALITY: {side} {symbol} LIMITâ†’MKT | bid=${(best_bid or 0.0):.6f} ask=${(best_ask or 0.0):.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | {latency_ms:.0f}ms")
                
                return {
                    'id': order_id,
                    'symbol': symbol,
                    'side': side,
                    'amount': filled + remaining,  # Total intended
                    'price': avg_fill,
                    'cost': effective_notional,
                    'status': 'filled',
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    'slippage_pct': slippage_pct,
                    'spread_pct': spread_pct,
                    'entry_method': 'LIMIT_MKT_FALLBACK',
                }
                
        except Exception as e:
            self.last_order_error = self._extract_exchange_error(e)
            logger.error(f"âŒ LIMIT ENTRY FAILED: {side} {symbol} | {self.last_order_error} â€” falling back to market")
            # Full market fallback on any error
            return await self.place_market_order(symbol, side, size_usd, leverage)
    
    async def close_position(self, symbol: str, side: str, amount: float) -> dict:
        """Pozisyon kapat (reduceOnly=True) â€” Market order. Phase 186: with exec logging."""
        if not self.enabled or not self.exchange:
            logger.error("âŒ LiveBinanceTrader not enabled, close rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            # Phase 186: Capture pre-close book state
            try:
                ticker = await self.exchange.fetch_ticker(ccxt_symbol)
                best_bid = ticker.get('bid', 0)
                best_ask = ticker.get('ask', 0)
                mid_price = (best_bid + best_ask) / 2 if best_bid and best_ask else ticker.get('last', 0)
                spread_pct = ((best_ask - best_bid) / mid_price * 100) if mid_price > 0 and best_bid and best_ask else 0
            except:
                best_bid = best_ask = mid_price = spread_pct = 0
            
            send_time = datetime.now().timestamp()
            
            # KapanÄ±ÅŸ emri - ters yÃ¶nde reduceOnly
            close_side = 'sell' if side == 'LONG' else 'buy'
            order = await self.exchange.create_market_order(
                ccxt_symbol,
                close_side,
                amount,
                params={'reduceOnly': True}
            )
            
            fill_time = datetime.now().timestamp()
            avg_fill = float(order.get('average') or 0)
            fee_info = order.get('fee') or {}
            fee_cost = float(fee_info.get('cost') or 0)
            latency_ms = (fill_time - send_time) * 1000
            
            # Slippage: for CLOSE, selling LONG hits bid, buying SHORT hits ask
            if side == 'LONG':
                reference = best_bid if best_bid else avg_fill
                slippage_pct = (reference - avg_fill) / reference * 100 if reference > 0 else 0
            else:
                reference = best_ask if best_ask else avg_fill
                slippage_pct = (avg_fill - reference) / reference * 100 if reference > 0 else 0
            
            logger.info(f"ðŸ“¤ BINANCE CLOSE: {side} {symbol} | Amount: {amount:.6f}")
            logger.info(f"   ðŸ†” Order ID: {order.get('id', 'N/A')}")
            logger.warning(f"ðŸ“Š EXEC_QUALITY_CLOSE: {side} {symbol} | bid=${(best_bid or 0.0):.6f} ask=${(best_ask or 0.0):.6f} spread={spread_pct:.3f}% | fill=${avg_fill:.6f} slip={slippage_pct:+.4f}% | fee=${fee_cost:.4f} | {latency_ms:.0f}ms")
            
            return {
                'id': order.get('id'),
                'symbol': symbol,
                'side': side,
                'amount': amount,
                'status': order.get('status', 'filled'),
                'timestamp': int(datetime.now().timestamp() * 1000),
                'slippage_pct': slippage_pct,
                'fee': fee_cost,
            }
            
        except Exception as e:
            logger.error(f"âŒ BINANCE CLOSE FAILED: {side} {symbol} | Error: {e}")
            # Phase 217: Retry with exponential backoff to prevent ghost positions
            for retry in range(3):
                try:
                    await asyncio.sleep(1 * (retry + 1))
                    logger.warning(f"ðŸ”„ CLOSE RETRY {retry+1}/3: {side} {symbol}")
                    order = await self.exchange.create_market_order(
                        ccxt_symbol, close_side, amount,
                        params={'reduceOnly': True}
                    )
                    logger.info(f"âœ… CLOSE RETRY SUCCESS: {side} {symbol} | Order: {order.get('id', 'N/A')}")
                    return {
                        'id': order.get('id'),
                        'symbol': symbol,
                        'side': side,
                        'amount': amount,
                        'status': order.get('status', 'filled'),
                        'timestamp': int(datetime.now().timestamp() * 1000),
                    }
                except Exception as retry_err:
                    logger.error(f"âŒ CLOSE RETRY {retry+1} FAILED: {retry_err}")
            
            # All retries failed â€” mark as ghost position risk
            logger.critical(f"ðŸš¨ GHOST POSITION RISK: {side} {symbol} close FAILED after 3 retries â€” manual intervention needed")
            return None
    
    async def close_position_limit(self, symbol: str, side: str, amount: float, price: float) -> dict:
        """
        Phase 179: Place a LIMIT close order at exact price (no slippage).
        Used for breakeven close â€” order sits on book until filled.
        """
        if not self.enabled or not self.exchange:
            logger.error("âŒ LiveBinanceTrader not enabled, limit close rejected")
            return None
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            close_side = 'sell' if side == 'LONG' else 'buy'
            
            # Price precision: match market requirements
            markets = await self.exchange.load_markets()
            market = markets.get(ccxt_symbol)
            if market:
                price = self.exchange.price_to_precision(ccxt_symbol, price)
                amount = self.exchange.amount_to_precision(ccxt_symbol, amount)
            
            order = await self.exchange.create_limit_order(
                ccxt_symbol,
                close_side,
                float(amount),
                float(price),
                params={
                    'reduceOnly': True,
                    'timeInForce': 'GTC'  # Good-Till-Cancel
                }
            )
            
            order_id = order.get('id', 'N/A')
            logger.warning(f"ðŸ”’ BREAKEVEN LIMIT ORDER: {side} {symbol} @ ${price} | Amount: {amount} | Order: {order_id}")
            
            return {
                'id': order_id,
                'symbol': symbol,
                'side': side,
                'amount': float(amount),
                'price': float(price),
                'status': order.get('status', 'open'),
                'timestamp': int(datetime.now().timestamp() * 1000)
            }
            
        except Exception as e:
            logger.error(f"âŒ BREAKEVEN LIMIT ORDER FAILED: {side} {symbol} @ ${price} | Error: {e}")
            return None
    
    async def cancel_order(self, symbol: str, order_id: str) -> bool:
        """Phase 179: Cancel an open order."""
        if not self.enabled or not self.exchange:
            return False
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            await self.exchange.cancel_order(order_id, ccxt_symbol)
            logger.info(f"ðŸ—‘ï¸ Order cancelled: {symbol} #{order_id}")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ Cancel order failed: {symbol} #{order_id} - {e}")
            return False
    
    async def check_order_status(self, symbol: str, order_id: str) -> dict:
        """Phase 179: Check if a limit order has been filled."""
        if not self.enabled or not self.exchange:
            return {'status': 'unknown'}
            
        ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
        
        try:
            order = await self.exchange.fetch_order(order_id, ccxt_symbol)
            return {
                'status': order.get('status', 'unknown'),  # open, closed, canceled
                'filled': float(order.get('filled') or 0.0),
                'remaining': float(order.get('remaining') or 0.0),
                'average': float(order.get('average') or 0.0),  # Average fill price
                'price': float(order.get('price') or 0.0),
            }
        except Exception as e:
            logger.warning(f"âš ï¸ Check order status failed: {symbol} #{order_id} - {e}")
            return {'status': 'error', 'error': str(e)}
    
    async def _execute_pending_close(self, close_order: dict):
        """Execute a pending close order from trailing stop hit."""
        try:
            symbol = close_order['symbol']
            side = close_order['side']
            amount = close_order['amount']
            reason = close_order['reason']
            pos_snapshot = close_order.get('pos_snapshot', {})
            
            logger.info(f"ðŸ”´ EXECUTING TRAIL CLOSE: {symbol} {side}")
            logger.info(f"   ðŸ“‹ Reason: {reason}")
            
            result = await self.close_position(symbol, side, amount)
            
            if result:
                logger.info(f"âœ… TRAIL CLOSE SUCCESS: {symbol} | Order ID: {result.get('id')}")
                
                now_ms = int(datetime.now().timestamp() * 1000)
                entry_price = pos_snapshot.get('entryPrice', 0)
                exit_price = pos_snapshot.get('exitPrice', 0)
                pnl = pos_snapshot.get('unrealizedPnl', 0)
                leverage = pos_snapshot.get('leverage', 10)
                size_usd = pos_snapshot.get('sizeUsd', 0)
                margin = pos_snapshot.get('margin', 0) or (size_usd / max(leverage, 1))
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Build trade_data for sync loop
                trade_data = {
                    'id': f"TRAIL_{symbol}_{now_ms}",
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': entry_price,
                    'exitPrice': exit_price,
                    'size': amount,
                    'sizeUsd': size_usd,
                    'pnl': round(pnl, 4),
                    'pnlPercent': close_order.get('pnl_percent', 0),
                    'margin': round(margin, 4),
                    'roi': round(roi, 2),
                    'openTime': pos_snapshot.get('openTime', 0),
                    'closeTime': now_ms,
                    'reason': reason,
                    'closeReason': reason,
                    'leverage': leverage,
                    'isLive': True,
                    'stopLoss': pos_snapshot.get('stopLoss', 0),
                    'takeProfit': pos_snapshot.get('takeProfit', 0),
                    'trailActivation': pos_snapshot.get('trailActivation', 0),
                    'trailingStop': pos_snapshot.get('trailingStop', 0),
                    'isTrailingActive': pos_snapshot.get('isTrailingActive', False),
                    'atr': pos_snapshot.get('atr', 0),
                    'spreadLevel': pos_snapshot.get('spreadLevel', 'unknown'),
                    'signalScore': pos_snapshot.get('signalScore', 0),
                    'hurst': pos_snapshot.get('hurst', 0.5),
                }
                
                # Phase 232b-P1: Write to GLOBAL pending_close_reasons WITH trade_data
                pending_close_reasons[symbol] = {
                    "reason": reason,
                    "original_reason": reason,
                    "timestamp": now_ms,
                    "trade_data": trade_data,
                    "entry_order_id": pos_snapshot.get('binance_order_id', ''),
                }
                
                # Phase 232b-P2: Persist to position_closes for restart safety
                try:
                    close_data = {
                        'symbol': symbol,
                        'side': side,
                        'reason': reason,
                        'original_reason': reason,
                        'entryPrice': entry_price,
                        'exitPrice': exit_price,
                        'pnl': pnl,
                        'leverage': leverage,
                        'sizeUsd': size_usd,
                        'margin': margin,
                        'roi': roi,
                        'timestamp': now_ms,
                        'stopLoss': pos_snapshot.get('stopLoss', 0),
                        'takeProfit': pos_snapshot.get('takeProfit', 0),
                        'atr': pos_snapshot.get('atr', 0),
                        'trailingStop': pos_snapshot.get('trailingStop', 0),
                        'trailActivation': pos_snapshot.get('trailActivation', 0),
                        'signalScore': pos_snapshot.get('signalScore', 0),
                        'spreadLevel': pos_snapshot.get('spreadLevel', 'unknown'),
                        'hurst': pos_snapshot.get('hurst', 0.5),
                        'entry_order_id': pos_snapshot.get('binance_order_id', ''),
                    }
                    safe_create_task(sqlite_manager.save_position_close(close_data))
                    logger.info(f"ðŸ’¾ TRAIL CLOSE persisted to position_closes: {symbol}")
                except Exception as db_err:
                    logger.debug(f"SQLite position_close save error: {db_err}")
            else:
                logger.error(f"âŒ TRAIL CLOSE FAILED: {symbol}")
                
            return result
            
        except Exception as e:
            logger.error(f"âŒ _execute_pending_close error: {e}")
            return None
    
    async def close_all_positions(self) -> list:
        """TÃ¼m aÃ§Ä±k pozisyonlarÄ± kapat (Emergency)."""
        if not self.enabled:
            return []
            
        closed = []
        positions = await self.get_positions()
        
        for pos in positions:
            result = await self.close_position(
                pos['symbol'], 
                pos['side'], 
                pos['size']
            )
            if result:
                closed.append(result)
                
        logger.warning(f"âš ï¸ EMERGENCY CLOSE: {len(closed)} positions closed")
        return closed
    
    async def get_pnl_from_binance(self) -> dict:
        """
        Binance Futures income history'den Today's PnL ve Total PnL hesapla.
        Returns: {todayPnl, todayPnlPercent, totalPnl, totalPnlPercent, todayTradesCount}
        """
        if not self.enabled or not self.exchange:
            return {
                'todayPnl': 0, 'todayPnlPercent': 0,
                'totalPnl': 0, 'totalPnlPercent': 0,
                'todayTradesCount': 0
            }
        
        try:
            # pytz imported globally
            
            # Turkey timezone (UTC+3)
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now_turkey = datetime.now(turkey_tz)
            
            # Start of today in Turkey time
            today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
            today_start_ms = int(today_start.timestamp() * 1000)
            
            # Fetch income history from Binance (all types for accurate Today's PnL)
            # Binance Today's PnL includes: REALIZED_PNL, FUNDING_FEE, COMMISSION, etc.
            # CCXT async uses camelCase: fapiPrivateGetIncome
            all_income = await self.exchange.fapiPrivateGetIncome({
                'limit': 1000  # All income types, max allowed
            })
            
            today_pnl = 0.0
            total_pnl = 0.0
            today_trades_count = 0
            
            logger.info(f"ðŸ“Š Income history: {len(all_income)} entries, today_start_ms={today_start_ms}")
            
            for income in all_income:
                income_type = income.get('incomeType', '')
                pnl = float(income.get('income') or 0)
                timestamp = int(income.get('time') or 0)
                
                # Only count trading-related income (exclude transfers, deposits)
                if income_type in ('REALIZED_PNL', 'FUNDING_FEE', 'COMMISSION'):
                    total_pnl += pnl
                    
                    if timestamp >= today_start_ms:
                        today_pnl += pnl
                        today_trades_count += 1
                        # Removed noisy individual income logging (Phase 105)
            
            # Calculate percentages based on wallet balance
            wallet_balance = self.last_balance if self.last_balance > 0 else 100
            today_pnl_percent = (today_pnl / wallet_balance) * 100
            total_pnl_percent = (total_pnl / wallet_balance) * 100
            
            logger.info(f"ðŸ“Š PnL from Binance: Today=${today_pnl:.2f} ({today_pnl_percent:.2f}%) | Total=${total_pnl:.2f}")
            
            return {
                'todayPnl': round(today_pnl, 2),
                'todayPnlPercent': round(today_pnl_percent, 2),
                'totalPnl': round(total_pnl, 2),
                'totalPnlPercent': round(total_pnl_percent, 2),
                'todayTradesCount': today_trades_count
            }
            
        except Exception as e:
            logger.error(f"PnL fetch error: {e}")
            return {
                'todayPnl': 0, 'todayPnlPercent': 0,
                'totalPnl': 0, 'totalPnlPercent': 0,
                'todayTradesCount': 0
            }

    async def get_trade_history(self, limit: int = 50, days_back: int = 7) -> list:
        """
        Binance Futures'dan trade history Ã§ek.
        Uses userTrades API to get entry/exit prices and combines with Income API for PnL.
        Returns list of trades in frontend-compatible format.
        """
        logger.info(f"get_trade_history called: enabled={self.enabled}, exchange={self.exchange is not None}")
        
        if not self.enabled or not self.exchange:
            logger.warning(f"get_trade_history: Early return - enabled={self.enabled}, exchange={self.exchange is not None}")
            return []
        
        try:
            # pytz imported globally
            from datetime import timedelta
            from collections import defaultdict
            
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now = datetime.now(turkey_tz)
            start_time = int((now - timedelta(days=days_back)).timestamp() * 1000)
            
            # Step 1: Get all Income records (REALIZED_PNL) - these represent closed positions
            logger.info(f"Fetching income history from {days_back} days back...")
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'startTime': start_time,
                'limit': min(limit * 2, 1000)  # Fetch more to ensure coverage
            })
            
            if not income_history:
                logger.warning("Trade history: No income history found")
                return []
            
            logger.info(f"Got {len(income_history)} income records")
            
            # Group income by symbol to get unique closed positions
            # Each income record represents a partial or full position close
            position_closes = []
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income') or 0)
                timestamp = int(income.get('time') or 0)
                
                if pnl == 0:
                    continue  # Skip zero PnL (partial fills without actual close)
                
                position_closes.append({
                    'symbol': symbol,
                    'pnl': pnl,
                    'timestamp': timestamp
                })
            
            logger.info(f"Found {len(position_closes)} position closes with non-zero PnL")
            
            # Phase 150: Aggregate partial fills â€” same symbol within Â±5 seconds = single trade
            aggregated_closes = []
            i = 0
            while i < len(position_closes):
                current = position_closes[i]
                agg_pnl = current['pnl']
                agg_timestamp = current['timestamp']
                j = i + 1
                while j < len(position_closes):
                    next_close = position_closes[j]
                    if (next_close['symbol'] == current['symbol'] and 
                        abs(next_close['timestamp'] - current['timestamp']) < 5000):  # Â±5 seconds
                        agg_pnl += next_close['pnl']
                        agg_timestamp = max(agg_timestamp, next_close['timestamp'])  # Use latest
                        j += 1
                    else:
                        break
                aggregated_closes.append({
                    'symbol': current['symbol'],
                    'pnl': agg_pnl,
                    'timestamp': agg_timestamp,
                    'partial_count': j - i
                })
                i = j
            
            logger.info(f"Phase 150: Aggregated {len(position_closes)} fills â†’ {len(aggregated_closes)} trades")
            position_closes = aggregated_closes
            
            # Step 2: For each closed position, try to get trade details
            trades = []
            processed_symbols = set()
            
            for close_info in position_closes:
                symbol = close_info['symbol']
                pnl = close_info['pnl']
                timestamp = close_info['timestamp']
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Try to get user trades for this symbol to get entry/exit prices
                entry_price = 0.0
                exit_price = 0.0
                side = 'LONG'  # Phase 181: Default, will be corrected by actual trade data below
                leverage = 1
                size_usd = 0.0
                qty = 0.0
                close_order_id = ''  # Phase 229: Binance close order ID
                
                # Fetch trades for this symbol around the close time
                try:
                    # Phase 181: Get trades from wider window (7 days for entry, 1 min for close)
                    trade_start = timestamp - (7 * 24 * 60 * 60 * 1000)  # 7 days before (entry may be old)
                    trade_end = timestamp + (60 * 1000)  # 1 minute after
                    
                    user_trades = await self.exchange.fapiPrivateGetUserTrades({
                        'symbol': symbol,
                        'startTime': trade_start,
                        'endTime': trade_end,
                        'limit': 100
                    })
                    
                    if user_trades and len(user_trades) > 0:
                        # Find the closing trade (closest to timestamp, reducing position)
                        # Trades with 'SELL' for LONG positions or 'BUY' for SHORT positions
                        for t in user_trades:
                            t_time = int(t.get('time', 0))
                            t_side = t.get('side', '')
                            t_price = float(t.get('price') or 0)
                            t_qty = float(t.get('qty') or 0)
                            realized = float(t.get('realizedPnl') or 0)
                            t_order_id = str(t.get('orderId', ''))  # Phase 229
                            
                            # If this trade has realized PnL matching our close, it's the exit
                            if abs(realized - pnl) < 0.01 and t_price > 0:
                                exit_price = t_price
                                qty = t_qty
                                close_order_id = t_order_id  # Phase 229
                                # If selling, was LONG. If buying, was SHORT
                                side = 'LONG' if t_side == 'SELL' else 'SHORT'
                                break
                            # Fallback: use the last trade before close time
                            elif t_time <= timestamp and t_price > 0:
                                exit_price = t_price
                                qty = t_qty
                                side = 'LONG' if t_side == 'SELL' else 'SHORT'
                        
                        # Try to find entry price from earlier trades
                        entry_side = 'BUY' if side == 'LONG' else 'SELL'
                        for t in reversed(user_trades):
                            if t.get('side') == entry_side and float(t.get('price') or 0) > 0:
                                entry_price = float(t.get('price') or 0)
                                break
                        
                        # If we found exit but no entry, estimate from PnL
                        if exit_price > 0 and entry_price == 0 and qty > 0:
                            # PnL = (exit - entry) * qty for LONG, (entry - exit) * qty for SHORT
                            if side == 'LONG':
                                entry_price = exit_price - (pnl / qty) if qty > 0 else 0
                            else:
                                entry_price = exit_price + (pnl / qty) if qty > 0 else 0
                        
                        size_usd = exit_price * qty if exit_price > 0 and qty > 0 else 0
                
                except Exception as e:
                    logger.debug(f"Could not fetch trades for {symbol}: {e}")
                
                # Get close reason from pending_close_reasons if available
                close_reason = 'Closed'
                reason_detail = 'Position closed on Binance'
                matched_close_id = None
                
                # First try in-memory pending_close_reasons
                if symbol in pending_close_reasons:
                    reason_data = pending_close_reasons.get(symbol, {})
                    reason_timestamp = reason_data.get('timestamp', 0)
                    # Match if within 30 minutes of close (extended from 5 min)
                    if abs(timestamp - reason_timestamp) < 30 * 60 * 1000:
                        close_reason = reason_data.get('reason', close_reason)
                        reason_detail = reason_data.get('original_reason', reason_detail)
                        # Use trade data from our system if available
                        trade_data = reason_data.get('trade_data', {})
                        if trade_data:
                            if trade_data.get('entryPrice', 0) > 0:
                                entry_price = trade_data.get('entryPrice')
                            if trade_data.get('exitPrice', 0) > 0:
                                exit_price = trade_data.get('exitPrice')
                            if trade_data.get('side'):
                                side = trade_data.get('side')
                            if trade_data.get('leverage', 0) > 0:
                                leverage = trade_data.get('leverage')
                            if trade_data.get('sizeUsd', 0) > 0:
                                size_usd = trade_data.get('sizeUsd')
                            # Override PnL from trade_data if available (more accurate)
                            if trade_data.get('pnl') is not None:
                                pnl = trade_data.get('pnl')
                
                # If not found in memory, try SQLite (for persistence after restart)
                # Phase 229: Pass close_order_id from in-memory or UserTrades
                mem_close_oid = pending_close_reasons.get(symbol, {}).get('close_order_id', '') if symbol in pending_close_reasons else ''
                effective_close_oid = mem_close_oid or close_order_id
                if reason_detail == 'Position closed on Binance':
                    try:
                        sqlite_close = await sqlite_manager.get_pending_close_reason(symbol, timestamp, window_minutes=60, close_order_id=effective_close_oid)
                        if sqlite_close:
                            close_reason = sqlite_close.get('reason', close_reason)
                            reason_detail = sqlite_close.get('original_reason', reason_detail)
                            matched_close_id = sqlite_close.get('id')
                            # Use SQLite data
                            if sqlite_close.get('entry_price', 0) > 0:
                                entry_price = sqlite_close.get('entry_price')
                            if sqlite_close.get('exit_price', 0) > 0:
                                exit_price = sqlite_close.get('exit_price')
                            if sqlite_close.get('side'):
                                side = sqlite_close.get('side')
                            if sqlite_close.get('leverage', 0) > 0:
                                leverage = sqlite_close.get('leverage')
                            if sqlite_close.get('size_usd', 0) > 0:
                                size_usd = sqlite_close.get('size_usd')
                            if sqlite_close.get('pnl') is not None:
                                pnl = sqlite_close.get('pnl')
                            logger.info(f"ðŸ“‹ Matched trade with SQLite close reason: {symbol} - {reason_detail}")
                    except Exception as e:
                        logger.debug(f"SQLite close reason lookup failed: {e}")
                
                # Calculate margin and ROI (Binance style: ROI = PnL / Margin * 100)
                margin = size_usd / leverage if leverage > 0 and size_usd > 0 else 0
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Frontend-compatible format
                trade = {
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': round(entry_price, 8) if entry_price else 0,
                    'exitPrice': round(exit_price, 8) if exit_price else 0,
                    'pnl': round(pnl, 4),
                    'closeTime': timestamp,
                    'closeReason': close_reason,
                    'pnlFormatted': f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}",
                    'timestamp': timestamp,
                    'time': close_time.strftime('%H:%M:%S'),
                    'date': close_time.strftime('%Y-%m-%d'),
                    'type': 'CLOSE',
                    'margin': round(margin, 4),
                    'leverage': leverage,
                    'sizeUsd': round(size_usd, 2),
                    'roi': round(roi, 2),  # Pre-calculated ROI for frontend
                    'reason': reason_detail
                }
                trades.append(trade)
                
                # Save to SQLite for historical analysis
                try:
                    trade_for_sqlite = trade.copy()
                    trade_for_sqlite['incomeId'] = f"{symbol}_{timestamp}"
                    safe_create_task(sqlite_manager.save_binance_trade(trade_for_sqlite))
                    # Mark matched position close as matched
                    if matched_close_id:
                        safe_create_task(sqlite_manager.mark_close_matched(matched_close_id))
                except Exception as e:
                    logger.debug(f"SQLite trade save error: {e}")
            
            # Sort by timestamp descending (newest first)
            trades.sort(key=lambda x: x['timestamp'], reverse=True)
            
            logger.info(f"ðŸ“Š Returning {len(trades)} trades from Binance (last {days_back} days)")
            return trades[:limit]
            
        except Exception as e:
            import traceback
            logger.error(f"Trade history fetch error: {e}")
            logger.error(f"Trade history traceback: {traceback.format_exc()}")
            return []
    
    async def sync_closed_trades_from_binance(self, hours_back: int = 24) -> int:
        """
        Phase 148: Sync closed trades from Binance to trade history.
        This captures trades that were missed (external closes, server restart).
        Returns number of new trades synced.
        """
        if not self.enabled or not self.exchange:
            return 0
        
        try:
            # pytz imported globally
            turkey_tz = pytz.timezone('Europe/Istanbul')
            now = datetime.now(turkey_tz)
            start_time = int((now - timedelta(hours=hours_back)).timestamp() * 1000)
            
            # Fetch REALIZED_PNL entries from Binance
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'startTime': start_time,
                'limit': 500
            })
            
            if not income_history:
                return 0
            
            # Get existing trade IDs to avoid duplicates
            existing_ids = set()
            if global_paper_trader:
                for trade in global_paper_trader.trades:
                    # Create unique ID from symbol + closeTime
                    # Phase 188: Use symbolFull if available (get_full_trade_history strips USDT)
                    close_time = trade.get('closeTime', 0)
                    symbol = trade.get('symbolFull', trade.get('symbol', ''))
                    existing_ids.add(f"{symbol}_{close_time}")
            
            synced_count = 0
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income') or 0)
                timestamp = int(income.get('time') or 0)
                
                # Create unique ID
                trade_id = f"{symbol}_{timestamp}"
                
                if trade_id in existing_ids:
                    continue  # Already in trade history
                
                # Skip very small PnL (likely partial fills or dust)
                if abs(pnl) < 0.01:
                    continue
                
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Create trade record
                trade = {
                    'id': f"BINANCE_{symbol}_{timestamp}",
                    'symbol': symbol,
                    'side': 'LONG' if pnl > 0 else 'SHORT',  # Estimate
                    'entryPrice': 0,
                    'exitPrice': 0,
                    'size': 0,
                    'sizeUsd': 0,
                    'pnl': round(pnl, 4),
                    'pnlPercent': 0,
                    'openTime': timestamp - 3600000,  # Estimate: 1 hour before close
                    'closeTime': timestamp,
                    'reason': 'Synced from Binance',
                    'closeReason': 'Synced from Binance',
                    'leverage': 0,
                    'isLive': True,
                    'signalScore': 0,
                    'mtfScore': 0
                }
                
                # Phase 239: Enrich from position_closes for metadata
                try:
                    pc_data = await sqlite_manager.lookup_position_close_metadata(symbol, timestamp)
                    if pc_data:
                        if pc_data.get('signal_score', 0) > 0:
                            trade['signalScore'] = pc_data['signal_score']
                        if pc_data.get('spread_level') and pc_data['spread_level'] != 'unknown':
                            trade['spreadLevel'] = pc_data['spread_level']
                        if pc_data.get('entry_price', 0) > 0:
                            trade['entryPrice'] = pc_data['entry_price']
                        if pc_data.get('exit_price', 0) > 0:
                            trade['exitPrice'] = pc_data['exit_price']
                        if pc_data.get('side'):
                            trade['side'] = pc_data['side']
                        if pc_data.get('leverage', 0) > 0:
                            trade['leverage'] = pc_data['leverage']
                        if pc_data.get('size_usd', 0) > 0:
                            trade['sizeUsd'] = pc_data['size_usd']
                        if pc_data.get('margin', 0) > 0:
                            trade['margin'] = pc_data['margin']
                        if pc_data.get('roi', 0) != 0:
                            trade['roi'] = pc_data['roi']
                        if pc_data.get('hurst', 0.5) != 0.5:
                            trade['hurst'] = pc_data['hurst']
                        if pc_data.get('entry_method') and pc_data['entry_method'] != 'MARKET':
                            trade['entry_method'] = pc_data['entry_method']
                        if pc_data.get('stop_loss', 0) > 0:
                            trade['stopLoss'] = pc_data['stop_loss']
                        if pc_data.get('take_profit', 0) > 0:
                            trade['takeProfit'] = pc_data['take_profit']
                        if pc_data.get('atr', 0) > 0:
                            trade['atr'] = pc_data['atr']
                        trade['pullbackPct'] = pc_data.get('pullback_pct', 0) or 0
                        if pc_data.get('original_reason') and pc_data['original_reason'] != 'Closed':
                            trade['reason'] = pc_data.get('reason', trade['reason'])
                            trade['closeReason'] = pc_data.get('reason', trade['closeReason'])
                        logger.info(f"ðŸ“‹ SYNC ENRICHED: {symbol} score={trade.get('signalScore',0)} spread={trade.get('spreadLevel','?')}")
                except Exception as enrich_err:
                    logger.debug(f"Sync enrichment failed for {symbol}: {enrich_err}")
                
                if global_paper_trader:
                    global_paper_trader.trades.append(trade)
                    synced_count += 1
                    existing_ids.add(trade_id)
                    
                    # Save to SQLite
                    try:
                        safe_create_task(sqlite_manager.save_trade(trade))
                    except Exception as e:
                        logger.debug(f"SQLite sync save error: {e}")
            
            if synced_count > 0:
                logger.info(f"ðŸ“¥ BINANCE SYNC: Added {synced_count} missing trades from last {hours_back}h")
                if global_paper_trader:
                    global_paper_trader.save_state()
            
            return synced_count
            
        except Exception as e:
            logger.error(f"sync_closed_trades_from_binance error: {e}")
            return 0
    
    async def backfill_trade_history_to_sqlite(self, limit: int = 1000):
        """
        Backfill last N trades from Binance Income API to SQLite.
        Called once at startup to populate historical data.
        """
        if not self.enabled or not self.exchange:
            logger.info("Backfill skipped: Binance trader not enabled")
            return 0
        
        try:
            # pytz imported globally
            turkey_tz = pytz.timezone('Europe/Istanbul')
            
            # Fetch last 1000 REALIZED_PNL entries (max allowed by Binance)
            logger.info(f"ðŸ“¥ Starting Binance trade history backfill (limit={limit})...")
            
            income_history = await self.exchange.fapiPrivateGetIncome({
                'incomeType': 'REALIZED_PNL',
                'limit': limit
            })
            
            if not income_history:
                logger.warning("Backfill: No income history found")
                return 0
            
            saved_count = 0
            
            for income in income_history:
                symbol = income.get('symbol', 'UNKNOWN')
                pnl = float(income.get('income') or 0)
                timestamp = int(income.get('time') or 0)
                
                # Skip very small PnL
                if abs(pnl) < 0.01:
                    continue
                
                close_time = datetime.fromtimestamp(timestamp / 1000, turkey_tz)
                
                # Check if we have close reason from SQLite
                close_reason = 'Closed'
                reason_detail = 'Historical (from Binance)'
                entry_price = 0
                exit_price = 0
                side = 'LONG' if pnl > 0 else 'SHORT'
                leverage = await sqlite_manager.get_leverage(symbol)  # Get cached leverage or default
                size_usd = 0
                
                # Try to find matching close from position_closes table
                try:
                    sqlite_close = await sqlite_manager.get_pending_close_reason(symbol, timestamp, window_minutes=60)
                    if sqlite_close:
                        close_reason = sqlite_close.get('reason', close_reason)
                        reason_detail = sqlite_close.get('original_reason', reason_detail)
                        entry_price = sqlite_close.get('entry_price', 0)
                        exit_price = sqlite_close.get('exit_price', 0)
                        side = sqlite_close.get('side', side)
                        leverage = sqlite_close.get('leverage', leverage)
                        size_usd = sqlite_close.get('size_usd', 0)
                except:
                    pass
                
                # Calculate margin and ROI
                margin = size_usd / leverage if leverage > 0 and size_usd > 0 else abs(pnl) / 0.1  # Estimate
                roi = (pnl / margin * 100) if margin > 0 else 0
                
                # Save to SQLite
                trade_data = {
                    'incomeId': f"{symbol}_{timestamp}",
                    'symbol': symbol,
                    'side': side,
                    'entryPrice': entry_price,
                    'exitPrice': exit_price,
                    'pnl': round(pnl, 4),
                    'roi': round(roi, 2),
                    'margin': round(margin, 4),
                    'leverage': leverage,
                    'sizeUsd': round(size_usd, 2),
                    'closeReason': close_reason,
                    'closeTime': timestamp
                }
                
                try:
                    await sqlite_manager.save_binance_trade(trade_data)
                    saved_count += 1
                except Exception as e:
                    # Likely duplicate, skip
                    pass
            
            logger.info(f"ðŸ“Š Binance backfill complete: {saved_count}/{len(income_history)} trades saved to SQLite")
            return saved_count
            
        except Exception as e:
            import traceback
            logger.error(f"backfill_trade_history_to_sqlite error: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return 0

    def get_status(self) -> dict:
        """Trader durumu."""
        return {
            'enabled': self.enabled,
            'initialized': self.initialized,
            'trading_mode': self.trading_mode,
            'last_balance': self.last_balance,
            'position_count': len(self.last_positions),
            'last_sync': self.last_sync_time,
            'last_order_error': self.last_order_error
        }


# Global LiveBinanceTrader instance
live_binance_trader = LiveBinanceTrader()


# Forward declaration for background tasks
background_scanner_task = None
position_updater_task = None
binance_sync_task = None

# Scanner runtime safeguards (prevents loop stalls from blocking trade execution).
SCANNER_SCAN_TIMEOUT_SEC = 35.0
SCANNER_MTF_UPDATE_TIMEOUT_SEC = 2.5
SCANNER_MTF_UPDATE_MAX_SYMBOLS = 20
SCANNER_MTF_UPDATE_BUDGET_SEC = 6.0
SCANNER_STALE_CACHE_SEC = 45
SCANNER_RESTART_COOLDOWN_SEC = 20

# UI cache refresh safeguards.
UI_TRADE_FETCH_INTERVAL_SEC = 300
UI_TRADE_FETCH_TIMEOUT_SEC = 25.0
_last_scanner_restart_ts = 0.0


def _is_scanner_task_alive() -> bool:
    """Return True when scanner task exists and is not done."""
    global background_scanner_task
    return background_scanner_task is not None and not background_scanner_task.done()


async def restart_background_scanner(reason: str, force: bool = False) -> bool:
    """
    Cancel and recreate scanner task.
    Handles alive-but-stuck tasks and enforces a short restart cooldown.
    """
    global background_scanner_task, _last_scanner_restart_ts
    now_ts = datetime.now().timestamp()
    if not force and (now_ts - _last_scanner_restart_ts) < SCANNER_RESTART_COOLDOWN_SEC:
        return False

    old_task = background_scanner_task
    current_task = asyncio.current_task()

    if old_task and not old_task.done():
        old_task.cancel()
        # Avoid deadlock if restart is requested from within scanner task itself.
        if old_task is not current_task:
            try:
                await asyncio.wait_for(old_task, timeout=2.0)
            except asyncio.TimeoutError:
                logger.warning("âš ï¸ Scanner cancel timeout; creating new task anyway")
            except asyncio.CancelledError:
                pass
            except Exception as cancel_err:
                logger.warning(f"âš ï¸ Scanner cancel error ignored: {cancel_err}")

    if 'multi_coin_scanner' in globals():
        multi_coin_scanner.running = True

    background_scanner_task = asyncio.create_task(background_scanner_loop())
    _last_scanner_restart_ts = now_ts
    logger.warning(f"ðŸ” Scanner task restarted ({reason})")
    return True

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan: start background scanner and position updater on startup."""
    global background_scanner_task, position_updater_task, binance_sync_task
    
    # Initialize SQLite database
    logger.info("ðŸ“ Initializing SQLite database...")
    await sqlite_manager.init_db()
    
    # Phase 211: Persist Global Settings on startup
    try:
        settings_payload = {
            'entry_tightness': global_paper_trader.entry_tightness,
            'exit_tightness': global_paper_trader.exit_tightness,
            'max_positions': global_paper_trader.max_positions,
            'strategy_mode': global_paper_trader.strategy_mode,
            'min_confidence_score': global_paper_trader.min_confidence_score,
            'z_score_threshold': global_paper_trader.z_score_threshold
        }
        asyncio.create_task(sqlite_manager.save_setting('global_config', settings_payload))
        logger.info("ðŸ’¾ Phase 211: Global settings persisted to DB on startup")
    except Exception as e:
        logger.warning(f"Failed to persist global settings: {e}")
    
    # Phase 187b: Load ALL trades from SQLite into paper_trader.trades
    # This ensures WebSocket/REST endpoints serve complete historical data from the start
    try:
        sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
        if sqlite_trades:
            global_paper_trader.trades = sqlite_trades
            logger.info(f"ðŸ“Š Phase 187b: Loaded {len(sqlite_trades)} trades from SQLite into memory")
        else:
            logger.info("ðŸ“Š Phase 187b: No trades found in SQLite")
    except Exception as e:
        logger.error(f"ðŸ“Š Phase 187b: Failed to load trades from SQLite: {e}")
    
    # Phase 154: Load persisted breakeven states
    await breakeven_stop_manager.load_from_sqlite()
    logger.info(f"ðŸ”’ Breakeven states loaded: {len(breakeven_stop_manager.breakeven_state)} active")
    
    # Initialize LiveBinanceTrader (if TRADING_MODE is live)
    # Note: Read TRADING_MODE here (after secrets are loaded) and update the trader
    trading_mode = os.environ.get('TRADING_MODE', 'paper')
    live_binance_trader.trading_mode = trading_mode  # Update trading mode from env
    logger.info(f"ðŸ“Š Trading Mode: {trading_mode.upper()}")
    
    if trading_mode == 'live':
        try:
            logger.info("ðŸ”Œ Initializing LiveBinanceTrader...")
            success = await live_binance_trader.initialize()
            if success:
                logger.info("âœ… LiveBinanceTrader ready for real trading!")
                
                # Backfill last 1000 trades to SQLite (one-time on startup)
                asyncio.create_task(live_binance_trader.backfill_trade_history_to_sqlite(1000))
                
                # Phase 239: Backfill missing metadata from position_closes
                asyncio.create_task(sqlite_manager.backfill_missing_metadata(48))
            else:
                logger.error("âŒ LiveBinanceTrader failed to initialize! Sync loop will retry...")
        except Exception as e:
            logger.error(f"âŒ CRITICAL: LiveBinanceTrader initialization error: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        # Phase 189: ALWAYS start sync loop - it has auto-reconnect logic
        binance_sync_task = asyncio.create_task(binance_position_sync_loop())
        logger.info("ðŸ”„ Binance position sync loop started (with auto-reconnect)!")
    else:
        logger.info("ðŸ“„ Paper trading mode - no Binance connection")
        # Phase 239 fix: run metadata backfill in paper mode too
        asyncio.create_task(sqlite_manager.backfill_missing_metadata(48))
    
    # Start Liquidation Tracker
    logger.info("ðŸ’€ Starting Liquidation Tracker...")
    asyncio.create_task(liquidation_tracker.start())
    
    logger.info("ðŸš€ Starting 24/7 Background Scanner...")
    
    # Start background scanner as asyncio task (scans all coins every 10 seconds)
    background_scanner_task = asyncio.create_task(background_scanner_loop())
    
    # Start position updater task (updates open positions every 2 seconds)
    position_updater_task = asyncio.create_task(position_price_update_loop())
    
    yield  # App is running
    
    # Shutdown: stop all tasks
    logger.info("ðŸ›‘ Shutting down Background Tasks...")
    for task in [background_scanner_task, position_updater_task, binance_sync_task]:
        if task:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
    
    # Close Binance connection
    if live_binance_trader.exchange:
        await live_binance_trader.exchange.close()
        logger.info("ðŸ”Œ Binance connection closed")


# ============================================================================
# Phase 142: Helper function for coin ATR percentage
# ============================================================================

def _get_coin_atr_percent(symbol: str) -> float:
    """
    Get ATR as percentage of price for a coin.
    Used by PortfolioRecoveryManager for dynamic trailing distance.
    
    Args:
        symbol: Trading pair symbol (e.g., 'BTCUSDT')
        
    Returns:
        ATR as percentage of price (e.g., 2.0 for 2%)
    """
    try:
        if multi_coin_scanner and hasattr(multi_coin_scanner, 'opportunities'):
            opp = multi_coin_scanner.opportunities.get(symbol)
            if opp and hasattr(opp, 'atr') and hasattr(opp, 'price'):
                if opp.price and opp.price > 0:
                    return (opp.atr / opp.price) * 100
    except Exception as e:
        logger.debug(f"Could not get ATR for {symbol}: {e}")
    return 2.0  # Default 2%


async def binance_position_sync_loop():
    """
    Binance'den pozisyon/bakiye senkronizasyonu (her 5 saniye).
    Live trading modunda Binance'deki gerÃ§ek pozisyonlarÄ± UI'a yansÄ±tÄ±r.
    
    Phase 72: TÃ¼m Binance pozisyonlarÄ±nÄ± (manuel dahil) algoritma yÃ¶netimi altÄ±na alÄ±r.
    """
    logger.info("ðŸ”„ Binance Position Sync Loop started")
    reconnect_interval = 30  # seconds between reconnect attempts
    last_reconnect_attempt = 0
    _phase218_recalc_done = False  # One-time flag
    _orphan_cleanup_done = False  # Phase 243: One-time orphan order cleanup
    
    while True:
        try:
            # ================================================================
            # Phase 218: ONE-TIME RECALC â€” fix SL/TP for existing positions
            # sl_atr=15 was used as raw multiplier instead of 1.5 (=15/10)
            # This runs ONCE per server lifetime to fix all positions
            # ================================================================
            if not _phase218_recalc_done and len(global_paper_trader.positions) > 0:
                _phase218_recalc_done = True
                fixed_count = 0
                sl_atr_corrected = global_paper_trader.sl_atr / 10  # 15 â†’ 1.5
                tp_atr_corrected = global_paper_trader.tp_atr / 10  # 30 â†’ 3.0
                et = global_paper_trader.exit_tightness  # 1.2
                
                for pos in global_paper_trader.positions:
                    try:
                        entry = pos.get('entryPrice', 0)
                        if entry <= 0:
                            continue
                        
                        atr = pos.get('atr', entry * 0.02)
                        side = pos.get('side', '')
                        
                        # Calculate dynamic ATR multiplier
                        dyn_mult = global_paper_trader.calculate_dynamic_atr_multiplier(atr, entry)
                        
                        adjusted_sl = sl_atr_corrected * et * dyn_mult
                        adjusted_tp = tp_atr_corrected * et * dyn_mult
                        
                        old_sl = pos.get('stopLoss', 0)
                        old_tp = pos.get('takeProfit', 0)
                        
                        if side == 'LONG':
                            new_sl = max(entry * 0.01, entry - (atr * adjusted_sl))
                            new_tp = entry + (atr * adjusted_tp)
                        else:
                            new_sl = entry + (atr * adjusted_sl)
                            new_tp = max(entry * 0.01, entry - (atr * adjusted_tp))
                        
                        # Only fix if the values are suspiciously far (>50% from entry)
                        sl_dist_pct = abs(entry - old_sl) / entry * 100 if entry > 0 else 0
                        if sl_dist_pct > 50:  # SL is more than 50% away â€” clearly wrong
                            pos['stopLoss'] = new_sl
                            pos['trailingStop'] = new_sl
                            pos['takeProfit'] = new_tp
                            
                            # Recalc trail activation/distance
                            trail_act_atr = global_paper_trader.trail_activation_atr * et * dyn_mult
                            trail_dist_atr = global_paper_trader.trail_distance_atr * et * dyn_mult
                            if side == 'LONG':
                                pos['trailActivation'] = entry + (atr * trail_act_atr)
                            else:
                                pos['trailActivation'] = entry - (atr * trail_act_atr)
                            pos['trailDistance'] = atr * trail_dist_atr
                            
                            # Reset trailing state since SL changed
                            pos['isTrailingActive'] = False
                            
                            fixed_count += 1
                            logger.warning(f"ðŸ”§ Phase 218 RECALC: {pos.get('symbol')} {side} | SL: {old_sl:.6f} â†’ {new_sl:.6f} | TP: {old_tp:.6f} â†’ {new_tp:.6f}")
                    except Exception as e:
                        logger.error(f"Phase 218 recalc error for {pos.get('symbol', '?')}: {e}")
                
                if fixed_count > 0:
                    global_paper_trader.save_state()
                    logger.warning(f"ðŸ”§ Phase 218: Fixed {fixed_count}/{len(global_paper_trader.positions)} positions with wrong SL/TP")
                else:
                    logger.info("âœ… Phase 218: All positions have correct SL/TP â€” no fix needed")
            
            # ================================================================
            # Phase 243: ONE-TIME ORPHAN ORDER CLEANUP
            # Cancel stale reduceOnly limit orders that have no matching position
            # Prevents "ghost" breakeven/trailing orders accumulating on Binance
            # ================================================================
            if not _orphan_cleanup_done and live_binance_trader.enabled and live_binance_trader.exchange:
                _orphan_cleanup_done = True
                try:
                    open_orders = await live_binance_trader.exchange.fetch_open_orders()
                    engine_symbols = {p.get('symbol') for p in global_paper_trader.positions}
                    orphan_cancelled = 0
                    for o in open_orders:
                        is_reduce = o.get('reduceOnly') or (o.get('info', {}).get('reduceOnly') == 'true')
                        if is_reduce:
                            # Normalize symbol: CCXT uses "SOL/USDT:USDT" format
                            raw_sym = o.get('symbol', '')
                            norm_sym = raw_sym.replace('/', '').replace(':USDT', '')
                            if norm_sym not in engine_symbols:
                                try:
                                    await live_binance_trader.exchange.cancel_order(o['id'], raw_sym)
                                    orphan_cancelled += 1
                                    logger.warning(f"ðŸ—‘ï¸ ORPHAN_CLEANUP: Cancelled stale reduceOnly order {o['id']} for {norm_sym}")
                                except Exception as cancel_err:
                                    logger.warning(f"âš ï¸ ORPHAN_CLEANUP: Failed to cancel {o['id']}: {cancel_err}")
                    if orphan_cancelled > 0:
                        logger.warning(f"ðŸ—‘ï¸ Phase 243: Cleaned up {orphan_cancelled} orphan reduceOnly orders")
                    else:
                        logger.info("âœ… Phase 243: No orphan orders found")
                except Exception as cleanup_err:
                    logger.warning(f"Orphan order cleanup failed: {cleanup_err}")
            
            # Phase 189: Auto-reconnect if Binance connection lost or failed on startup
            if not live_binance_trader.enabled and live_binance_trader.trading_mode == 'live':
                now = datetime.now().timestamp()
                if now - last_reconnect_attempt > reconnect_interval:
                    last_reconnect_attempt = now
                    logger.warning(f"ðŸ”Œ RECONNECT: live_binance_trader.enabled=False, attempting reconnect...")
                    try:
                        success = await live_binance_trader.initialize()
                        if success:
                            logger.warning(f"âœ… RECONNECT SUCCESS: Binance live trading restored!")
                            # Clean ghost positions (no isLive flag) that accumulated while disconnected
                            ghost_count = len([p for p in global_paper_trader.positions if not p.get('isLive')])
                            if ghost_count > 0:
                                global_paper_trader.positions = [p for p in global_paper_trader.positions if p.get('isLive')]
                                logger.warning(f"ðŸ§¹ CLEANUP: Removed {ghost_count} ghost positions (no isLive flag)")
                        else:
                            logger.error(f"âŒ RECONNECT FAILED: {getattr(live_binance_trader, 'last_error', 'unknown')}")
                    except Exception as re:
                        logger.error(f"âŒ RECONNECT ERROR: {re}")
                await asyncio.sleep(3)
                continue
            
            if live_binance_trader.enabled:
                # Bakiye gÃ¼ncelle
                balance = await live_binance_trader.get_balance()
                
                # PaperTradingEngine bakiyesini Binance'den al
                global_paper_trader.balance = balance['total']
                # Phase 75: Store full balance details for scanner_update
                global_paper_trader.liveBalance = {
                    'walletBalance': balance.get('walletBalance', balance.get('total', 0)),
                    'marginBalance': balance.get('marginBalance', balance.get('total', 0)),
                    'availableBalance': balance.get('availableBalance', balance.get('free', 0)),
                    'unrealizedPnl': balance.get('unrealizedPnl', 0)
                }
                
                # ================================================================
                # Phase 244B: FUNDING FEE ACCUMULATION PER POSITION
                # Fetch recent funding fees and assign to open positions
                # ================================================================
                try:
                    if global_paper_trader.positions and live_binance_trader.exchange:
                        # Only fetch every ~60 seconds (controlled by flag)
                        _funding_last_fetch = getattr(live_binance_trader, '_funding_last_fetch', 0)
                        now_ts = datetime.now().timestamp()
                        if now_ts - _funding_last_fetch > 60:  # Every 60 seconds
                            live_binance_trader._funding_last_fetch = now_ts
                            try:
                                recent_income = await live_binance_trader.exchange.fapiPrivateGetIncome({
                                    'incomeType': 'FUNDING_FEE',
                                    'limit': 100
                                })
                                # Map funding to positions by symbol
                                for inc in recent_income:
                                    inc_symbol = (inc.get('symbol') or '').replace('USDT', '') + 'USDT'
                                    inc_time = int(inc.get('time') or 0)
                                    inc_amount = float(inc.get('income') or 0)
                                    # Find matching position and accumulate if funding is newer than position open
                                    for pos in global_paper_trader.positions:
                                        pos_symbol = pos.get('symbol', '')
                                        pos_open = pos.get('openTime', 0)
                                        if pos_symbol == inc_symbol and inc_time > pos_open:
                                            # Track which funding IDs we've already counted
                                            counted_ids = pos.get('_funding_ids', set())
                                            funding_id = f"{inc_symbol}_{inc_time}"
                                            if funding_id not in counted_ids:
                                                counted_ids.add(funding_id)
                                                pos['_funding_ids'] = counted_ids
                                                old_funding = pos.get('accumulated_funding', 0)
                                                pos['accumulated_funding'] = old_funding + inc_amount
                                                if abs(inc_amount) > 0.001:
                                                    logger.debug(f"ðŸ’° FUNDING: {pos_symbol} +${inc_amount:+.4f} (total: ${pos.get('accumulated_funding', 0):+.4f})")
                            except Exception as fund_err:
                                logger.debug(f"Funding fee fetch error: {fund_err}")
                except Exception as fund_outer_err:
                    pass  # Non-critical, don't break sync
                
                # ================================================================
                # Phase 142: Portfolio Recovery Trailing Check
                # ================================================================
                try:
                    total_upnl = balance.get('unrealizedPnl', 0)
                    
                    # Get BTC/ETH ATR for dynamic trailing distance
                    btc_atr_pct = _get_coin_atr_percent('BTCUSDT')
                    eth_atr_pct = _get_coin_atr_percent('ETHUSDT')
                    
                    # Update recovery manager â€” use Binance Margin Balance
                    margin_bal = balance.get('marginBalance', balance.get('total', 100.0))
                    recovery_status = portfolio_recovery_manager.update(
                        total_unrealized_pnl=total_upnl,
                        btc_atr_pct=btc_atr_pct,
                        eth_atr_pct=eth_atr_pct,
                        wallet_balance=margin_bal
                    )
                    
                    # Check if we should close all positions
                    if portfolio_recovery_manager.should_close_all():
                        logger.warning(f"ðŸ”´ RECOVERY CLOSE: Closing all {len(global_paper_trader.positions)} positions!")
                        positions_to_close = global_paper_trader.positions[:]  # Copy to avoid mutation
                        closed_count = 0
                        total_pnl = 0.0
                        
                        for pos in positions_to_close:
                            try:
                                current_price = pos.get('currentPrice', pos.get('markPrice', pos.get('entryPrice', 0)))
                                pnl_before = pos.get('unrealizedPnl', 0)
                                global_paper_trader.close_position(pos, current_price, "RECOVERY_CLOSE_ALL")
                                closed_count += 1
                                total_pnl += pnl_before
                            except Exception as pe:
                                logger.error(f"Error closing position {pos.get('symbol')}: {pe}")
                        
                        logger.warning(f"ðŸ”´ RECOVERY COMPLETED: Closed {closed_count} positions, Total PnL: ${total_pnl:.2f}")
                        portfolio_recovery_manager.start_cooldown()
                        
                except Exception as re:
                    logger.error(f"Portfolio recovery check error: {re}")
                
                # PozisyonlarÄ± gÃ¼ncelle (Binance'den) - FAST MODE to reduce API calls
                # Phase 82: Use fast=True (1 API call instead of 21+)
                # Binance limits: 2400 weight/min - fast mode uses ~5 weight vs ~110 weight
                binance_positions = await live_binance_trader.get_positions(fast=True)
                logger.info(f"ðŸ“Š Binance sync: {len(binance_positions)} positions from API")
                
                # Store for fallback access
                live_binance_trader.last_positions = binance_positions
                
                # ================================================================
                # PHASE 228: Fetch bookTicker for real bid-ask spread
                # Used by both position enrichment and sync trail params
                # ================================================================
                sync_book_cache = await multi_coin_scanner.fetch_book_tickers()
                
                # ================================================================
                # PHASE XXX: ENRICH POSITIONS WITH DYNAMIC SPREAD LEVEL
                # Phase 228: Use real bid-ask spread when available, ATR fallback
                for bp in binance_positions:
                    try:
                        symbol = bp.get('symbol', '')
                        # Try to get analyzer for this coin to calculate volatility
                        analyzer = multi_coin_scanner.analyzers.get(symbol) if hasattr(multi_coin_scanner, 'analyzers') else None
                        
                        # Phase 228: Use real bid-ask spread from REST bookTicker
                        book = sync_book_cache.get(symbol, {}) if sync_book_cache else {}
                        book_bid = book.get('bid', 0)
                        book_ask = book.get('ask', 0)
                        if book_bid > 0 and book_ask > 0 and book_ask > book_bid:
                            real_spread = ((book_ask - book_bid) / ((book_ask + book_bid) / 2)) * 100
                            # Classify bid-ask spread level
                            if real_spread < 0.02:
                                bp['spread_level'] = 'Very Low'
                            elif real_spread < 0.05:
                                bp['spread_level'] = 'Low'
                            elif real_spread < 0.15:
                                bp['spread_level'] = 'Normal'
                            elif real_spread < 0.40:
                                bp['spread_level'] = 'High'
                            elif real_spread < 0.80:
                                bp['spread_level'] = 'Very High'
                            elif real_spread < 1.50:
                                bp['spread_level'] = 'Extreme'
                            else:
                                bp['spread_level'] = 'Ultra'
                            bp['atr_pct'] = real_spread  # Store real spread as atr_pct for compatibility
                        elif analyzer and hasattr(analyzer, 'highs') and hasattr(analyzer, 'lows') and hasattr(analyzer, 'closes'):
                            # ATR fallback when no bookTicker data
                            highs = list(analyzer.highs)
                            lows = list(analyzer.lows)
                            closes = list(analyzer.closes)
                            if len(closes) >= 14:
                                atr_pct = calculate_atr_percentage(symbol, highs, lows, closes)
                                bp['spread_level'] = calculate_spread_level(atr_pct=atr_pct)
                                bp['atr_pct'] = atr_pct
                            else:
                                bp['spread_level'] = 'Normal'
                                bp['atr_pct'] = 2.0
                        else:
                            bp['spread_level'] = 'Normal'
                            bp['atr_pct'] = 2.0
                    except Exception as enrich_err:
                        bp['spread_level'] = 'Normal'
                        bp['atr_pct'] = 2.0
                
                # ================================================================
                # PHASE XXX: BREAKEVEN STOP & LOSS RECOVERY TRAIL
                # Check live Binance positions for breakeven and recovery conditions
                # ================================================================
                try:
                    if binance_positions and live_binance_trader.enabled:
                        # Check breakeven conditions
                        breakeven_actions = await breakeven_stop_manager.check_positions(binance_positions, live_binance_trader)
                        if breakeven_actions.get('breakeven_activated') or breakeven_actions.get('breakeven_closed'):
                            logger.info(f"ðŸ”’ Breakeven: activated={breakeven_actions['breakeven_activated']}, closed={breakeven_actions['breakeven_closed']}")
                        
                        # Check loss recovery trail conditions
                        recovery_actions = await loss_recovery_trail_manager.check_positions(binance_positions, live_binance_trader)
                        if recovery_actions.get('recovery_trail_activated') or recovery_actions.get('recovery_closed'):
                            logger.info(f"ðŸ”„ Recovery: trail_activated={recovery_actions['recovery_trail_activated']}, closed={recovery_actions['recovery_closed']}")
                except Exception as mgr_err:
                    logger.warning(f"Position manager error: {mgr_err}")
                
                # Phase 72: Sync ALL Binance positions into PaperTradingEngine
                # This ensures algorithm manages all positions (including manual)
                # ================================================================
                existing_symbols = {p.get('symbol') for p in global_paper_trader.positions if p.get('isLive')}
                
                for bp in binance_positions:
                    symbol = bp.get('symbol', '')
                    
                    # Check if position already exists in engine
                    if symbol not in existing_symbols:
                        # New position (manual or from previous session) - add with default params
                        entry_price = bp.get('entryPrice', 0)
                        mark_price = bp.get('markPrice', entry_price)
                        
                        # ================================================================
                        # Phase 151: Dynamic volatility calculation for synced positions
                        # ================================================================
                        # Get ticker data for volatility estimation
                        tickers = binance_ws_manager.get_tickers([symbol])
                        ticker = tickers.get(symbol) if tickers else None
                        
                        # Phase 243: Prefer real 14-period ATR from scanner cache
                        sync_analyzer = multi_coin_scanner.analyzers.get(symbol) if hasattr(multi_coin_scanner, 'analyzers') else None
                        if sync_analyzer and hasattr(sync_analyzer, 'highs') and hasattr(sync_analyzer, 'closes') and len(list(sync_analyzer.closes)) >= 14:
                            _h, _l, _c = list(sync_analyzer.highs), list(sync_analyzer.lows), list(sync_analyzer.closes)
                            estimated_atr = calculate_atr(_h, _l, _c, period=14)
                            volatility_pct = (estimated_atr / entry_price * 100) if entry_price > 0 else 2.0
                            logger.info(f"ðŸ“ SYNC_ATR: {symbol} using real 14-period ATR={estimated_atr:.6f} ({volatility_pct:.2f}%)")
                        elif ticker and entry_price > 0:
                            # Fallback: 24h range estimation (unchanged)
                            high_24h = float(ticker.get('high') or entry_price * 1.02)
                            low_24h = float(ticker.get('low') or entry_price * 0.98)
                            estimated_atr = (high_24h - low_24h) / 3
                            volatility_pct = (estimated_atr / entry_price) * 100 if entry_price > 0 else 2.0
                            logger.info(f"ðŸ“ SYNC_ATR: {symbol} using 24h range fallback ATR={estimated_atr:.6f} ({volatility_pct:.2f}%)")
                        else:
                            # Fallback to 2% estimate
                            estimated_atr = entry_price * 0.02 if entry_price > 0 else 0.02
                            volatility_pct = 2.0
                        
                        # Phase 228: Always use REST bookTicker for spread (independent of WS ticker)
                        book = sync_book_cache.get(symbol, {}) if sync_book_cache else {}
                        bid = book.get('bid', 0)
                        ask = book.get('ask', 0)
                        sync_spread_pct = ((ask - bid) / ((ask + bid) / 2) * 100) if bid > 0 and ask > 0 and ask > bid else 0.05
                        
                        atr = estimated_atr
                        
                        # Get dynamic trail parameters based on volatility
                        trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
                            volatility_pct=volatility_pct,
                            hurst=0.5,  # Default neutral
                            price=entry_price,
                            spread_pct=sync_spread_pct,  # Phase 178: Real spread
                            settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
                            settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
                        )
                        
                        logger.info(f"ðŸ“Š Volatility calc: {symbol} ATR%={volatility_pct:.2f}% â†’ trail_act={trail_activation_atr}x, trail_dist={trail_distance_atr}x")
                        
                        # Calculate default exit parameters
                        # IMPORTANT: If position is already profitable, set TP beyond CURRENT price
                        # to avoid instant TP trigger on sync
                        # Phase 210: Minimum trail activation distance = 0.5 ATR
                        min_trail_distance = atr * 0.5
                        
                        if bp['side'] == 'LONG':
                            # For LONG: if mark > entry, position is profitable
                            if mark_price > entry_price:
                                # Phase 243: Protect 50% of unrealized profit instead of breakeven
                                profit_distance = mark_price - entry_price
                                stop_loss = entry_price + (profit_distance * 0.5)  # Lock 50% profit
                                take_profit = mark_price + (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price + min_trail_distance  # Phase 210: Min 0.5 ATR from entry
                            else:
                                stop_loss = entry_price - (atr * global_paper_trader.sl_atr / 10)
                                take_profit = entry_price + (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price + (atr * trail_activation_atr)  # Phase 151: Dynamic
                        else:
                            # For SHORT: if mark < entry, position is profitable
                            if mark_price < entry_price:
                                # Phase 243: Protect 50% of unrealized profit instead of breakeven
                                profit_distance = entry_price - mark_price
                                stop_loss = entry_price - (profit_distance * 0.5)  # Lock 50% profit
                                take_profit = mark_price - (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price - min_trail_distance  # Phase 210: Min 0.5 ATR from entry
                            else:
                                stop_loss = entry_price + (atr * global_paper_trader.sl_atr / 10)
                                take_profit = entry_price - (atr * global_paper_trader.tp_atr / 10)
                                trail_activation = entry_price - (atr * trail_activation_atr)  # Phase 151: Dynamic
                        
                        new_pos = {
                            'id': bp.get('id', f"BIN_{symbol}_{int(datetime.now().timestamp())}"),
                            'symbol': symbol,
                            'side': bp.get('side', 'LONG'),
                            'size': bp.get('size', bp.get('contracts', 0)),  # Phase 149: Fallback to contracts
                            'sizeUsd': bp.get('sizeUsd', 0),
                            'entryPrice': entry_price,
                            'markPrice': bp.get('markPrice', entry_price),
                            'leverage': bp.get('leverage', 10),
                            'margin': bp.get('margin', 0),
                            'initialMargin': bp.get('margin', 0),
                            'openTime': bp.get('openTime', int(datetime.now().timestamp() * 1000)),
                            # Exit parameters
                            'stopLoss': stop_loss,
                            'takeProfit': take_profit,
                            'trailActivation': trail_activation,
                            'trailDistance': atr * trail_distance_atr,  # Phase 151: Dynamic trail distance
                            'trailingStop': stop_loss,
                            'isTrailingActive': False,  # Phase 213: Don't auto-activate â€” wait for ROI >= 1.5%
                            'slConfirmCount': 0,
                            'atr': atr,
                            'volatilityPct': volatility_pct,  # Phase 151: Store for reference
                            'dynamicTrailActivation': trail_activation_atr,  # Phase 151: Store multiplier
                            'dynamicTrailDistance': trail_distance_atr,  # Phase 151: Store multiplier
                            'isLive': True,
                            'isSynced': True,  # Mark as synced from Binance
                            # Phase 214: Failed Continuation Detector
                            'fc_was_in_profit': False,
                            'fc_failed_count': 0,
                            'fc_max_profit_pct': 0.0,
                        }
                        
                        global_paper_trader.positions.append(new_pos)
                        logger.info(f"ðŸ“¥ SYNCED: {bp['side']} {symbol} @ ${entry_price:.4f} | Vol:{volatility_pct:.1f}% Trail:{trail_activation_atr}x/{trail_distance_atr}x")
                    else:
                        # Update existing position with current Binance data
                        # Phase 88: Also sync SIZE to prevent close amount mismatches
                        # Phase 141: Sync CONTRACTS alongside SIZE for consistency
                        # Phase 190: PROTECTED FIELDS â€” these are NEVER overwritten by sync:
                        #   partial_tp_state, breakeven_activated, kill_switch_reduced,
                        #   isTrailingActive, trailingStop, stopLoss, takeProfit,
                        #   slConfirmCount, slBreachStartTime, highestProfit,
                        #   gradual_exit_mode, recovery_mode, recovery_sl,
                        #   time_reduced_4h, time_reduced_8h, _partial_close_ts
                        for pos in global_paper_trader.positions:
                            # Phase 155: Match by symbol only (ignore isLive for existing Binance positions)
                            if pos.get('symbol') == symbol:
                                # FORCE isLive=True for all Binance positions
                                pos['isLive'] = True
                                
                                # Phase 188: Cooldown after partial close â€” don't overwrite size
                                # for 30 seconds to prevent duplicate reduction orders
                                partial_close_ts = pos.get('_partial_close_ts', 0)
                                cooldown_active = (datetime.now().timestamp() - partial_close_ts) < 30 if partial_close_ts > 0 else False
                                
                                # Sync critical values from Binance (source of truth)
                                position_size = bp.get('size', bp.get('contracts', pos.get('size')))
                                if not cooldown_active:
                                    pos['size'] = position_size      # Phase 88: Sync size!
                                    pos['contracts'] = position_size # Phase 141: Keep both in sync
                                    pos['sizeUsd'] = bp.get('sizeUsd', pos.get('sizeUsd'))
                                else:
                                    logger.info(f"â¸ï¸ SYNC_COOLDOWN: {symbol} skipping size sync ({30 - (datetime.now().timestamp() - partial_close_ts):.0f}s remaining)")
                                pos['markPrice'] = bp.get('markPrice', pos.get('markPrice'))
                                pos['unrealizedPnl'] = bp.get('unrealizedPnl', 0)
                                pos['unrealizedPnlPercent'] = bp.get('unrealizedPnlPercent', 0)
                                
                                # DEBUG: Log what we're updating
                                logger.debug(f"ðŸ“Š Sync update: {symbol} SL={pos.get('stopLoss', 'NONE')} TP={pos.get('takeProfit', 'NONE')} Trail={pos.get('isTrailingActive', 'NONE')}")
                                
                                mark_price = bp.get('markPrice', pos.get('markPrice', 0))
                                # Phase 204: Prefer currentPrice (close/last price) over markPrice
                                current_price_sync = pos.get('currentPrice', mark_price)
                                entry_price = pos.get('entryPrice', 0)
                                
                                # Phase 154: Initialize ALL exit params if missing
                                pos_atr = pos.get('atr', entry_price * 0.02) if entry_price > 0 else 0
                                
                                # Initialize ATR if missing
                                if not pos.get('atr') and entry_price > 0:
                                    pos['atr'] = entry_price * 0.02  # 2% default ATR
                                    pos_atr = pos['atr']
                                
                                # Initialize SL if missing or zero
                                if not pos.get('stopLoss') or pos.get('stopLoss', 0) == 0:
                                    sl_mult = global_paper_trader.sl_multiplier
                                    if pos['side'] == 'LONG':
                                        pos['stopLoss'] = max(entry_price * 0.01, entry_price - (pos_atr * sl_mult))
                                    else:
                                        pos['stopLoss'] = entry_price + (pos_atr * sl_mult)
                                    logger.info(f"ðŸ“Š Exit fix: {symbol} stopLoss set to {pos['stopLoss']:.6f}")
                                
                                # Initialize TP if missing or zero
                                if not pos.get('takeProfit') or pos.get('takeProfit', 0) == 0:
                                    tp_mult = global_paper_trader.tp_multiplier
                                    if pos['side'] == 'LONG':
                                        pos['takeProfit'] = entry_price + (pos_atr * tp_mult)
                                    else:
                                        pos['takeProfit'] = max(entry_price * 0.01, entry_price - (pos_atr * tp_mult))
                                    logger.info(f"ðŸ“Š Exit fix: {symbol} takeProfit set to {pos['takeProfit']:.6f}")
                                
                                # Phase 192: Fix existing negative SL/TP
                                if pos.get('stopLoss', 0) < 0:
                                    pos['stopLoss'] = entry_price * 0.01
                                    pos['trailingStop'] = pos['stopLoss']
                                    logger.warning(f"ðŸ”§ Phase 192: Fixed negative SL for {symbol}")
                                if pos.get('takeProfit', 0) < 0:
                                    pos['takeProfit'] = entry_price * 0.01
                                    logger.warning(f"ðŸ”§ Phase 192: Fixed negative TP for {symbol}")
                                
                                # Initialize trailActivation if missing
                                if not pos.get('trailActivation') or pos.get('trailActivation', 0) == 0:
                                    trail_act_mult = global_paper_trader.trail_activation_atr
                                    if pos['side'] == 'LONG':
                                        pos['trailActivation'] = entry_price + (pos_atr * trail_act_mult)
                                    else:
                                        pos['trailActivation'] = entry_price - (pos_atr * trail_act_mult)
                                    logger.info(f"ðŸ“Š Exit fix: {symbol} trailActivation set to {pos['trailActivation']:.6f}")
                                
                                # Initialize trailDistance if missing
                                if not pos.get('trailDistance'):
                                    pos['trailDistance'] = pos_atr * global_paper_trader.trail_distance_atr
                                    logger.info(f"ðŸ“Š Exit fix: {symbol} trailDistance set to {pos['trailDistance']:.6f}")
                                
                                # Initialize trailingStop if missing (use SL as initial value)
                                if not pos.get('trailingStop'):
                                    pos['trailingStop'] = pos.get('stopLoss', 0)
                                
                                # Phase 213: Trail activation requires minimum ROI of 1.5%
                                # (replaces Phase 154/210 forced activation)
                                if current_price_sync > 0 and entry_price > 0:
                                    sync_leverage = pos.get('leverage', 10)
                                    
                                    if pos['side'] == 'LONG':
                                        sync_price_move = ((current_price_sync - entry_price) / entry_price) * 100
                                    else:
                                        sync_price_move = ((entry_price - current_price_sync) / entry_price) * 100
                                    sync_roi = sync_price_move * sync_leverage
                                    
                                    # Phase 231h: Only price_move check + breakeven on activation
                                    if (sync_price_move >= 0.75 or sync_roi >= 5.0) and not pos.get('isTrailingActive', False):
                                        pos['isTrailingActive'] = True
                                        # Breakeven on BOTH stopLoss AND trailingStop
                                        if pos['side'] == 'LONG':
                                            _sync_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP_SYNC')
                                            be_price = entry_price * (1 + _sync_buf)
                                            pos['stopLoss'] = max(pos.get('stopLoss', 0), be_price)
                                            pos['trailingStop'] = max(pos.get('trailingStop', 0), be_price)
                                        else:
                                            _sync_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP_SYNC')
                                            be_price = entry_price * (1 - _sync_buf)
                                            pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_price)
                                            pos['trailingStop'] = min(pos.get('trailingStop', float('inf')), be_price)
                                        logger.info(f"ðŸ“Š TRAIL+BE(sync): {symbol} {pos['side']} price_move={sync_price_move:.2f}%, SL+Trailâ†’breakeven")
                                break
                
                # ================================================================
                # Phase 100: Record externally closed positions to trade history
                # Without this, manual closes on Binance don't appear in UI history
                # ================================================================
                binance_symbols = {p.get('symbol') for p in binance_positions}
                closed_positions = []
                remaining_positions = []
                
                for p in global_paper_trader.positions:
                    if p.get('isLive') and p.get('symbol') not in binance_symbols:
                        # This position was closed externally on Binance
                        closed_positions.append(p)
                    else:
                        remaining_positions.append(p)
                
                # Record closed positions to trade history
                for pos in closed_positions:
                    symbol = pos.get('symbol', 'UNKNOWN')
                    engine_triggered = False  # Track if engine set the reason
                    
                    # Phase 138: Check if engine set a pending reason
                    if symbol in pending_close_reasons:
                        # Use engine's reason and trade data
                        reason_data = pending_close_reasons.pop(symbol)
                        trade = reason_data.get('trade_data', {})
                        # Update with actual Binance close data if available
                        trade['closeTime'] = int(datetime.now().timestamp() * 1000)
                        trade['reason'] = reason_data.get('reason', 'External Close (Binance)')
                        trade['closeReason'] = trade['reason']  # Phase 232c: dual field
                        engine_triggered = True
                        logger.info(f"ðŸ“‹ REASON MATCHED: {symbol} = {reason_data.get('reason')}")
                    else:
                        # No pending reason â€” infer from position data
                        exit_price = pos.get('markPrice', pos.get('entryPrice', 0))
                        pnl = pos.get('unrealizedPnl', 0)
                        pnl_percent = pos.get('unrealizedPnlPercent', 0)
                        entry_price = pos.get('entryPrice', 0)
                        side = pos.get('side', 'LONG')
                        tp = pos.get('takeProfit', 0)
                        sl = pos.get('stopLoss', 0)
                        is_trailing = pos.get('isTrailingActive', False)
                        leverage_val = pos.get('leverage', 10)
                        margin_val = pos.get('initialMargin', 0) or (pos.get('sizeUsd', 0) / max(leverage_val, 1))
                        roi_val = (pnl / margin_val * 100) if margin_val > 0 else 0
                        
                        # Phase 203 + Phase 210: Smart reason inference from position state
                        inferred_reason = 'External Close (Binance)'
                        
                        # Step 1: Try TP/SL price match
                        if tp > 0 and entry_price > 0:
                            if side == 'LONG' and exit_price >= tp * 0.998:
                                inferred_reason = f"ðŸŸ¢ TP: Take Profit Tetiklendi ({roi_val:+.1f}%)"
                            elif side == 'SHORT' and exit_price <= tp * 1.002:
                                inferred_reason = f"ðŸŸ¢ TP: Take Profit Tetiklendi ({roi_val:+.1f}%)"
                        
                        # Step 2: Try trailing stop inference
                        if inferred_reason.startswith('External'):
                            if is_trailing and pnl >= 0:
                                inferred_reason = f"ðŸ“ˆ TRAIL: Trailing Stop Tetiklendi ({roi_val:+.1f}%)"
                            elif is_trailing and pnl < 0:
                                inferred_reason = f"ðŸ”´ SL: Trailing Stop Tetiklendi ({roi_val:+.1f}%)"
                            elif sl > 0:
                                if side == 'LONG' and exit_price <= sl * 1.002:
                                    inferred_reason = f"ðŸ”´ SL: Stop Loss Tetiklendi ({roi_val:+.1f}%)"
                                elif side == 'SHORT' and exit_price >= sl * 0.998:
                                    inferred_reason = f"ðŸ”´ SL: Stop Loss Tetiklendi ({roi_val:+.1f}%)"
                        
                        # Step 3: Phase 210 â€” PnL-based fallback inference
                        if inferred_reason.startswith('External'):
                            if roi_val >= 10:
                                inferred_reason = f"ðŸŸ¢ TP_INFERRED: KarlÄ± Ã‡Ä±kÄ±ÅŸ ({roi_val:+.1f}%)"
                            elif roi_val <= -5:
                                inferred_reason = f"ðŸ”´ SL_INFERRED: ZararlÄ± Ã‡Ä±kÄ±ÅŸ ({roi_val:+.1f}%)"
                            elif abs(roi_val) <= 2:
                                inferred_reason = f"ðŸ“Š BREAKEVEN_INFERRED: BaÅŸabaÅŸ ({roi_val:+.1f}%)"
                            else:
                                inferred_reason = f"ðŸ“‹ CLOSE_INFERRED: Pozisyon KapandÄ± ({roi_val:+.1f}%)"
                        
                        if 'INFERRED' in inferred_reason:
                            logger.info(f"ðŸ” REASON INFERRED (Phase 210): {symbol} = {inferred_reason}")
                        elif inferred_reason != 'External Close (Binance)':
                            logger.info(f"ðŸ” REASON INFERRED: {symbol} = {inferred_reason}")
                        else:
                            logger.info(f"ðŸ”— EXTERNAL CLOSE: {symbol} â€” no engine reason, no inference match")
                        
                        trade = {
                            "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                            "symbol": symbol,
                            "side": side,
                            "entryPrice": entry_price,
                            "exitPrice": exit_price,
                            "size": pos.get('size', 0),
                            "sizeUsd": pos.get('sizeUsd', 0),
                            "pnl": pnl,
                            "pnlPercent": pnl_percent,
                            "margin": margin_val,
                            "roi": roi_val,
                            "openTime": pos.get('openTime', 0),
                            "closeTime": int(datetime.now().timestamp() * 1000),
                            "reason": inferred_reason,
                            "closeReason": inferred_reason,
                            "leverage": leverage_val,
                            "isLive": True,
                            "signalScore": pos.get('signalScore', 0),
                            "mtfScore": pos.get('mtfScore', 0),
                            "zScore": pos.get('zScore', 0),
                            "spreadLevel": pos.get('spreadLevel', 'unknown'),
                            "stopLoss": sl,
                            "takeProfit": tp,
                            "trailActivation": pos.get('trailActivation', 0),
                            "trailingStop": pos.get('trailingStop', 0),
                            "isTrailingActive": is_trailing,
                            "atr": pos.get('atr', 0),
                        }
                    
                    global_paper_trader.trades.append(trade)
                    
                    # Save to SQLite
                    try:
                        safe_create_task(sqlite_manager.save_trade(trade))
                    except Exception as e:
                        logger.debug(f"SQLite save error: {e}")
                    
                    # Update stats only for external closes (engine already updated stats)
                    if not engine_triggered:
                        global_paper_trader.stats['totalTrades'] += 1
                        global_paper_trader.stats['totalPnl'] += trade.get('pnl', 0)
                        if trade.get('pnl', 0) > 0:
                            global_paper_trader.stats['winningTrades'] += 1
                        else:
                            global_paper_trader.stats['losingTrades'] += 1
                    
                    logger.info(f"ðŸ“¥ CLOSE RECORDED: {pos.get('side')} {symbol} | PnL: ${trade.get('pnl', 0):.2f} | Reason: {trade.get('reason')}")
                
                global_paper_trader.positions = remaining_positions
                
                if closed_positions:
                    global_paper_trader.save_state()
                    logger.info(f"âœ… Recorded {len(closed_positions)} externally closed positions to trade history")
                
                # Sync timestamp
                live_binance_trader.last_sync_time = int(datetime.now().timestamp() * 1000)
                
                # Phase 83: Position count verification
                engine_live_count = len([p for p in global_paper_trader.positions if p.get('isLive')])
                if len(binance_positions) != engine_live_count:
                    logger.warning(f"âš ï¸ Position mismatch: Binance={len(binance_positions)}, Engine={engine_live_count}")
                
                # UI'a broadcast et
                await ui_ws_manager.broadcast('binance_sync', {
                    'balance': balance,
                    'positions': binance_positions,
                    'position_count': len(binance_positions),
                    'sync_time': live_binance_trader.last_sync_time,
                    'trading_mode': 'live'
                })
                
                # Phase 84: Refresh PnL cache every sync cycle for consistent UI display
                try:
                    pnl_data = await live_binance_trader.get_pnl_from_binance()
                    live_binance_trader.cached_pnl = pnl_data
                    logger.info(f"âœ… Sync: ${balance['total']:.2f} | {len(binance_positions)} pos | PnL today=${pnl_data.get('todayPnl', 0):.2f}")
                except Exception as pe:
                    logger.warning(f"PnL cache refresh failed: {pe}")
                
                # Phase 191: Update position symbols for WS callback
                binance_ws_manager.position_symbols = set(
                    p.get('symbol') for p in global_paper_trader.positions if p.get('symbol')
                )
                if binance_ws_manager.on_price_update is None:
                    binance_ws_manager.on_price_update = on_position_price_update
                    logger.info(f"âš¡ Phase 191: WebSocket callback registered for {len(binance_ws_manager.position_symbols)} symbols")
                
                # ================================================================
                # Phase 148: Periodic trade history sync from Binance
                # Runs every 5 minutes (100 loops Ã— 3s = 300s = 5 min)
                # ================================================================
                if not hasattr(live_binance_trader, '_trade_sync_counter'):
                    live_binance_trader._trade_sync_counter = 0
                
                live_binance_trader._trade_sync_counter += 1
                
                if live_binance_trader._trade_sync_counter >= 100:  # Every 5 minutes
                    live_binance_trader._trade_sync_counter = 0
                    try:
                        synced = await live_binance_trader.sync_closed_trades_from_binance(hours_back=24)
                        if synced > 0:
                            logger.info(f"ðŸ“¥ Trade history sync: {synced} new trades added")
                    except Exception as tse:
                        logger.warning(f"Trade history sync failed: {tse}")
                
        except Exception as e:
            import traceback
            logger.error(f"Binance sync error: {e}\n{traceback.format_exc()}")
        
        # Phase 86: Reduced interval to 3s (was 10s) - utilizing ~60% of API capacity
        # Weight calculation: 20 calls/min Ã— 40 weight = 800 weight/min (of 2400 limit)
        await asyncio.sleep(3)

app = FastAPI(title="HHQ-1 Quant Backend", version="2.0.0", lifespan=lifespan)

# CORS for React Frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# ATR CALCULATION (Average True Range)
# ============================================================================

def calculate_atr(highs: list, lows: list, closes: list, period: int = 14) -> float:
    """
    Calculate Average True Range for volatility-based stop loss/take profit.
    
    ATR = Average of True Range over N periods
    True Range = max(High-Low, |High-PrevClose|, |Low-PrevClose|)
    
    Args:
        highs: List of high prices
        lows: List of low prices
        closes: List of close prices
        period: ATR period (default 14)
        
    Returns:
        ATR value
    """
    if len(closes) < period + 1:
        # Not enough data, estimate from price volatility
        if closes:
            return np.std(closes[-20:]) * 2 if len(closes) >= 20 else closes[-1] * 0.02
        return 0.0
    
    try:
        highs = np.array(highs)
        lows = np.array(lows)
        closes = np.array(closes)
        
        # True Range calculation
        tr1 = highs[1:] - lows[1:]  # High - Low
        tr2 = np.abs(highs[1:] - closes[:-1])  # |High - Prev Close|
        tr3 = np.abs(lows[1:] - closes[:-1])  # |Low - Prev Close|
        
        true_range = np.maximum(np.maximum(tr1, tr2), tr3)
        
        # ATR is the moving average of True Range
        if len(true_range) >= period:
            atr = np.mean(true_range[-period:])
            return float(atr)
        return float(np.mean(true_range))
        
    except Exception as e:
        logger.warning(f"ATR calculation error: {e}")
        return 0.0


# ============================================================================
# PHASE 193: ENHANCED TECHNICAL INDICATORS (pandas-ta powered)
# ============================================================================

def calculate_enhanced_indicators(highs: list, lows: list, closes: list, volumes: list = None) -> dict:
    """
    Calculate a comprehensive set of technical indicators using pandas-ta.
    Falls back to manual calculations if pandas-ta is not available.
    
    Returns dict with:
        macd_histogram: MACD histogram value (positive=bullish momentum)
        macd_signal_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        bb_position: Price position within Bollinger Bands (-1 to +1, >1 = above upper)
        bb_width: Band width as % of price (volatility measure)
        stoch_rsi_k: Stochastic RSI %K (0-100, <20=oversold, >80=overbought)
        stoch_rsi_d: Stochastic RSI %D (smoothed)
        stoch_rsi_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        atr_pta: ATR calculated by pandas-ta (more accurate EMA smoothing)
        ema_8: 8-period EMA
        ema_21: 21-period EMA
        ema_cross: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        vwap_value: VWAP if volumes available
    """
    result = {
        'macd_histogram': 0.0,
        'macd_signal_cross': 'NEUTRAL',
        'bb_position': 0.0,
        'bb_width': 0.0,
        'stoch_rsi_k': 50.0,
        'stoch_rsi_d': 50.0,
        'stoch_rsi_cross': 'NEUTRAL',
        'atr_pta': 0.0,
        'ema_8': 0.0,
        'ema_21': 0.0,
        'ema_cross': 'NEUTRAL',
        'vwap_value': 0.0,
        'squeeze_on': False,
        'squeeze_hist': 0.0,
        'chop_value': 50.0,
    }
    
    if len(closes) < 30:
        return result
    
    try:
        if PANDAS_TA_AVAILABLE:
            df = pd.DataFrame({
                'high': highs,
                'low': lows,
                'close': closes,
            })
            if volumes:
                df['volume'] = volumes
            
            # MACD (12, 26, 9)
            macd = df.ta.macd(fast=12, slow=26, signal=9)
            if macd is not None and not macd.empty:
                hist_col = [c for c in macd.columns if 'MACDh' in c or 'Histogram' in c.title()]
                signal_col = [c for c in macd.columns if 'MACDs' in c]
                macd_col = [c for c in macd.columns if c.startswith('MACD_')]
                
                if hist_col:
                    result['macd_histogram'] = float(macd[hist_col[0]].iloc[-1] or 0)
                
                # MACD crossover detection
                if macd_col and signal_col:
                    macd_line = macd[macd_col[0]].iloc[-2:]
                    signal_line = macd[signal_col[0]].iloc[-2:]
                    if len(macd_line) >= 2 and len(signal_line) >= 2:
                        prev_diff = float(macd_line.iloc[0] or 0) - float(signal_line.iloc[0] or 0)
                        curr_diff = float(macd_line.iloc[1] or 0) - float(signal_line.iloc[1] or 0)
                        if prev_diff <= 0 and curr_diff > 0:
                            result['macd_signal_cross'] = 'BULLISH'
                        elif prev_diff >= 0 and curr_diff < 0:
                            result['macd_signal_cross'] = 'BEARISH'
            
            # Bollinger Bands (20, 2)
            bbands = df.ta.bbands(length=20, std=2)
            if bbands is not None and not bbands.empty:
                upper_col = [c for c in bbands.columns if 'BBU' in c]
                lower_col = [c for c in bbands.columns if 'BBL' in c]
                mid_col = [c for c in bbands.columns if 'BBM' in c]
                bw_col = [c for c in bbands.columns if 'BBB' in c]
                
                if upper_col and lower_col:
                    upper = float(bbands[upper_col[0]].iloc[-1] or 0)
                    lower = float(bbands[lower_col[0]].iloc[-1] or 0)
                    price = closes[-1]
                    band_range = upper - lower
                    if band_range > 0:
                        # -1 = at lower band, 0 = middle, +1 = at upper band
                        result['bb_position'] = ((price - lower) / band_range) * 2 - 1
                    if mid_col:
                        mid = float(bbands[mid_col[0]].iloc[-1] or 0)
                        if mid > 0:
                            result['bb_width'] = (band_range / mid) * 100
            
            # Stochastic RSI (14, 14, 3, 3)
            stochrsi = df.ta.stochrsi(length=14, rsi_length=14, k=3, d=3)
            if stochrsi is not None and not stochrsi.empty:
                k_col = [c for c in stochrsi.columns if 'STOCHRSIk' in c]
                d_col = [c for c in stochrsi.columns if 'STOCHRSId' in c]
                
                if k_col:
                    result['stoch_rsi_k'] = float(stochrsi[k_col[0]].iloc[-1] or 50)
                if d_col:
                    result['stoch_rsi_d'] = float(stochrsi[d_col[0]].iloc[-1] or 50)
                
                # StochRSI crossover
                if k_col and d_col and len(stochrsi) >= 2:
                    prev_k = float(stochrsi[k_col[0]].iloc[-2] or 50)
                    curr_k = result['stoch_rsi_k']
                    prev_d = float(stochrsi[d_col[0]].iloc[-2] or 50)
                    curr_d = result['stoch_rsi_d']
                    if prev_k <= prev_d and curr_k > curr_d and curr_k < 30:
                        result['stoch_rsi_cross'] = 'BULLISH'
                    elif prev_k >= prev_d and curr_k < curr_d and curr_k > 70:
                        result['stoch_rsi_cross'] = 'BEARISH'
            
            # ATR (14) â€” Wilder's smoothing (more accurate than SMA)
            atr_result = df.ta.atr(length=14)
            if atr_result is not None and not atr_result.empty:
                result['atr_pta'] = float(atr_result.iloc[-1] or 0)
            
            # EMA 8 & 21 crossover
            ema8 = df.ta.ema(length=8)
            ema21 = df.ta.ema(length=21)
            if ema8 is not None and ema21 is not None and not ema8.empty and not ema21.empty:
                result['ema_8'] = float(ema8.iloc[-1] or 0)
                result['ema_21'] = float(ema21.iloc[-1] or 0)
                if result['ema_8'] > result['ema_21']:
                    result['ema_cross'] = 'BULLISH'
                elif result['ema_8'] < result['ema_21']:
                    result['ema_cross'] = 'BEARISH'
            
            # VWAP (if volumes available)
            if volumes and len(volumes) == len(closes):
                try:
                    vwap = df.ta.vwap()
                    if vwap is not None and not vwap.empty:
                        result['vwap_value'] = float(vwap.iloc[-1] or 0)
                except Exception:
                    pass

            # Choppiness Index (14)
            # CHOP > 61.8 means choppy/ranging, CHOP < 38.2 means trending
            try:
                chop = df.ta.chop(length=14)
                if chop is not None and not chop.empty:
                    result['chop_value'] = float(chop.iloc[-1] or 50.0)
            except Exception:
                pass

            # TTM Squeeze
            # Identifies periods of market consolidation (squeeze) and momentum breakouts
            try:
                # Returns DataFrame with columns like SQZ_20_2.0_20_1.5, SQZ_ON, SQZ_OFF, SQZ_NO
                sqz = df.ta.squeeze(length=20, bb_std=2.0, kc_mult=1.5, mom_length=20)
                if sqz is not None and not sqz.empty:
                    sqz_on_col = [c for c in sqz.columns if 'SQZ_ON' in c]
                    # The main momentum histogram column
                    sqz_hist_col = [c for c in sqz.columns if c.startswith('SQZ_') and 'ON' not in c and 'OFF' not in c and 'NO' not in c]
                    
                    if sqz_on_col:
                        result['squeeze_on'] = bool(sqz[sqz_on_col[0]].iloc[-1] == 1)
                    if sqz_hist_col:
                        result['squeeze_hist'] = float(sqz[sqz_hist_col[0]].iloc[-1] or 0.0)
            except Exception as sqz_err:
                logger.debug(f"Squeeze calc error: {sqz_err}")
        
        else:
            # Manual fallback calculations (basic versions)
            closes_arr = np.array(closes)
            
            # Simple MACD manual
            if len(closes_arr) >= 26:
                ema12 = pd.Series(closes_arr).ewm(span=12).mean().iloc[-1]
                ema26 = pd.Series(closes_arr).ewm(span=26).mean().iloc[-1]
                result['macd_histogram'] = float(ema12 - ema26)
            
            # Simple Bollinger Bands manual
            if len(closes_arr) >= 20:
                sma20 = np.mean(closes_arr[-20:])
                std20 = np.std(closes_arr[-20:])
                upper = sma20 + 2 * std20
                lower = sma20 - 2 * std20
                band_range = upper - lower
                if band_range > 0:
                    result['bb_position'] = ((closes_arr[-1] - lower) / band_range) * 2 - 1
                    result['bb_width'] = (band_range / sma20) * 100 if sma20 > 0 else 0
            
            # Simple EMA crossover manual
            if len(closes_arr) >= 21:
                ema8 = pd.Series(closes_arr).ewm(span=8).mean().iloc[-1]
                ema21 = pd.Series(closes_arr).ewm(span=21).mean().iloc[-1]
                result['ema_8'] = float(ema8)
                result['ema_21'] = float(ema21)
                result['ema_cross'] = 'BULLISH' if ema8 > ema21 else 'BEARISH'
        
    except Exception as e:
        logger.warning(f"Enhanced indicator calculation error: {e}")
    
    return result


# ============================================================================
# HURST EXPONENT CALCULATION (R/S Analysis)
# ============================================================================

def calculate_hurst(prices: list, min_window: int = 10) -> float:
    """
    Calculate Hurst Exponent using autocorrelation-based method.
    
    Phase 128: Replaced R/S with returns autocorrelation for more natural variation.
    
    H > 0.55 â†’ Trending market (positive autocorrelation)
    H < 0.45 â†’ Mean-reverting market (negative autocorrelation)
    H â‰ˆ 0.50 â†’ Random walk (no autocorrelation)
    """
    n = len(prices)
    
    if n < 20:  # Need at least 20 prices for meaningful calculation
        return 0.5
    
    try:
        ts = np.array(prices)
        
        # Calculate log returns
        returns = np.diff(np.log(ts))
        
        if len(returns) < 15:
            return 0.5
        
        # Method 1: Autocorrelation-based Hurst estimate
        # Positive autocorrelation â†’ H > 0.5 (trending)
        # Negative autocorrelation â†’ H < 0.5 (mean-reverting)
        
        # Calculate lag-1 autocorrelation
        mean_ret = np.mean(returns)
        var_ret = np.var(returns)
        
        if var_ret == 0:
            return 0.5
        
        # Compute autocorrelation for multiple lags
        autocorr_sum = 0.0
        valid_lags = 0
        
        for lag in [1, 2, 3, 5, 8]:  # Fibonacci-like lags for multi-scale
            if lag >= len(returns):
                break
            numerator = np.sum((returns[lag:] - mean_ret) * (returns[:-lag] - mean_ret))
            denominator = len(returns[lag:]) * var_ret
            if denominator > 0:
                autocorr = numerator / denominator
                autocorr_sum += autocorr
                valid_lags += 1
        
        if valid_lags == 0:
            return 0.5
        
        avg_autocorr = autocorr_sum / valid_lags
        
        # Map autocorrelation (-1 to +1) to Hurst (0.1 to 0.9)
        # autocorr = +0.5 â†’ H = 0.75 (strong trending)
        # autocorr = 0.0  â†’ H = 0.50 (random walk)
        # autocorr = -0.5 â†’ H = 0.25 (strong mean reversion)
        hurst = 0.5 + (avg_autocorr * 0.5)
        
        # Add variance-based adjustment for more differentiation
        # High variance coins get slight trending bias, low variance slight MR bias
        returns_std = np.std(returns)
        median_std = 0.02  # Typical crypto daily return std
        
        if returns_std > median_std * 2:
            hurst += 0.05  # Volatile = slight trending bias
        elif returns_std < median_std * 0.5:
            hurst -= 0.05  # Calm = slight MR bias
        
        # Clamp to reasonable bounds
        hurst = max(0.15, min(0.85, hurst))
        
        return round(hurst, 3)  # 3 decimal places for variation
        
    except Exception as e:
        logger.warning(f"Hurst calculation error: {e}")
        return 0.5


# ============================================================================
# SMART MONEY CONCEPTS (SMC) CALCULATION - Phase 208
# ============================================================================

def extract_smc_features(ohlcv: list) -> dict:
    """
    Extract Order Blocks (OB) and Fair Value Gaps (FVG) using smartmoneyconcepts.
    Requires at least 15 candles, returns the nearest unmitigated FVG/OB.
    """
    result = {
        'fvg_bullish': None,
        'fvg_bearish': None,
        'ob_bullish': None,
        'ob_bearish': None
    }
    
    if not ohlcv or len(ohlcv) < 15:
        return result
        
    try:
        import pandas as pd
        from smartmoneyconcepts import smc
        
        # ohlcv format: [timestamp, open, high, low, close, volume]
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        
        # 1. Swing Highs/Lows
        swing_hl = smc.swing_highs_lows(df, swing_length=3)
        
        # 2. Order Blocks (OB)
        ob = smc.ob(df, swing_highs_lows=swing_hl)
        ob_unmitigated = ob[ob['MitigatedIndex'].isna() | (ob['MitigatedIndex'] == 0)]
        
        bull_obs = ob_unmitigated[ob_unmitigated['OB'] == 1]
        bear_obs = ob_unmitigated[ob_unmitigated['OB'] == -1]
        
        if not bull_obs.empty:
            last_bull = bull_obs.iloc[-1]
            result['ob_bullish'] = {'top': float(last_bull['Top']), 'bottom': float(last_bull['Bottom'])}
            
        if not bear_obs.empty:
            last_bear = bear_obs.iloc[-1]
            result['ob_bearish'] = {'top': float(last_bear['Top']), 'bottom': float(last_bear['Bottom'])}
            
        # 3. Fair Value Gaps (FVG)
        fvg = smc.fvg(df)
        fvg_unmitigated = fvg[fvg['MitigatedIndex'].isna() | (fvg['MitigatedIndex'] == 0)]
        
        bull_fvgs = fvg_unmitigated[fvg_unmitigated['FVG'] == 1]
        bear_fvgs = fvg_unmitigated[fvg_unmitigated['FVG'] == -1]
        
        if not bull_fvgs.empty:
            last_bull_fvg = bull_fvgs.iloc[-1]
            result['fvg_bullish'] = {'top': float(last_bull_fvg['Top']), 'bottom': float(last_bull_fvg['Bottom'])}
            
        if not bear_fvgs.empty:
            last_bear_fvg = bear_fvgs.iloc[-1]
            result['fvg_bearish'] = {'top': float(last_bear_fvg['Top']), 'bottom': float(last_bear_fvg['Bottom'])}
            
        return result
        
    except ImportError:
        logger.debug("smartmoneyconcepts package not installed. Skipping SMC.")
    except Exception as e:
        logger.debug(f"SMC feature extraction error: {e}")
        
    return result

# ============================================================================
# ADX (Average Directional Index) CALCULATION - Phase 137
# ============================================================================

def calculate_adx(highs: list, lows: list, closes: list, period: int = 14) -> tuple:
    """
    Calculate Average Directional Index (ADX) for trend strength and direction.
    
    Phase 137: ADX + Hurst kombinasyonu ile regime detection.
    Phase XXX: Extended to return trend direction for signal filtering.
    
    ADX > 25 â†’ GÃ¼Ã§lÃ¼ trend (mean reversion riskli)
    ADX < 20 â†’ ZayÄ±f trend / Range (mean reversion iÃ§in ideal)
    ADX 20-25 â†’ GeÃ§iÅŸ bÃ¶lgesi
    
    Returns:
        tuple: (adx, trend_direction, plus_di, minus_di)
        - adx: Trend strength (5-80)
        - trend_direction: "BULLISH" if +DI > -DI, "BEARISH" if -DI > +DI, else "NEUTRAL"
        - plus_di: Positive Directional Indicator
        - minus_di: Negative Directional Indicator
    """
    n = len(highs)
    
    if n < period + 1:
        return 25.0, "NEUTRAL", 0.0, 0.0  # Neutral default
    
    try:
        highs_arr = np.array(highs)
        lows_arr = np.array(lows)
        closes_arr = np.array(closes)
        
        # +DM, -DM ve True Range hesapla
        plus_dm = []
        minus_dm = []
        tr = []
        
        for i in range(1, n):
            high_diff = highs_arr[i] - highs_arr[i-1]
            low_diff = lows_arr[i-1] - lows_arr[i]
            
            # +DM: YukarÄ± hareket daha bÃ¼yÃ¼kse ve pozitifse
            if high_diff > low_diff and high_diff > 0:
                plus_dm.append(high_diff)
            else:
                plus_dm.append(0)
            
            # -DM: AÅŸaÄŸÄ± hareket daha bÃ¼yÃ¼kse ve pozitifse
            if low_diff > high_diff and low_diff > 0:
                minus_dm.append(low_diff)
            else:
                minus_dm.append(0)
            
            # True Range
            tr_val = max(
                highs_arr[i] - lows_arr[i],
                abs(highs_arr[i] - closes_arr[i-1]),
                abs(lows_arr[i] - closes_arr[i-1])
            )
            tr.append(tr_val)
        
        if len(tr) < period:
            return 25.0, "NEUTRAL", 0.0, 0.0
        
        # Smoothed averages (Wilder's smoothing - period average)
        atr = sum(tr[-period:]) / period
        
        if atr == 0:
            return 25.0, "NEUTRAL", 0.0, 0.0
        
        plus_di = 100 * sum(plus_dm[-period:]) / (atr * period)
        minus_di = 100 * sum(minus_dm[-period:]) / (atr * period)
        
        # DX hesapla
        di_sum = plus_di + minus_di
        if di_sum == 0:
            return 25.0, "NEUTRAL", plus_di, minus_di
        
        dx = abs(plus_di - minus_di) / di_sum * 100
        
        # Clamp to reasonable bounds
        adx = max(5.0, min(80.0, dx))
        
        # Determine trend direction based on +DI vs -DI
        di_diff = plus_di - minus_di
        if di_diff > 5:  # Significant bullish directional movement
            trend_direction = "BULLISH"
        elif di_diff < -5:  # Significant bearish directional movement
            trend_direction = "BEARISH"
        else:
            trend_direction = "NEUTRAL"
        
        return round(adx, 1), trend_direction, round(plus_di, 1), round(minus_di, 1)
        
    except Exception as e:
        logger.warning(f"ADX calculation error: {e}")
        return 25.0, "NEUTRAL", 0.0, 0.0


# ============================================================================
# DYNAMIC SPREAD LEVEL CALCULATION - Based on ATR/Volatility
# ============================================================================

def calculate_spread_level(atr_pct: float = None, highs: list = None, lows: list = None, closes: list = None) -> str:
    """
    Calculate spread level based on price volatility (ATR as % of price).
    
    Args:
        atr_pct: Pre-calculated ATR as percentage of price (optional)
        highs, lows, closes: Raw price data to calculate volatility (optional)
        
    Returns:
        Spread level: 'Very Low', 'Low', 'Normal', 'High', 'Very High', 'Extreme', 'Ultra'
        
    Thresholds (based on typical crypto volatility):
    - Very Low: ATR < 1% (BTC, ETH)
    - Low: ATR 1-2%
    - Normal: ATR 2-4%
    - High: ATR 4-7%  
    - Very High: ATR 7-12% (meme coins)
    - Extreme: ATR 12-20% (hyper-volatile)
    - Ultra: ATR > 20% (extreme edge cases)
    """
    
    # Calculate volatility from candle data if not provided
    if atr_pct is None and highs and lows and closes:
        try:
            n = min(len(highs), len(lows), len(closes))
            if n >= 14:
                # Calculate ATR from last 14 candles
                tr_values = []
                for i in range(1, min(15, n)):
                    tr = max(
                        highs[-i] - lows[-i],
                        abs(highs[-i] - closes[-i-1]) if i < n-1 else highs[-i] - lows[-i],
                        abs(lows[-i] - closes[-i-1]) if i < n-1 else highs[-i] - lows[-i]
                    )
                    tr_values.append(tr)
                
                if tr_values:
                    atr = sum(tr_values) / len(tr_values)
                    price = closes[-1] if closes else 1
                    atr_pct = (atr / price * 100) if price > 0 else 2.0
        except Exception:
            pass
    
    # Default to Normal if calculation failed
    if atr_pct is None:
        return 'Normal'
    
    # Map ATR percentage to spread level
    if atr_pct < 1.0:
        return 'Very Low'   # BTC, ETH - stable majors
    elif atr_pct < 2.0:
        return 'Low'        # Large caps
    elif atr_pct < 4.0:
        return 'Normal'     # Mid caps
    elif atr_pct < 7.0:
        return 'High'       # Small caps, volatile
    elif atr_pct < 12.0:
        return 'Very High'  # Meme coins, very volatile
    elif atr_pct < 20.0:
        return 'Extreme'    # Hyper-volatile, new launches
    else:
        return 'Ultra'      # Extreme edge cases


def calculate_atr_percentage(symbol: str, highs: list, lows: list, closes: list, period: int = 14) -> float:
    """
    Calculate ATR as percentage of current price.
    Used for dynamic spread level and position management.
    
    Returns: ATR percentage (e.g., 2.5 means 2.5% volatility)
    """
    if len(closes) < period + 1:
        return 2.0  # Default to 2% if not enough data
    
    try:
        tr_values = []
        for i in range(1, min(period + 1, len(closes))):
            tr = max(
                highs[-i] - lows[-i],
                abs(highs[-i] - closes[-i-1]),
                abs(lows[-i] - closes[-i-1])
            )
            tr_values.append(tr)
        
        if not tr_values:
            return 2.0
            
        atr = sum(tr_values) / len(tr_values)
        current_price = closes[-1]
        
        if current_price <= 0:
            return 2.0
            
        return (atr / current_price) * 100
        
    except Exception as e:
        logger.warning(f"ATR percentage calculation error for {symbol}: {e}")
        return 2.0


# ============================================================================
# Z-SCORE CALCULATION
# ============================================================================

def calculate_zscore(spread_series: list, lookback: int = 20) -> float:
    """
    Calculate Z-Score for pairs trading / mean reversion.
    |Z| > 2.0 â†’ Trading opportunity
    """
    if len(spread_series) < lookback:
        return 0.0
    
    try:
        series = np.array(spread_series[-lookback:])
        mean = np.mean(series)
        std = np.std(series, ddof=1)
        
        if std > 0:
            current = series[-1]
            return (current - mean) / std
        return 0.0
        
    except Exception as e:
        logger.warning(f"Z-Score calculation error: {e}")
        return 0.0


# ============================================================================
# RSI CALCULATION (Relative Strength Index)
# ============================================================================

def calculate_rsi(closes: list, period: int = 14) -> float:
    """
    Calculate RSI (Relative Strength Index).
    
    RSI < 30 â†’ Oversold (LONG opportunity)
    RSI > 70 â†’ Overbought (SHORT opportunity)
    RSI 30-70 â†’ Neutral
    
    Returns: RSI value (0-100)
    """
    if len(closes) < period + 1:
        return 50.0  # Neutral
    
    try:
        prices = np.array(closes[-(period + 1):])
        deltas = np.diff(prices)
        
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        
        avg_gain = np.mean(gains)
        avg_loss = np.mean(losses)
        
        if avg_loss == 0:
            return 100.0 if avg_gain > 0 else 50.0
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
        
    except Exception as e:
        logger.warning(f"RSI calculation error: {e}")
        return 50.0


# ============================================================================
# CONSECUTIVE BAR CONFIRMATION
# ============================================================================

def check_consecutive_bars(closes: list, signal_side: str, required_bars: int = 2) -> tuple:
    """
    Check if the last N bars confirm the signal direction.
    
    For LONG signals: we want bars to be falling (creating oversold conditions)
    For SHORT signals: we want bars to be rising (creating overbought conditions)
    
    Args:
        closes: List of close prices
        signal_side: "LONG" or "SHORT"
        required_bars: Number of consecutive bars required (default 2)
        
    Returns:
        (confirmed: bool, consecutive_count: int, direction: str)
    """
    if len(closes) < required_bars + 1:
        return True, 0, "INSUFFICIENT_DATA"  # Not enough data, allow signal
    
    try:
        recent_closes = list(closes[-(required_bars + 1):])
        
        # Calculate bar directions
        bullish_count = 0
        bearish_count = 0
        
        for i in range(1, len(recent_closes)):
            if recent_closes[i] > recent_closes[i-1]:
                bullish_count += 1
            elif recent_closes[i] < recent_closes[i-1]:
                bearish_count += 1
        
        # Determine direction
        if bearish_count >= required_bars:
            direction = "BEARISH"
        elif bullish_count >= required_bars:
            direction = "BULLISH"
        else:
            direction = "MIXED"
        
        # For LONG: we want recent bars to be bearish (price falling = oversold setup)
        # For SHORT: we want recent bars to be bullish (price rising = overbought setup)
        if signal_side == "LONG":
            confirmed = bearish_count >= required_bars
            return confirmed, bearish_count, direction
        else:  # SHORT
            confirmed = bullish_count >= required_bars
            return confirmed, bullish_count, direction
            
    except Exception as e:
        logger.warning(f"Consecutive bar check error: {e}")
        return True, 0, "ERROR"  # On error, allow signal


# ============================================================================
# VOLUME SPIKE DETECTION
# ============================================================================

def detect_volume_spike(volumes: list, lookback: int = 20, threshold: float = 2.0) -> tuple:
    """
    Detect volume spikes (volume > threshold * average).
    
    Args:
        volumes: List of volume values
        lookback: Period for average calculation
        threshold: Multiple of average to consider a spike
        
    Returns:
        (is_spike: bool, volume_ratio: float)
    """
    if len(volumes) < lookback + 1:
        return False, 1.0
    
    try:
        recent_volumes = np.array(volumes[-(lookback + 1):-1], dtype=float)  # Exclude current
        current_volume = float(volumes[-1] or 0.0)

        # WebSocket volume feed anlÄ±k olarak eksik gelebilir.
        # Bu durumda LOW_VOL false-negative Ã¼retmemek iÃ§in nÃ¶tr davran.
        if current_volume <= 0:
            return False, 1.0

        positive_recent = recent_volumes[recent_volumes > 0]
        if len(positive_recent) < max(5, lookback // 3):
            return False, 1.0

        avg_volume = np.mean(positive_recent)
        if avg_volume <= 0:
            return False, 1.0

        volume_ratio = current_volume / avg_volume
        if not np.isfinite(volume_ratio):
            return False, 1.0

        volume_ratio = float(np.clip(volume_ratio, 0.1, 10.0))
        is_spike = volume_ratio >= threshold
        
        return is_spike, volume_ratio
        
    except Exception as e:
        logger.warning(f"Volume spike detection error: {e}")
        return False, 1.0


# ============================================================================
# PHASE 22: MULTI-TIMEFRAME CONFIGURATION
# ============================================================================

# Timeframes to analyze (exclude 3d+)
MTF_CONFIRMATION_TIMEFRAMES = ['1m', '5m', '15m', '1h', '4h', '1d']
MTF_MIN_AGREEMENT = 4  # Minimum TF agreement required

# Volatility-based parameters using ATR as percentage of price
# Phase 73: ATR% thresholds adjusted 5Ã— higher to match observed values
# Observed ATR% in production: 13-55% (higher than typical due to 4h OHLCV source)
# Low volatility = tighter stops, higher leverage | High volatility = wider stops, lower leverage
# Phase 184: Leverage reduced to safer levels for small accounts
VOLATILITY_LEVELS = {
    "very_low":  {"max_atr_pct": 10.0,  "trail": 0.5, "sl": 1.5, "tp": 2.5, "leverage": 15, "pullback": 0.003},  # <10% = 15x (was 50x)
    "low":       {"max_atr_pct": 20.0,  "trail": 1.0, "sl": 2.0, "tp": 3.0, "leverage": 10, "pullback": 0.006},  # <20% = 10x (was 25x)
    "normal":    {"max_atr_pct": 30.0,  "trail": 1.5, "sl": 2.5, "tp": 4.0, "leverage": 7,  "pullback": 0.012},  # <30% = 7x (was 10x)
    "high":      {"max_atr_pct": 50.0,  "trail": 2.0, "sl": 3.0, "tp": 5.0, "leverage": 5,  "pullback": 0.018},  # <50% = 5x
    "very_high": {"max_atr_pct": 70.0,  "trail": 3.0, "sl": 4.0, "tp": 6.0, "leverage": 3,  "pullback": 0.024},  # <70% = 3x
    "extreme":   {"max_atr_pct": 90.0,  "trail": 4.0, "sl": 5.0, "tp": 8.0, "leverage": 3,  "pullback": 0.030},  # <90% = 3x, hyper-volatile
    "ultra":     {"max_atr_pct": 999,   "trail": 5.0, "sl": 6.0, "tp": 10.0,"leverage": 3,  "pullback": 0.036}   # 90%+ = 3x, extreme
}

# ============================================================================
# FIBONACCI RETRACEMENT ENGINE â€” Feature Flags & Helpers
# Phase FIB: Dual-role Fibonacci (score bonus + entry refinement)
# ============================================================================

FIB_ENABLED = True               # Master switch â€” ACTIVE (Canary AÅŸama 1)
FIB_SCORE_ENABLED = True         # Score bonus layer (Layer 23)
FIB_ENTRY_ENABLED = True         # Entry blend layer â€” ACTIVE
FIB_MAX_ENTRY_DEV_PCT = 1.0      # Max deviation between fib_entry and atr_entry (%)
FIB_BLEND_ALPHA = 0.35           # Blend weight (0=pure ATR, 1=pure fib)

# ============================================================================
# ENTRY QUALITY GATE â€” Feature Flags
# Phase EQG: Filter out low-volume, weak-momentum entries
# ============================================================================

ENTRY_QUALITY_GATE_ENABLED = True
ENTRY_QUALITY_MODE = 'hard'      # 'soft' = score -15 | 'hard' = reject
EQ_MIN_VOLUME_RATIO = 1.25      # KoÅŸul A: min volume ratio
EQ_MIN_IMBALANCE = 4.0          # KoÅŸul B: min OB imbalance
EQ_MIN_OB_TREND = 2.0           # KoÅŸul B: min ob_imbalance_trend
EQ_MIN_VOLUME_24H = 1_500_000   # KoÅŸul C: min 24h volume ($)
EQ_MAX_SPREAD = 0.20            # KoÅŸul C: max spread (%)
EQ_MIN_DEPTH_USD = 120_000      # Legacy max cap for execution depth threshold
EQ_MIN_DEPTH_USD_BASE = 20_000  # Dynamic min floor
EQ_OBI_OPPOSE_VETO = 0.35       # Execution: OBI opposing veto threshold

# Signal memory / reinforcement (same coin repeated signals)
SIGNAL_MEMORY_ENABLED = True
SIGNAL_MEMORY_TTL_SECONDS = 45 * 60
SIGNAL_MEMORY_MAX_BONUS = 8
SIGNAL_MEMORY_BONUS_STEP = 2
SIGNAL_MEMORY_THINBOOK_RELAX_STEP = 0.10
SIGNAL_MEMORY_THINBOOK_MIN_SCALE = 0.65
SIGNAL_MEMORY_PENDING_EXTEND_STEP_SECONDS = 300
SIGNAL_MEMORY_PENDING_EXTEND_MAX_SECONDS = 1800
SIGNAL_MEMORY_OPPOSITE_FLIP_MIN_SCORE_GAP = 6

# MTF soft-override for high-quality setups
MTF_SOFT_OVERRIDE_ENABLED = True
MTF_SOFT_OVERRIDE_MIN_SCORE = 102
MTF_SOFT_OVERRIDE_PENALTY = 12
MTF_SOFT_OVERRIDE_MIN_EQ = 2
MTF_SOFT_OVERRIDE_SMART_SCORE_RELAX = 10
MTF_SOFT_OVERRIDE_SMART_MIN_EQ = 1

# Strong counter-trend MTF relax (pass with strict risk caps)
MTF_COUNTERTREND_SOFTPASS_ENABLED = True
MTF_COUNTERTREND_SOFTPASS_MIN_SCORE = 90
MTF_COUNTERTREND_SOFTPASS_MIN_EQ = 1
MTF_COUNTERTREND_SOFTPASS_MIN_EXEC = 60.0
MTF_COUNTERTREND_SOFTPASS_PENALTY = 14
MTF_COUNTERTREND_SOFTPASS_STRONG_EXTRA_PENALTY = 6
MTF_COUNTERTREND_SOFTPASS_MAX_LEVERAGE = 12
MTF_COUNTERTREND_SOFTPASS_SIZE_MULT = 0.65

# Volatile regime: strict by default, but allow near-threshold high-quality soft pass
VOLATILE_VETO_SOFTPASS_ENABLED = True
VOLATILE_VETO_SOFTPASS_MAX_GAP = 8
VOLATILE_VETO_SOFTPASS_PENALTY_BASE = 4
VOLATILE_VETO_SOFTPASS_LEVERAGE_CAP = 14
VOLATILE_VETO_SOFTPASS_SIZE_MULT = 0.75

# Thin-book guard soft-pass (controlled relax for high-quality SMART_V2 setups)
THIN_BOOK_SMART_SOFTPASS_ENABLED = True
THIN_BOOK_SMART_SOFTPASS_DEPTH_RATIO = 0.76
THIN_BOOK_SMART_SOFTPASS_MIN_SCORE = 108
THIN_BOOK_SMART_SOFTPASS_MIN_EXEC = 66.0
THIN_BOOK_SMART_SOFTPASS_MIN_EQ = 2
THIN_BOOK_SMART_SOFTPASS_MAX_SPREAD = 0.18
THIN_BOOK_SMART_SOFTPASS_PENALTY = 8

# Ultra-selective relax (only very high-quality SMART_V2 setups)
THIN_BOOK_SUPER_SOFTPASS_ENABLED = True
THIN_BOOK_SUPER_SOFTPASS_DEPTH_RATIO = 0.70
THIN_BOOK_SUPER_SOFTPASS_MIN_SCORE = 118
THIN_BOOK_SUPER_SOFTPASS_MIN_EXEC = 72.0
THIN_BOOK_SUPER_SOFTPASS_MIN_EQ = 3
THIN_BOOK_SUPER_SOFTPASS_MAX_SPREAD = 0.14
THIN_BOOK_SUPER_SOFTPASS_MIN_VOL_RATIO = 1.20
THIN_BOOK_SUPER_SOFTPASS_PENALTY = 10

# Hybrid execution quality gate (entry strictness)
EXEC_QUALITY_GATE_ENABLED = True
EXEC_QUALITY_MIN_SCORE = 58.0
EXEC_QUALITY_STRICT_MIN_SCORE = 66.0

# =========================================================================
# PHASE 237: SIGNAL QUALITY & FILL RATE â€” Feature Flags
# All default False for canary rollout
# =========================================================================
SOFT_RISK_GATE_ENABLED = False
ENTRY_TRADEABILITY_ENABLED = False
PENDING_SM_V2_ENABLED = False
REJECT_ATTRIBUTION_ENABLED = False

# =========================================================================
# PHASE 238A: BREAKEVEN BUFFER â€” Dynamic replacement for hardcoded 0.05%
# =========================================================================
BREAKEVEN_LIMIT_EXIT_ENABLED = False  # If True + is_live: try limit-close before market

def compute_breakeven_buffer_pct(
    spread_pct: float = 0.05,
    expected_slippage_pct: float = 0.02,
    is_live: bool = False,
    spread_level: str = "LOW",
    reason: str = "",
) -> float:
    """Compute dynamic breakeven buffer as a ratio (0.001 to 0.006).
    
    Formula: round_trip_fee + 0.6Ã—spread + p90_slippage + safety_margin
    Clamp: min 0.10% (0.001), max 0.60% (0.006)
    Returns float ratio, e.g. 0.0015 for 0.15%.
    """
    try:
        ROUND_TRIP_FEE_PCT = 0.10  # 0.05% maker+taker each side
        # Spread contribution (60% of spread â€” partial fill expected)
        spread_contrib = 0.6 * max(0, float(spread_pct))
        # Slippage contribution
        slip = max(0, float(expected_slippage_pct))
        # Spread level bump (normalize â€” system uses title-case: High/Very High/Extreme/Ultra)
        level_bump = 0.0
        sl = str(spread_level).upper()
        if sl in ("HIGH", "VERY HIGH", "EXTREME", "ULTRA"):
            level_bump = 0.04
        elif sl in ("NORMAL", "MEDIUM"):
            level_bump = 0.02
        # Live gets extra safety (real market impact)
        live_bump = 0.02 if is_live else 0.0
        # Safety margin
        safety = 0.02
        buffer_pct = ROUND_TRIP_FEE_PCT + spread_contrib + slip + level_bump + live_bump + safety
        # Clamp [0.10%, 0.60%]
        buffer_pct = max(0.10, min(0.60, round(buffer_pct, 4)))
        return buffer_pct / 100  # ratio
    except Exception:
        return 0.0015  # Safe fallback: 0.15%


# =========================================================================
# PHASE 237A: SOFT RISK DOWNGRADE GATE
# Converts certain hard-rejects into soft-passes with risk penalties
# =========================================================================
def evaluate_risk_gate(
    signal: dict,
    context: dict,
) -> dict:
    """
    Hard reject koÅŸullarÄ±nÄ± deÄŸerlendir, mÃ¼mkÃ¼nse SOFT_PASS'a dÃ¶nÃ¼ÅŸtÃ¼r.
    
    context keys:
      gate_type: "THIN_BOOK" | "OBI_NEUTRAL_LOW_VOL" | "BTC_FILTER" | "MTF_REJECT"
      depth_ratio: float (THIN_BOOK iÃ§in)
      obi_value: float (OBI iÃ§in)
      vol_ratio: float
      mtf_score: int (MTF iÃ§in)
      eq_count: int
      exec_score: float
      spread_pct: float
      is_extreme: bool (BTC_FILTER extreme durumu)
      strategy_mode: str
      
    Returns:
      decision: "PASS" | "SOFT_PASS" | "HARD_REJECT"
      reason_code: str
      score_penalty: int
      size_mult: float
      leverage_cap: int | None
    """
    try:
        gate = str(context.get("gate_type", "")).upper()
        score = int(signal.get("confidenceScore", 0) or 0)
        eq = int(context.get("eq_count", 0) or 0)
        exec_s = float(context.get("exec_score", 0.0) or 0.0)
        spread = float(context.get("spread_pct", 0.05) or 0.05)
        strat = str(context.get("strategy_mode", "LEGACY")).upper()
        is_smart = strat == "SMART_V2"

        # === THIN_BOOK ===
        if gate == "THIN_BOOK":
            depth_r = float(context.get("depth_ratio", 0.0) or 0.0)
            if depth_r >= 0.65 and score >= 85 and eq >= 1 and spread <= 0.25:
                return {
                    "decision": "SOFT_PASS",
                    "reason_code": f"RISK_GATE(TB:dr={depth_r:.2f})",
                    "score_penalty": 6,
                    "size_mult": 0.6,
                    "leverage_cap": 12,
                }
            return {"decision": "HARD_REJECT", "reason_code": f"RISK_GATE(TB:HARD:dr={depth_r:.2f})",
                    "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}

        # === OBI_NEUTRAL_LOW_VOL ===
        if gate == "OBI_NEUTRAL_LOW_VOL":
            obi = abs(float(context.get("obi_value", 0) or 0))
            vr = float(context.get("vol_ratio", 0) or 0)
            if score >= 88 and eq >= 1 and vr >= 0.6:
                return {
                    "decision": "SOFT_PASS",
                    "reason_code": f"RISK_GATE(OBI:obi={obi:.3f},vr={vr:.1f})",
                    "score_penalty": 5,
                    "size_mult": 0.7,
                    "leverage_cap": 10,
                }
            return {"decision": "HARD_REJECT", "reason_code": f"RISK_GATE(OBI:HARD)",
                    "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}

        # === BTC_FILTER ===
        if gate == "BTC_FILTER":
            is_extreme = bool(context.get("is_extreme", False))
            if is_extreme:
                return {"decision": "HARD_REJECT", "reason_code": "RISK_GATE(BTC:EXTREME)",
                        "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}
            if score >= 90 and eq >= 2:
                return {
                    "decision": "SOFT_PASS",
                    "reason_code": "RISK_GATE(BTC:MODERATE)",
                    "score_penalty": 4,
                    "size_mult": 0.7,
                    "leverage_cap": 8,
                }
            return {"decision": "HARD_REJECT", "reason_code": "RISK_GATE(BTC:HARD)",
                    "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}

        # === MTF_REJECT ===
        if gate == "MTF_REJECT":
            mtf_s = int(context.get("mtf_score", -100) or -100)
            if mtf_s > -65 and eq >= 2 and score >= 92:
                return {
                    "decision": "SOFT_PASS",
                    "reason_code": f"RISK_GATE(MTF:s={mtf_s},eq={eq})",
                    "score_penalty": 8,
                    "size_mult": 0.6,
                    "leverage_cap": 10,
                }
            return {"decision": "HARD_REJECT", "reason_code": f"RISK_GATE(MTF:HARD:s={mtf_s})",
                    "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}

        return {"decision": "HARD_REJECT", "reason_code": f"RISK_GATE(UNKNOWN:{gate})",
                "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}
    except Exception:
        return {"decision": "HARD_REJECT", "reason_code": "RISK_GATE(ERR)",
                "score_penalty": 0, "size_mult": 1.0, "leverage_cap": None}


# =========================================================================
# PHASE 237B: ENTRY TRADEABILITY SCORE
# Measures execution quality of the current market conditions
# =========================================================================
def compute_entry_tradeability(
    signal: dict,
    market_ctx: dict,
) -> dict:
    """
    Computes 0-100 tradeability score based on execution quality.
    
    market_ctx keys:
      spread_pct, depth_ratio, obi_value, obi_direction_stable,
      volume_ratio, is_volume_spike, drift_risk, market_regime,
      strategy_mode
    
    Returns:
      score: 0-100
      components: dict
      decision: "PASS" | "SOFT_PASS" | "REJECT"
    """
    try:
        spread = float(market_ctx.get("spread_pct", 0.05) or 0.05)
        depth_r = float(market_ctx.get("depth_ratio", 1.0) or 1.0)
        obi = float(market_ctx.get("obi_value", 0) or 0)
        obi_stable = bool(market_ctx.get("obi_direction_stable", True))
        vr = float(market_ctx.get("volume_ratio", 1.0) or 1.0)
        is_vs = bool(market_ctx.get("is_volume_spike", False))
        drift = float(market_ctx.get("drift_risk", 0) or 0)
        regime = str(market_ctx.get("market_regime", "RANGING")).upper()
        strat = str(market_ctx.get("strategy_mode", "LEGACY")).upper()

        components = {}

        # 1) Spread quality (0-25)
        if spread <= 0.05:
            sq = 25
        elif spread <= 0.10:
            sq = 20
        elif spread <= 0.18:
            sq = 12
        elif spread <= 0.30:
            sq = 6
        else:
            sq = 0
        components["spread"] = sq

        # 2) Depth/liquidity (0-25)
        if depth_r >= 1.5:
            dq = 25
        elif depth_r >= 1.0:
            dq = 20
        elif depth_r >= 0.76:
            dq = 12
        elif depth_r >= 0.50:
            dq = 6
        else:
            dq = 0
        components["depth"] = dq

        # 3) OBI stability (0-20)
        signal_side = str(signal.get("action", "")).upper()
        obi_aligned = (obi > 0.2 and signal_side == "LONG") or (obi < -0.2 and signal_side == "SHORT")
        obi_opposing = (obi > 0.2 and signal_side == "SHORT") or (obi < -0.2 and signal_side == "LONG")
        if obi_aligned and obi_stable:
            oq = 20
        elif obi_aligned:
            oq = 15
        elif not obi_opposing:
            oq = 10
        elif obi_opposing and abs(obi) < 0.35:
            oq = 5
        else:
            oq = 0
        components["obi"] = oq

        # 4) Volume quality (0-20)
        if is_vs and vr >= 2.0:
            vq = 20
        elif vr >= 1.5:
            vq = 16
        elif vr >= 1.0:
            vq = 12
        elif vr >= 0.7:
            vq = 6
        else:
            vq = 2
        components["volume"] = vq

        # 5) Drift/slippage risk (0-10)
        if drift <= 0.3:
            drq = 10
        elif drift <= 0.6:
            drq = 6
        elif drift <= 1.0:
            drq = 3
        else:
            drq = 0
        components["drift"] = drq

        total = sq + dq + oq + vq + drq

        # Strategy-specific thresholds
        min_pass = 55 if strat == "SMART_V2" else 45
        if regime == "VOLATILE":
            min_pass += 5

        min_soft = max(35, min_pass - 10)

        if total >= min_pass:
            decision = "PASS"
        elif total >= min_soft:
            decision = "SOFT_PASS"
        else:
            decision = "REJECT"

        return {
            "score": total,
            "components": components,
            "decision": decision,
        }
    except Exception:
        return {"score": 50, "components": {}, "decision": "PASS"}


# =========================================================================
# PHASE 237C: PENDING ORDER STATE MACHINE
# Explicit states with guarded transitions
# =========================================================================
PENDING_STATES = ("CREATED", "WAIT_CONFIRM", "TRAIL_ACTIVE", "READY_EXEC", "FILLING", "FILLED",
                  "EXPIRED", "CANCELLED", "HARD_REJECTED")

PENDING_TRANSITIONS = {
    "CREATED": ("WAIT_CONFIRM", "EXPIRED", "CANCELLED", "HARD_REJECTED"),
    "WAIT_CONFIRM": ("TRAIL_ACTIVE", "READY_EXEC", "EXPIRED", "CANCELLED"),
    "TRAIL_ACTIVE": ("READY_EXEC", "EXPIRED", "CANCELLED"),
    "READY_EXEC": ("FILLING", "EXPIRED", "CANCELLED"),
    "FILLING": ("FILLED", "EXPIRED", "CANCELLED"),
    # Terminal states
    "FILLED": (),
    "EXPIRED": (),
    "CANCELLED": (),
    "HARD_REJECTED": (),
}


def transition_pending_state(
    order: dict,
    new_state: str,
    reason: str = "",
    current_time_ms: int = 0,
) -> bool:
    """
    Transition pending order to new_state with guard.
    Returns True if transition was valid and applied, False otherwise.
    """
    try:
        old_state = order.get("state", "CREATED")
        allowed = PENDING_TRANSITIONS.get(old_state, ())
        if new_state not in allowed:
            logger.debug(
                f"PENDING_STATE: illegal transition {old_state}â†’{new_state} "
                f"for {order.get('symbol','?')} (reason={reason})"
            )
            return False
        order["state"] = new_state
        order["stateChangedAt"] = current_time_ms or int(time.time() * 1000)
        order["transitionCount"] = int(order.get("transitionCount", 0) or 0) + 1
        order["lastTransitionReason"] = reason
        return True
    except Exception:
        return False


# =========================================================================
# PHASE 237D: REJECT ATTRIBUTION TRACKER
# Tracks hard-rejected signals to measure false-negative rate
# =========================================================================
_reject_attribution_log = []  # [{symbol, side, price, score, reason, time_ms, atr}]
_reject_attribution_summary = {}  # {reason: {total, fn_count}}
REJECT_ATTRIBUTION_WINDOW_MS = 60 * 60 * 1000  # 60 min evaluation window
REJECT_ATTRIBUTION_MAX_LOG = 500  # prevent unbounded growth


def track_reject_for_attribution(
    symbol: str,
    side: str,
    price: float,
    score: int,
    reason: str,
    atr: float,
    time_ms: int = 0,
):
    """Log a hard-rejected signal for later evaluation."""
    try:
        if not REJECT_ATTRIBUTION_ENABLED:
            return
        ts = time_ms or int(time.time() * 1000)
        _reject_attribution_log.append({
            "symbol": symbol, "side": side, "price": price,
            "score": score, "reason": reason, "atr": atr, "ts": ts,
            "evaluated": False, "is_fn": False,
        })
        # Trim oldest
        while len(_reject_attribution_log) > REJECT_ATTRIBUTION_MAX_LOG:
            _reject_attribution_log.pop(0)
    except Exception:
        pass


def evaluate_reject_attribution(current_prices: dict):
    """
    Evaluate past rejects: if price moved +1R in signal direction
    without first going -1R, count as false-negative.
    """
    try:
        if not REJECT_ATTRIBUTION_ENABLED:
            return
        now_ms = int(time.time() * 1000)
        for entry in _reject_attribution_log:
            if entry.get("evaluated"):
                continue
            elapsed = now_ms - entry["ts"]
            if elapsed < 30 * 60 * 1000:  # wait at least 30 min
                continue
            if elapsed > REJECT_ATTRIBUTION_WINDOW_MS:
                entry["evaluated"] = True
                continue

            symbol = entry["symbol"]
            current_price = current_prices.get(symbol, 0)
            if current_price <= 0:
                continue

            entry_price = entry["price"]
            atr = entry["atr"]
            if atr <= 0:
                entry["evaluated"] = True
                continue

            side = entry["side"]
            # +1R = price moved 1Ã—ATR in signal direction
            if side == "LONG":
                favorable = current_price >= entry_price + atr
                adverse = current_price <= entry_price - atr
            else:
                favorable = current_price <= entry_price - atr
                adverse = current_price >= entry_price + atr

            if favorable:
                entry["evaluated"] = True
                entry["is_fn"] = True
                reason = entry["reason"].split(":")[0] if ":" in entry["reason"] else entry["reason"]
                _reject_attribution_summary.setdefault(reason, {"total": 0, "fn_count": 0})
                _reject_attribution_summary[reason]["total"] += 1
                _reject_attribution_summary[reason]["fn_count"] += 1
                # P3 fix: increment pipeline false_negative_count
                try:
                    if 'global_paper_trader' in globals() and global_paper_trader:
                        global_paper_trader.pipeline_metrics['false_negative_count'] = (
                            global_paper_trader.pipeline_metrics.get('false_negative_count', 0) + 1
                        )
                except Exception:
                    pass
                logger.info(
                    f"ðŸ” FN_TRACK: {symbol} {side} score={entry['score']} "
                    f"reason={entry['reason']} â†’ moved +1R, FALSE NEGATIVE"
                )
            elif adverse or elapsed > REJECT_ATTRIBUTION_WINDOW_MS:
                entry["evaluated"] = True
                entry["is_fn"] = False
                reason = entry["reason"].split(":")[0] if ":" in entry["reason"] else entry["reason"]
                _reject_attribution_summary.setdefault(reason, {"total": 0, "fn_count": 0})
                _reject_attribution_summary[reason]["total"] += 1
    except Exception:
        pass


def get_reject_attribution_summary() -> dict:
    """Return summary for status endpoint."""
    try:
        total_fn = sum(v["fn_count"] for v in _reject_attribution_summary.values())
        total_reject = sum(v["total"] for v in _reject_attribution_summary.values())
        # Top blockers sorted by fn_count desc
        top_blockers = sorted(
            [{"reason": k, **v, "fn_pct": round(v["fn_count"] / max(1, v["total"]) * 100, 1)}
             for k, v in _reject_attribution_summary.items()],
            key=lambda x: x["fn_count"],
            reverse=True,
        )[:5]
        return {
            "falseNegativeCount": total_fn,
            "totalRejected": total_reject,
            "fnRate": round(total_fn / max(1, total_reject) * 100, 1),
            "topRejectBlockers": top_blockers,
        }
    except Exception:
        return {"falseNegativeCount": 0, "totalRejected": 0, "fnRate": 0, "topRejectBlockers": []}




def get_dynamic_depth_threshold(
    spread_pct: float,
    volume_24h: float,
    signal_score: float,
    leverage: int
) -> float:
    """
    Compute dynamic thin-book threshold.
    Lower threshold for high-quality/high-liquidity signals, higher for noisy setups.
    Clamped to [EQ_MIN_DEPTH_USD_BASE, EQ_MIN_DEPTH_USD].
    """
    base = 60_000.0

    # Wider spreads demand more depth.
    if spread_pct <= 0.05:
        spread_factor = 0.85
    elif spread_pct <= 0.15:
        spread_factor = 1.00
    elif spread_pct <= 0.35:
        spread_factor = 1.20
    else:
        spread_factor = 1.40

    # Higher 24h volume lowers required top-of-book depth.
    if volume_24h >= 80_000_000:
        vol_factor = 0.60
    elif volume_24h >= 20_000_000:
        vol_factor = 0.75
    elif volume_24h >= 5_000_000:
        vol_factor = 0.90
    elif volume_24h >= EQ_MIN_VOLUME_24H:
        vol_factor = 1.00
    else:
        vol_factor = 1.15

    # Stronger score can pass with thinner book.
    if signal_score >= 120:
        score_factor = 0.65
    elif signal_score >= 110:
        score_factor = 0.75
    elif signal_score >= 100:
        score_factor = 0.85
    elif signal_score >= 90:
        score_factor = 0.95
    else:
        score_factor = 1.00

    # Higher leverage requires a bit more depth.
    if leverage <= 8:
        lev_factor = 0.90
    elif leverage <= 15:
        lev_factor = 1.00
    elif leverage <= 25:
        lev_factor = 1.10
    else:
        lev_factor = 1.20

    raw = base * spread_factor * vol_factor * score_factor * lev_factor
    return max(EQ_MIN_DEPTH_USD_BASE, min(float(EQ_MIN_DEPTH_USD), raw))


def _clamp(value: float, low: float, high: float) -> float:
    return max(low, min(high, float(value)))


def get_btc_penalty_risk_caps(btc_penalty: float) -> tuple:
    """
    Map BTC counter-trend penalty to risk caps.
    Returns: (leverage_cap, size_multiplier_cap)
    """
    p = max(0.0, float(btc_penalty or 0.0))
    if p >= 0.80:
        return 2, 0.25
    if p >= 0.60:
        return 3, 0.35
    if p >= 0.45:
        return 4, 0.50
    if p >= 0.30:
        return 6, 0.70
    if p >= 0.20:
        return 8, 0.85
    return None, None


# =========================================================================
# PHASE 236: BLENDED REGIME BIAS HELPERS
# Coin-specific + BTC macro â†’ weighted directional bias
# =========================================================================

def compute_coin_macro_bias(
    coin_daily_trend: str = "NEUTRAL",
    adx: float = 25.0,
    hurst: float = 0.5,
    adx_trend: str = "NEUTRAL",
) -> dict:
    """
    Coin'in kendi macro trendini hesapla.
    Returns: {dir: UP/DOWN/NEUTRAL, confidence: 0.0-1.0, source: str}
    """
    try:
        direction = "NEUTRAL"
        conf = 0.0
        sources = []

        # 1) coin_daily_trend (aÄŸÄ±rlÄ±k: %50)
        cdt = str(coin_daily_trend or "NEUTRAL").upper()
        cdt_score = 0.0
        if cdt == "STRONG_BULLISH":
            cdt_score = 1.0
        elif cdt == "BULLISH":
            cdt_score = 0.6
        elif cdt == "STRONG_BEARISH":
            cdt_score = -1.0
        elif cdt == "BEARISH":
            cdt_score = -0.6
        # NEUTRAL â†’ 0.0
        if cdt_score != 0.0:
            sources.append(f"CDT={cdt}")

        # 2) ADX trend yÃ¶nÃ¼ (aÄŸÄ±rlÄ±k: %30)
        adx_val = float(adx or 25.0)
        at = str(adx_trend or "NEUTRAL").upper()
        adx_score = 0.0
        if at == "BULLISH" and adx_val > 20:
            adx_score = min(1.0, (adx_val - 20) / 30)  # 20â†’0, 50â†’1
            sources.append(f"ADX={adx_val:.0f}B")
        elif at == "BEARISH" and adx_val > 20:
            adx_score = -min(1.0, (adx_val - 20) / 30)
            sources.append(f"ADX={adx_val:.0f}S")

        # 3) Hurst (aÄŸÄ±rlÄ±k: %20) â€” coin trending mi?
        h = float(hurst or 0.5)
        hurst_mult = 1.0
        if h > 0.55:
            hurst_mult = 1.0 + (h - 0.55) * 2.0  # trending â†’ amplify
            sources.append(f"H={h:.2f}T")
        elif h < 0.40:
            hurst_mult = 0.5  # mean-reverting â†’ dampen directional bias
            sources.append(f"H={h:.2f}R")

        # Weighted combination
        combined = cdt_score * 0.50 + adx_score * 0.30
        # Hurst amplifies or dampens the magnitude
        combined *= hurst_mult

        # ADX strength also affects confidence
        adx_conf = min(1.0, max(0.0, (adx_val - 15) / 35))  # 15â†’0, 50â†’1

        if combined > 0.05:
            direction = "UP"
            conf = min(1.0, abs(combined) * 0.8 + adx_conf * 0.2)
        elif combined < -0.05:
            direction = "DOWN"
            conf = min(1.0, abs(combined) * 0.8 + adx_conf * 0.2)
        else:
            direction = "NEUTRAL"
            conf = 0.0

        return {"dir": direction, "confidence": round(conf, 2), "source": "+".join(sources) or "NONE"}
    except Exception:
        return {"dir": "NEUTRAL", "confidence": 0.0, "source": "ERR"}


def compute_btc_macro_bias(
    macro_regime: str = "RANGING",
    macro_trend_dir: str = "NEUTRAL",
    btc_regime: str = "QUIET",
) -> dict:
    """
    BTC/market macro yÃ¶n bias'Ä±.
    Returns: {dir: UP/DOWN/NEUTRAL, confidence: 0.0-1.0}
    """
    try:
        mr = str(macro_regime or "RANGING").upper()
        mtd = str(macro_trend_dir or "NEUTRAL").upper()
        br = str(btc_regime or "QUIET").upper()

        direction = "NEUTRAL"
        conf = 0.0

        if mr == "TRENDING_DOWN":
            direction = "DOWN"
            conf = 0.85
        elif mr == "TRENDING_UP":
            direction = "UP"
            conf = 0.85
        elif mr == "VOLATILE":
            if mtd == "DOWN":
                direction = "DOWN"
                conf = 0.65
            elif mtd == "UP":
                direction = "UP"
                conf = 0.65
            else:
                direction = "NEUTRAL"
                conf = 0.0  # yÃ¶n belirsiz
        elif mr == "TRENDING":
            if mtd == "DOWN":
                direction = "DOWN"
                conf = 0.55
            elif mtd == "UP":
                direction = "UP"
                conf = 0.55

        # BTC regime volatile + directional â†’ boost
        if br == "VOLATILE" and mtd != "NEUTRAL" and conf < 0.50:
            direction = mtd
            conf = 0.50

        return {"dir": direction, "confidence": round(conf, 2)}
    except Exception:
        return {"dir": "NEUTRAL", "confidence": 0.0}


def blend_macro_bias(
    coin_bias: dict,
    btc_bias: dict,
    btc_corr: float = None,
) -> dict:
    """
    Coin + BTC bias'Ä± aÄŸÄ±rlÄ±klÄ± olarak birleÅŸtir.
    Default: w_coin=0.65, w_btc=0.35
    btc_corr varsa dinamik aÄŸÄ±rlÄ±k.
    Returns: {dir, confidence, w_coin, w_btc}
    """
    try:
        w_coin = 0.65
        w_btc = 0.35

        # Dinamik aÄŸÄ±rlÄ±k (btc_corr varsa)
        if btc_corr is not None:
            corr = max(0.0, min(1.0, abs(float(btc_corr))))
            # YÃ¼ksek korelasyon â†’ BTC daha Ã¶nemli (max 0.50)
            # DÃ¼ÅŸÃ¼k korelasyon â†’ coin daha Ã¶nemli (coin min 0.50)
            w_btc = 0.25 + corr * 0.25   # 0.25 â†’ 0.50
            w_coin = 1.0 - w_btc          # 0.75 â†’ 0.50

        c_dir = (coin_bias or {}).get("dir", "NEUTRAL")
        c_conf = float((coin_bias or {}).get("confidence", 0.0))
        b_dir = (btc_bias or {}).get("dir", "NEUTRAL")
        b_conf = float((btc_bias or {}).get("confidence", 0.0))

        # Numerik skor: UP=+1, DOWN=-1, NEUTRAL=0
        dir_map = {"UP": 1.0, "DOWN": -1.0, "NEUTRAL": 0.0}
        c_val = dir_map.get(c_dir, 0.0) * c_conf
        b_val = dir_map.get(b_dir, 0.0) * b_conf

        blended = c_val * w_coin + b_val * w_btc

        if blended > 0.05:
            final_dir = "UP"
        elif blended < -0.05:
            final_dir = "DOWN"
        else:
            final_dir = "NEUTRAL"

        final_conf = min(1.0, abs(blended))

        return {
            "dir": final_dir,
            "confidence": round(final_conf, 2),
            "w_coin": round(w_coin, 2),
            "w_btc": round(w_btc, 2),
        }
    except Exception:
        return {"dir": "NEUTRAL", "confidence": 0.0, "w_coin": 0.65, "w_btc": 0.35}


STRATEGY_MODE_LEGACY = "LEGACY"
STRATEGY_MODE_SMART_V2 = "SMART_V2"


def get_smart_v2_strategy_profile(
    mode: str,
    signal_side: str,
    hurst: float,
    adx: float,
    spread_pct: float,
    volume_ratio: float,
    volatility_ratio: float,
    market_regime: str,
    is_volume_spike: bool,
    imbalance: float,
    ob_imbalance_trend: float,
    macro_trend_dir: str = "NEUTRAL",  # Phase 235: "UP", "DOWN", "NEUTRAL"
) -> dict:
    """
    Select SMART_V2 strategy and return strategy-specific entry/exit tuning.
    Falls back to LEGACY-neutral multipliers when mode != SMART_V2.
    """
    base_profile = {
        "strategy_mode": STRATEGY_MODE_LEGACY,
        "active_strategy": "legacy",
        "strategy_label": "Legacy",
        "threshold_mult": 1.0,
        "min_score_offset": 0,
        "score_bonus": 0,
        "entry_mult": 1.0,
        "exit_mult": 1.0,
        "leverage_mult": 1.0,
        "notes": [],
    }

    if str(mode or STRATEGY_MODE_LEGACY).upper() != STRATEGY_MODE_SMART_V2:
        return base_profile

    safe_side = "LONG" if signal_side == "LONG" else "SHORT"
    side_sign = 1.0 if safe_side == "LONG" else -1.0
    safe_hurst = float(hurst or 0.5)
    safe_adx = float(adx or 20.0)
    safe_spread = max(0.01, float(spread_pct or 0.05))
    safe_vol_ratio = max(0.2, float(volume_ratio or 1.0))
    safe_volatility_ratio = max(0.3, float(volatility_ratio or 1.0))
    regime_upper = str(market_regime or "RANGING").upper()

    ob_alignment = side_sign * (float(imbalance or 0.0) * 0.65 + float(ob_imbalance_trend or 0.0) * 0.35)

    profile = {
        "strategy_mode": STRATEGY_MODE_SMART_V2,
        "active_strategy": "balanced_flow",
        "strategy_label": "Dengeli AkÄ±ÅŸ",
        "threshold_mult": 1.0,
        "min_score_offset": 3,
        "score_bonus": 0,
        "entry_mult": 1.0,
        "exit_mult": 1.0,
        "leverage_mult": 1.0,
        "notes": ["BALANCED"],
    }

    # Strategy routing by coin behavior.
    if safe_adx >= 32 and safe_hurst >= 0.58 and (safe_vol_ratio >= 1.25 or is_volume_spike):
        profile.update({
            "active_strategy": "momentum_breakout",
            "strategy_label": "Momentum KÄ±rÄ±lÄ±m",
            "threshold_mult": 1.10,
            "min_score_offset": 8,
            "score_bonus": 4 if ob_alignment >= 2.5 else 2,
            "entry_mult": 0.78,
            "exit_mult": 1.22,
            "leverage_mult": 1.05,
            "notes": ["MOMENTUM", "BREAKOUT"],
        })
    elif safe_adx >= 28 and safe_hurst >= 0.55:
        profile.update({
            "active_strategy": "trend_follow",
            "strategy_label": "Trend Takibi",
            "threshold_mult": 1.06,
            "min_score_offset": 6,
            "score_bonus": 2,
            "entry_mult": 0.86,
            "exit_mult": 1.18,
            "leverage_mult": 1.02,
            "notes": ["TREND"],
        })
    elif safe_hurst <= 0.43 and safe_adx <= 26:
        profile.update({
            "active_strategy": "mean_reversion",
            "strategy_label": "Ortalamaya DÃ¶nÃ¼ÅŸ",
            "threshold_mult": 0.96,
            "min_score_offset": 2,
            "score_bonus": 3 if abs(ob_alignment) < 2.0 else 1,
            "entry_mult": 1.12,
            "exit_mult": 0.92,
            "leverage_mult": 0.94,
            "notes": ["MEAN_REVERSION"],
        })
    elif regime_upper == "VOLATILE" or safe_volatility_ratio >= 1.35:
        profile.update({
            "active_strategy": "volatile_guard",
            "strategy_label": "Volatilite KorumasÄ±",
            "threshold_mult": 1.18,
            "min_score_offset": 10,
            "score_bonus": 0,
            "entry_mult": 1.24,
            "exit_mult": 1.35,
            "leverage_mult": 0.86,
            "notes": ["VOLATILE_GUARD"],
        })
    elif safe_spread <= 0.08 and safe_volatility_ratio <= 0.90 and safe_vol_ratio >= 0.9:
        profile.update({
            "active_strategy": "low_vol_scalp",
            "strategy_label": "DÃ¼ÅŸÃ¼k Volatilite",
            "threshold_mult": 0.93,
            "min_score_offset": 3,
            "score_bonus": 2,
            "entry_mult": 0.88,
            "exit_mult": 0.88,
            "leverage_mult": 1.00,
            "notes": ["LOW_VOL"],
        })

    # Microstructure refinement.
    if ob_alignment <= -3.5:
        profile["min_score_offset"] += 4
        profile["threshold_mult"] *= 1.03
        profile["leverage_mult"] *= 0.92
        profile["notes"].append("OB_CONTRA_HARD")
    elif ob_alignment >= 3.5:
        profile["score_bonus"] += 2
        profile["notes"].append("OB_ALIGN_STRONG")
    
    # ===== Phase 235: REGIME-AWARE DIRECTIONAL TUNING =====
    safe_macro_dir = str(macro_trend_dir or "NEUTRAL").upper()
    is_pro_trend = (
        (safe_macro_dir == "DOWN" and safe_side == "SHORT") or
        (safe_macro_dir == "UP" and safe_side == "LONG")
    )
    is_counter_trend = (
        (safe_macro_dir == "DOWN" and safe_side == "LONG") or
        (safe_macro_dir == "UP" and safe_side == "SHORT")
    )
    if regime_upper == "VOLATILE" and is_pro_trend:
        # Volatil + pro-trend: daha agresif entry, daha geniÅŸ TP
        profile["entry_mult"] *= 0.85
        profile["exit_mult"] *= 1.30
        profile["score_bonus"] += 5
        profile["min_score_offset"] = max(0, profile["min_score_offset"] - 5)
        profile["notes"].append("PRO_TREND_VOL")
    elif regime_upper == "VOLATILE" and is_counter_trend:
        # Volatil + karÅŸÄ±-trend: Ã§ok seÃ§ici
        profile["min_score_offset"] += 8
        profile["leverage_mult"] *= 0.80
        profile["notes"].append("COUNTER_TREND_STRICT")

    # Clamp outputs to safe bounds.
    profile["threshold_mult"] = _clamp(profile["threshold_mult"], 0.85, 1.30)
    profile["entry_mult"] = _clamp(profile["entry_mult"], 0.65, 1.45)
    profile["exit_mult"] = _clamp(profile["exit_mult"], 0.70, 1.60)
    profile["leverage_mult"] = _clamp(profile["leverage_mult"], 0.75, 1.15)
    profile["min_score_offset"] = int(_clamp(profile["min_score_offset"], 0, 20))
    profile["score_bonus"] = int(_clamp(profile["score_bonus"], -5, 10))

    return profile


def compute_execution_quality_score(
    signal_side: str,
    confidence_score: float,
    volume_ratio: float,
    spread_pct: float,
    atr_pct: float,
    imbalance: float,
    ob_imbalance_trend: float,
    eq_count: int,
    fib_active: bool,
    fib_bonus: float,
    is_volume_spike: bool,
    zscore: float,
    adx: float,
    hurst: float
) -> dict:
    """
    Hybrid execution quality score.
    Higher score => cleaner microstructure and stronger setup quality.
    """
    score = float(confidence_score)
    notes = []

    # Microstructure / liquidity quality
    if volume_ratio >= 2.0:
        score += 8
        notes.append("VOL_STRONG")
    elif volume_ratio >= 1.25:
        score += 4
        notes.append("VOL_OK")
    elif volume_ratio < 0.9:
        score -= 10
        notes.append("VOL_WEAK")

    if spread_pct <= 0.06:
        score += 6
        notes.append("SPREAD_TIGHT")
    elif spread_pct <= 0.18:
        score += 2
    elif spread_pct >= 0.40:
        score -= 12
        notes.append("SPREAD_WIDE")
    elif spread_pct >= 0.25:
        score -= 6

    # Order book alignment
    side_sign = 1.0 if signal_side == "LONG" else -1.0
    side_imbalance = side_sign * float(imbalance)
    side_ob_trend = side_sign * float(ob_imbalance_trend)

    if side_imbalance >= 8:
        score += 8
        notes.append("OB_ALIGN")
    elif side_imbalance >= 3:
        score += 4
    elif side_imbalance <= -4:
        score -= 12
        notes.append("OB_CONTRA")

    if side_ob_trend >= 4:
        score += 6
        notes.append("OB_FLOW")
    elif side_ob_trend <= -3:
        score -= 8
        notes.append("OB_FLOW_CONTRA")

    # Quality signals
    if eq_count >= 3:
        score += 7
        notes.append("EQ3")
    elif eq_count == 2:
        score += 3

    if fib_active:
        score += min(8.0, max(0.0, float(fib_bonus)))
        notes.append("FIB")

    if is_volume_spike:
        score += 3

    # Context penalty/bonus
    if atr_pct >= 6.0:
        score -= 4
    elif atr_pct <= 1.2:
        score += 2

    if abs(zscore) >= 2.5:
        score += 3
    elif abs(zscore) < 1.7:
        score -= 2

    trend_strength = _clamp((adx - 18.0) / 25.0, 0.0, 1.0) * 0.6 + _clamp((hurst - 0.45) / 0.2, 0.0, 1.0) * 0.4
    if trend_strength >= 0.75:
        score += 2

    return {
        "score": round(score, 2),
        "passed": score >= EXEC_QUALITY_MIN_SCORE,
        "strict_passed": score >= EXEC_QUALITY_STRICT_MIN_SCORE,
        "notes": notes[:6],
    }

# ============================================================================
# Phase 239V2: Dynamic Minimum Pullback Floor
# ============================================================================
def compute_dynamic_min_pullback_pct(
    atr_pct: float,
    spread_pct: float,
    volume_ratio: float,
    ob_imbalance: float,
    ob_imbalance_trend: float,
    side: str,
    signal_score: float,
    adx: float = 20.0,
    hurst: float = 0.50,
    coin_daily_trend: str = 'NEUTRAL',
    entry_algo_multiplier: float = 1.0,
    # legacy compat â€” ignored in V2
    ob_trend: str = 'neutral',
    regime: str = 'neutral',
) -> dict:
    """Compute dynamic minimum pullback percentage (V2).

    Returns dict with:
      final_pct      â€” percent value (e.g. 0.85 = 0.85%)
      base           â€” raw base before adjustments
      adj_total      â€” sum of all adjustments
      tight_mult     â€” sqrt-based entry_tightness multiplier
      regime_band    â€” 'aligned' | 'neutral' | 'counter'
      clamp_min/max  â€” band limits applied
    """
    import math

    atr_p = _clamp(float(atr_pct or 2.0), 0.5, 7.0)
    sp = float(spread_pct or 0.0)
    vol_r = float(volume_ratio or 1.0)
    ob_trend_val = float(ob_imbalance_trend or 0.0)
    sc = float(signal_score or 0)
    _adx = float(adx or 20.0)
    _hurst = float(hurst or 0.50)

    # â”€â”€ base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    base = 0.50 + 0.16 * atr_p + 1.40 * max(sp - 0.03, 0.0)

    # â”€â”€ volume adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vol_adj = 0.0
    if vol_r < 1.0:
        vol_adj = min(0.32, (1.0 - vol_r) * 0.28)
    elif vol_r > 2.5:
        vol_adj = -min(0.12, (vol_r - 2.5) * 0.06)

    # â”€â”€ order-book adjustment (uses raw trend value) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ob_adj = 0.0
    if side == 'LONG' and ob_trend_val < -4.0:
        ob_adj = 0.20
    elif side == 'SHORT' and ob_trend_val > 4.0:
        ob_adj = 0.20
    elif side == 'LONG' and ob_trend_val > 4.0:
        ob_adj = -0.06
    elif side == 'SHORT' and ob_trend_val < -4.0:
        ob_adj = -0.06

    # â”€â”€ score adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    score_adj = 0.0
    if sc >= 115:
        score_adj = -0.10
    elif sc >= 100:
        score_adj = -0.05

    # â”€â”€ regime classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    trend_aligned = (
        (side == 'LONG' and coin_daily_trend in ('BULLISH', 'STRONG_BULLISH')) or
        (side == 'SHORT' and coin_daily_trend in ('BEARISH', 'STRONG_BEARISH'))
    )
    trend_opposed = (
        (side == 'LONG' and coin_daily_trend in ('BEARISH', 'STRONG_BEARISH')) or
        (side == 'SHORT' and coin_daily_trend in ('BULLISH', 'STRONG_BULLISH'))
    )

    if _adx > 25 and trend_aligned:
        regime_band = 'aligned'
        clamp_min, clamp_max = 0.45, 1.35
    elif (_adx > 25 and trend_opposed) or _hurst > 0.65:
        regime_band = 'counter'
        clamp_min, clamp_max = 0.70, 2.60
    else:
        regime_band = 'neutral'
        clamp_min, clamp_max = 0.60, 1.90

    # â”€â”€ regime adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    regime_adj = 0.0
    if regime_band == 'counter':
        regime_adj = 0.15
    elif regime_band == 'aligned':
        regime_adj = -0.06

    adj_total = vol_adj + ob_adj + score_adj + regime_adj

    # â”€â”€ entry_tightness (sqrt, dampened) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    et = _clamp(float(entry_algo_multiplier or 1.0), 0.5, 15.0)
    tight_mult = 1.0 + (math.sqrt(et) - 1.0) * 0.25

    raw = (base + adj_total) * tight_mult
    final = _clamp(raw, clamp_min, clamp_max)

    logger.info(
        f"PULLBACK_V2: side={side} atr={atr_p:.1f} sp={sp:.3f} vol={vol_r:.2f} "
        f"ob_tr={ob_trend_val:.1f} score={sc:.0f} regime={regime_band} "
        f"base={base:.3f} adj={adj_total:.3f} tight={tight_mult:.3f} "
        f"raw={raw:.3f} clamp=[{clamp_min},{clamp_max}] final={final:.3f}%"
    )

    return {
        'final_pct': round(final, 4),
        'base': round(base, 4),
        'adj_total': round(adj_total, 4),
        'tight_mult': round(tight_mult, 4),
        'regime_band': regime_band,
        'clamp_min': clamp_min,
        'clamp_max': clamp_max,
    }


# ============================================================================
# Phase 239V2: Pending Revalidation Gate (fill Ã¶ncesi son kontrol)
# ============================================================================
def revalidate_pending_entry(order: dict, opportunity: dict, now_ms: int) -> dict:
    """Revalidate pending order conditions just before execution.

    Returns dict with UNIFIED decision model:
      decision       â€” 'PASS' | 'WARN_WAIT' | 'FAIL_DROP'
      allow_market   â€” bool, whether market fallback is permitted
      recheck_score  â€” float 0-100
      reasons        â€” list[str] of sub-component notes
      reason_summary â€” str, single-line summary for logging
    """
    reasons = []
    score = 0.0
    hard_reject = False

    if not opportunity:
        # No live data â€” execute (conservative: better fill than miss)
        return {
            'decision': 'PASS', 'allow_market': False, 'recheck_score': 50.0,
            'reasons': ['NO_LIVE_DATA'], 'reason_summary': 'NO_LIVE_DATA',
        }

    order_side = order.get('side', '')
    order_spread = float(order.get('spreadPct', 0.05) or 0.05)
    order_signal_score = float(order.get('signalScore', 0) or 0)
    created_at = int(order.get('createdAt', now_ms) or now_ms)
    age_min = (now_ms - created_at) / 60000.0

    live_side = opportunity.get('signalAction', 'NONE')
    live_spread = float(opportunity.get('spreadPct', 0) or 0)
    live_vol_ratio = float(opportunity.get('volumeRatio', 1.0) or 1.0)
    live_ob_trend = float(opportunity.get('obImbalanceTrend', 0) or 0)

    # â”€â”€ 1. Direction alignment (30 pt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if live_side == order_side:
        score += 30
        reasons.append(f"DIR_OK({live_side})")
    elif live_side == 'NONE':
        score += 15
        reasons.append("DIR_NEUTRAL")
    else:
        hard_reject = True
        reasons.append(f"DIR_FLIP({order_side}â†’{live_side})")

    # â”€â”€ 2. Spread health (20 pt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    spread_limit = max(order_spread * 1.8, 0.35)
    if live_spread <= order_spread * 1.0:
        score += 20
        reasons.append("SPREAD_OK")
    elif live_spread <= order_spread * 1.3:
        score += 14
        reasons.append(f"SPREAD_MILD({live_spread:.3f})")
    elif live_spread <= spread_limit:
        score += 6
        reasons.append(f"SPREAD_HIGH({live_spread:.3f})")
    else:
        hard_reject = True
        reasons.append(f"SPREAD_REJECT({live_spread:.3f}>{spread_limit:.3f})")

    # â”€â”€ 3. Order book alignment (20 pt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if order_side == 'LONG':
        if live_ob_trend > 2:
            score += 20
            reasons.append("OB_ALIGNED")
        elif live_ob_trend > -2:
            score += 12
            reasons.append("OB_NEUTRAL")
        elif live_ob_trend > -5:
            score += 4
            reasons.append(f"OB_WEAK({live_ob_trend:.1f})")
        else:
            hard_reject = True
            reasons.append(f"OB_VETO({live_ob_trend:.1f})")
    else:  # SHORT
        if live_ob_trend < -2:
            score += 20
            reasons.append("OB_ALIGNED")
        elif live_ob_trend < 2:
            score += 12
            reasons.append("OB_NEUTRAL")
        elif live_ob_trend < 5:
            score += 4
            reasons.append(f"OB_WEAK({live_ob_trend:.1f})")
        else:
            hard_reject = True
            reasons.append(f"OB_VETO({live_ob_trend:.1f})")

    # â”€â”€ 4. Volume / liquidity health (15 pt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if live_vol_ratio >= 1.0:
        score += 15
        reasons.append("VOL_OK")
    elif live_vol_ratio >= 0.7:
        score += 10
        reasons.append(f"VOL_THIN({live_vol_ratio:.2f})")
    elif live_vol_ratio >= 0.4:
        score += 4
        reasons.append(f"VOL_LOW({live_vol_ratio:.2f})")
    else:
        if live_spread > 0.20:
            hard_reject = True
            reasons.append(f"LIQ_REJECT(vol={live_vol_ratio:.2f},sp={live_spread:.3f})")
        else:
            score += 2
            reasons.append(f"VOL_VERYLOW({live_vol_ratio:.2f})")

    # â”€â”€ 5. Freshness / regime drift (15 pt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if age_min < 10:
        score += 15
        reasons.append("FRESH")
    elif age_min < 20:
        score += 12
        reasons.append(f"AGE_OK({age_min:.0f}m)")
    elif age_min < 30:
        score += 6
        reasons.append(f"AGE_OLD({age_min:.0f}m)")
    else:
        score += 2
        reasons.append(f"AGE_STALE({age_min:.0f}m)")

    # â”€â”€ Unified decision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if hard_reject or score < 40:
        decision = 'FAIL_DROP'
        allow_market = False
    elif score >= 65:
        decision = 'PASS'
        allow_market = score >= 80 and order_signal_score >= 95
    else:
        decision = 'WARN_WAIT'
        allow_market = False

    reason_summary = ', '.join(reasons[:4])
    logger.info(
        f"ENTRY_RECHECK_DECISION: {order.get('symbol','')} {order_side} "
        f"decision={decision} score={score:.0f} hard={hard_reject} "
        f"| {reason_summary}"
    )

    return {
        'decision': decision,
        'allow_market': allow_market,
        'recheck_score': round(score, 1),
        'reasons': reasons,
        'reason_summary': reason_summary,
    }




def get_hybrid_entry_profile(
    atr_pct: float,
    spread_pct: float,
    volume_ratio: float,
    leverage: int,
    entry_tightness: float,
    confidence_score: float,
    eq_count: int,
    fib_active: bool,
    adx: float,
    hurst: float,
    is_volume_spike: bool
) -> dict:
    """
    Returns dynamic entry pullback and trail-entry activation thresholds.
    All output values already include settings multiplier (`entry_tightness`).
    """
    safe_atr_pct = max(0.3, float(atr_pct))
    safe_spread_pct = max(0.01, float(spread_pct))
    safe_vol_ratio = max(0.2, float(volume_ratio))
    safe_lev = max(1, int(leverage or 1))
    tightness = _clamp(entry_tightness, 0.5, 15.0)
    tightness_mult = math.sqrt(tightness)

    # Base pullback (percentage terms)
    base_pullback_pct = (safe_atr_pct * 0.42) + (safe_spread_pct * 0.70)

    # Quality factor: stronger setup => slightly shallower pullback
    if confidence_score >= 120 and eq_count >= 3:
        quality_mult = 0.80
    elif confidence_score >= 110:
        quality_mult = 0.88
    elif confidence_score >= 95:
        quality_mult = 0.96
    elif confidence_score >= 80:
        quality_mult = 1.05
    else:
        quality_mult = 1.15

    # Market microstructure factor
    micro_mult = 1.0
    if safe_vol_ratio < 1.0:
        micro_mult *= 1.15
    elif safe_vol_ratio >= 2.0:
        micro_mult *= 0.90
    if safe_spread_pct >= 0.25:
        micro_mult *= 1.20

    # Trend factor: strong trend means slightly shallower entry
    trend_strength = _clamp((adx - 18.0) / 25.0, 0.0, 1.0) * 0.6 + _clamp((hurst - 0.45) / 0.2, 0.0, 1.0) * 0.4
    trend_mult = 1.0 - (trend_strength * 0.14)

    # Fib/volume spike can allow earlier but still controlled entry
    confluence_mult = 1.0
    if fib_active:
        confluence_mult *= 0.93
    if is_volume_spike and trend_strength > 0.5:
        confluence_mult *= 0.92

    pullback_pct = base_pullback_pct * tightness_mult * quality_mult * micro_mult * trend_mult * confluence_mult
    pullback_pct = _clamp(pullback_pct, 0.15, 12.0)

    # Trail-entry activation thresholds (pct)
    trail_threshold_mult = _clamp(
        tightness_mult * (1.0 + max(0.0, safe_spread_pct - 0.08) * 2.0) * (1.12 if safe_vol_ratio < 1.0 else 0.92 if safe_vol_ratio > 2.0 else 1.0),
        0.7,
        2.6,
    )
    min_move_pct, min_roi_pct = get_dynamic_trail_activation_threshold(
        atr_pct=safe_atr_pct,
        spread_pct=safe_spread_pct,
        volume_ratio=safe_vol_ratio,
        leverage=safe_lev,
        threshold_mult=trail_threshold_mult,
    )

    return {
        "pullback_pct": round(pullback_pct, 4),
        "trail_entry_min_move_pct": round(min_move_pct, 3),
        "trail_entry_min_roi_pct": round(min_roi_pct, 2),
        "entry_tightness_mult": round(tightness_mult, 3),
        "entry_threshold_mult": round(trail_threshold_mult, 3),
    }


def get_hybrid_runtime_trail_distance(
    base_trail_distance: float,
    atr_pct: float,
    spread_pct: float,
    volume_ratio: float,
    roi_pct: float,
    exit_tightness: float,
    hurst: float = 0.5,
    adx: float = 20.0
) -> float:
    """
    Dynamic trailing distance for open positions.
    Uses volatility + liquidity + trend + ROI, and includes exit_tightness multiplier.
    """
    base = max(0.0, float(base_trail_distance))
    if base <= 0:
        return 0.0

    safe_atr_pct = max(0.3, float(atr_pct))
    safe_spread_pct = max(0.01, float(spread_pct))
    safe_vol_ratio = max(0.2, float(volume_ratio))
    tightness_mult = math.sqrt(_clamp(exit_tightness, 0.3, 15.0))

    # Volatility expansion
    if safe_atr_pct < 1.0:
        volatility_mult = 0.70
    elif safe_atr_pct < 1.8:
        volatility_mult = 0.85
    elif safe_atr_pct < 3.0:
        volatility_mult = 1.00
    elif safe_atr_pct < 4.5:
        volatility_mult = 1.25
    elif safe_atr_pct < 6.5:
        volatility_mult = 1.55
    else:
        volatility_mult = 1.90

    micro_mult = 1.0 + max(0.0, safe_spread_pct - 0.08) * 2.2
    if safe_vol_ratio < 1.0:
        micro_mult *= 1.15
    elif safe_vol_ratio >= 2.0:
        micro_mult *= 0.92

    trend_strength = _clamp((adx - 18.0) / 25.0, 0.0, 1.0) * 0.6 + _clamp((hurst - 0.45) / 0.2, 0.0, 1.0) * 0.4
    trend_mult = 1.0 + (trend_strength * 0.20)

    dynamic_distance = base * volatility_mult * tightness_mult * micro_mult * trend_mult

    # Profit-aware tightening (less aggressive to avoid premature exits)
    if roi_pct >= 30:
        dynamic_distance *= 0.68
    elif roi_pct >= 20:
        dynamic_distance *= 0.78
    elif roi_pct >= 12:
        dynamic_distance *= 0.88
    elif roi_pct >= 6:
        dynamic_distance *= 0.95

    return _clamp(dynamic_distance, base * 0.6, base * 3.5)

# Fibonacci ratios
FIB_RATIOS = {
    '0.236': 0.236,
    '0.382': 0.382,
    '0.500': 0.500,
    '0.618': 0.618,
    '0.786': 0.786,
}

# Score bonus per Fibonacci level (capped at 12 total)
FIB_SCORE_MAP = {
    '0.618': 8,
    '0.500': 6,
    '0.382': 4,
    '0.236': 2,
    '0.786': 3,
}
FIB_SCORE_CAP = 12
FIB_CONFLUENCE_BONUS = 2  # Extra bonus when VP/Sweep aligns


def detect_swings_atr(highs: list, lows: list, closes: list, atr: float,
                      lookback: int = 30, k: float = 1.5) -> dict:
    """
    ATR-filtered swing high/low detection (Method 2 from Fibonacci guide).
    
    A swing is valid only if the price move from the last swing exceeds k Ã— ATR,
    filtering out small fake moves and noise.
    
    Args:
        highs: List of high prices
        lows: List of low prices
        closes: List of close prices
        atr: Current ATR value
        lookback: How many bars to look back
        k: ATR multiplier threshold (1.5 = need 1.5Ã— ATR move for valid swing)
    
    Returns:
        {
            'swing_high': float or None,
            'swing_low': float or None,
            'swing_high_idx': int or -1,
            'swing_low_idx': int or -1,
            'valid': bool
        }
    """
    result = {
        'swing_high': None, 'swing_low': None,
        'swing_high_idx': -1, 'swing_low_idx': -1,
        'valid': False
    }
    
    if len(highs) < lookback or len(lows) < lookback or atr <= 0:
        return result
    
    min_move = k * atr  # Minimum price move for a valid swing
    
    # Use the last `lookback` bars
    h = highs[-lookback:]
    l = lows[-lookback:]
    c = closes[-lookback:]
    
    # Find highest high and lowest low
    max_h = max(h)
    min_l = min(l)
    max_h_idx = len(h) - 1 - h[::-1].index(max_h)  # Last occurrence
    min_l_idx = len(l) - 1 - l[::-1].index(min_l)
    
    # Check if the range is significant (> k * ATR)
    swing_range = max_h - min_l
    if swing_range < min_move:
        return result  # Range too small â€” no meaningful swing
    
    # Validate: use fractal confirmation (2-bar lookback)
    # Swing High: bar[i] high > bar[i-1] high AND bar[i] high > bar[i-2] high
    valid_sh = False
    for i in range(len(h) - 1, 1, -1):
        if h[i] == max_h and h[i] > h[i-1] and h[i] > h[i-2]:
            max_h_idx = i
            valid_sh = True
            break
    
    valid_sl = False
    for i in range(len(l) - 1, 1, -1):
        if l[i] == min_l and l[i] < l[i-1] and l[i] < l[i-2]:
            min_l_idx = i
            valid_sl = True
            break
    
    if not valid_sh:
        # Fallback: just use the max high
        valid_sh = True
    if not valid_sl:
        valid_sl = True
    
    # Ensure swing high happened after swing low (for uptrend) or vice versa
    # We return both and let the caller decide based on trend
    result['swing_high'] = max_h
    result['swing_low'] = min_l
    result['swing_high_idx'] = max_h_idx
    result['swing_low_idx'] = min_l_idx
    result['valid'] = valid_sh and valid_sl
    
    return result


def calculate_fib_levels(swing_high: float, swing_low: float, trend: str = 'UP') -> dict:
    """
    Calculate Fibonacci retracement levels from swing high/low.
    
    Uptrend: levels measured down from swing_high (retracement of upward move)
    Downtrend: levels measured up from swing_low (retracement of downward move)
    
    Args:
        swing_high: The swing high price
        swing_low: The swing low price
        trend: 'UP' or 'DOWN'
    
    Returns:
        {
            '0.236': price_level,
            '0.382': price_level,
            '0.500': price_level,
            '0.618': price_level,
            '0.786': price_level,
            'range': swing_high - swing_low
        }
    """
    price_range = swing_high - swing_low
    if price_range <= 0:
        return {}
    
    levels = {'range': price_range}
    
    for name, ratio in FIB_RATIOS.items():
        if trend == 'UP':
            # Uptrend retracement: price pulls back down from high
            levels[name] = swing_high - (price_range * ratio)
        else:
            # Downtrend retracement: price bounces up from low
            levels[name] = swing_low + (price_range * ratio)
    
    return levels


def build_fib_context(signal_side: str, price: float, atr: float,
                      adx: float, hurst: float, trend_data: dict,
                      sweep_result: dict = None, volume_profile_poc: float = 0) -> dict:
    """
    Build Fibonacci context for signal scoring and entry refinement.
    
    Uses cached OHLCV data from MTF trend updates to detect swings
    and calculate Fibonacci levels. Produces score bonus (capped at 12)
    and optimal entry price.
    
    Args:
        signal_side: 'LONG' or 'SHORT'
        price: Current price
        atr: Current ATR
        adx: Current ADX
        hurst: Current Hurst exponent
        trend_data: From mtf_confirmation.coin_trends[symbol]
        sweep_result: LiquiditySweep detection result (optional)
        volume_profile_poc: Volume profile POC price (optional)
    
    Returns:
        {
            'fib_active': bool,
            'fib_score_bonus': int (0-12),
            'fib_entry': float (0 if inactive),
            'fib_level': str or None ('0.618', '0.5', etc.),
            'fib_zone_upper': float,
            'fib_zone_lower': float,
            'confluence': list,
            'skip_reason': str (if inactive)
        }
    """
    result = {
        'fib_active': False,
        'fib_score_bonus': 0,
        'fib_entry': 0,
        'fib_level': None,
        'fib_zone_upper': 0,
        'fib_zone_lower': 0,
        'confluence': [],
        'skip_reason': ''
    }
    
    # Need OHLCV data from MTF cache
    ohlcv_4h = trend_data.get('ohlcv_4h', [])
    
    if not ohlcv_4h or len(ohlcv_4h) < 20:
        result['skip_reason'] = 'no_data'
        return result
    
    # Check: Fibonacci works best in trending markets
    # If Hurst < 0.45 (mean-reverting) AND ADX < 20 (no trend), skip
    if hurst < 0.40 and adx < 15:
        result['skip_reason'] = 'chop_market'
        return result
    
    # Extract OHLCV arrays
    highs_4h = [c[2] for c in ohlcv_4h]
    lows_4h = [c[3] for c in ohlcv_4h]
    closes_4h = [c[4] for c in ohlcv_4h]
    
    # Detect swings on 4H data
    swings = detect_swings_atr(highs_4h, lows_4h, closes_4h, atr, lookback=min(30, len(ohlcv_4h)), k=1.5)
    
    if not swings['valid'] or swings['swing_high'] is None or swings['swing_low'] is None:
        result['skip_reason'] = 'no_swing'
        return result
    
    # Determine trend from signal side
    trend = 'UP' if signal_side == 'LONG' else 'DOWN'
    
    # Calculate Fibonacci levels
    fib_levels = calculate_fib_levels(swings['swing_high'], swings['swing_low'], trend)
    
    if not fib_levels:
        result['skip_reason'] = 'no_range'
        return result
    
    # Zone width: ATR Ã— 0.5 on each side of the fib level
    zone_width = atr * 0.5
    
    # Find which zone (if any) the current price is in
    best_level = None
    best_bonus = 0
    best_fib_price = 0
    
    for level_name in ['0.618', '0.500', '0.382', '0.786', '0.236']:
        fib_price = fib_levels.get(level_name, 0)
        if fib_price <= 0:
            continue
        
        zone_upper = fib_price + zone_width
        zone_lower = fib_price - zone_width
        
        if zone_lower <= price <= zone_upper:
            bonus = FIB_SCORE_MAP.get(level_name, 0)
            if bonus > best_bonus:
                best_bonus = bonus
                best_level = level_name
                best_fib_price = fib_price
                result['fib_zone_upper'] = zone_upper
                result['fib_zone_lower'] = zone_lower
    
    if best_level is None:
        result['skip_reason'] = 'not_in_zone'
        return result
    
    # Confluence checks
    confluence = []
    confluence_bonus = 0
    
    # Check LiquiditySweep confluence
    if sweep_result and sweep_result.get('sweep_type'):
        sweep_type = sweep_result['sweep_type']
        if (sweep_type == 'BULLISH' and signal_side == 'LONG') or \
           (sweep_type == 'BEARISH' and signal_side == 'SHORT'):
            confluence.append('LiqSweep')
            confluence_bonus += 1
    
    # Check VolumeProfile POC confluence
    if volume_profile_poc and volume_profile_poc > 0:
        poc_distance = abs(best_fib_price - volume_profile_poc)
        if poc_distance < zone_width:
            confluence.append('VP_POC')
            confluence_bonus += 1
    
    # Cap confluence bonus
    confluence_bonus = min(confluence_bonus, FIB_CONFLUENCE_BONUS)
    
    # Total score bonus (capped at FIB_SCORE_CAP)
    total_bonus = min(best_bonus + confluence_bonus, FIB_SCORE_CAP)
    
    result['fib_active'] = True
    result['fib_score_bonus'] = total_bonus
    result['fib_entry'] = best_fib_price
    result['fib_level'] = best_level
    result['confluence'] = confluence
    
    return result


# =====================================================
# DYNAMIC TRAIL PARAMETERS (Hybrid Approach)
# Calculates trail_activation and trail_distance based on:
# 1. Volatility (ATR %)
# 2. Hurst exponent (trend vs mean-reversion)
# 3. Price factor (low price = more risk)
# 4. Spread factor (high spread = more risk)
# =====================================================
def get_dynamic_trail_params(
    volatility_pct: float,
    hurst: float = 0.5,
    price: float = 0.0,
    spread_pct: float = 0.0,
    settings_activation: float = 0.0,
    settings_distance: float = 0.0
) -> tuple:
    """
    Calculate dynamic trail_activation_atr and trail_distance_atr.
    
    Phase 231: Now respects settings values as upper caps.
    
    Args:
        volatility_pct: ATR as percentage of price (e.g., 5.0 for 5%)
        hurst: Hurst exponent (0-1, >0.5 = trending, <0.5 = mean reverting)
        price: Current price for price factor calculation
        spread_pct: Current spread percentage
        settings_activation: Settings trail_activation_atr (used as cap, 0=no cap)
        settings_distance: Settings trail_distance_atr (used as cap, 0=no cap)
        
    Returns:
        tuple: (trail_activation_atr, trail_distance_atr)
    """
    import math
    
    # 1. BASE VALUES FROM VOLATILITY
    # Low volatility â†’ wider trails (let profits run)
    # High volatility â†’ tighter trails (lock in profits quickly)
    if volatility_pct <= 2.0:
        base_activation = 2.0   # Need big move before trail
        base_distance = 1.5     # Wide trail distance
    elif volatility_pct <= 4.0:
        base_activation = 1.5
        base_distance = 1.0
    elif volatility_pct <= 6.0:
        base_activation = 1.2
        base_distance = 0.8
    elif volatility_pct <= 10.0:
        base_activation = 1.0
        base_distance = 0.6
    else:
        base_activation = 0.8   # Quick activation for very volatile
        base_distance = 0.5     # Tight trail
    
    # 2. HURST ADJUSTMENT
    # Trending (>0.5) â†’ wider trails to capture bigger moves
    # Mean-reverting (<0.5) â†’ tighter trails, exit quickly
    # Phase 213: Trending coins get significantly wider trails (min 2x)
    if hurst >= 0.65:
        hurst_mult = 2.0   # Strong trend â†’ let it run (was 1.4)
    elif hurst >= 0.55:
        hurst_mult = 1.6   # Mild trend â†’ still wide (was 1.2)
    elif hurst >= 0.45:
        hurst_mult = 1.0   # Random walk
    elif hurst >= 0.35:
        hurst_mult = 0.8   # Mild mean-reversion â†’ tighter
    else:
        hurst_mult = 0.6   # Strong mean-reversion â†’ very tight
    
    # 3. PRICE FACTOR (Log scale)
    # Low price coins are riskier â†’ tighter trails
    if price > 0:
        log_price = math.log10(max(price, 0.0001))
        price_factor = max(0.5, min(1.0, (log_price + 2) / 4))
    else:
        price_factor = 1.0
    
    # 4. SPREAD FACTOR
    # High spread = low liquidity â†’ tighter trails (exit while you can)
    if spread_pct > 0:
        spread_factor = max(0.6, 1.0 - spread_pct * 1.5)
    else:
        spread_factor = 1.0
    
    # COMBINED: Riskier coins get tighter trails
    risk_mult = (price_factor + spread_factor) / 2  # Average of price and spread risk
    
    # Final calculation
    final_activation = base_activation * hurst_mult * max(0.5, risk_mult)
    final_distance = base_distance * hurst_mult * max(0.5, risk_mult)
    
    # Clamp to reasonable ranges
    final_activation = max(0.5, min(3.0, final_activation))  # 0.5-3.0 range
    final_distance = max(0.3, min(2.5, final_distance))      # 0.3-2.5 range (Phase 213: was 2.0)
    
    # Phase 213: Enforce minimum 2x distance for trending coins
    if hurst >= 0.55:
        final_distance = max(final_distance, base_distance * 1.5)  # At least 1.5x base for trending
    
    # Phase 231: Cap at settings values â€” user settings always respected
    if settings_activation > 0:
        final_activation = min(final_activation, settings_activation)
    if settings_distance > 0:
        final_distance = min(final_distance, settings_distance)
    
    return round(final_activation, 2), round(final_distance, 2)


# =====================================================
# DYNAMIC TRAIL ACTIVATION THRESHOLD
# ATR + spread + volume bazlÄ± dinamik eÅŸik hesaplama
# Sabit 0.75% / 5.0% yerine piyasa koÅŸullarÄ±na gÃ¶re ayarlanÄ±r
# =====================================================
def get_dynamic_trail_activation_threshold(
    atr_pct: float,
    spread_pct: float,
    volume_ratio: float,
    leverage: int,
    threshold_mult: float = 1.0
) -> tuple:
    """
    Calculate dynamic trail activation thresholds based on market conditions.
    
    Args:
        atr_pct: ATR as percentage of price (e.g., 2.0 for 2%)
        spread_pct: Current bid-ask spread percentage
        volume_ratio: Current volume / average volume ratio
        leverage: Position leverage
    
    Returns:
        tuple: (min_price_move_pct, min_roi_pct)
    """
    th_mult = _clamp(threshold_mult, 0.60, 3.00)

    # Base: ATR'nin %40'Ä± (min 0.5%, max 2.0%)
    base_move = max(0.5, min(2.0, atr_pct * 0.40))
    
    # Spread factor: yÃ¼ksek spread â†’ daha geniÅŸ eÅŸik (noise filtresi)
    # 0.05% normal spread, Ã¼stÃ¼ = ek buffer
    spread_factor = 1.0 + max(0, (spread_pct - 0.05)) * 3.0
    
    # Volume factor: dÃ¼ÅŸÃ¼k volume â†’ daha geniÅŸ eÅŸik (fake move filtresi)
    if volume_ratio >= 2.0:
        vol_factor = 0.85    # YÃ¼ksek volume: daha erken trail OK
    elif volume_ratio >= 1.0:
        vol_factor = 1.0     # Normal
    else:
        vol_factor = 1.25    # DÃ¼ÅŸÃ¼k volume: daha geÃ§ trail
    
    min_price_move = round(base_move * spread_factor * vol_factor * th_mult, 3)
    min_price_move = max(0.4, min(3.5, min_price_move))  # Hard clamp
    
    # ROI = min_price_move Ã— leverage (ama min 4%, max 20%)
    min_roi = round(min_price_move * max(1, leverage), 1)
    min_roi = max(4.0, min(28.0, min_roi))
    
    return min_price_move, min_roi


def update_runtime_trail_telemetry(
    pos: dict,
    dynamic_trail_distance: float,
    effective_exit_tightness: float,
    min_price_move_pct: float,
    min_roi_pct: float,
    threshold_mult: float,
    entry_price: float
):
    """
    Persist runtime trail/exit telemetry on the position for UI observability.
    """
    try:
        safe_entry = float(entry_price or 0)
        safe_distance = float(dynamic_trail_distance or 0)
        distance_pct = (safe_distance / safe_entry * 100.0) if safe_entry > 0 else 0.0
        pos['effectiveExitTightness'] = round(float(effective_exit_tightness or 1.0), 3)
        pos['runtimeTrailDistance'] = round(safe_distance, 8)
        pos['runtimeTrailDistancePct'] = round(distance_pct, 4)
        pos['runtimeTrailActivationMovePct'] = round(float(min_price_move_pct or 0), 3)
        pos['runtimeTrailActivationRoiPct'] = round(float(min_roi_pct or 0), 2)
        pos['runtimeTrailThresholdMult'] = round(float(threshold_mult or 1.0), 3)
        pos['runtimeTrailLastUpdateTs'] = int(datetime.now().timestamp() * 1000)
    except Exception:
        pass


def check_emergency_sl_static(pos: dict, current_price: float, trailing_stop: float) -> bool:
    """
    Phase 217: Unified trail-based Emergency SL check â€” single source of truth.
    Checks if current price exceeds the trailing stop by >1% of entry price.
    Returns True if emergency breach detected.
    """
    entry_price = pos.get('entryPrice', 0)
    if entry_price <= 0 or trailing_stop <= 0:
        return False
    
    EMERGENCY_MARGIN_PCT = 1.0  # %1 of entry price
    emergency_margin = entry_price * (EMERGENCY_MARGIN_PCT / 100)
    side = pos.get('side', 'LONG')
    
    if side == 'LONG' and current_price <= (trailing_stop - emergency_margin):
        return True
    elif side == 'SHORT' and current_price >= (trailing_stop + emergency_margin):
        return True
    return False

def check_failed_continuation(pos: dict, candle_close_price: float) -> str:
    """
    Phase 214: Failed Continuation Detector
    KalÄ±cÄ±lÄ±k saÄŸlayamayan pozisyonlarÄ± tespit eder.
    
    MantÄ±k: Fiyat N kez meaningful profit zone'a girip entry'ye geri dÃ¶nÃ¼yorsa,
    giriÅŸ noktasÄ± yanlÄ±ÅŸtÄ±r â†’ breakeven'da kapat.
    
    Returns: 'FAILED_CONTINUATION' if position should be closed, else ''
    """
    entry_price = pos.get('entryPrice', 0)
    if entry_price <= 0:
        return ''
    
    side = pos.get('side', 'LONG')
    pos_atr = pos.get('atr', entry_price * 0.02)
    atr_pct = (pos_atr / entry_price) * 100 if entry_price > 0 else 2.0
    
    # Skip if position already reached 5%+ profit (trail handles it)
    fc_max_profit = pos.get('fc_max_profit_pct', 0.0)
    if fc_max_profit >= 5.0:
        return ''
    
    # ---- Dynamic max attempts based on ATR% ----
    if atr_pct < 2.0:
        max_attempts = 4   # BTC/ETH â€” low noise
    elif atr_pct < 4.0:
        max_attempts = 3   # Medium volatility
    elif atr_pct < 8.0:
        max_attempts = 3   # High volatility
    else:
        max_attempts = 2   # Meme coin â€” fast exit
    
    # Trend mode: +1 tolerance
    if pos.get('trend_mode', False):
        max_attempts += 1
    
    # Clamp to 2-4 range (5 with trend mode)
    max_attempts = max(2, min(5, max_attempts))
    
    # Time-based reduction: after 8 hours, -1 attempt (min 2)
    open_time = pos.get('openTime', 0)
    if open_time > 0:
        elapsed_hours = (datetime.now().timestamp() * 1000 - open_time) / (1000 * 3600)
        if elapsed_hours >= 8:
            max_attempts = max(2, max_attempts - 1)
    
    # ---- Calculate current profit state ----
    # Minimum profit depth: 0.3Ã— ATR for meaningful move
    min_profit_depth = pos_atr * 0.3
    # Breakeven zone: dynamic buffer (Phase 238A)
    _fc_spread = pos.get('spreadPct', 0.05)
    _fc_buf = compute_breakeven_buffer_pct(spread_pct=_fc_spread, spread_level=pos.get('spreadLevel', 'LOW'), reason='FC_CHECK')
    be_tolerance = entry_price * _fc_buf
    
    if side == 'LONG':
        price_vs_entry = candle_close_price - entry_price
        in_profit = price_vs_entry >= min_profit_depth
        at_breakeven = abs(candle_close_price - entry_price) <= be_tolerance
    else:  # SHORT
        price_vs_entry = entry_price - candle_close_price
        in_profit = price_vs_entry >= min_profit_depth
        at_breakeven = abs(candle_close_price - entry_price) <= be_tolerance
    
    # Track max profit % seen
    current_pnl_pct = abs(pos.get('unrealizedPnlPercent', 0))
    if current_pnl_pct > fc_max_profit:
        pos['fc_max_profit_pct'] = current_pnl_pct
    
    was_in_profit = pos.get('fc_was_in_profit', False)
    failed_count = pos.get('fc_failed_count', 0)
    
    # ---- State machine ----
    if in_profit and not was_in_profit:
        # Entered meaningful profit zone
        pos['fc_was_in_profit'] = True
    elif (at_breakeven or price_vs_entry < 0) and was_in_profit:
        # Was profitable, now back at breakeven or losing â†’ failed break
        pos['fc_failed_count'] = failed_count + 1
        pos['fc_was_in_profit'] = False
        failed_count = pos['fc_failed_count']
        logger.info(
            f"ðŸ“Š FAILED_BREAK #{failed_count}/{max_attempts}: {pos.get('symbol','?')} {side} "
            f"(depth={min_profit_depth:.6f}, atr%={atr_pct:.1f}%)"
        )
    # Note: If price is in shallow profit (above entry but < 0.3 ATR), we keep
    # was_in_profit=True so we correctly count the failed break when price returns to BE
    
    # ---- Check if max attempts reached ----
    if failed_count >= max_attempts:
        return 'FAILED_CONTINUATION'
    
    return ''

# ===================================================================
# Phase 215: LIVE MTF POSITION GUARD
# GiriÅŸ filtresi + aÃ§Ä±k pozisyon sÄ±kÄ±laÅŸtÄ±rma/geniÅŸletme
# ===================================================================

# Son MTF guard gÃ¼ncelleme zamanÄ± (global)
_last_mtf_guard_update = 0

def check_ma_alignment_veto(symbol: str, action: str) -> tuple:
    """
    Phase 215 Katman 1: MA Alignment Hard Veto
    4H + 1D trend + Supertrend Ã¼Ã§Ã¼ de aynÄ± yÃ¶nde ise ters sinyali HARD REJECT et.
    Returns: (vetoed: bool, reason: str)
    """
    trend_data = mtf_confirmation.coin_trends.get(symbol, {})
    
    trend_4h = trend_data.get('trend_4h', 'NEUTRAL')
    trend_1d = trend_data.get('trend_1d', 'NEUTRAL')
    supertrend_dir = trend_data.get('supertrend_dir', 0)  # 1=bull, -1=bear
    
    bullish_alignment = (
        trend_4h in ('BULLISH', 'STRONG_BULLISH') and
        trend_1d in ('BULLISH', 'STRONG_BULLISH') and
        supertrend_dir == 1
    )
    bearish_alignment = (
        trend_4h in ('BEARISH', 'STRONG_BEARISH') and
        trend_1d in ('BEARISH', 'STRONG_BEARISH') and
        supertrend_dir == -1
    )
    
    if action == 'SHORT' and bullish_alignment:
        return True, f"MA_VETO: 4H={trend_4h}, 1D={trend_1d}, ST=BULL â†’ SHORT blocked"
    if action == 'LONG' and bearish_alignment:
        return True, f"MA_VETO: 4H={trend_4h}, 1D={trend_1d}, ST=BEAR â†’ LONG blocked"
    
    return False, ""

def _apply_tightening(pos: dict, factor: float):
    """Phase 215: SL mesafesini, trail distance'Ä± ve trail activation'Ä± sÄ±kÄ±laÅŸtÄ±r."""
    entry = pos['entryPrice']
    side = pos['side']
    
    # Orijinal deÄŸerleri sakla (ilk seferde â€” tek sefer)
    if not pos.get('_mtf_originals_saved', False):
        pos['original_sl'] = pos.get('stopLoss', 0)
        pos['original_trail_distance'] = pos.get('trailDistance', 0)
        pos['original_trail_activation'] = pos.get('trailActivation', entry)
        pos['original_tp'] = pos.get('takeProfit', 0)
        pos['_mtf_originals_saved'] = True
    
    orig_sl = pos['original_sl']
    
    # SL sÄ±kÄ±laÅŸtÄ±r (sadece trail aktif DEÄžÄ°LSE)
    if not pos.get('isTrailingActive', False) and orig_sl > 0:
        if side == 'LONG':
            sl_distance = entry - orig_sl
            new_sl = entry - (sl_distance * factor)
            # Orijinal SL'den hesapla â€” factor deÄŸiÅŸtikÃ§e SL de ayarlansÄ±n
            pos['stopLoss'] = new_sl
        else:  # SHORT
            sl_distance = orig_sl - entry
            new_sl = entry + (sl_distance * factor)
            pos['stopLoss'] = new_sl
    
    # Trail distance sÄ±kÄ±laÅŸtÄ±r
    orig_td = pos.get('original_trail_distance', 0)
    if orig_td > 0:
        pos['trailDistance'] = orig_td * factor
    
    # Trail activation dÃ¼ÅŸÃ¼r (daha erken trail baÅŸlasÄ±n)
    orig_ta = pos.get('original_trail_activation', entry)
    if side == 'LONG':
        ta_diff = orig_ta - entry
        if ta_diff > 0:
            pos['trailActivation'] = entry + (ta_diff * factor)
    else:
        ta_diff = entry - orig_ta
        if ta_diff > 0:
            pos['trailActivation'] = entry - (ta_diff * factor)
    
    pos['mtf_guard_factor'] = factor

def _apply_widening(pos: dict, expand: float):
    """Phase 215: TP ve trail distance geniÅŸlet (pro-trend + kÃ¢rda)."""
    entry = pos['entryPrice']
    side = pos['side']
    
    if not pos.get('_mtf_originals_saved', False):
        pos['original_tp'] = pos.get('takeProfit', 0)
        pos['original_trail_distance'] = pos.get('trailDistance', 0)
        pos['original_sl'] = pos.get('stopLoss', 0)
        pos['original_trail_activation'] = pos.get('trailActivation', entry)
        pos['_mtf_originals_saved'] = True
    
    orig_tp = pos.get('original_tp', 0)
    orig_td = pos.get('original_trail_distance', 0)
    
    # TP geniÅŸlet
    if orig_tp > 0:
        if side == 'LONG':
            tp_distance = orig_tp - entry
            if tp_distance > 0:
                pos['takeProfit'] = entry + (tp_distance * expand)
        else:
            tp_distance = entry - orig_tp
            if tp_distance > 0:
                pos['takeProfit'] = entry - (tp_distance * expand)
    
    # Trail distance geniÅŸlet (daha geniÅŸ trail = daha geÃ§ Ã§Ä±kÄ±ÅŸ)
    if orig_td > 0:
        pos['trailDistance'] = orig_td * expand
    
    pos['mtf_guard_factor'] = expand

async def apply_mtf_position_guard(positions: list, exchange):
    """
    Phase 215 Katman 2: Her 30 dakikada bir aÃ§Ä±k pozisyonlar iÃ§in MTF re-evaluation.
    Contra-trend â†’ SL/Trail sÄ±kÄ±laÅŸtÄ±r
    Pro-trend + kÃ¢rda â†’ TP/Trail geniÅŸlet
    """
    global _last_mtf_guard_update
    now = datetime.now().timestamp()
    
    if now - _last_mtf_guard_update < 1800:  # 30 dakika
        return
    _last_mtf_guard_update = now
    
    if not positions or not exchange:
        return
    
    logger.info(f"ðŸ“Š MTF_GUARD: {len(positions)} pozisyon iÃ§in trend re-evaluation baÅŸlÄ±yor")
    
    for pos in positions:
        try:
            symbol = pos.get('symbol', '')
            side = pos.get('side', 'LONG')
            entry = pos.get('entryPrice', 0)
            if entry <= 0 or not symbol:
                continue
            
            # MTF trend gÃ¼ncelle (API call)
            await mtf_confirmation.update_coin_trend(symbol, exchange)
            mtf_result = mtf_confirmation.confirm_signal(symbol, side)
            mtf_score = mtf_result.get('mtf_score', 0)
            
            # Mevcut PnL hesapla
            current_price = pos.get('currentPrice', entry)
            if side == 'LONG':
                pnl_pct = ((current_price - entry) / entry) * 100
            else:
                pnl_pct = ((entry - current_price) / entry) * 100
            
            trends = mtf_result.get('trends', {})
            trend_info = f"15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}, 1d:{trends.get('1d','?')}"
            
            # ---- CONTRA-TREND SIKILAÅžTIRMAa ----
            if mtf_score < 0:
                if mtf_score < -25:
                    factor = 0.30   # Ã§ok agresif
                elif mtf_score < -10:
                    factor = 0.50
                else:
                    factor = 0.70
                
                _apply_tightening(pos, factor)
                logger.warning(
                    f"âš ï¸ MTF_GUARD TIGHTEN: {symbol} {side} | "
                    f"MTF={mtf_score} | factor={factor:.0%} | PnL={pnl_pct:+.1f}% | {trend_info}"
                )
            
            # ---- PRO-TREND GENÄ°ÅžLETME (sadece kÃ¢rda) ----
            elif mtf_score > 25 and pnl_pct > 0:
                if mtf_score > 50:
                    expand = 1.40
                else:
                    expand = 1.20
                
                _apply_widening(pos, expand)
                logger.info(
                    f"ðŸ“ˆ MTF_GUARD WIDEN: {symbol} {side} | "
                    f"MTF={mtf_score} | expand={expand:.0%} | PnL={pnl_pct:+.1f}% | {trend_info}"
                )
            
            else:
                # NÃ¶tr â€” orijinal deÄŸerlere dÃ¶n ve flag temizle
                if pos.get('_mtf_originals_saved', False):
                    if not pos.get('isTrailingActive', False):
                        pos['stopLoss'] = pos.get('original_sl', pos['stopLoss'])
                    pos['trailDistance'] = pos.get('original_trail_distance', pos.get('trailDistance', 0))
                    pos['trailActivation'] = pos.get('original_trail_activation', pos.get('trailActivation', entry))
                    pos['takeProfit'] = pos.get('original_tp', pos.get('takeProfit', 0))
                    # Temizle â€” yeni cycle'da taze kayÄ±t yapÄ±lsÄ±n
                    for key in ['original_sl', 'original_tp', 'original_trail_distance', 
                                'original_trail_activation', '_mtf_originals_saved']:
                        pos.pop(key, None)
                pos.pop('mtf_guard_factor', None)
                logger.debug(f"ðŸ“Š MTF_GUARD NEUTRAL: {symbol} {side} | MTF={mtf_score} | restored originals")
        
        except Exception as guard_err:
            logger.debug(f"MTF Guard error for {pos.get('symbol', '?')}: {guard_err}")

def get_volatility_adjusted_params(volatility_pct: float, atr: float, price: float = 0.0, spread_pct: float = 0.0) -> dict:
    """
    Get SL/TP/Trail/Leverage based on volatility (ATR as % of price).
    Phase 35: Using ATR percentage for proper volatility classification.
    Phase 43: Combined leverage formula with price and spread factors.
    
    Combined Formula:
        base_leverage = from VOLATILITY_LEVELS (3-50x based on volatility)
        price_factor = min(price / 10, 1.0)  # $10 altÄ± sÃ¼rekli azalt
        spread_factor = max(0.2, 1 - spread_pct * 2)  # Spread yÃ¼ksekse azalt
        final_leverage = base_leverage * price_factor * spread_factor
    
    Args:
        volatility_pct: ATR as percentage of price (e.g., 2.5 for 2.5%)
        atr: Absolute ATR value for calculating distances
        price: Current price for price_factor calculation
        spread_pct: Current spread percentage for spread_factor calculation
        
    Returns:
        dict with trail_distance, stop_loss, take_profit, leverage, pullback, level
    """
    for level, params in VOLATILITY_LEVELS.items():
        if volatility_pct <= params["max_atr_pct"]:
            base_leverage = params["leverage"]  # Volatility-based base (3-50x)
            
            # Phase 43: Combined leverage formula (logarithmic version)
            # Price Factor: Logarithmic reduction for low-price coins
            # Phase 61: FIXED - previous formula was broken, all prices mapped to 0.85
            # NEW: Softer gradient: $100+=1.0, $10=0.98, $1=0.95, $0.1=0.92, $0.01=0.89
            import math
            if price > 0:
                log_price = math.log10(max(price, 0.0001))  # -4 to ~5 range
                # Fixed formula: 0.95 base + 0.03 per log unit
                price_factor = max(0.85, min(1.0, 0.95 + log_price * 0.03))
            else:
                price_factor = 1.0  # If price=0, don't penalize
            
            # Spread Factor: Reduce leverage for high spread coins
            # Phase 60: Relaxed - Ã—1.5 (was Ã—2), min 0.65 (was 0.5)
            if spread_pct > 0:
                spread_factor = max(0.65, 1.0 - spread_pct * 1.5)  # max %23 spread = min 0.65 factor
            else:
                spread_factor = 1.0
            
            # Combined formula: base Ã— price_factor Ã— spread_factor
            final_leverage = base_leverage * price_factor * spread_factor
            
            # Ensure minimum 3x leverage
            final_leverage = max(3, int(round(final_leverage)))
            
            if final_leverage != base_leverage:
                logger.debug(f"Combined leverage: base={base_leverage}x Ã— price={price_factor:.2f} Ã— spread={spread_factor:.2f} â†’ final={final_leverage}x")
            
            return {
                "trail_distance": atr * params["trail"],
                "stop_loss": atr * params["sl"],
                "take_profit": atr * params["tp"],
                "leverage": final_leverage,
                "pullback": params["pullback"],
                "sl_multiplier": params["sl"],
                "tp_multiplier": params["tp"],
                "trail_multiplier": params["trail"],
                # Phase 223c: Normalize to Title Case for consumer compatibility
                "level": level.replace('_', ' ').title()
            }
    
    # Default to ultra
    params = VOLATILITY_LEVELS["ultra"]
    base_leverage = params["leverage"]
    
    # Apply logarithmic Combined Formula for default case too
    # Phase 61: FIXED formula
    import math
    if price > 0:
        log_price = math.log10(max(price, 0.0001))
        price_factor = max(0.85, min(1.0, 0.95 + log_price * 0.03))  # Fixed formula
    else:
        price_factor = 1.0
    
    spread_factor = max(0.65, 1.0 - spread_pct * 1.5) if spread_pct > 0 else 1.0  # Phase 60: Relaxed
    final_leverage = max(3, int(round(base_leverage * price_factor * spread_factor)))
    
    return {
        "trail_distance": atr * params["trail"],
        "stop_loss": atr * params["sl"],
        "take_profit": atr * params["tp"],
        "leverage": final_leverage,
        "pullback": params["pullback"],
        "sl_multiplier": params["sl"],
        "tp_multiplier": params["tp"],
        "trail_multiplier": params["trail"],
        "level": "Ultra"  # Phase 228: New top level
    }


class MultiTimeframeAnalyzer:
    """
    Phase 22: Analyze multiple timeframes for signal confirmation.
    Only enter trades when 3+ timeframes agree.
    """
    
    def __init__(self):
        self.timeframes = MTF_CONFIRMATION_TIMEFRAMES
        self.min_agreement = MTF_MIN_AGREEMENT
        self.tf_signals = {}
        self.last_update = {}
    
    def analyze_timeframe(self, closes: list, highs: list = None, lows: list = None) -> dict:
        """Analyze a single timeframe and return signal."""
        if len(closes) < 20:
            return {"direction": "NEUTRAL", "strength": 0, "hurst": 0.5, "zscore": 0}
        
        # Calculate indicators
        hurst = calculate_hurst(closes)
        
        # Calculate Z-Score from price spread
        if len(closes) >= 20:
            ma = np.mean(closes[-20:])
            spreads = [c - ma for c in closes[-20:]]
            zscore = calculate_zscore(spreads)
        else:
            zscore = 0
        
        # Determine direction
        direction = "NEUTRAL"
        strength = 0
        
        # Mean Reversion (Hurst < 0.45)
        if hurst < 0.45:
            if zscore < -2.0:
                direction = "LONG"
                strength = abs(zscore)
            elif zscore > 2.0:
                direction = "SHORT"
                strength = abs(zscore)
        
        # Trend Following (Hurst > 0.55)
        elif hurst > 0.55:
            if zscore > 1.5:
                direction = "LONG"
                strength = abs(zscore)
            elif zscore < -1.5:
                direction = "SHORT"
                strength = abs(zscore)
        
        return {
            "direction": direction,
            "strength": strength,
            "hurst": hurst,
            "zscore": zscore
        }
    
    def get_mtf_confirmation(self, tf_signals: dict, spread_pct: float = 0.05) -> dict:
        """Check if timeframes agree. Dynamic threshold based on spread."""
        if not tf_signals:
            return None
        
        # Determine strictness based on spread
        # High spread (>0.15%) requires stricter confirmation (6 TFs)
        required_agreement = 6 if spread_pct > 0.15 else self.min_agreement
        
        long_count = sum(1 for s in tf_signals.values() if s.get('direction') == 'LONG')
        short_count = sum(1 for s in tf_signals.values() if s.get('direction') == 'SHORT')
        
        total_tfs = len(tf_signals)
        
        if long_count >= required_agreement:
            long_signals = [s for s in tf_signals.values() if s.get('direction') == 'LONG']
            avg_strength = np.mean([s.get('strength', 0) for s in long_signals])
            return {
                "action": "LONG",
                "tf_count": long_count,
                "total_tfs": total_tfs,
                "required_agreement": required_agreement,
                "strength": avg_strength,
                "confidence": long_count / total_tfs,
                "details": tf_signals
            }
        elif short_count >= required_agreement:
            short_signals = [s for s in tf_signals.values() if s.get('direction') == 'SHORT']
            avg_strength = np.mean([s.get('strength', 0) for s in short_signals])
            return {
                "action": "SHORT",
                "tf_count": short_count,
                "total_tfs": total_tfs,
                "required_agreement": required_agreement,
                "strength": avg_strength,
                "confidence": short_count / total_tfs,
                "details": tf_signals
            }
        
        return None  # Not enough agreement
    
    def calculate_position_size_multiplier(self, mtf_signal: dict) -> float:
        """Calculate position size multiplier based on TF agreement."""
        if not mtf_signal:
            return 0.5
        
        tf_count = mtf_signal.get('tf_count', 0)
        
        if tf_count >= 5:
            return 2.0  # Full conviction
        elif tf_count >= 4:
            return 1.5  # High conviction
        elif tf_count >= 3:
            return 1.0  # Normal
        else:
            return 0.5  # Low conviction
            
    def calculate_dynamic_leverage(self, mtf_signal: dict) -> int:
        """Calculate dynamic leverage based on TF agreement."""
        if not mtf_signal:
            return 50
        
        tf_count = mtf_signal.get('tf_count', 0)
        
        if tf_count >= 6:
            return 100  # Maximum leverage for maximum conviction
        elif tf_count >= 5:
            return 75
        elif tf_count >= 4:
            return 50
        else:
            return 25   # Minimum leverage for low conviction


# Global MTF Analyzer instance
mtf_analyzer = MultiTimeframeAnalyzer()


# ============================================================================
# PHASE 30: VOLUME PROFILE ANALYZER
# ============================================================================

class VolumeProfileAnalyzer:
    """
    Volume Profile analizi ile POC, VAH, VAL seviyeleri.
    Entry/exit iÃ§in Ã¶nemli destek/direnÃ§ seviyeleri saÄŸlar.
    """
    
    def __init__(self, value_area_pct: float = 0.70):
        self.value_area_pct = value_area_pct  # %70 varsayÄ±lan
        self.poc = None  # Point of Control
        self.vah = None  # Value Area High
        self.val = None  # Value Area Low
        self.profile = {}
        self.last_update = 0
        logger.info("VolumeProfileAnalyzer initialized")
    
    def calculate_profile(self, ohlcv_data: list, bins: int = 50) -> dict:
        """
        OHLCV verilerinden volume profile hesapla.
        """
        if len(ohlcv_data) < 20:
            return {}
        
        # Fiyat aralÄ±ÄŸÄ±nÄ± belirle
        all_highs = [c[2] for c in ohlcv_data]
        all_lows = [c[3] for c in ohlcv_data]
        all_volumes = [c[5] for c in ohlcv_data]
        
        price_min = min(all_lows)
        price_max = max(all_highs)
        price_range = price_max - price_min
        
        if price_range <= 0:
            return {}
        
        bin_size = price_range / bins
        
        # Her bin iÃ§in hacim topla
        volume_profile = {}
        for i in range(bins):
            bin_price = price_min + (i + 0.5) * bin_size
            volume_profile[bin_price] = 0
        
        for candle in ohlcv_data:
            high, low, volume = candle[2], candle[3], candle[5]
            # VWAP benzeri daÄŸÄ±tÄ±m - candle boyunca hacmi daÄŸÄ±t
            candle_range = high - low
            if candle_range <= 0:
                continue
            
            for bin_price in volume_profile.keys():
                if low <= bin_price <= high:
                    volume_profile[bin_price] += volume / bins
        
        self.profile = volume_profile
        
        # POC - En yÃ¼ksek hacimli seviye
        if volume_profile:
            self.poc = max(volume_profile.keys(), key=lambda x: volume_profile[x])
        
        # Value Area hesapla (%70 hacim)
        total_volume = sum(volume_profile.values())
        target_volume = total_volume * self.value_area_pct
        
        # POC'tan baÅŸlayarak geniÅŸle
        sorted_bins = sorted(volume_profile.keys(), key=lambda x: abs(x - self.poc))
        accumulated_volume = 0
        value_area_prices = []
        
        for price in sorted_bins:
            accumulated_volume += volume_profile[price]
            value_area_prices.append(price)
            if accumulated_volume >= target_volume:
                break
        
        if value_area_prices:
            self.vah = max(value_area_prices)
            self.val = min(value_area_prices)
        
        self.last_update = datetime.now().timestamp()
        
        return {
            "poc": self.poc,
            "vah": self.vah,
            "val": self.val,
            "profile": volume_profile
        }
    
    def get_signal_boost(self, current_price: float, signal_action: str) -> float:
        """
        Fiyat Ã¶nemli seviyelerdeyse sinyal gÃ¼cÃ¼nÃ¼ artÄ±r.
        Returns: 0.0-0.3 arasÄ± boost deÄŸeri
        """
        if not self.poc or not self.vah or not self.val:
            return 0.0
        
        # Tolerans: %0.5 fiyat
        tolerance = current_price * 0.005
        
        boost = 0.0
        
        # LONG sinyali iÃ§in
        if signal_action == "LONG":
            # VAL veya POC yakÄ±nÄ±nda LONG = gÃ¼Ã§lÃ¼
            if abs(current_price - self.val) < tolerance:
                boost = 0.3  # Max boost
            elif abs(current_price - self.poc) < tolerance:
                boost = 0.2
            elif current_price < self.poc:
                boost = 0.1  # POC altÄ±nda LONG iyi
        
        # SHORT sinyali iÃ§in
        elif signal_action == "SHORT":
            # VAH veya POC yakÄ±nÄ±nda SHORT = gÃ¼Ã§lÃ¼
            if abs(current_price - self.vah) < tolerance:
                boost = 0.3
            elif abs(current_price - self.poc) < tolerance:
                boost = 0.2
            elif current_price > self.poc:
                boost = 0.1  # POC Ã¼stÃ¼nde SHORT iyi
        
        return boost
    
    def get_key_levels(self) -> dict:
        """Ã–nemli seviyeleri dÃ¶ndÃ¼r."""
        return {
            "poc": self.poc,
            "vah": self.vah,
            "val": self.val
        }


# Global Volume Profile instances (per-coin for accurate POC calculations)
volume_profiler = VolumeProfileAnalyzer()  # Fallback for single-coin mode
coin_volume_profiles = {}  # {symbol: VolumeProfileAnalyzer} for multi-coin scanning


# ============================================================================
# LIQUIDITY SWEEP / SFP (Swing Failure Pattern) DETECTOR
# ============================================================================

class LiquiditySweepDetector:
    """
    Liquidity Sweep ve Swing Failure Pattern (SFP) tespiti.
    
    MantÄ±k:
    - Fiyat Ã¶nceki bir tepenin (high) Ã¼zerine Ã§Ä±kÄ±p, oradaki stop-loss emirlerini
      tetikledikten sonra hÄ±zla ters yÃ¶ne dÃ¶nerse = BEARISH sweep (SHORT sinyali gÃ¼Ã§lenir)
    - Fiyat Ã¶nceki bir dibin (low) altÄ±na inip, stop-loss'larÄ± tetikledikten sonra
      hÄ±zla ters yÃ¶ne dÃ¶nerse = BULLISH sweep (LONG sinyali gÃ¼Ã§lenir)
    
    Bu pattern bÃ¼yÃ¼k oyuncularÄ±n "likidite avÄ±" yaptÄ±ÄŸÄ± noktalarÄ± yakalar.
    """
    
    def __init__(self, lookback: int = 20, sweep_threshold_pct: float = 0.1):
        """
        Args:
            lookback: KaÃ§ bar geriye bakÄ±lacak (swing high/low iÃ§in)
            sweep_threshold_pct: Sweep olarak sayÄ±lmasÄ± iÃ§in minimum aÅŸma yÃ¼zdesi
        """
        self.lookback = lookback
        self.sweep_threshold_pct = sweep_threshold_pct
        self.last_sweep = None
        self.sweep_time = 0
        
    def detect_sweep(self, highs: list, lows: list, closes: list) -> dict:
        """
        Liquidity sweep tespiti yap.
        
        Args:
            highs: Son N bar'Ä±n high deÄŸerleri
            lows: Son N bar'Ä±n low deÄŸerleri
            closes: Son N bar'Ä±n close deÄŸerleri
            
        Returns:
            {
                'sweep_type': 'BULLISH' | 'BEARISH' | None,
                'sweep_level': float (sweep edilen seviye),
                'rejection_strength': float (0-1 arasÄ±, ne kadar gÃ¼Ã§lÃ¼ reddedildi),
                'score_bonus': int (sinyal skoruna eklenecek bonus)
            }
        """
        result = {
            'sweep_type': None,
            'sweep_level': 0,
            'rejection_strength': 0,
            'score_bonus': 0
        }
        
        if len(highs) < self.lookback + 2 or len(lows) < self.lookback + 2:
            return result
        
        # Son bar hariÃ§ lookback period'daki swing high/low'u bul
        lookback_highs = highs[-(self.lookback + 1):-1]
        lookback_lows = lows[-(self.lookback + 1):-1]
        
        swing_high = max(lookback_highs)
        swing_low = min(lookback_lows)
        
        # Mevcut ve Ã¶nceki bar
        current_high = highs[-1]
        current_low = lows[-1]
        current_close = closes[-1]
        prev_close = closes[-2]
        
        # Sweep threshold hesapla
        price_range = swing_high - swing_low
        if price_range <= 0:
            return result
        
        sweep_threshold = price_range * (self.sweep_threshold_pct / 100)
        
        # BEARISH SWEEP: High sweep edip aÅŸaÄŸÄ± kapanÄ±ÅŸ
        # Fiyat swing high'Ä±n Ã¼zerine Ã§Ä±kÄ±p, sonra altÄ±nda kapandÄ±
        if current_high > swing_high + sweep_threshold:
            # Ne kadar Ã¼zerine Ã§Ä±ktÄ±?
            overshoot = current_high - swing_high
            
            # Ama close swing high'Ä±n altÄ±nda mÄ±? (rejection)
            if current_close < swing_high:
                # Rejection strength: ne kadar gÃ¼Ã§lÃ¼ reddedildi
                wick_size = current_high - current_close
                body_size = abs(current_close - prev_close)
                
                if wick_size > 0:
                    rejection_strength = min(1.0, wick_size / (wick_size + body_size + 0.0001))
                else:
                    rejection_strength = 0
                
                result['sweep_type'] = 'BEARISH'
                result['sweep_level'] = swing_high
                result['rejection_strength'] = rejection_strength
                
                # Bonus hesapla: GÃ¼Ã§lÃ¼ sweep = daha fazla bonus
                if rejection_strength > 0.7:
                    result['score_bonus'] = 20  # Ã‡ok gÃ¼Ã§lÃ¼ sweep
                elif rejection_strength > 0.5:
                    result['score_bonus'] = 15
                elif rejection_strength > 0.3:
                    result['score_bonus'] = 10
                else:
                    result['score_bonus'] = 5
                    
                self.last_sweep = result
                self.sweep_time = datetime.now().timestamp()
                return result
        
        # BULLISH SWEEP: Low sweep edip yukarÄ± kapanÄ±ÅŸ
        # Fiyat swing low'un altÄ±na inip, sonra Ã¼stÃ¼nde kapandÄ±
        if current_low < swing_low - sweep_threshold:
            # Ne kadar altÄ±na indi?
            undershoot = swing_low - current_low
            
            # Ama close swing low'un Ã¼stÃ¼nde mi? (rejection)
            if current_close > swing_low:
                # Rejection strength
                wick_size = current_close - current_low
                body_size = abs(current_close - prev_close)
                
                if wick_size > 0:
                    rejection_strength = min(1.0, wick_size / (wick_size + body_size + 0.0001))
                else:
                    rejection_strength = 0
                
                result['sweep_type'] = 'BULLISH'
                result['sweep_level'] = swing_low
                result['rejection_strength'] = rejection_strength
                
                # Bonus hesapla
                if rejection_strength > 0.7:
                    result['score_bonus'] = 20
                elif rejection_strength > 0.5:
                    result['score_bonus'] = 15
                elif rejection_strength > 0.3:
                    result['score_bonus'] = 10
                else:
                    result['score_bonus'] = 5
                    
                self.last_sweep = result
                self.sweep_time = datetime.now().timestamp()
                return result
        
        return result
    
    def get_signal_modifier(self, signal_side: str, sweep_result: dict) -> tuple:
        """
        Sweep sonucuna gÃ¶re sinyal modifikasyonu dÃ¶ndÃ¼r.
        
        Args:
            signal_side: 'LONG' veya 'SHORT'
            sweep_result: detect_sweep() sonucu
            
        Returns:
            (score_modifier: int, reason: str)
        """
        if not sweep_result or not sweep_result.get('sweep_type'):
            return 0, ""
        
        sweep_type = sweep_result['sweep_type']
        bonus = sweep_result['score_bonus']
        
        # BULLISH sweep = LONG sinyalini gÃ¼Ã§lendir
        if sweep_type == 'BULLISH' and signal_side == 'LONG':
            return bonus, f"LiqSweep(BULL+{bonus}p)"
        
        # BEARISH sweep = SHORT sinyalini gÃ¼Ã§lendir
        if sweep_type == 'BEARISH' and signal_side == 'SHORT':
            return bonus, f"LiqSweep(BEAR+{bonus}p)"
        
        # Ters yÃ¶nde sweep = cezalandÄ±r
        if sweep_type == 'BULLISH' and signal_side == 'SHORT':
            return -10, "LiqSweep(BULL-10p)"
        
        if sweep_type == 'BEARISH' and signal_side == 'LONG':
            return -10, "LiqSweep(BEAR-10p)"
        
        return 0, ""


# Global Liquidity Sweep Detector instance
liquidity_sweep_detector = LiquiditySweepDetector(lookback=20, sweep_threshold_pct=0.1)


# ============================================================================
# SMT DIVERGENCE (Smart Money Technique Divergence)
# ============================================================================

class SMTDivergenceDetector:
    """
    SMT Divergence: BTC ve ETH arasÄ±ndaki korelasyon kopukluÄŸunu tespit eder.
    
    MantÄ±k:
    - BTC yeni bir dip yaparken ETH o dibi yapmazsa (daha yÃ¼ksek dipte kalÄ±rsa)
      = Gizli alÄ±m gÃ¼cÃ¼ var, LONG sinyali gÃ¼Ã§lenir
    - BTC yeni bir tepe yaparken ETH o tepeyi yapmazsa (daha dÃ¼ÅŸÃ¼k tepede kalÄ±rsa)
      = Gizli satÄ±ÅŸ gÃ¼cÃ¼ var, SHORT sinyali gÃ¼Ã§lenir
    
    Bu tek grafiÄŸe bakarak gÃ¶rÃ¼lemeyen korelasyon kopukluÄŸunu yakalar.
    """
    
    def __init__(self, lookback: int = 20):
        """
        Args:
            lookback: Swing high/low tespiti iÃ§in geriye bakÄ±ÅŸ periyodu
        """
        self.lookback = lookback
        self.btc_prices = []  # (timestamp, high, low, close)
        self.eth_prices = []
        self.last_divergence = None
        self.divergence_time = 0
        
    def update_prices(self, btc_high: float, btc_low: float, btc_close: float,
                      eth_high: float, eth_low: float, eth_close: float):
        """BTC ve ETH fiyatlarÄ±nÄ± gÃ¼ncelle."""
        now = datetime.now().timestamp()
        
        self.btc_prices.append({
            'ts': now, 'high': btc_high, 'low': btc_low, 'close': btc_close
        })
        self.eth_prices.append({
            'ts': now, 'high': eth_high, 'low': eth_low, 'close': eth_close
        })
        
        # Son 100 bar'Ä± tut
        if len(self.btc_prices) > 100:
            self.btc_prices = self.btc_prices[-100:]
            self.eth_prices = self.eth_prices[-100:]
    
    def detect_divergence(self) -> dict:
        """
        SMT Divergence tespiti yap.
        
        Returns:
            {
                'divergence_type': 'BULLISH' | 'BEARISH' | None,
                'strength': float (0-1 arasÄ±),
                'score_bonus': int
            }
        """
        result = {
            'divergence_type': None,
            'strength': 0,
            'score_bonus': 0
        }
        
        if len(self.btc_prices) < self.lookback + 2:
            return result
        
        # Son lookback bar'daki swing high/low'larÄ± bul
        btc_highs = [p['high'] for p in self.btc_prices[-(self.lookback + 1):-1]]
        btc_lows = [p['low'] for p in self.btc_prices[-(self.lookback + 1):-1]]
        eth_highs = [p['high'] for p in self.eth_prices[-(self.lookback + 1):-1]]
        eth_lows = [p['low'] for p in self.eth_prices[-(self.lookback + 1):-1]]
        
        btc_swing_high = max(btc_highs)
        btc_swing_low = min(btc_lows)
        eth_swing_high = max(eth_highs)
        eth_swing_low = min(eth_lows)
        
        # Mevcut deÄŸerler
        btc_current_high = self.btc_prices[-1]['high']
        btc_current_low = self.btc_prices[-1]['low']
        eth_current_high = self.eth_prices[-1]['high']
        eth_current_low = self.eth_prices[-1]['low']
        
        # BULLISH DIVERGENCE: BTC yeni dip yapÄ±yor, ETH yapmÄ±yor
        btc_new_low = btc_current_low < btc_swing_low
        eth_holds_low = eth_current_low > eth_swing_low
        
        if btc_new_low and eth_holds_low:
            # ETH ne kadar gÃ¼Ã§lÃ¼ tutuyor?
            eth_strength = (eth_current_low - eth_swing_low) / (eth_swing_high - eth_swing_low + 0.0001)
            strength = min(1.0, abs(eth_strength))
            
            result['divergence_type'] = 'BULLISH'
            result['strength'] = strength
            
            if strength > 0.5:
                result['score_bonus'] = 15
            elif strength > 0.3:
                result['score_bonus'] = 10
            else:
                result['score_bonus'] = 5
            
            self.last_divergence = result
            self.divergence_time = datetime.now().timestamp()
            return result
        
        # BEARISH DIVERGENCE: BTC yeni tepe yapÄ±yor, ETH yapmÄ±yor
        btc_new_high = btc_current_high > btc_swing_high
        eth_fails_high = eth_current_high < eth_swing_high
        
        if btc_new_high and eth_fails_high:
            # ETH ne kadar zayÄ±f?
            eth_weakness = (eth_swing_high - eth_current_high) / (eth_swing_high - eth_swing_low + 0.0001)
            strength = min(1.0, abs(eth_weakness))
            
            result['divergence_type'] = 'BEARISH'
            result['strength'] = strength
            
            if strength > 0.5:
                result['score_bonus'] = 15
            elif strength > 0.3:
                result['score_bonus'] = 10
            else:
                result['score_bonus'] = 5
            
            self.last_divergence = result
            self.divergence_time = datetime.now().timestamp()
            return result
        
        return result
    
    def get_signal_modifier(self, signal_side: str) -> tuple:
        """
        Divergence sonucuna gÃ¶re sinyal modifikasyonu dÃ¶ndÃ¼r.
        
        Returns:
            (score_modifier: int, reason: str)
        """
        # Son 5 dakika iÃ§indeki divergence'Ä± kullan
        if self.last_divergence and self.divergence_time > 0:
            age = datetime.now().timestamp() - self.divergence_time
            if age > 300:  # 5 dakikadan eski
                return 0, ""
            
            div_type = self.last_divergence.get('divergence_type')
            bonus = self.last_divergence.get('score_bonus', 0)
            
            # BULLISH divergence = LONG gÃ¼Ã§lenir
            if div_type == 'BULLISH' and signal_side == 'LONG':
                return bonus, f"SMT(BULL+{bonus}p)"
            
            # BEARISH divergence = SHORT gÃ¼Ã§lenir
            if div_type == 'BEARISH' and signal_side == 'SHORT':
                return bonus, f"SMT(BEAR+{bonus}p)"
            
            # Ters yÃ¶nde = ceza
            if div_type == 'BULLISH' and signal_side == 'SHORT':
                return -10, "SMT(BULL-10p)"
            
            if div_type == 'BEARISH' and signal_side == 'LONG':
                return -10, "SMT(BEAR-10p)"
        
        return 0, ""


# Global SMT Divergence Detector instance
smt_divergence_detector = SMTDivergenceDetector(lookback=20)


# ============================================================================
# PHASE 31: MULTI-COIN SCANNER
# ============================================================================

class CoinOpportunity:
    """Data class for coin opportunity information."""
    def __init__(self, symbol: str):
        self.symbol = symbol
        self.price: float = 0.0
        self.signal_score: int = 0
        self.signal_action: str = "NONE"  # LONG/SHORT/NONE
        self.zscore: float = 0.0
        self.hurst: float = 0.5
        self.spread_pct: float = 0.0  # ATR-based volatility % (legacy)
        self.bid_ask_spread_pct: float = 0.0  # Real bid-ask spread % (0 = not yet received)
        self.has_real_spread: bool = False
        self.imbalance: float = 0.0
        self.volume_24h: float = 0.0
        self.price_change_24h: float = 0.0
        self.last_signal_time: Optional[float] = None
        self.atr: float = 0.0
        self.last_update: float = 0.0
        self.leverage: int = 10  # Default leverage, updated by SignalGenerator
        self.pullback_pct: float = 0.0  # Pullback percentage for signal
        self.dynamic_trail_activation: float = 1.5  # Per-coin dynamic trail activation (ATR multiple)
        self.dynamic_trail_distance: float = 1.0  # Per-coin dynamic trail distance (ATR multiple)
        # Phase EQG + FIB: UI observability fields
        self.volume_ratio: float = 0.0
        self.is_volume_spike: bool = False
        self.ob_imbalance_trend: float = 0.0
        self.entry_quality_pass: bool = False
        self.entry_quality_reasons: list = []
        self.fib_active: bool = False
        self.fib_level: Optional[str] = None
        self.fib_bonus: int = 0
        self.fib_entry: float = 0.0
        self.fib_blend_alpha: float = 0.0
        self.entry_price: float = 0.0  # Backend ideal_entry price
        self.trail_entry_min_move_pct: float = 0.0
        self.trail_entry_min_roi_pct: float = 0.0
        self.entry_threshold_mult: float = 1.0
        self.entry_exec_score: float = 0.0
        self.entry_exec_passed: bool = True
        self.strategy_mode: str = STRATEGY_MODE_LEGACY
        self.active_strategy: str = "legacy"
        self.strategy_label: str = "Legacy"
        self.execution_reject_reason: Optional[str] = None
        self.execution_reject_ts: int = 0
        # Phase 239V2: Pullback + recheck telemetry
        self.pullback_dyn_base: float = 0.0
        self.pullback_dyn_final: float = 0.0
        self.pullback_dyn_floor: float = 0.0
        self.pullback_dyn_regime_band: str = 'neutral'
        self.pullback_model_version: str = 'v2'
        self.recheck_score: float = 0.0
        self.recheck_decision: str = ''
        self.recheck_reasons: list = []
    
    def to_dict(self) -> dict:
        return {
            "symbol": self.symbol,
            "price": self.price,
            "signalScore": self.signal_score,
            "signalAction": self.signal_action,
            "zscore": round(self.zscore, 2),
            "hurst": round(self.hurst, 2),
            "spreadPct": round(self.bid_ask_spread_pct, 4),  # Real bid-ask spread from WebSocket
            "hasRealSpread": bool(self.has_real_spread),  # True when real bid/ask data received
            "volatilityPct": round(self.spread_pct, 4),  # ATR-based volatility
            "imbalance": round(self.imbalance, 2),
            "volume24h": self.volume_24h,
            "priceChange24h": round(self.price_change_24h, 2),
            "lastSignalTime": self.last_signal_time,
            "atr": self.atr,
            "lastUpdate": self.last_update,
            "leverage": self.leverage,
            "pullbackPct": round(self.pullback_pct, 2),
            "dynamic_trail_activation": round(float(self.dynamic_trail_activation), 3),
            "dynamic_trail_distance": round(float(self.dynamic_trail_distance), 3),
            # Phase EQG + FIB: UI observability
            "volumeRatio": round(float(self.volume_ratio), 2),
            "isVolumeSpike": bool(self.is_volume_spike),
            "obImbalanceTrend": round(float(self.ob_imbalance_trend), 1),
            "entryQualityPass": bool(self.entry_quality_pass),
            "entryQualityReasons": list(self.entry_quality_reasons) if self.entry_quality_reasons else [],
            "fibActive": bool(self.fib_active),
            "fibLevel": self.fib_level,
            "fibBonus": int(self.fib_bonus),
            "fibEntry": round(float(self.fib_entry), 8) if self.fib_entry else 0,
                "fibBlendAlpha": float(self.fib_blend_alpha),
                "entryPriceBackend": round(float(self.entry_price), 8) if self.entry_price else 0,
                "trailEntryMinMovePct": round(float(self.trail_entry_min_move_pct), 3),
                "trailEntryMinRoiPct": round(float(self.trail_entry_min_roi_pct), 2),
                "entryThresholdMult": round(float(self.entry_threshold_mult), 3),
                "entryExecScore": round(float(self.entry_exec_score), 2),
                "entryExecPassed": bool(self.entry_exec_passed),
                "strategyMode": self.strategy_mode,
                "activeStrategy": self.active_strategy,
                "strategyLabel": self.strategy_label,
                "executionRejectReason": self.execution_reject_reason,
                "executionRejectTs": int(self.execution_reject_ts or 0),
                # Phase 239V2: Pullback + recheck telemetry
                "pullbackDynBase": round(float(self.pullback_dyn_base), 4),
                "pullbackDynFinal": round(float(self.pullback_dyn_final), 4),
                "pullbackDynFloor": round(float(self.pullback_dyn_floor), 4),
                "pullbackDynRegimeBand": str(self.pullback_dyn_regime_band),
                "pullbackModelVersion": str(self.pullback_model_version),
                "recheckScore": round(float(self.recheck_score), 1),
                "recheckDecision": str(self.recheck_decision),
                "recheckReasons": list(self.recheck_reasons) if self.recheck_reasons else [],
            }


class LightweightCoinAnalyzer:
    """Lightweight analyzer for a single coin in multi-coin scanning."""
    
    def __init__(self, symbol: str):
        self.symbol = symbol
        self.ccxt_symbol = symbol.replace("USDT", "/USDT")
        self.prices: deque = deque(maxlen=200)
        self.highs: deque = deque(maxlen=200)
        self.lows: deque = deque(maxlen=200)
        self.closes: deque = deque(maxlen=200)
        self.volumes: deque = deque(maxlen=200)
        self.spreads: deque = deque(maxlen=100)
        self.opportunity = CoinOpportunity(symbol)
        self.signal_generator = SignalGenerator()
        self.signal_generator.min_signal_interval = 60  # 1 minute per coin in multi-scan mode
        self.is_preloaded = False  # Track if historical data is loaded
        
        # VWAP calculation variables
        self.vwap_numerator: float = 0.0
        self.vwap_denominator: float = 0.0
        self.vwap: float = 0.0
        
        # Coin-specific statistics for dynamic thresholds
        self.rsi_history: deque = deque(maxlen=100)  # Son 100 RSI deÄŸeri
        self.volume_ratio_history: deque = deque(maxlen=100)  # Son 100 volume ratio
        self.hurst_history: deque = deque(maxlen=100)  # Son 100 Hurst deÄŸeri
        
        # Phase 156: Order book imbalance trend tracking
        self.imbalance_history: deque = deque(maxlen=100)  # Son ~5 dk imbalance kaydÄ±
        
        # Phase 178: Tick aggregation for proper candle-like high/low/volume
        self._tick_high: float = 0.0
        self._tick_low: float = float('inf')
        self._tick_volume: float = 0.0
        self._tick_count: int = 0
        self._last_candle_time: float = 0.0
        self._candle_interval: int = 300  # 5-minute candles (matches preload)
    
    def get_coin_stats(self) -> dict:
        """
        Coin'e Ã¶zgÃ¼ istatistikleri dÃ¶ndÃ¼r.
        Bu deÄŸerler konfirmasyon eÅŸiklerini dinamik olarak ayarlamak iÃ§in kullanÄ±lÄ±r.
        """
        stats = {
            'rsi_avg': 50.0,
            'rsi_std': 10.0,
            'volume_avg': 1.0,
            'volume_std': 0.5,
            'hurst_avg': 0.5,
            'hurst_std': 0.1,
            'sample_count': 0
        }
        
        if len(self.rsi_history) >= 10:
            rsi_arr = np.array(self.rsi_history)
            stats['rsi_avg'] = float(np.mean(rsi_arr))
            stats['rsi_std'] = float(np.std(rsi_arr))
        
        if len(self.volume_ratio_history) >= 10:
            vol_arr = np.array(self.volume_ratio_history)
            stats['volume_avg'] = float(np.mean(vol_arr))
            stats['volume_std'] = float(np.std(vol_arr))
        
        if len(self.hurst_history) >= 10:
            hurst_arr = np.array(self.hurst_history)
            stats['hurst_avg'] = float(np.mean(hurst_arr))
            stats['hurst_std'] = float(np.std(hurst_arr))
        
        stats['sample_count'] = min(len(self.rsi_history), len(self.volume_ratio_history), len(self.hurst_history))
        
        return stats
    
    def _get_imbalance_trend(self) -> float:
        """
        Phase 156: Son ~5 dk bid/ask imbalance trendi.
        Recent avg - Old avg = trend direction.
        > 0 â†’ alÄ±cÄ± baskÄ±sÄ± artÄ±yor (LONG'a bonus)
        < 0 â†’ satÄ±cÄ± baskÄ±sÄ± artÄ±yor (SHORT'a bonus)
        """
        if len(self.imbalance_history) < 20:
            return 0.0
        
        imb_list = list(self.imbalance_history)
        recent = imb_list[-10:]  # Son 10 tick
        older = imb_list[-30:-10] if len(imb_list) >= 30 else imb_list[:-10]
        
        if not older:
            return 0.0
        
        recent_avg = sum(recent) / len(recent)
        older_avg = sum(older) / len(older)
        
        return recent_avg - older_avg
    
    def get_daily_trend(self) -> tuple:
        """
        Coin'in kendi gÃ¼nlÃ¼k trendini hesapla.
        Mevcut closes verisinden son ~24 saat deÄŸiÅŸimini hesaplar.
        
        Returns:
            (trend: str, change_pct: float)
            trend: "STRONG_BULLISH", "BULLISH", "NEUTRAL", "BEARISH", "STRONG_BEARISH"
        """
        # 5 dakikalÄ±k mum kullanÄ±yorsak, 24 saat = ~288 mum
        # Ama muhtemelen daha az verimiz var, mevcut en eski veriden hesapla
        if len(self.closes) < 50:  # En az 50 bar (~4 saat 5m mumlarla)
            return "NEUTRAL", 0.0
        
        try:
            closes_list = list(self.closes)
            current = closes_list[-1]
            
            # Son 100 bar'Ä±n baÅŸÄ±ndan karÅŸÄ±laÅŸtÄ±r (yoksa en eski bar)
            lookback = min(100, len(closes_list) - 1)
            past_price = closes_list[-lookback]
            
            if past_price <= 0:
                return "NEUTRAL", 0.0
            
            change_pct = ((current - past_price) / past_price) * 100
            
            # Trend belirleme
            if change_pct > 5.0:
                return "STRONG_BULLISH", change_pct
            elif change_pct > 2.0:
                return "BULLISH", change_pct
            elif change_pct < -5.0:
                return "STRONG_BEARISH", change_pct
            elif change_pct < -2.0:
                return "BEARISH", change_pct
            else:
                return "NEUTRAL", change_pct
                
        except Exception as e:
            logger.warning(f"Daily trend calculation error for {self.symbol}: {e}")
            return "NEUTRAL", 0.0
    
    def calculate_volatility(self) -> tuple:
        """
        Close-to-close volatilite hesapla.
        Log return standard deviation kullanarak gerÃ§ek zamanlÄ± volatilite Ã¶lÃ§Ã¼mÃ¼.
        
        Returns:
            (volatility_pct: float, trail_multiplier: float)
            - volatility_pct: YÄ±llÄ±k volatilite yÃ¼zdesi (0-200+)
            - trail_multiplier: Trail distance Ã§arpanÄ± (0.6 - 2.0)
        """
        MIN_BARS = 20  # En az 20 bar gerekli
        
        if len(self.closes) < MIN_BARS:
            return 2.0, 1.0  # Yeterli veri yoksa varsayÄ±lan
        
        try:
            closes = list(self.closes)
            
            # Log returns hesapla: ln(close[i] / close[i-1])
            log_returns = []
            for i in range(1, len(closes)):
                if closes[i-1] > 0 and closes[i] > 0:
                    log_return = np.log(closes[i] / closes[i-1])
                    log_returns.append(log_return)
            
            if len(log_returns) < MIN_BARS - 1:
                return 2.0, 1.0
            
            # Volatilite = std(log_returns) * sqrt(bars_per_year)
            # 5 dakika mum â†’ 288 bar/gÃ¼n â†’ 105,120 bar/yÄ±l
            std_return = np.std(log_returns)
            annualized_vol = std_return * np.sqrt(105120) * 100  # YÃ¼zde olarak
            
            # GÃ¼nlÃ¼k volatilite (daha pratik)
            daily_vol = std_return * np.sqrt(288) * 100  # % olarak
            
            # Trail Ã§arpanÄ± hesapla
            # DÃ¼ÅŸÃ¼k volatilite (<%2 gÃ¼nlÃ¼k) = sÄ±kÄ± trail (0.6x)
            # YÃ¼ksek volatilite (>%8 gÃ¼nlÃ¼k) = geniÅŸ trail (2.0x)
            if daily_vol < 1.5:
                trail_mult = 0.6   # BTC/ETH seviyesi - Ã§ok sÄ±kÄ±
            elif daily_vol < 3.0:
                trail_mult = 0.8   # Major altcoin
            elif daily_vol < 5.0:
                trail_mult = 1.0   # Normal
            elif daily_vol < 8.0:
                trail_mult = 1.4   # Volatil
            else:
                trail_mult = 2.0   # Meme coin - Ã§ok geniÅŸ
            
            return daily_vol, trail_mult
            
        except Exception as e:
            logger.warning(f"Volatility calculation error for {self.symbol}: {e}")
            return 2.0, 1.0
    
    def preload_historical_data(self, ohlcv_data: list):
        """
        Preload historical OHLCV data for immediate Z-Score/Hurst calculation.
        
        Args:
            ohlcv_data: List of OHLCV candles [[timestamp, open, high, low, close, volume], ...]
        """
        if not ohlcv_data or len(ohlcv_data) < 20:
            return
        
        # Clear existing data
        self.prices.clear()
        self.highs.clear()
        self.lows.clear()
        self.closes.clear()
        self.volumes.clear()
        self.spreads.clear()
        
        # Load historical data
        for candle in ohlcv_data:
            try:
                _, open_price, high, low, close, volume = candle
                self.prices.append(close)
                self.closes.append(close)
                self.highs.append(high)
                self.lows.append(low)
                self.volumes.append(volume)
            except Exception:
                continue
        
        # Phase 114: Calculate spreads RETROACTIVELY after all candles are loaded
        # This ensures we get 20+ spreads if we have 40+ candles
        closes_list = list(self.closes)
        for i in range(19, len(closes_list)):  # Start from index 19 (20th candle)
            ma = np.mean(closes_list[max(0, i-19):i+1])  # 20-period MA ending at position i
            spread = closes_list[i] - ma
            self.spreads.append(spread)
        
        if len(self.prices) > 0:
            self.opportunity.price = self.prices[-1]
            self.opportunity.last_update = datetime.now().timestamp()
            self.is_preloaded = True
            # Phase 205: Set initial candle close from preloaded data
            last_candle_close[self.symbol] = self.prices[-1]
            
            # Preload VWAP from historical data
            self.vwap_numerator = 0.0
            self.vwap_denominator = 0.0
            for i, candle in enumerate(ohlcv_data):
                try:
                    _, _, high, low, close, volume = candle
                    typical_price = (high + low + close) / 3
                    self.vwap_numerator += typical_price * volume
                    self.vwap_denominator += volume
                except:
                    continue
            if self.vwap_denominator > 0:
                self.vwap = self.vwap_numerator / self.vwap_denominator
            
            logger.info(f"ðŸ“Š {self.symbol}: Preloaded {len(self.prices)} candles, spreads={len(self.spreads)}")
        
    def update_price(self, price: float, high: float = None, low: float = None, volume: float = 0):
        """
        Update price data with tick aggregation for proper candle construction.
        
        Phase 178: Instead of appending 24H high/low from WS ticker every tick,
        accumulate ticks and create proper 5-minute candles with real per-candle
        high/low/volume data. This fixes ATR/ADX inflation.
        """
        now = datetime.now().timestamp()
        
        # Always update display price immediately
        self.opportunity.price = price
        self.opportunity.last_update = now
        
        # Track tick min/max/volume within current candle window
        self._tick_high = max(self._tick_high, price)
        if self._tick_low == float('inf'):
            self._tick_low = price
        else:
            self._tick_low = min(self._tick_low, price)
        self._tick_volume += volume
        self._tick_count += 1
        
        # Initialize candle timer on first call
        if self._last_candle_time == 0:
            self._last_candle_time = now
        
        # Close candle every _candle_interval seconds
        elapsed = now - self._last_candle_time
        if elapsed >= self._candle_interval and self._tick_count > 1:
            # Append completed candle data
            self.prices.append(price)
            self.closes.append(price)
            self.highs.append(self._tick_high)
            self.lows.append(self._tick_low)
            self.volumes.append(self._tick_volume)
            
            # Phase 205: Update global candle close price for exit decisions
            last_candle_close[self.symbol] = price
            
            # Update VWAP with proper candle data (Typical Price = (H+L+C)/3)
            typical_price = (self._tick_high + self._tick_low + price) / 3
            self.vwap_numerator += typical_price * self._tick_volume
            self.vwap_denominator += self._tick_volume
            if self.vwap_denominator > 0:
                self.vwap = self.vwap_numerator / self.vwap_denominator
            
            # Phase 115: Smart spreads calculation
            closes_len = len(self.closes)
            if closes_len >= 20:
                if closes_len >= 40 and len(self.spreads) < 20:
                    # Retroactively calculate all spreads
                    self.spreads.clear()
                    closes_list = list(self.closes)
                    for i in range(19, len(closes_list)):
                        ma = np.mean(closes_list[max(0, i-19):i+1])
                        spread = closes_list[i] - ma
                        self.spreads.append(spread)
                    logger.info(f"ðŸ“Š {self.symbol}: Retroactive spreads calculated - closes={closes_len}, spreads={len(self.spreads)}")
                else:
                    # Normal incremental spread calculation
                    ma = np.mean(list(self.closes)[-20:])
                    spread = price - ma
                    self.spreads.append(spread)
            
            # Reset tick accumulators for next candle
            self._tick_high = price
            self._tick_low = price
            self._tick_volume = 0.0
            self._tick_count = 0
            self._last_candle_time = now
    
    def analyze(self, imbalance: float = 0, basis_pct: float = 0.0) -> Optional[dict]:
        """Analyze coin and generate signal if conditions met."""
        # PHASE 103: Debug analyzer.analyze() calls
        if not hasattr(self, '_analyze_count'):
            self._analyze_count = 0
        self._analyze_count += 1
        if self._analyze_count % 500 == 1:
            logger.info(f"ðŸ” ANALYZE #{self._analyze_count}: {self.symbol} prices={len(self.prices)}")
        
        if len(self.prices) < 20:  # Reduced from 50 to 20 for faster startup
            return None
            
        prices_list = list(self.prices)
        highs_list = list(self.highs)
        lows_list = list(self.lows)
        closes_list = list(self.closes)
        
        # Calculate metrics
        # Phase 124: Adjust Hurst window for small samples (<50 candles)
        min_window = 5 if len(prices_list) < 50 else 10
        hurst = calculate_hurst(prices_list, min_window=min_window)
        
        # Phase 128: Log Hurst value for each coin (periodically to avoid spam)
        if self._analyze_count <= 5 or self._analyze_count % 100 == 0:
            logger.info(f"ðŸ“ˆ HURST: {self.symbol} H={hurst:.3f} (prices={len(prices_list)}, min_win={min_window})")
        
        # Phase 122: Calculate Z-Score - lowered threshold to 20 closes for faster activation
        closes_count = len(self.closes)
        if closes_count >= 20:
            # Phase 125: Start calculating spreads from index 9 (using 10-period MA initially)
            # This allows us to have ~11 spreads when we hit 20 closes, ensuring immediate Z-Score
            closes_list = list(self.closes)
            temp_spreads = []
            for i in range(9, len(closes_list)):
                ma = np.mean(closes_list[max(0, i-19):i+1])
                spread = closes_list[i] - ma
                temp_spreads.append(spread)
            
            # Phase 122: Lowered from 20 to 5 spreads for faster activation
            # With 25 closes we get 6 spreads (index 19-24), enough for Z-Score
            if len(temp_spreads) >= 5:
                # Phase 124: Pass explicit lookback to override default 20
                zscore = calculate_zscore(temp_spreads, lookback=len(temp_spreads))
            else:
                zscore = 0
        else:
            zscore = 0
            if hasattr(self, '_zscore_debug_count'):
                self._zscore_debug_count += 1
            else:
                self._zscore_debug_count = 0
            if self._zscore_debug_count % 100 == 0:
                logger.info(f"ðŸ“Š ZSCORE_DEBUG: {self.symbol} closes={closes_count}/40 needed")
        atr = calculate_atr(highs_list, lows_list, closes_list)
        
        # Phase 137: Calculate ADX for regime detection - now returns tuple with trend direction
        adx, adx_trend, plus_di, minus_di = calculate_adx(highs_list, lows_list, closes_list)
        
        # Phase 193: Calculate enhanced indicators (MACD, BB, StochRSI, EMA cross)
        enhanced_ind = calculate_enhanced_indicators(
            highs_list, lows_list, closes_list,
            volumes=list(self.volumes) if len(self.volumes) >= 30 else None
        )
        
        self.opportunity.hurst = hurst
        self.opportunity.zscore = zscore
        self.opportunity.atr = atr
        self.opportunity.adx = adx  # Phase 137: ADX for regime detection
        self.opportunity.adx_trend = adx_trend  # Trend direction: BULLISH/BEARISH/NEUTRAL
        self.opportunity.imbalance = imbalance
        
        # Phase 156: Record imbalance for short-term trend tracking
        self.imbalance_history.append(imbalance)
        
        # Phase 35: Calculate volatility as ATR percentage of price
        # This is the TRUE volatility measure - no artificial capping
        # BTC typically ~1.5%, SOL ~2.5%, DOGE ~4%, meme coins 5%+
        if atr > 0 and self.opportunity.price > 0:
            volatility_pct = (atr / self.opportunity.price) * 100
            self.opportunity.spread_pct = volatility_pct  # Store actual volatility %
        
        # Calculate VWAP Z-Score for Layer 3 scoring
        vwap_zscore = 0.0
        if self.vwap > 0 and len(prices_list) >= 20:
            price_std = np.std(prices_list[-20:])
            if price_std > 0:
                vwap_zscore = (self.opportunity.price - self.vwap) / price_std
        
        # Get HTF trend from global BTC filter for Layer 4 scoring
        htf_trend = "NEUTRAL"
        try:
            if 'btc_filter' in globals() and btc_filter is not None:
                htf_trend = btc_filter.btc_trend or "NEUTRAL"
        except:
            pass
        
        # Calculate RSI for Layer 10 scoring
        rsi_value = 50.0  # Default neutral
        if len(prices_list) >= 15:
            rsi_value = calculate_rsi(prices_list, period=14)
        
        # Calculate Volume Ratio for Layer 11 scoring
        # Phase XXX: Re-enabled volume spike detection for breakout warning
        volume_ratio = 1.0
        is_volume_spike = False
        if len(self.volumes) >= 21:
            is_volume_spike, volume_ratio = detect_volume_spike(list(self.volumes), lookback=20, threshold=2.0)
        
        # Update coin-specific statistics for dynamic thresholds
        self.rsi_history.append(rsi_value)
        self.volume_ratio_history.append(volume_ratio)
        self.hurst_history.append(hurst)
        
        # Get coin stats for dynamic threshold calculation
        coin_stats = self.get_coin_stats()
        
        # Detect Liquidity Sweep / SFP for Layer 13
        sweep_result = None
        if len(self.highs) >= 22 and len(self.lows) >= 22:
            sweep_result = liquidity_sweep_detector.detect_sweep(
                list(self.highs), list(self.lows), prices_list
            )
        # Get coin's own daily trend (not BTC's)
        coin_daily_trend, coin_daily_change = self.get_daily_trend()
        
        # Phase 177: Use real bid-ask spread, conservative fallback (0.10%) if not yet received
        effective_spread = self.opportunity.bid_ask_spread_pct if self.opportunity.has_real_spread else 0.10
        
        # Fetch MTF trend data for SMC (Phase 208) and FIB (Phase FIB)
        trend_data = mtf_confirmation.coin_trends.get(self.symbol, {}) if 'mtf_confirmation' in globals() else {}
        
        # Phase FIB: Build Fibonacci context for Cloud Scanner (OHLCV already cached by update_coin_trend)
        cs_fib_context = None
        if FIB_ENABLED:
            try:
                if trend_data:
                    # Pre-determine signal side from z-score direction (not threshold)
                    # P2 fix: actual threshold is dynamic (effective_threshold), so just use direction
                    pre_side = 'LONG' if zscore < 0 else ('SHORT' if zscore > 0 else None)
                    if pre_side:
                        cs_fib_context = build_fib_context(
                            signal_side=pre_side,
                            price=self.opportunity.price,
                            atr=atr,
                            adx=adx,
                            hurst=hurst,
                            trend_data=trend_data,
                            sweep_result=sweep_result,
                        )
            except Exception as fib_err:
                logger.debug(f"FIB context error in scanner: {fib_err}")
        
        # Generate signal with VWAP, HTF trend, Basis, Whale, RSI, Volume, Sweep, CoinStats, DailyTrend, ADX
        signal = self.signal_generator.generate_signal(
            hurst=hurst,
            zscore=zscore,
            imbalance=imbalance,
            price=self.opportunity.price,
            atr=atr,
            spread_pct=effective_spread,
            vwap_zscore=vwap_zscore,
            htf_trend=htf_trend,
            basis_pct=basis_pct,
            symbol=self.symbol,  # For liquidation cascade lookup
            whale_zscore=whale_tracker.get_whale_zscore(self.symbol),  # Whale activity
            smc_data=trend_data.get('smc_1h'),  # Phase 208
            rsi=rsi_value,  # RSI for Layer 10
            volume_ratio=volume_ratio,  # Volume spike for Layer 11
            sweep_result=sweep_result,  # Liquidity Sweep for Layer 13
            coin_stats=coin_stats,  # Coin-specific statistics for dynamic thresholds
            coin_daily_trend=coin_daily_trend,  # Coin's own daily trend (not BTC's)
            volume_24h=self.opportunity.volume_24h,  # Phase 123: Pass 24h volume
            adx=adx,  # ADX value for trend strength
            adx_trend=adx_trend,  # Trend direction: BULLISH/BEARISH/NEUTRAL
            is_volume_spike=is_volume_spike,  # Volume breakout detection
            market_regime=market_regime_detector.current_regime if 'market_regime_detector' in globals() else 'RANGING',
            ob_imbalance_trend=self._get_imbalance_trend(),  # Phase 156: Short-term OB flow
            funding_rate=funding_oi_tracker.funding_rates.get(self.symbol, 0.0),  # Phase 157
            coin_wr_penalty=trade_pattern_analyzer.get_coin_penalty(self.symbol),  # Phase 157
            side_wr_penalty=0,  # Phase 157: calculated inside generate_signal where signal_side is known
            enhanced_indicators=enhanced_ind,  # Phase 193: MACD, BB, StochRSI, EMA cross
            fib_context=cs_fib_context,  # Phase FIB: Fibonacci context
        )
        
        if signal:
            self.opportunity.signal_score = signal.get('confidenceScore', 0)
            self.opportunity.signal_action = signal.get('action', 'NONE')
            self.opportunity.leverage = signal.get('leverage', 10)
            self.opportunity.pullback_pct = signal.get('pullbackPct', 0)
            self.opportunity.dynamic_trail_activation = signal.get('dynamic_trail_activation', 1.5)
            self.opportunity.dynamic_trail_distance = signal.get('dynamic_trail_distance', 1.0)
            self.opportunity.last_signal_time = datetime.now().timestamp()
            # Phase EQG + FIB: Store observability fields
            self.opportunity.volume_ratio = signal.get('volumeRatio', 0)
            self.opportunity.is_volume_spike = signal.get('isVolumeSpike', False)
            self.opportunity.ob_imbalance_trend = signal.get('obImbalanceTrend', 0)
            self.opportunity.entry_quality_pass = signal.get('entryQualityPass', False)
            self.opportunity.entry_quality_reasons = signal.get('entryQualityReasons', [])
            self.opportunity.fib_active = signal.get('fibActive', False)
            self.opportunity.fib_level = signal.get('fibLevel')
            self.opportunity.fib_bonus = signal.get('fibBonus', 0)
            self.opportunity.fib_entry = signal.get('fibEntry', 0)
            self.opportunity.fib_blend_alpha = signal.get('fibBlendAlpha', 0)
            self.opportunity.entry_price = signal.get('entryPrice', 0) or signal.get('entry', 0)
            self.opportunity.trail_entry_min_move_pct = signal.get('trailEntryMinMovePct', 0)
            self.opportunity.trail_entry_min_roi_pct = signal.get('trailEntryMinRoiPct', 0)
            self.opportunity.entry_threshold_mult = signal.get('entryThresholdMult', 1.0)
            self.opportunity.entry_exec_score = signal.get('entryExecScore', signal.get('confidenceScore', 0))
            self.opportunity.entry_exec_passed = signal.get('entryExecPassed', True)
            self.opportunity.strategy_mode = signal.get('strategyMode', STRATEGY_MODE_LEGACY)
            self.opportunity.active_strategy = signal.get('activeStrategy', 'legacy')
            self.opportunity.strategy_label = signal.get('strategyLabel', 'Legacy')
            # Execution-stage reject reason (if any) for UI observability
            # Phase 239V2: Pullback + recheck telemetry
            self.opportunity.pullback_dyn_base = signal.get('pullbackDynBase', 0)
            self.opportunity.pullback_dyn_final = signal.get('pullbackDynFinal', 0)
            self.opportunity.pullback_dyn_floor = signal.get('pullbackDynFloor', 0)
            self.opportunity.pullback_dyn_regime_band = signal.get('pullbackDynRegimeBand', 'neutral')
            self.opportunity.pullback_model_version = signal.get('pullbackModelVersion', 'v2')
            self.opportunity.recheck_score = signal.get('recheckScore', 0)
            self.opportunity.recheck_decision = signal.get('recheckDecision', '')
            self.opportunity.recheck_reasons = signal.get('recheckReasons', [])
            try:
                if 'global_paper_trader' in globals():
                    feedback = global_paper_trader.get_execution_feedback(self.symbol)
                    if feedback:
                        self.opportunity.execution_reject_reason = feedback.get('reason')
                        self.opportunity.execution_reject_ts = int(feedback.get('ts', 0) or 0)
                    else:
                        self.opportunity.execution_reject_reason = None
                        self.opportunity.execution_reject_ts = 0
            except Exception:
                self.opportunity.execution_reject_reason = None
                self.opportunity.execution_reject_ts = 0
            return signal
        else:
            # Decay signal score over time if no new signal
            if self.opportunity.last_signal_time:
                elapsed = datetime.now().timestamp() - self.opportunity.last_signal_time
                if elapsed > 300:  # 5 minutes
                    self.opportunity.signal_score = 0
                    self.opportunity.signal_action = "NONE"
            
        return None


class BinanceWebSocketManager:
    """
    Binance Futures WebSocket Manager for real-time ticker data.
    Uses !ticker@arr stream for all market tickers.
    """
    
    def __init__(self):
        self.ws = None
        self.tickers: Dict[str, dict] = {}
        self.running = False
        self.connected = False
        self.last_update = 0
        self.ws_url = "wss://fstream.binance.com/ws/!ticker@arr"  # Phase 228: bookTicker via REST instead
        self._reconnect_task = None
        # Phase 191: Callback pattern for real-time position updates
        self.position_symbols: set = set()  # Aktif pozisyonlu semboller
        self.on_price_update = None  # async callback(symbol, ticker_data)
        self._pending_updates: list = []  # Bekleyen callback Ã§aÄŸrÄ±larÄ±
        logger.info("BinanceWebSocketManager initialized (Phase 191: callback support)")
    
    async def connect(self):
        """Connect to Binance Futures WebSocket."""
        import websockets
        
        while self.running:
            try:
                logger.info(f"Connecting to Binance WebSocket: {self.ws_url}")
                async with websockets.connect(self.ws_url, ping_interval=20, ping_timeout=10) as ws:
                    self.ws = ws
                    self.connected = True
                    logger.info("Connected to Binance WebSocket")
                    
                    async for message in ws:
                        if not self.running:
                            break
                        
                        try:
                            data = json.loads(message)
                            if isinstance(data, list):
                                self._process_ticker_message(data)
                            
                            # Phase 191: Process pending position price updates
                            if self._pending_updates:
                                updates = self._pending_updates.copy()
                                self._pending_updates.clear()
                                for sym, tick in updates:
                                    try:
                                        await self.on_price_update(sym, tick)
                                    except Exception as cb_err:
                                        logger.debug(f"WS callback error {sym}: {cb_err}")
                        except json.JSONDecodeError:
                            continue
                            
            except Exception as e:
                logger.error(f"Binance WebSocket error: {e}")
                self.connected = False
                if self.running:
                    await asyncio.sleep(5)  # Reconnect after 5 seconds
    
    def _process_ticker_message(self, data: list):
        """Process ticker array message from Binance."""
        if not isinstance(data, list):
            return
            
        for ticker in data:
            symbol = ticker.get('s', '')  # Symbol
            if not symbol.endswith('USDT'):
                continue
                
            # Calculate simple imbalance from bid/ask quantities (may be 0 for futures ticker)
            bid_qty = float(ticker.get('B', 0))  # Best bid quantity
            ask_qty = float(ticker.get('A', 0))  # Best ask quantity
            
            # Preserve existing bid/ask from bookTicker (futures ticker@arr doesn't have b/a)
            existing = self.tickers.get(symbol, {})
            raw_base_volume = float(ticker.get('v', 0) or 0)  # 24h cumulative base volume
            prev_raw_base_volume = float(existing.get('_baseVolumeRaw', raw_base_volume) or raw_base_volume)
            volume_delta = raw_base_volume - prev_raw_base_volume
            if symbol not in self.tickers:
                # Ä°lk pakette delta gÃ¼venilir deÄŸil; nÃ¶tr baÅŸlat
                volume_delta = 0.0
            elif volume_delta < 0:
                # Binance 24h window reset olabilir
                volume_delta = raw_base_volume
            
            self.tickers[symbol] = {
                'last': float(ticker.get('c', 0)),  # Close price
                'percentage': float(ticker.get('P', 0)),  # Price change percent
                'quoteVolume': float(ticker.get('q', 0)),  # Quote volume (USDT)
                'baseVolume': raw_base_volume,  # 24h cumulative base asset volume
                'volumeDelta': max(0.0, float(volume_delta)),  # Incremental volume since previous WS update
                'high': float(ticker.get('h', 0)),  # High
                'low': float(ticker.get('l', 0)),  # Low
                'bid': existing.get('bid', 0),  # Preserved from bookTicker
                'ask': existing.get('ask', 0),  # Preserved from bookTicker
                'bidQty': existing.get('bidQty', bid_qty),  # Preserved from bookTicker
                'askQty': existing.get('askQty', ask_qty),  # Preserved from bookTicker
                'imbalance': existing.get('imbalance', 0),  # Preserved from bookTicker
                'timestamp': int(ticker.get('E', 0)),  # Event time
                '_baseVolumeRaw': raw_base_volume,  # Internal state for delta calc
            }
        
        # Phase 178: SMT Divergence moved to update_btc_eth_state() for candle-based data
        # Using 24H high/low from ticker gave false swing high/low detection
        
        self.last_update = datetime.now().timestamp()
        
        # Phase 191: Queue position price callbacks for async processing
        if self.on_price_update and self.position_symbols:
            for ticker in data:
                sym = ticker.get('s', '')
                if sym in self.position_symbols:
                    self._pending_updates.append((sym, self.tickers[sym]))

    # Phase 228: _process_book_ticker removed â€” using REST API instead (see CloudScanner.fetch_book_tickers)
    
    def get_tickers(self, symbols: list = None) -> dict:
        """Get current ticker data for specified symbols."""
        if symbols is None:
            return self.tickers
        
        return {s: self.tickers[s] for s in symbols if s in self.tickers}
    
    async def start(self):
        """Start WebSocket connection."""
        self.running = True
        asyncio.create_task(self.connect())
    
    async def stop(self):
        """Stop WebSocket connection."""
        self.running = False
        self.connected = False
        if self.ws:
            await self.ws.close()


# Global WebSocket manager
binance_ws_manager = BinanceWebSocketManager()


# ============================================================================
# LIQUIDATION CASCADE TRACKER
# ============================================================================

class LiquidationTracker:
    """
    Tracks real-time liquidations from Binance Futures.
    Detects cascade events (>$100K in 30 seconds) for signal scoring.
    
    WebSocket: wss://fstream.binance.com/ws/!forceOrder@arr
    """
    
    def __init__(self):
        self.ws = None
        self.running = False
        self.connected = False
        # symbol -> list of {timestamp, side, qty_usd}
        self.recent_liquidations: Dict[str, list] = {}
        self.cascade_threshold = 100000  # $100K threshold
        self.cascade_window = 30  # 30 seconds window
        self.total_liquidations = 0
        logger.info("ðŸ’€ LiquidationTracker initialized")
    
    async def connect(self):
        """Connect to Binance Liquidation WebSocket stream."""
        try:
            url = "wss://fstream.binance.com/ws/!forceOrder@arr"
            self.ws = await websockets.connect(url, ping_interval=180, ping_timeout=30)
            self.connected = True
            self.running = True
            logger.info("âœ… Liquidation WebSocket connected")
            
            asyncio.create_task(self._listen())
            
        except Exception as e:
            logger.error(f"Liquidation WebSocket connection failed: {e}")
            self.connected = False
    
    async def _listen(self):
        """Listen for liquidation events."""
        while self.running and self.ws:
            try:
                msg = await asyncio.wait_for(self.ws.recv(), timeout=60)
                data = json.loads(msg)
                await self._process_liquidation(data)
            except asyncio.TimeoutError:
                continue
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Liquidation WebSocket disconnected")
                self.connected = False
                break
            except Exception as e:
                logger.debug(f"Liquidation stream error: {e}")
    
    async def _process_liquidation(self, data: dict):
        """Process a liquidation event."""
        try:
            # Format: {"e":"forceOrder","E":timestamp,"o":{order details}}
            if data.get('e') != 'forceOrder':
                return
            
            order = data.get('o', {})
            symbol = order.get('s', '')  # e.g., "BTCUSDT"
            side = order.get('S', '')  # "BUY" or "SELL"
            qty = float(order.get('q', 0))  # Original quantity
            price = float(order.get('p', 0))  # Price
            
            usd_value = qty * price
            now = datetime.now().timestamp()
            
            # Store liquidation
            if symbol not in self.recent_liquidations:
                self.recent_liquidations[symbol] = []
            
            self.recent_liquidations[symbol].append({
                'timestamp': now,
                'side': side,
                'usd': usd_value
            })
            
            self.total_liquidations += 1
            
            # Cleanup old entries (keep last 60 seconds)
            cutoff = now - 60
            for sym in list(self.recent_liquidations.keys()):
                self.recent_liquidations[sym] = [
                    l for l in self.recent_liquidations[sym] 
                    if l['timestamp'] > cutoff
                ]
                if not self.recent_liquidations[sym]:
                    del self.recent_liquidations[sym]
            
            # Log significant liquidations
            if usd_value > 50000:
                logger.info(f"ðŸ’€ LIQD: {symbol} {side} ${usd_value:,.0f}")
                
        except Exception as e:
            logger.debug(f"Liquidation processing error: {e}")
    
    def get_cascade_score(self, symbol: str, signal_side: str) -> tuple:
        """
        Calculate cascade score for a symbol.
        
        Returns: (score, reason)
        - Score: 0-15 points
        - Reason: Description for logging
        """
        now = datetime.now().timestamp()
        cutoff = now - self.cascade_window
        
        if symbol not in self.recent_liquidations:
            return 0, ""
        
        # Calculate total liquidation value in window
        longs_liq = 0  # BUY = closing a short (short squeezed)
        shorts_liq = 0  # SELL = closing a long (long liquidated)
        
        for liq in self.recent_liquidations[symbol]:
            if liq['timestamp'] > cutoff:
                if liq['side'] == 'BUY':
                    longs_liq += liq['usd']
                else:
                    shorts_liq += liq['usd']
        
        # Logic:
        # If LONG signal and lots of shorts being liquidated (BUY orders) = bullish cascade
        # If SHORT signal and lots of longs being liquidated (SELL orders) = bearish cascade
        
        if signal_side == "LONG" and longs_liq > self.cascade_threshold:
            # Short squeeze happening - bullish
            return 15, f"LIQD(short-squeeze ${longs_liq:,.0f})"
        elif signal_side == "SHORT" and shorts_liq > self.cascade_threshold:
            # Long liquidation cascade - bearish
            return 15, f"LIQD(long-cascade ${shorts_liq:,.0f})"
        
        # Partial points for smaller cascades
        relevant_liq = longs_liq if signal_side == "LONG" else shorts_liq
        if relevant_liq > 50000:
            return 10, f"LIQD(${relevant_liq:,.0f})"
        elif relevant_liq > 20000:
            return 5, f"LIQD(${relevant_liq:,.0f})"
        
        return 0, ""
    
    def get_stats(self) -> dict:
        """Get tracker statistics."""
        return {
            "connected": self.connected,
            "total_tracked": self.total_liquidations,
            "active_symbols": len(self.recent_liquidations)
        }
    
    async def start(self):
        """Start the liquidation tracker."""
        await self.connect()
    
    async def stop(self):
        """Stop the liquidation tracker."""
        self.running = False
        self.connected = False
        if self.ws:
            await self.ws.close()


# Global Liquidation Tracker
liquidation_tracker = LiquidationTracker()


# ============================================================================
# WHALE ACTIVITY TRACKER
# ============================================================================

class WhaleTracker:
    """
    Tracks large trade activity (whale movements) per symbol.
    
    Uses volume spikes to detect whale activity:
    - Tracks volume over rolling windows
    - Calculates Z-score of recent volume vs average
    - Positive Z-score = high buying volume (bullish whale)
    - Negative Z-score = high selling volume (bearish whale)
    """
    
    def __init__(self):
        # symbol -> {volumes: deque, buy_volumes: deque, sell_volumes: deque, last_price: float}
        self.symbol_data: Dict[str, dict] = {}
        self.volume_window = 20  # Rolling window for Z-score
        self.whale_threshold_usd = 50000  # $50K+ trade = whale
        logger.info("ðŸ‹ WhaleTracker initialized")
    
    def update(self, symbol: str, price: float, volume: float, price_change_pct: float):
        """
        Update whale tracking with new ticker data.
        
        Args:
            symbol: Trading symbol (e.g., "BTCUSDT")
            price: Current price
            volume: Recent volume in base currency
            price_change_pct: Recent price change percentage
        """
        if symbol not in self.symbol_data:
            self.symbol_data[symbol] = {
                'volumes': deque(maxlen=self.volume_window),
                'volume_changes': deque(maxlen=self.volume_window),
                'last_volume': 0,
                'last_update': 0
            }
        
        data = self.symbol_data[symbol]
        now = datetime.now().timestamp()
        
        # Skip if updated too recently (< 1 second)
        if now - data.get('last_update', 0) < 1:
            return
        
        volume_usd = volume * price
        
        # Track volume change with direction from price change
        # Positive price change + high volume = whale buying
        # Negative price change + high volume = whale selling
        if data['last_volume'] > 0 and volume_usd > self.whale_threshold_usd:
            volume_delta = volume_usd - data['last_volume']
            # Sign volume delta by price direction
            if price_change_pct > 0:
                data['volume_changes'].append(volume_delta)  # Positive = buy pressure
            else:
                data['volume_changes'].append(-abs(volume_delta))  # Negative = sell pressure
        
        data['volumes'].append(volume_usd)
        data['last_volume'] = volume_usd
        data['last_update'] = now
    
    def get_whale_zscore(self, symbol: str) -> float:
        """
        Calculate whale Z-score for a symbol.
        
        Returns:
            Z-score: positive = whale buying, negative = whale selling
        """
        if symbol not in self.symbol_data:
            return 0.0
        
        data = self.symbol_data[symbol]
        changes = list(data.get('volume_changes', []))
        
        if len(changes) < 5:
            return 0.0
        
        # Calculate Z-score of recent volume changes
        mean = sum(changes) / len(changes)
        if len(changes) < 2:
            return 0.0
        
        variance = sum((x - mean) ** 2 for x in changes) / len(changes)
        std = variance ** 0.5
        
        if std < 1:
            return 0.0
        
        # Get most recent values (last 3)
        recent = changes[-3:]
        recent_mean = sum(recent) / len(recent)
        
        zscore = (recent_mean - mean) / std
        return round(max(-5, min(5, zscore)), 2)  # Clamp to [-5, 5]
    
    def get_stats(self) -> dict:
        """Get tracker statistics."""
        return {
            "tracked_symbols": len(self.symbol_data),
            "active_whales": sum(
                1 for s in self.symbol_data.values() 
                if len(s.get('volume_changes', [])) > 5
            )
        }


# Global Whale Tracker
whale_tracker = WhaleTracker()


# ============================================================================
# PHASE 157: FUNDING RATE + OPEN INTEREST TRACKER
# Binance premiumIndex API'den funding rate Ã§eker, sinyal skorlamasÄ±nda kullanÄ±r.
# ============================================================================

class FundingOITracker:
    """
    Phase 157: Funding Rate + Open Interest tracker.
    
    Funding Rate:
    - Pozitif (+) = Ã§oÄŸunluk LONG â†’ SHORT sinyali gÃ¼Ã§lenir (contrarian)
    - Negatif (-) = Ã§oÄŸunluk SHORT â†’ LONG sinyali gÃ¼Ã§lenir (contrarian)
    - Extreme (>0.08% veya <-0.08%) = kalabalÄ±kla aynÄ± yÃ¶ne sinyal VETOlanÄ±r
    
    5 dk cache â€” her Ã§aÄŸrÄ±da API'ye gitmez.
    """
    
    def __init__(self):
        self.funding_rates: Dict[str, float] = {}  # symbol -> funding rate
        self.last_fetch_time: float = 0
        self.fetch_interval: float = 300  # 5 dakika
        self.fetch_count: int = 0
        self.last_error: str = ""
        logger.info("ðŸ’° FundingOITracker initialized (Phase 157)")
    
    async def fetch_funding_rates(self, exchange) -> bool:
        """TÃ¼m coinlerin funding rate'ini tek API Ã§aÄŸrÄ±sÄ±yla Ã§ek."""
        now = datetime.now().timestamp()
        if now - self.last_fetch_time < self.fetch_interval:
            return True  # Cache hala geÃ§erli
        
        try:
            # Binance premiumIndex â€” tek Ã§aÄŸrÄ±da tÃ¼m coinler
            response = await exchange.fetch(
                'https://fapi.binance.com/fapi/v1/premiumIndex'
            )
            
            if isinstance(response, list):
                for item in response:
                    symbol = item.get('symbol', '')
                    if symbol.endswith('USDT'):
                        rate = float(item.get('lastFundingRate', 0))
                        self.funding_rates[symbol] = rate
                
                self.last_fetch_time = now
                self.fetch_count += 1
                self.last_error = ""
                
                if self.fetch_count <= 3 or self.fetch_count % 20 == 0:
                    # Sample: BTC funding
                    btc_rate = self.funding_rates.get('BTCUSDT', 0)
                    logger.info(f"ðŸ’° Funding rates updated: {len(self.funding_rates)} coins | BTC={btc_rate*100:.4f}% | fetch #{self.fetch_count}")
                
                return True
            
        except Exception as e:
            self.last_error = str(e)[:100]
            if self.fetch_count < 5:
                logger.warning(f"ðŸ’° Funding rate fetch error: {self.last_error}")
            return False
        
        return False
    
    def get_funding_signal(self, symbol: str, signal_side: str) -> tuple:
        """
        Funding rate'e gÃ¶re sinyal bonus/penalty/veto dÃ¶ndÃ¼r.
        
        Returns:
            (score_adjustment: int, reason: str, should_veto: bool)
        """
        rate = self.funding_rates.get(symbol, 0)
        
        if rate == 0:
            return (0, "", False)
        
        rate_pct = rate * 100  # YÃ¼zdeye Ã§evir
        abs_rate = abs(rate_pct)
        
        # EXTREME funding â€” kalabalÄ±kla aynÄ± yÃ¶nde sinyal VETOla
        if abs_rate > 0.08:
            if rate_pct > 0 and signal_side == "LONG":
                # Herkes LONG + biz de LONG = tehlikeli
                return (-15, f"FR_EXTREME(+{rate_pct:.3f}%)", True)
            elif rate_pct < 0 and signal_side == "SHORT":
                # Herkes SHORT + biz de SHORT = tehlikeli
                return (-15, f"FR_EXTREME({rate_pct:.3f}%)", True)
            elif rate_pct > 0 and signal_side == "SHORT":
                # Herkes LONG + biz SHORT = contrarian squeeze oynamasÄ±
                return (10, f"FR_SQUEEZE(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                # Herkes SHORT + biz LONG = contrarian squeeze oynamasÄ±
                return (10, f"FR_SQUEEZE({rate_pct:.3f}%)", False)
        
        # YÃ¼ksek funding â€” contrarian bonus
        if abs_rate > 0.03:
            if rate_pct > 0 and signal_side == "SHORT":
                return (8, f"FR_HIGH(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                return (8, f"FR_HIGH({rate_pct:.3f}%)", False)
            elif rate_pct > 0 and signal_side == "LONG":
                return (-5, f"FR_CROWD(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "SHORT":
                return (-5, f"FR_CROWD({rate_pct:.3f}%)", False)
        
        # Normal funding â€” hafif contrarian bonus
        if abs_rate > 0.01:
            if rate_pct > 0 and signal_side == "SHORT":
                return (3, f"FR(+{rate_pct:.3f}%)", False)
            elif rate_pct < 0 and signal_side == "LONG":
                return (3, f"FR({rate_pct:.3f}%)", False)
        
        return (0, "", False)
    
    def get_status(self) -> dict:
        """Tracker durumunu dÃ¶ndÃ¼r."""
        return {
            "coins_tracked": len(self.funding_rates),
            "last_fetch": self.last_fetch_time,
            "fetch_count": self.fetch_count,
            "last_error": self.last_error,
            "btc_funding": self.funding_rates.get('BTCUSDT', 0) * 100,
            "eth_funding": self.funding_rates.get('ETHUSDT', 0) * 100,
        }

# Global Funding+OI Tracker
funding_oi_tracker = FundingOITracker()


# ============================================================================
# PHASE 157: TRADE PATTERN ANALYZER
# KapanmÄ±ÅŸ trade'lerden Ã¶ÄŸrenme â€” coin/saat/side bazlÄ± WR analizi.
# ============================================================================

class TradePatternAnalyzer:
    """
    Phase 157: KapanmÄ±ÅŸ trade pattern analizi.
    
    Hangi koÅŸullarda kazanÄ±yoruz/kaybediyoruz sorusuna sistematik cevap.
    Min 20 trade gerektirir â€” yetersiz veriyle penalty uygulanmaz.
    """
    
    MIN_TRADES = 20  # Minimum trade sayÄ±sÄ±
    MIN_COIN_TRADES = 5  # Coin bazlÄ± minimum
    
    def __init__(self):
        self.last_analysis = None
        self.coin_wr: Dict[str, dict] = {}  # symbol -> {wins, losses, wr}
        self.hour_wr: Dict[int, dict] = {}  # hour -> {wins, losses, wr}
        self.side_wr: Dict[str, dict] = {}  # LONG/SHORT -> {wins, losses, wr}
        self.score_bins: Dict[str, dict] = {}  # score_range -> {wins, losses, wr}
        self.analysis_time: float = 0
        self.analysis_interval: float = 3600  # 1 saat
        logger.info("ðŸ“Š TradePatternAnalyzer initialized (Phase 157)")
    
    def analyze(self, trades: list) -> dict:
        """KapanmÄ±ÅŸ trade pattern analizi."""
        now = datetime.now().timestamp()
        if now - self.analysis_time < self.analysis_interval and self.last_analysis:
            return self.last_analysis
        
        if len(trades) < self.MIN_TRADES:
            return {"status": "insufficient_data", "trades_needed": self.MIN_TRADES - len(trades)}
        
        # Son 100 trade'i analiz et
        recent = trades[-100:] if len(trades) > 100 else trades
        
        # Coin bazlÄ± WR
        self.coin_wr = {}
        for t in recent:
            sym = t.get('symbol', 'UNKNOWN')
            pnl = t.get('pnl', 0)
            if sym not in self.coin_wr:
                self.coin_wr[sym] = {'wins': 0, 'losses': 0, 'total_pnl': 0}
            if pnl > 0:
                self.coin_wr[sym]['wins'] += 1
            else:
                self.coin_wr[sym]['losses'] += 1
            self.coin_wr[sym]['total_pnl'] += pnl
        
        # WR hesapla
        for sym, data in self.coin_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Saat bazlÄ± WR
        self.hour_wr = {}
        for t in recent:
            close_time = t.get('closeTime', 0)
            if close_time > 0:
                hour = datetime.fromtimestamp(close_time / 1000).hour
                if hour not in self.hour_wr:
                    self.hour_wr[hour] = {'wins': 0, 'losses': 0}
                if t.get('pnl', 0) > 0:
                    self.hour_wr[hour]['wins'] += 1
                else:
                    self.hour_wr[hour]['losses'] += 1
        
        for hour, data in self.hour_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Side bazlÄ± WR
        self.side_wr = {'LONG': {'wins': 0, 'losses': 0}, 'SHORT': {'wins': 0, 'losses': 0}}
        for t in recent:
            side = t.get('side', 'LONG')
            if side in self.side_wr:
                if t.get('pnl', 0) > 0:
                    self.side_wr[side]['wins'] += 1
                else:
                    self.side_wr[side]['losses'] += 1
        
        for side, data in self.side_wr.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        # Score bazlÄ± WR
        self.score_bins = {}
        for t in recent:
            score = t.get('signalScore', 0)
            if score < 60:
                bin_name = "50-59"
            elif score < 70:
                bin_name = "60-69"
            elif score < 80:
                bin_name = "70-79"
            else:
                bin_name = "80+"
            
            if bin_name not in self.score_bins:
                self.score_bins[bin_name] = {'wins': 0, 'losses': 0}
            if t.get('pnl', 0) > 0:
                self.score_bins[bin_name]['wins'] += 1
            else:
                self.score_bins[bin_name]['losses'] += 1
        
        for bin_name, data in self.score_bins.items():
            total = data['wins'] + data['losses']
            data['wr'] = (data['wins'] / total * 100) if total > 0 else 50
            data['total'] = total
        
        self.analysis_time = now
        
        # Ã–zet
        total_trades = len(recent)
        total_wins = sum(1 for t in recent if t.get('pnl', 0) > 0)
        overall_wr = (total_wins / total_trades * 100) if total_trades > 0 else 50
        
        # En kÃ¶tÃ¼/iyi coinler
        worst_coins = [s for s, d in self.coin_wr.items() 
                       if d['total'] >= self.MIN_COIN_TRADES and d['wr'] < 35]
        best_coins = [s for s, d in self.coin_wr.items() 
                      if d['total'] >= self.MIN_COIN_TRADES and d['wr'] > 65]
        
        self.last_analysis = {
            "status": "ok",
            "total_trades": total_trades,
            "overall_wr": overall_wr,
            "worst_coins": worst_coins,
            "best_coins": best_coins,
            "coin_count": len(self.coin_wr),
            "side_wr": {k: v['wr'] for k, v in self.side_wr.items()},
            "score_bins": {k: v['wr'] for k, v in self.score_bins.items()},
        }
        
        logger.info(f"ðŸ“Š TradePattern: {total_trades} trades | WR={overall_wr:.0f}% | worst={worst_coins[:3]} | best={best_coins[:3]}")
        
        return self.last_analysis
    
    def get_coin_penalty(self, symbol: str) -> int:
        """DÃ¼ÅŸÃ¼k WR coin'e penalty dÃ¶ndÃ¼r."""
        data = self.coin_wr.get(symbol)
        if not data or data['total'] < self.MIN_COIN_TRADES:
            return 0
        
        wr = data['wr']
        if wr < 25:
            return -15  # Ã‡ok kÃ¶tÃ¼ â€” gÃ¼Ã§lÃ¼ penalty
        elif wr < 35:
            return -10  # KÃ¶tÃ¼
        elif wr < 40:
            return -5   # OrtalamanÄ±n altÄ±
        elif wr > 70:
            return 5    # Ä°yi coin â€” hafif bonus
        
        return 0
    
    def get_side_penalty(self, side: str) -> int:
        """DÃ¼ÅŸÃ¼k WR taraf iÃ§in penalty."""
        data = self.side_wr.get(side)
        if not data or data.get('total', 0) < 10:
            return 0
        
        wr = data['wr']
        if wr < 35:
            return -5  # Bu taraf zayÄ±f
        elif wr > 65:
            return 3   # Bu taraf gÃ¼Ã§lÃ¼
        
        return 0

# Global Trade Pattern Analyzer
trade_pattern_analyzer = TradePatternAnalyzer()

# Stores all UI-relevant data in memory, updated by background scanner.
# WebSocket endpoints read from this cache instead of making fresh API calls.
# ============================================================================

class UIStateCache:
    """
    Cache for UI state - updated by background scanner every 3 seconds.
    WebSocket endpoints read from this cache for instant data delivery.
    
    Benefits:
    - Eliminates 3+ minute UI loading delay
    - Reduces Binance API rate limit usage
    - All UI clients see consistent data
    """
    
    def __init__(self):
        self.opportunities = []
        self.stats = {
            "totalCoins": 0,
            "analyzedCoins": 0,
            "longSignals": 0,
            "shortSignals": 0,
            "activeSignals": 0,
            "lastUpdate": 0
        }
        self.balance = 0
        self.live_balance = None
        self.positions = []
        self.trades = []
        self.binance_trades = []  # Phase 157: Trades fetched from Binance
        self.pnl_data = {
            "todayPnl": 0,
            "todayPnlPercent": 0,
            "totalPnl": 0,
            "totalPnlPercent": 0
        }
        self.logs = []
        self.trading_mode = "paper"
        self.last_update = 0
        self.btc_state = {}
        self.enabled = True
        self._initialized = False
        # Phase 157: Delayed trade history fetch after position close
        self.pending_trade_fetch_time = 0  # Unix timestamp when to fetch
        self.last_binance_trade_fetch = 0  # Last successful fetch time
        self.trade_fetch_in_progress = False  # Prevent overlapping heavy Binance trade sync jobs
    
    def trigger_trade_fetch(self, delay_seconds: int = 3):
        """Schedule a Binance trade history fetch after delay."""
        self.pending_trade_fetch_time = datetime.now().timestamp() + delay_seconds
        logger.info(f"ðŸ“Š Trade history fetch scheduled in {delay_seconds}s")
    
    def get_state(self) -> dict:
        """Return complete UI state for WebSocket - instant, no API calls."""
        return {
            "type": "scanner_update",
            "opportunities": self.opportunities,
            "stats": self.stats,
            "portfolio": {
                "balance": self.balance,
                "positions": self.positions,
                "trades": sorted(self.trades, key=lambda t: t.get('closeTime', 0), reverse=True),
                "stats": {
                    **self.pnl_data,
                    "liveBalance": self.live_balance,
                    "winRate": 0,
                    "totalTrades": len(self.trades)
                },
                "logs": self.logs[-100:],
                "enabled": self.enabled
            },
            "tradingMode": self.trading_mode,
            "timestamp": self.last_update,
            "message": "Cache data" if self._initialized else "Initializing..."
        }
    
    def is_ready(self) -> bool:
        """Check if cache has been populated at least once."""
        return self._initialized and self.last_update > 0


# Global UI State Cache instance
ui_state_cache = UIStateCache()


class MultiCoinScanner:
    """
    Phase 31: Multi-Coin Scanner
    Scans all Binance Futures perpetual contracts for trading opportunities.
    """
    
    def __init__(self, max_coins: int = 100):
        self.max_coins = max_coins
        self.coins: list = []
        self.analyzers: Dict[str, LightweightCoinAnalyzer] = {}
        self.running = False
        self.exchange = None
        self.last_fetch_time = 0
        self.opportunities: list = []
        self.active_signals: list = []
        # Caching for rate limit protection
        self.ticker_cache: dict = {}
        self.ticker_cache_time: float = 0
        self.cache_ttl: int = 10  # Cache valid for 10 seconds (Binance optimized)
        
        # BTC Basis tracking (Spot-Futures spread)
        self.btc_basis_pct: float = 0.0
        self.btc_spot_price: float = 0.0
        self.btc_futures_price: float = 0.0
        self.last_basis_update: float = 0
        
        logger.info(f"MultiCoinScanner initialized (max_coins={max_coins})")
    
    async def fetch_all_futures_symbols(self) -> list:
        """Fetch all USDT perpetual contracts from Binance Futures."""
        
        # Method 1: Try direct Binance API (most reliable, bypasses CCXT issues)
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get("https://fapi.binance.com/fapi/v1/exchangeInfo", timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        symbols = []
                        for s in data.get('symbols', []):
                            if (s.get('symbol', '').endswith('USDT') and 
                                s.get('contractType') == 'PERPETUAL' and 
                                s.get('status') == 'TRADING'):
                                symbols.append(s['symbol'])
                        
                        if len(symbols) > 100:  # Sanity check
                            symbols = sorted(list(set(symbols)))
                            logger.info(f"âœ… Fetched {len(symbols)} USDT perpetual contracts (direct API)")
                            self.coins = symbols
                            return symbols
        except Exception as e:
            logger.warning(f"Direct Binance API failed: {e}, trying CCXT...")
        
        # Method 2: Try CCXT (may fail on some servers due to geo-restrictions)
        try:
            if not self.exchange:
                api_key = os.environ.get('BINANCE_API_KEY', '')
                api_secret = os.environ.get('BINANCE_SECRET', '')
                
                exchange_config = {
                    'enableRateLimit': True,
                    'options': {'defaultType': 'future'}
                }
                
                if api_key and api_secret:
                    exchange_config['apiKey'] = api_key
                    exchange_config['secret'] = api_secret
                    logger.info("Using authenticated Binance API (with API key)")
                else:
                    logger.info("Using public Binance API (no API key)")
                
                self.exchange = ccxt_async.binance(exchange_config)
            
            markets = await self.exchange.load_markets()
            
            # Filter for USDT perpetual contracts only
            symbols = []
            for symbol, market in markets.items():
                if (market.get('quote') == 'USDT' and 
                    market.get('linear', False) and 
                    market.get('active', True) and
                    ':USDT' in symbol):
                    base = market.get('base', '')
                    if base:
                        symbols.append(f"{base}USDT")
            
            symbols = sorted(list(set(symbols)))
            
            if len(symbols) > 100:
                logger.info(f"âœ… Fetched {len(symbols)} USDT perpetual contracts (CCXT)")
                self.coins = symbols
                return symbols
                
        except Exception as e:
            logger.error(f"CCXT also failed: {e}")
        
        # Method 3: Fallback to hardcoded top 100 coins
        logger.warning("âš ï¸ All API methods failed, using fallback 100 coin list")
        self.coins = [
            # Top 20
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT',
            'DOGEUSDT', 'ADAUSDT', 'AVAXUSDT', 'TRXUSDT', 'DOTUSDT',
            'LINKUSDT', 'MATICUSDT', 'ICPUSDT', 'SHIBUSDT', 'LTCUSDT',
            'BCHUSDT', 'UNIUSDT', 'ATOMUSDT', 'NEARUSDT', 'XLMUSDT',
            # 21-40
            'APTUSDT', 'FILUSDT', 'LDOUSDT', 'ARBUSDT', 'OPUSDT',
            'INJUSDT', 'RNDRUSDT', 'HBARUSDT', 'VETUSDT', 'AAVEUSDT',
            'IMXUSDT', 'MKRUSDT', 'GRTUSDT', 'THETAUSDT', 'FTMUSDT',
            'ALGOUSDT', 'RUNEUSDT', 'EGLDUSDT', 'SNXUSDT', 'AXSUSDT',
            # 41-60
            'SANDUSDT', 'MANAUSDT', 'GALAUSDT', 'APEUSDT', 'CHZUSDT',
            'CRVUSDT', 'LRCUSDT', 'ENJUSDT', 'DYDXUSDT', 'MINAUSDT',
            'KAVAUSDT', 'COMPUSDT', 'GMTUSDT', 'ONEUSDT', 'IOTAUSDT',
            'ZECUSDT', 'KSMUSDT', 'DASHUSDT', 'SUIUSDT', 'SEIUSDT',
            # 61-80  
            '1000PEPEUSDT', '1000SHIBUSDT', 'WIFUSDT', 'BONKUSDT', 'FLOKIUSDT',
            'ORDIUSDT', 'TIAUSDT', 'FETUSDT', 'AGIXUSDT', 'OCEANUSDT',
            'WOOUSDT', 'BLURUSDT', 'CFXUSDT', 'STXUSDT', 'ARKMUSDT',
            'PENDLEUSDT', 'JOEUSDT', 'HOOKUSDT', 'MAGICUSDT', 'TUSDT',
            # 81-100
            'CKBUSDT', 'TRUUSDT', 'SSVUSDT', 'RPLUSDT', 'GMXUSDT',
            'LEVERUSDT', 'CYBERUSDT', 'ARKUSDT', 'POLYXUSDT', 'BIGTIMEUSDT',
            'WLDUSDT', 'LQTYUSDT', 'OXTUSDT', 'AMBUSDT', 'PHBUSDT',
            'COMBOUSDT', 'MAVUSDT', 'XVSUSDT', 'EDUUSDT', 'IDUSDT'
        ]
        logger.info(f"Using fallback list of {len(self.coins)} coins")
        return self.coins
    
    def get_or_create_analyzer(self, symbol: str) -> LightweightCoinAnalyzer:
        """Get existing analyzer or create new one."""
        if symbol not in self.analyzers:
            self.analyzers[symbol] = LightweightCoinAnalyzer(symbol)
        return self.analyzers[symbol]
    
    async def fetch_ticker_data(self, symbols: list) -> dict:
        """Fetch ticker data from WebSocket stream (instant, no API call)."""
        global binance_ws_manager
        
        # Start WebSocket if not running
        if not binance_ws_manager.running:
            await binance_ws_manager.start()
            # Wait a moment for initial data
            await asyncio.sleep(2)
        
        # Get tickers from WebSocket cache
        result = binance_ws_manager.get_tickers(symbols)
        
        if result:
            logger.info(f"Got {len(result)} tickers from WebSocket (instant)")
            return result
        
        # Fallback to REST API if WebSocket has no data yet
        logger.warning("WebSocket has no data, falling back to REST API")
        try:
            if not self.exchange:
                return {}
            
            tickers = await self.exchange.fetch_tickers()
            
            rest_result = {}
            for symbol in symbols:
                ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
                if ccxt_symbol in tickers:
                    rest_result[symbol] = tickers[ccxt_symbol]
            
            logger.info(f"Fetched {len(rest_result)} tickers from REST API (fallback)")
            return rest_result
            
        except Exception as e:
            logger.error(f"Error fetching tickers: {e}")
            return {}
    
    async def fetch_ticker_data_coingecko(self, symbols: list) -> dict:
        """Fallback: Fetch ticker data from CoinGecko API (no geo restrictions)."""
        import aiohttp
        import time
        
        # Check cache first to prevent rate limits
        current_time = time.time()
        if self.ticker_cache and (current_time - self.ticker_cache_time) < self.cache_ttl:
            logger.debug("Using cached ticker data")
            return self.ticker_cache
        
        # Map symbols to CoinGecko IDs (100 coins)
        symbol_to_coingecko = {
            # Top 20
            'BTCUSDT': 'bitcoin', 'ETHUSDT': 'ethereum', 'BNBUSDT': 'binancecoin',
            'SOLUSDT': 'solana', 'XRPUSDT': 'ripple', 'DOGEUSDT': 'dogecoin',
            'ADAUSDT': 'cardano', 'AVAXUSDT': 'avalanche-2', 'TRXUSDT': 'tron',
            'DOTUSDT': 'polkadot', 'LINKUSDT': 'chainlink', 'MATICUSDT': 'matic-network',
            'ICPUSDT': 'internet-computer', 'SHIBUSDT': 'shiba-inu', 'LTCUSDT': 'litecoin',
            'BCHUSDT': 'bitcoin-cash', 'UNIUSDT': 'uniswap', 'ATOMUSDT': 'cosmos',
            'NEARUSDT': 'near', 'XLMUSDT': 'stellar',
            # 21-40
            'APTUSDT': 'aptos', 'FILUSDT': 'filecoin', 'LDOUSDT': 'lido-dao',
            'ARBUSDT': 'arbitrum', 'OPUSDT': 'optimism', 'INJUSDT': 'injective-protocol',
            'RNDRUSDT': 'render-token', 'HBARUSDT': 'hedera-hashgraph', 'VETUSDT': 'vechain',
            'AAVEUSDT': 'aave', 'IMXUSDT': 'immutable-x', 'MKRUSDT': 'maker',
            'GRTUSDT': 'the-graph', 'THETAUSDT': 'theta-token', 'FTMUSDT': 'fantom',
            'ALGOUSDT': 'algorand', 'RUNEUSDT': 'thorchain', 'EGLDUSDT': 'elrond-erd-2',
            'SNXUSDT': 'havven', 'AXSUSDT': 'axie-infinity',
            # 41-60
            'SANDUSDT': 'the-sandbox', 'MANAUSDT': 'decentraland', 'GALAUSDT': 'gala',
            'APEUSDT': 'apecoin', 'CHZUSDT': 'chiliz', 'CRVUSDT': 'curve-dao-token',
            'LRCUSDT': 'loopring', 'ENJUSDT': 'enjincoin', 'DYDXUSDT': 'dydx',
            'MINAUSDT': 'mina-protocol', 'KAVAUSDT': 'kava', 'COMPUSDT': 'compound-governance-token',
            'GMTUSDT': 'stepn', 'ONEUSDT': 'harmony', 'IOTAUSDT': 'iota',
            'ZECUSDT': 'zcash', 'KSMUSDT': 'kusama', 'DASHUSDT': 'dash',
            'SUIUSDT': 'sui', 'SEIUSDT': 'sei-network',
            # 61-80
            '1000PEPEUSDT': 'pepe', '1000SHIBUSDT': 'shiba-inu', 'WIFUSDT': 'dogwifhat',
            'BONKUSDT': 'bonk', 'FLOKIUSDT': 'floki', 'ORDIUSDT': 'ordinals',
            'TIAUSDT': 'celestia', 'FETUSDT': 'fetch-ai', 'AGIXUSDT': 'singularitynet',
            'OCEANUSDT': 'ocean-protocol', 'WOOUSDT': 'woo-network', 'BLURUSDT': 'blur',
            'CFXUSDT': 'conflux-token', 'STXUSDT': 'blockstack', 'ARKMUSDT': 'arkham',
            'PENDLEUSDT': 'pendle', 'JOEUSDT': 'joe', 'HOOKUSDT': 'hooked-protocol',
            'MAGICUSDT': 'magic', 'TUSDT': 'threshold-network-token',
            # 81-100
            'CKBUSDT': 'nervos-network', 'TRUUSDT': 'truefi', 'SSVUSDT': 'ssv-network',
            'RPLUSDT': 'rocket-pool', 'GMXUSDT': 'gmx', 'LEVERUSDT': 'leverfi',
            'CYBERUSDT': 'cyberconnect', 'ARKUSDT': 'ark', 'POLYXUSDT': 'polymesh',
            'BIGTIMEUSDT': 'big-time', 'WLDUSDT': 'worldcoin-wld', 'LQTYUSDT': 'liquity',
            'OXTUSDT': 'orchid-protocol', 'AMBUSDT': 'amber', 'PHBUSDT': 'phoenix-global',
            'COMBOUSDT': 'furucombo', 'MAVUSDT': 'maverick-protocol', 'XVSUSDT': 'venus',
            'EDUUSDT': 'edu-coin', 'IDUSDT': 'space-id'
        }
        
        try:
            # Get coins we can map
            coin_ids = [symbol_to_coingecko.get(s) for s in symbols if s in symbol_to_coingecko]
            coin_ids = [c for c in coin_ids if c]  # Remove None
            
            if not coin_ids:
                logger.warning("No coins to fetch from CoinGecko")
                return {}
            
            # CoinGecko API - free, no API key needed
            url = f"https://api.coingecko.com/api/v3/simple/price?ids={','.join(coin_ids)}&vs_currencies=usd&include_24hr_change=true&include_24hr_vol=true"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        result = {}
                        # Reverse map CoinGecko data to symbols
                        coingecko_to_symbol = {v: k for k, v in symbol_to_coingecko.items()}
                        
                        for coin_id, price_data in data.items():
                            symbol = coingecko_to_symbol.get(coin_id)
                            if symbol:
                                # Format data similar to CCXT ticker
                                price = price_data.get('usd', 0)
                                change_pct = price_data.get('usd_24h_change', 0)
                                volume = price_data.get('usd_24h_vol', 0)
                                
                                result[symbol] = {
                                    'last': price,
                                    'percentage': change_pct,
                                    'quoteVolume': volume,
                                    'high': price * 1.02,  # Approximate
                                    'low': price * 0.98,   # Approximate
                                }
                        
                        # Update cache
                        if result:
                            self.ticker_cache = result
                            self.ticker_cache_time = current_time
                        
                        logger.info(f"Fetched {len(result)} tickers from CoinGecko fallback")
                        return result
                    else:
                        logger.warning(f"CoinGecko API error: {response.status}")
                        # Return cached data if available
                        if self.ticker_cache:
                            logger.info("Returning cached data due to API error")
                            return self.ticker_cache
                        return {}
                        
        except Exception as e:
            logger.error(f"CoinGecko fallback error: {e}")
            # Return cached data if available
            if self.ticker_cache:
                logger.info("Returning cached data due to exception")
                return self.ticker_cache
            return {}
    
    async def update_btc_basis(self):
        """
        Update BTC Spot-Futures basis (spread).
        Called every minute to avoid rate limits.
        Positive basis = Futures > Spot (bullish sentiment, good for shorts)
        Negative basis = Futures < Spot (bearish sentiment, good for longs)
        """
        import aiohttp
        import time
        
        now = time.time()
        # Only update once per minute to avoid rate limits
        if now - self.last_basis_update < 60:
            return
        
        try:
            # Get BTC Futures price from our ticker cache
            btc_futures = self.ticker_cache.get('BTCUSDT', {})
            self.btc_futures_price = btc_futures.get('last', 0)
            
            if self.btc_futures_price <= 0:
                return
            
            # Fetch BTC Spot price from Binance Spot API (public, no auth needed)
            async with aiohttp.ClientSession() as session:
                url = "https://api.binance.com/api/v3/ticker/price?symbol=BTCUSDT"
                async with session.get(url, timeout=5) as response:
                    if response.status == 200:
                        data = await response.json()
                        self.btc_spot_price = float(data.get('price', 0))
                        
                        if self.btc_spot_price > 0:
                            basis = self.btc_futures_price - self.btc_spot_price
                            self.btc_basis_pct = (basis / self.btc_spot_price) * 100
                            self.last_basis_update = now
                            logger.debug(f"BTC Basis updated: {self.btc_basis_pct:.4f}% (Futures: ${self.btc_futures_price:.2f}, Spot: ${self.btc_spot_price:.2f})")
        except Exception as e:
            logger.debug(f"BTC basis update error: {e}")
    
    async def fetch_book_tickers(self) -> dict:
        """Phase 228: Fetch book tickers (bid/ask) via REST API.
        
        Binance Futures !ticker@arr WS does NOT include bid/ask fields.
        This REST call gets all book tickers in one request.
        """
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://fapi.binance.com/fapi/v1/ticker/bookTicker',
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        cache = {}
                        for item in data:
                            symbol = item.get('symbol', '')
                            if symbol.endswith('USDT'):
                                cache[symbol] = {
                                    'bid': float(item.get('bidPrice', 0)),
                                    'ask': float(item.get('askPrice', 0)),
                                    'bidQty': float(item.get('bidQty', 0)),
                                    'askQty': float(item.get('askQty', 0)),
                                }
                        return cache
                    else:
                        logger.warning(f"BookTicker REST failed: status={resp.status}")
                        return {}
        except Exception as e:
            logger.warning(f"BookTicker REST error: {e}")
            return {}
    
    async def scan_all_coins(self) -> list:
        """Scan all coins and return opportunities."""
        if not self.coins:
            await self.fetch_all_futures_symbols()
        
        # Fetch all ticker data at once
        tickers = await self.fetch_ticker_data(self.coins)
        
        # Phase 228: Fetch book tickers (bid/ask) via REST API
        book_cache = await self.fetch_book_tickers()
        # P3 fix: Log intersection with scanned coins, not total cache
        matched = len(set(book_cache.keys()) & set(tickers.keys())) if book_cache else 0
        logger.info(f"ðŸ“Š BookTicker: {matched}/{len(tickers)} scanned coins have bid/ask data")
        
        # Update BTC basis (Spot-Futures spread) - once per minute
        await self.update_btc_basis()
        
        opportunities = []
        signals = []
        
        # Yield control to event loop every N coins to prevent blocking API requests
        # Lower value = more responsive API but slightly slower scan
        yield_every = 10  # Yield frequently to keep API responsive
        coin_count = 0
        
        for symbol, ticker in tickers.items():
            try:
                analyzer = self.get_or_create_analyzer(symbol)
                
                # Update price data from ticker
                price = ticker.get('last', 0)
                high = ticker.get('high', price)
                low = ticker.get('low', price)
                # WebSocket path uses incremental delta volume; REST fallback has only baseVolume.
                volume = ticker.get('volumeDelta', ticker.get('baseVolume', 0))
                imbalance = ticker.get('imbalance', 0)  # L1 Order Book imbalance from WebSocket
                
                if price <= 0:
                    continue
                
                analyzer.update_price(price, high, low, volume)
                analyzer.opportunity.volume_24h = ticker.get('quoteVolume', 0)
                analyzer.opportunity.price_change_24h = ticker.get('percentage', 0)
                
                # P2 fix: Reset spread flag each scan â€” prevents stale data on REST fail
                analyzer.opportunity.has_real_spread = False
                
                # P1 fix: Set WS imbalance as default, then let bookTicker override
                analyzer.opportunity.imbalance = imbalance
                
                # Phase 228: Calculate real bid-ask spread from REST bookTicker
                book = book_cache.get(symbol, {})
                bid = book.get('bid', 0)
                ask = book.get('ask', 0)
                if bid > 0 and ask > 0 and ask > bid:
                    mid = (ask + bid) / 2
                    bid_ask_spread = ((ask - bid) / mid) * 100
                    analyzer.opportunity.bid_ask_spread_pct = round(bid_ask_spread, 4)
                    analyzer.opportunity.has_real_spread = True
                    # P1 fix: Override imbalance with real L1 data from bookTicker
                    bid_qty = book.get('bidQty', 0)
                    ask_qty = book.get('askQty', 0)
                    if bid_qty + ask_qty > 0:
                        imbalance = ((bid_qty - ask_qty) / (bid_qty + ask_qty)) * 100
                        analyzer.opportunity.imbalance = imbalance
                
                # Update whale tracker with volume and price change
                whale_tracker.update(symbol, price, volume, ticker.get('percentage', 0))
                
                # Analyze for signal with BTC basis and L1 imbalance (uses bookTicker imbalance if available)
                signal = analyzer.analyze(imbalance=imbalance, basis_pct=self.btc_basis_pct)
                
                if signal:
                    signal['symbol'] = symbol
                    # Phase 230B: Propagate coin data for BTC filter multi-factor override
                    signal['priceChange24h'] = analyzer.opportunity.price_change_24h
                    signal['volume24h'] = analyzer.opportunity.volume_24h
                    signal['zscore'] = analyzer.opportunity.zscore
                    signals.append(signal)
                
                opportunities.append(analyzer.opportunity.to_dict())
                
                # Yield control to event loop periodically to allow API requests to be processed
                coin_count += 1
                if coin_count % yield_every == 0:
                    await asyncio.sleep(0)
                
            except Exception as e:
                logger.debug(f"Error analyzing {symbol}: {e}")
                continue
        
        # Sort by signal score (highest first)
        opportunities.sort(key=lambda x: x.get('signalScore', 0), reverse=True)
        
        self.opportunities = opportunities
        self.active_signals = signals
        
        # Phase 127: Log active signal count for tracing
        if signals:
            signal_symbols = [s.get('symbol', '?') for s in signals]
            logger.info(f"ðŸ“¡ SCAN_RESULT: {len(signals)} active signals collected: {signal_symbols[:5]}{'...' if len(signals) > 5 else ''}")
        
        return opportunities
    
    def get_scanner_stats(self) -> dict:
        """Get overall scanner statistics."""
        long_count = sum(1 for o in self.opportunities if o.get('signalAction') == 'LONG')
        short_count = sum(1 for o in self.opportunities if o.get('signalAction') == 'SHORT')
        
        return {
            "totalCoins": len(self.coins),
            "analyzedCoins": len(self.opportunities),
            "longSignals": long_count,
            "shortSignals": short_count,
            "activeSignals": len(self.active_signals),
            "lastUpdate": datetime.now().timestamp()
        }
    
    async def preload_all_coins(self, top_n: int = 50):
        """
        Preload historical OHLCV data for top N coins at startup.
        This enables immediate Z-Score/Hurst calculation without waiting for data to accumulate.
        
        Args:
            top_n: Number of top coins to preload (default 50 to balance speed and coverage)
        """
        if not self.coins:
            await self.fetch_all_futures_symbols()
        
        if not self.exchange:
            logger.info("ðŸ“Š Creating exchange for OHLCV preloading...")
            try:
                import ccxt.async_support as ccxt_async
                api_key = os.environ.get('BINANCE_API_KEY', '')
                api_secret = os.environ.get('BINANCE_SECRET', '')
                exchange_config = {
                    'enableRateLimit': True,
                    'options': {'defaultType': 'future'}
                }
                if api_key and api_secret:
                    exchange_config['apiKey'] = api_key
                    exchange_config['secret'] = api_secret
                self.exchange = ccxt_async.binance(exchange_config)
                logger.info("âœ… Exchange created for preload")
            except Exception as e:
                logger.error(f"âŒ Failed to create exchange for preload: {e}")
                return
        
        # Preload top N coins (most traded/popular)
        priority_coins = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 
                         'BNBUSDT', 'ADAUSDT', 'AVAXUSDT', 'DOTUSDT', 'LINKUSDT']
        
        coins_to_preload = priority_coins + [c for c in self.coins[:top_n] if c not in priority_coins]
        coins_to_preload = coins_to_preload[:top_n]
        
        logger.info(f"Starting OHLCV preload for {len(coins_to_preload)} coins...")
        
        preloaded_count = 0
        failed_count = 0
        
        for symbol in coins_to_preload:
            try:
                # Fetch 5-minute candles (last 100 = ~8 hours of data)
                ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
                ohlcv = await self.exchange.fetch_ohlcv(ccxt_symbol, '5m', limit=100)
                
                if ohlcv and len(ohlcv) >= 20:
                    analyzer = self.get_or_create_analyzer(symbol)
                    analyzer.preload_historical_data(ohlcv)
                    preloaded_count += 1
                else:
                    failed_count += 1
                    
            except Exception as e:
                logger.info(f"âŒ Failed to preload {symbol}: {str(e)[:50]}")
                failed_count += 1
                continue
            
            # Small delay to avoid rate limits (respect Binance API limits)
            if preloaded_count % 10 == 0:
                await asyncio.sleep(0.5)
        
        logger.info(f"OHLCV preload complete: {preloaded_count} success, {failed_count} failed")
    
    async def close(self):
        """Cleanup resources."""
        if self.exchange:
            await self.exchange.close()
            self.exchange = None

# Global MultiCoinScanner instance (no limit - scans ALL perpetuals)
multi_coin_scanner = MultiCoinScanner(max_coins=999)


# ============================================================================
# PHASE 98: ASYNC TRADE CACHE REFRESH (non-blocking for scanner loop)
# ============================================================================

async def _refresh_binance_trade_cache_async(trigger: str = "periodic"):
    """
    Refresh Binance trade history in the background.
    Kept separate from scanner loop so heavy trade enrichment does not block entries.
    """
    if not live_binance_trader.enabled:
        return
    if ui_state_cache.trade_fetch_in_progress:
        return

    ui_state_cache.trade_fetch_in_progress = True
    fetch_started = datetime.now().timestamp()
    try:
        logger.info(f"ðŸ“Š BINANCE_FETCH_ASYNC: trigger={trigger} limit=300 days=7")
        binance_trades = await asyncio.wait_for(
            live_binance_trader.get_trade_history(limit=300, days_back=7),
            timeout=UI_TRADE_FETCH_TIMEOUT_SEC
        )
        if not binance_trades:
            ui_state_cache.last_binance_trade_fetch = fetch_started
            return

        saved_count = 0
        for bt in binance_trades:
            try:
                bt_copy = bt.copy()
                bt_copy['incomeId'] = f"{bt.get('symbol', 'UNK')}_{bt.get('closeTime', bt.get('timestamp', 0))}"
                await sqlite_manager.save_binance_trade(bt_copy)
                saved_count += 1
            except Exception as save_err:
                logger.debug(f"Save trade error: {save_err}")

        sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
        ui_state_cache.binance_trades = binance_trades
        ui_state_cache.trades = sqlite_trades
        ui_state_cache.last_binance_trade_fetch = datetime.now().timestamp()
        ui_state_cache.pending_trade_fetch_time = 0
        logger.info(
            f"ðŸ“Š BINANCE_FETCH_ASYNC_DONE: saved={saved_count} loaded={len(sqlite_trades)} trigger={trigger}"
        )
    except asyncio.TimeoutError:
        ui_state_cache.last_binance_trade_fetch = fetch_started
        logger.warning(f"â±ï¸ BINANCE_FETCH_ASYNC_TIMEOUT: trigger={trigger} > {UI_TRADE_FETCH_TIMEOUT_SEC:.0f}s")
    except Exception as e:
        ui_state_cache.last_binance_trade_fetch = fetch_started
        logger.warning(f"ðŸ“Š BINANCE_FETCH_ASYNC_ERROR: trigger={trigger} err={e}")
    finally:
        ui_state_cache.trade_fetch_in_progress = False


# ============================================================================
# PHASE 98: UI CACHE UPDATE FUNCTION
# Called by background scanner to populate cache with fresh Binance data.
# ============================================================================

async def update_ui_cache(opportunities: list, stats: dict):
    """
    Update UI state cache with latest scanner data and Binance info.
    This is called every 3 seconds by the background scanner loop.
    
    Args:
        opportunities: List of filtered coin opportunities from scanner
        stats: Scanner statistics dict
    """
    global ui_state_cache
    
    # Phase 157: Debug - log every call
    logger.info(f"ðŸ”„ update_ui_cache CALLED: {len(opportunities)} opportunities, live={live_binance_trader.enabled}")
    
    try:
        # Apply BTC filter to opportunities
        filtered_opportunities = []
        for opp in opportunities:
            signal_action = opp.get('signalAction', 'NONE')
            symbol = opp.get('symbol', '')
            
            if signal_action == 'NONE':
                filtered_opportunities.append(opp)
            else:
                # Phase 225: PriceShock block (before BTC filter)
                shock_blocked, shock_reason = price_shock_manager.should_block_signal(signal_action, symbol)
                if shock_blocked:
                    opp['signalAction'] = 'NONE'
                    opp['signalScore'] = 0
                    opp['shockBlocked'] = shock_reason
                    filtered_opportunities.append(opp)
                    continue
                
                btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
                    symbol, signal_action,
                    coin_change_pct=opp.get('priceChange24h', 0),
                    volume_24h=opp.get('volume24h', 0),
                    zscore=opp.get('zscore', 0),
                    spread_pct=opp.get('spreadPct', 0)
                )
                if btc_allowed:
                    if btc_penalty > 0:
                        original_score = opp.get('signalScore', 0)
                        opp['signalScore'] = int(original_score * (1 - btc_penalty))
                        opp['btcFilterNote'] = btc_reason
                        cap_lev, cap_size = get_btc_penalty_risk_caps(btc_penalty)
                        if cap_lev:
                            existing_cap = opp.get('overrideLeverageCap')
                            opp['overrideLeverageCap'] = min(existing_cap, cap_lev) if existing_cap else cap_lev
                            # Phase 238B: Leverage pipeline transparency
                            opp['leverageCapApplied'] = True
                            opp['leverageCapValue'] = opp['overrideLeverageCap']
                            opp['leverageCapReason'] = f"BTC_FILTER:{btc_reason.split(':')[0] if ':' in btc_reason else 'MODERATE'}"
                        if cap_size:
                            existing_size_cap = float(opp.get('overrideSizeMult', 1.0) or 1.0)
                            opp['overrideSizeMult'] = min(existing_size_cap, cap_size)
                    # Phase 230B: Apply override risk caps
                    if btc_filter.last_override:
                        existing_cap = opp.get('overrideLeverageCap')
                        opp['overrideLeverageCap'] = min(existing_cap, 3) if existing_cap else 3
                        existing_size_cap = float(opp.get('overrideSizeMult', 1.0) or 1.0)
                        opp['overrideSizeMult'] = min(existing_size_cap, 0.5)
                        opp['btcOverride'] = True
                        # Phase 238B: Leverage pipeline
                        opp['leverageCapApplied'] = True
                        opp['leverageCapValue'] = opp['overrideLeverageCap']
                        opp['leverageCapReason'] = 'BTC_FILTER:EXTREME'
                    filtered_opportunities.append(opp)
                else:
                    opp['signalAction'] = 'NONE'
                    opp['signalScore'] = 0
                    opp['btcFilterBlocked'] = btc_reason
                    filtered_opportunities.append(opp)
        
        # Update opportunities and stats
        ui_state_cache.opportunities = filtered_opportunities
        
        # Calculate signal counts from filtered opportunities (only those above min confidence threshold)
        min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
        long_count = sum(1 for o in filtered_opportunities if o.get('signalAction') == 'LONG' and o.get('signalScore', 0) >= min_score)
        short_count = sum(1 for o in filtered_opportunities if o.get('signalAction') == 'SHORT' and o.get('signalScore', 0) >= min_score)
        
        ui_state_cache.stats = {
            "totalCoins": stats.get('totalCoins', len(multi_coin_scanner.coins)),
            "analyzedCoins": len(filtered_opportunities),
            "longSignals": long_count,
            "shortSignals": short_count,
            "activeSignals": long_count + short_count,
            "btcState": btc_filter.get_state(),
            "lastUpdate": datetime.now().timestamp()
        }
        
        # Fetch Binance data (live mode) or use paper trader data
        if live_binance_trader.enabled:
            try:
                # Use sync-loop snapshots to avoid blocking scanner with extra Binance API calls.
                balance_data = (
                    getattr(global_paper_trader, 'liveBalance', None)
                    or ui_state_cache.live_balance
                    or {}
                )
                if not balance_data:
                    balance_data = {
                        "walletBalance": global_paper_trader.balance,
                        "marginBalance": global_paper_trader.balance,
                        "availableBalance": global_paper_trader.balance,
                        "unrealizedPnl": 0.0,
                    }
                positions = list(getattr(live_binance_trader, 'last_positions', []) or [])
                if not positions:
                    positions = [dict(p) for p in global_paper_trader.positions if p.get('isLive')]
                
                # Phase 155: Merge Binance positions with exit params from global_paper_trader
                # global_paper_trader.positions has TP/SL/Trail data from sync loop
                merged_positions = []
                paper_positions = {p.get('symbol'): p for p in global_paper_trader.positions}
                
                for bp in positions:
                    symbol = bp.get('symbol', '')
                    paper_pos = paper_positions.get(symbol, {})
                    
                    # Start with Binance data
                    merged = dict(bp)
                    
                    # Merge exit parameters from paper trader (if available)
                    if paper_pos:
                        merged['stopLoss'] = paper_pos.get('stopLoss', bp.get('stopLoss', 0))
                        merged['takeProfit'] = paper_pos.get('takeProfit', bp.get('takeProfit', 0))
                        merged['trailingStop'] = paper_pos.get('trailingStop', paper_pos.get('stopLoss', 0))
                        merged['trailActivation'] = paper_pos.get('trailActivation', 0)
                        merged['atr'] = paper_pos.get('atr', 0)
                        merged['effectiveExitTightness'] = paper_pos.get('effectiveExitTightness', global_paper_trader.exit_tightness)
                        merged['runtimeTrailDistance'] = paper_pos.get('runtimeTrailDistance', paper_pos.get('trailDistance', 0))
                        merged['runtimeTrailDistancePct'] = paper_pos.get('runtimeTrailDistancePct', 0.0)
                        merged['runtimeTrailActivationMovePct'] = paper_pos.get('runtimeTrailActivationMovePct', 0.0)
                        merged['runtimeTrailActivationRoiPct'] = paper_pos.get('runtimeTrailActivationRoiPct', 0.0)
                        merged['runtimeTrailThresholdMult'] = paper_pos.get('runtimeTrailThresholdMult', 1.0)
                        merged['runtimeTrailLastUpdateTs'] = paper_pos.get('runtimeTrailLastUpdateTs', 0)
                        # Phase 231k: Use paper_pos openTime (original entry) â€” not Binance updateTime
                        if paper_pos.get('openTime', 0) > 0:
                            merged['openTime'] = paper_pos['openTime']
                        
                        # Phase 156: isTrailingActive must be based on CURRENT profitability from Binance
                        # Phase 204: Use currentPrice (close/last) instead of markPrice (can spike with wicks)
                        close_price = bp.get('currentPrice', bp.get('markPrice', 0))
                        entry_price = bp.get('entryPrice', 0)
                        side = bp.get('side', 'LONG')
                        
                        if close_price > 0 and entry_price > 0:
                            # Phase 231: Use paper_pos's REAL trail state, don't infer from profitability
                            # Old bug: was setting isTrailingActive = (profitable?) which was wrong
                            merged['isTrailingActive'] = paper_pos.get('isTrailingActive', False)
                        else:
                            merged['isTrailingActive'] = paper_pos.get('isTrailingActive', False)
                    else:
                        # No paper position - calculate default exit params
                        entry = bp.get('entryPrice', 0)
                        atr = entry * 0.02 if entry > 0 else 0  # 2% default ATR
                        sl_mult = getattr(global_paper_trader, 'sl_multiplier', 2.0)  # Default 2x ATR
                        tp_mult = getattr(global_paper_trader, 'tp_multiplier', 3.0)  # Default 3x ATR
                        
                        if bp.get('side') == 'LONG':
                            merged['stopLoss'] = max(entry * 0.01, entry - (atr * sl_mult))
                            merged['takeProfit'] = entry + (atr * tp_mult)
                        else:
                            merged['stopLoss'] = entry + (atr * sl_mult)
                            merged['takeProfit'] = max(entry * 0.01, entry - (atr * tp_mult))
                        
                        merged['trailingStop'] = merged['stopLoss']
                        merged['isTrailingActive'] = False
                        merged['atr'] = atr
                        merged['effectiveExitTightness'] = getattr(global_paper_trader, 'exit_tightness', 1.0)
                        merged['runtimeTrailDistance'] = merged.get('trailDistance', 0)
                        merged['runtimeTrailDistancePct'] = round((merged.get('trailDistance', 0) / entry * 100), 4) if entry > 0 else 0.0
                        merged['runtimeTrailActivationMovePct'] = 0.0
                        merged['runtimeTrailActivationRoiPct'] = 0.0
                        merged['runtimeTrailThresholdMult'] = 1.0
                        merged['runtimeTrailLastUpdateTs'] = int(datetime.now().timestamp() * 1000)
                    
                    merged_positions.append(merged)
                
                ui_state_cache.balance = balance_data.get('walletBalance', 0)
                ui_state_cache.live_balance = balance_data
                ui_state_cache.positions = sorted(merged_positions, key=lambda p: p.get('openTime', 0), reverse=True)
                ui_state_cache.trading_mode = "live"
                logger.info(f"ðŸ“Š UI Cache updated: {len(merged_positions)} positions, balance=${balance_data.get('walletBalance', 0):.2f}")
                if not ui_state_cache.pnl_data:
                    ui_state_cache.pnl_data = global_paper_trader.get_today_pnl()
                        
            except Exception as e:
                logger.warning(f"Binance data fetch error: {e}")
        else:
            # Paper trading mode
            ui_state_cache.balance = global_paper_trader.balance
            ui_state_cache.positions = global_paper_trader.positions
            ui_state_cache.pnl_data = global_paper_trader.get_today_pnl()
            ui_state_cache.trading_mode = "paper"
            # Phase 232: Sync trades on every cycle (fix stale cache)
            ui_state_cache.trades = sorted(
                global_paper_trader.trades,
                key=lambda t: t.get('closeTime', t.get('close_time', 0)),
                reverse=True
            )
        
        # Phase 150: Trade history â€” SQLite first, then Binance delta
        now = datetime.now().timestamp()
        time_since_last_fetch = now - ui_state_cache.last_binance_trade_fetch
        triggered = ui_state_cache.pending_trade_fetch_time > 0 and now >= ui_state_cache.pending_trade_fetch_time
        periodic = time_since_last_fetch > UI_TRADE_FETCH_INTERVAL_SEC
        
        # Phase 187b: Startup instant load from SQLite trades table (full data)
        if not ui_state_cache.trades:
            try:
                sqlite_trades = await sqlite_manager.get_full_trade_history(limit=0)
                if sqlite_trades:
                    ui_state_cache.trades = sqlite_trades
                    logger.info(f"ðŸ“Š INSTANT_LOAD: {len(sqlite_trades)} trades from SQLite trades table (full data)")
            except Exception as e:
                logger.debug(f"SQLite instant load error: {e}")
        
        should_fetch_binance = (
            live_binance_trader.enabled
            and not ui_state_cache.trade_fetch_in_progress
            and (triggered or periodic)
        )
        
        logger.info(f"ðŸ“Š TRADE_CHECK: should={should_fetch_binance}, enabled={live_binance_trader.enabled}, triggered={triggered}, periodic={periodic}, since={time_since_last_fetch:.0f}s")
        
        if should_fetch_binance:
            # Reserve fetch slot immediately to prevent burst task creation.
            ui_state_cache.last_binance_trade_fetch = now
            if triggered:
                ui_state_cache.pending_trade_fetch_time = 0
            fetch_trigger = "triggered" if triggered else "periodic"
            safe_create_task(
                _refresh_binance_trade_cache_async(trigger=fetch_trigger),
                name=f"ui_trade_refresh_{fetch_trigger}"
            )
        
        # Phase 150: Old fallback removed â€” SQLite instant load handles this at startup
        
        logger.info(f"ðŸ“Š UI_CACHE_END: trades={len(ui_state_cache.trades)}, initialized={ui_state_cache._initialized}")
        
        # Update logs and metadata
        ui_state_cache.logs = global_paper_trader.logs[-100:]
        ui_state_cache.enabled = global_paper_trader.enabled
        ui_state_cache.last_update = datetime.now().timestamp()
        ui_state_cache._initialized = True
        
    except Exception as e:
        logger.error(f"UI cache update error: {e}")


# ============================================================================
# 24/7 BACKGROUND SCANNER LOOP
# ============================================================================

async def background_scanner_loop():
    """
    24/7 Background scanner that runs independently of frontend connections.
    Scans all coins, generates signals, and executes paper trades automatically.
    """
    logger.info("ðŸ”„ Background Scanner Loop started - running 24/7")
    
    scan_interval = 3  # Phase 86: Reduced to 3s for faster signal detection (~60% API capacity)
    
    # Wait for app to fully initialize
    await asyncio.sleep(3)
    
    try:
        # Initialize scanner
        if not multi_coin_scanner.coins:
            await multi_coin_scanner.fetch_all_futures_symbols()
            logger.info(f"ðŸ“Š Scanning ALL {len(multi_coin_scanner.coins)} USDT perpetual contracts")
            logger.info("Starting background OHLCV preload for Z-Score/Hurst calculation...")
            await multi_coin_scanner.preload_all_coins(top_n=50)  # Preload top 50
        
        multi_coin_scanner.running = True
        
        # Track last coin refresh time (refresh every 30 minutes)
        last_coin_refresh = datetime.now().timestamp()
        coin_refresh_interval = 1800  # 30 minutes
        
        while multi_coin_scanner.running:
            try:
                # PHASE 104: Track loop iterations
                if not hasattr(multi_coin_scanner, '_loop_iteration'):
                    multi_coin_scanner._loop_iteration = 0
                multi_coin_scanner._loop_iteration += 1
                
                # Update BTC trend for HTF scoring (every scan cycle)
                try:
                    if multi_coin_scanner.exchange:
                        await btc_filter.update_btc_state(multi_coin_scanner.exchange)
                except Exception as e:
                    logger.debug(f"BTC filter update error: {e}")
                
                # Phase 157: Fetch funding rates (cached â€” only calls API every 5 min)
                try:
                    if multi_coin_scanner.exchange:
                        await funding_oi_tracker.fetch_funding_rates(multi_coin_scanner.exchange)
                except Exception as e:
                    logger.debug(f"Funding rate fetch error: {e}")
                
                # Phase 157: Trade pattern analysis (cached â€” only runs every 1 hour)
                try:
                    if hasattr(global_paper_trader, 'trades') and global_paper_trader.trades:
                        trade_pattern_analyzer.analyze(global_paper_trader.trades)
                except Exception as e:
                    logger.debug(f"Trade pattern analysis error: {e}")
                
                # Phase 225: Check for price shocks (after BTC + funding data available)
                try:
                    price_shock_manager.check_for_shock(btc_filter, liquidation_tracker, funding_oi_tracker)
                    # If shock active, tighten exposed positions + cancel opposing pending
                    if price_shock_manager.shock_mode != 'NORMAL':
                        price_shock_manager.tighten_exposed_positions(global_paper_trader.positions)
                        cancelled = price_shock_manager.cancel_opposing_pending(global_paper_trader.pending_orders)
                        for c in cancelled:
                            global_paper_trader.add_log(f"âš¡ SHOCK_CANCEL: {c.get('side')} {c.get('symbol')} pending order cancelled ({price_shock_manager.shock_mode})")
                except Exception as e:
                    logger.debug(f"PriceShock check error: {e}")
                
                # Refresh coin list every 30 minutes to catch new listings
                now = datetime.now().timestamp()
                if now - last_coin_refresh > coin_refresh_interval:
                    old_count = len(multi_coin_scanner.coins)
                    await multi_coin_scanner.fetch_all_futures_symbols()
                    new_count = len(multi_coin_scanner.coins)
                    if new_count > old_count:
                        logger.info(f"ðŸ†• New coins detected: {new_count - old_count} added (total: {new_count})")
                    last_coin_refresh = now
                
                # Scan all coins (guard against hanging network calls).
                try:
                    opportunities = await asyncio.wait_for(
                        multi_coin_scanner.scan_all_coins(),
                        timeout=SCANNER_SCAN_TIMEOUT_SEC
                    )
                except asyncio.TimeoutError:
                    logger.error(f"â±ï¸ SCAN TIMEOUT: scan_all_coins > {SCANNER_SCAN_TIMEOUT_SEC:.0f}s (cycle skipped)")
                    await asyncio.sleep(1)
                    continue
                stats = multi_coin_scanner.get_scanner_stats()
                
                # PHASE 105: Periodic scan summary log (first 5 iterations + every 50th)
                loop_iter = multi_coin_scanner._loop_iteration
                if loop_iter <= 5 or loop_iter % 50 == 0:
                    # Get sample analyzer price count
                    sample_prices = 0
                    if multi_coin_scanner.analyzers and 'BTCUSDT' in multi_coin_scanner.analyzers:
                        sample_prices = len(multi_coin_scanner.analyzers['BTCUSDT'].prices)
                    logger.info(f"ðŸ”„ SCAN #{loop_iter}: {len(opportunities)} coins | BTC prices={sample_prices}")
                
                # PHASE 98: Update UI cache with latest data (instant delivery to UI)
                try:
                    await asyncio.wait_for(update_ui_cache(opportunities, stats), timeout=8.0)
                except asyncio.TimeoutError:
                    logger.error("â±ï¸ UI cache update timeout (>8s), skipping this cycle")
                    continue
                
                # Phase 152: Periodic status summary to UI logs (every ~60 sec)
                if loop_iter % 20 == 0 and 'global_paper_trader' in globals():
                    pt = global_paper_trader
                    active_sigs = len(multi_coin_scanner.active_signals)
                    total_pnl = sum(p.get('unrealizedPnl', 0) for p in pt.positions)
                    pt.add_log(f"ðŸ“Š DURUM: {len(pt.positions)} poz | {active_sigs} sinyal | Bakiye: ${pt.balance:.0f} | AÃ§Ä±k PnL: ${total_pnl:.2f}")
                
                # Update market regime with BTC price (from btc_filter OR from opportunities)
                try:
                    btc_price = btc_filter.btc_price
                    if not btc_price or btc_price <= 0:
                        # Fallback: get from scan results
                        btc_opp = next((o for o in opportunities if o['symbol'] == 'BTCUSDT'), None)
                        if btc_opp:
                            btc_price = btc_opp.get('currentPrice', 0)
                    if btc_price and btc_price > 0:
                        market_regime_detector.update_btc_price(btc_price)
                except Exception as regime_err:
                    logger.debug(f"Market regime update error: {regime_err}")
                
                # Process signals for paper trading (only if enabled)
                if global_paper_trader.enabled:
                    # Phase 36 IMPROVED: Position-based kill switch check
                    # Checks each position individually, applies gradual reduction
                    if global_paper_trader.positions:
                        kill_switch_actions = await daily_kill_switch.check_positions(global_paper_trader)
                        # Log and broadcast if any actions were taken
                        if kill_switch_actions.get('reduced') or kill_switch_actions.get('closed'):
                            logger.info(f"ðŸš¨ Kill Switch Actions: Reduced={kill_switch_actions['reduced']}, Closed={kill_switch_actions['closed']}")
                            # Broadcast kill switch event to UI
                            await ui_ws_manager.broadcast_kill_switch(kill_switch_actions)
                        
                        # Phase 231: check_positions moved AFTER position price update (below)
                        # Was here previously â€” caused partial TP to use stale PnL
                        
                        # Phase 215: Live MTF Position Guard (her 30 dakikada)
                        try:
                            await apply_mtf_position_guard(
                                global_paper_trader.positions,
                                multi_coin_scanner.exchange
                            )
                        except Exception as mtf_guard_err:
                            logger.debug(f"MTF Guard error: {mtf_guard_err}")
                    
                    # UPDATE MTF TRENDS for coins with active signals (before processing)
                    # Bounded by time/symbol budget so scanner loop cannot stall.
                    mtf_update_symbols = []
                    mtf_seen = set()

                    for signal in multi_coin_scanner.active_signals:
                        s = signal.get('symbol', '')
                        if s and s not in mtf_seen:
                            mtf_seen.add(s)
                            mtf_update_symbols.append(s)

                    # FIB pre-warm only in SMART_V2 to keep LEGACY path lightweight.
                    strategy_mode_upper = str(getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY)).upper()
                    if FIB_ENABLED and strategy_mode_upper == STRATEGY_MODE_SMART_V2:
                        for opp in opportunities:
                            s = opp.get('symbol', '')
                            if s and s not in mtf_seen and opp.get('signalScore', 0) > 0:
                                mtf_seen.add(s)
                                mtf_update_symbols.append(s)
                            if len(mtf_update_symbols) >= (SCANNER_MTF_UPDATE_MAX_SYMBOLS * 2):
                                break

                    mtf_budget_start = datetime.now().timestamp()
                    mtf_updated = 0
                    mtf_timeout_count = 0
                    for sym in mtf_update_symbols:
                        if mtf_updated >= SCANNER_MTF_UPDATE_MAX_SYMBOLS:
                            break
                        if datetime.now().timestamp() - mtf_budget_start >= SCANNER_MTF_UPDATE_BUDGET_SEC:
                            break
                        try:
                            if multi_coin_scanner.exchange:
                                await asyncio.wait_for(
                                    mtf_confirmation.update_coin_trend(sym, multi_coin_scanner.exchange),
                                    timeout=SCANNER_MTF_UPDATE_TIMEOUT_SEC
                                )
                                mtf_updated += 1
                        except asyncio.TimeoutError:
                            mtf_timeout_count += 1
                            logger.debug(f"MTF update timeout for {sym}")
                        except Exception as mtf_err:
                            logger.debug(f"MTF update error for {sym}: {mtf_err}")

                    if (loop_iter % 20 == 0) and (mtf_timeout_count > 0 or len(mtf_update_symbols) > mtf_updated):
                        logger.info(
                            f"ðŸ“Š MTF_BUDGET: requested={len(mtf_update_symbols)} updated={mtf_updated} "
                            f"timeouts={mtf_timeout_count} budget={SCANNER_MTF_UPDATE_BUDGET_SEC:.1f}s"
                        )
                    
                    for signal in multi_coin_scanner.active_signals:
                        try:
                            symbol = signal.get('symbol', 'UNKNOWN')
                            price = signal.get('price', 0)
                            
                            # Update paper trader symbol temporarily for this signal
                            old_symbol = global_paper_trader.symbol
                            global_paper_trader.symbol = symbol
                            
                            # Get latest ATR from analyzer
                            if symbol in multi_coin_scanner.analyzers:
                                analyzer = multi_coin_scanner.analyzers[symbol]
                                current_atr = analyzer.opportunity.atr
                                signal['atr'] = current_atr
                            
                            # Execute trade (includes MTF confirmation check)
                            await process_signal_for_paper_trading(signal, price)
                            
                            # Restore symbol
                            global_paper_trader.symbol = old_symbol
                            
                        except Exception as sig_error:
                            logger.debug(f"Signal processing error for {symbol}: {sig_error}")
                            continue
                
                # =====================================================================
                # PHASE 32: UPDATE OPEN POSITIONS WITH REAL-TIME PRICES
                # =====================================================================
                for pos in list(global_paper_trader.positions):
                    try:
                        pos_symbol = pos.get('symbol', '')
                        
                        # Find current price for this position from scanner data
                        current_price = None
                        for opp in opportunities:
                            if opp.get('symbol') == pos_symbol:
                                current_price = opp.get('price', 0)
                                break
                        
                        if current_price and current_price > 0:
                            # Calculate unrealized PnL
                            entry_price = pos.get('entryPrice', current_price)
                            size = pos.get('size', 0)
                            size_usd = pos.get('sizeUsd', 0)
                            leverage = pos.get('leverage', 1)
                            
                            if pos['side'] == 'LONG':
                                pnl = (current_price - entry_price) * size
                            else:
                                pnl = (entry_price - current_price) * size
                            
                            pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
                            
                            pos['unrealizedPnl'] = round(pnl, 2)
                            pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
                            pos['currentPrice'] = current_price  # Store for frontend
                            
                            # =========================================================
                            # Phase 183: PENDING LIMIT CLOSE MONITOR
                            # Check if any pending limit orders (TP/Trail) have filled
                            # or timed out â†’ market fallback
                            # =========================================================
                            pending = pos.get('pending_limit_close')
                            if pending and pos.get('isLive', False) and live_binance_trader.enabled:
                                order_id = pending.get('order_id')
                                placed_at = pending.get('placed_at', 0)
                                timeout = pending.get('timeout_seconds', 60)
                                reason = pending.get('reason', 'TP_HIT')
                                elapsed = datetime.now().timestamp() - placed_at
                                
                                try:
                                    order_status = await live_binance_trader.check_order_status(pos_symbol, order_id)
                                    status = order_status.get('status', 'unknown')
                                    
                                    if status == 'closed':
                                        # Phase 185: Check for partial fills
                                        fill_price = order_status.get('average', pending.get('limit_price', current_price))
                                        remaining_amt = order_status.get('remaining', 0)
                                        filled_amt = order_status.get('filled', 0)
                                        
                                        if remaining_amt > 0:
                                            # Phase 232: Partial fill â†’ weighted avg exit price
                                            logger.warning(f"âš ï¸ LIMIT_PARTIAL: {pos_symbol} filled={filled_amt:.4f} remaining={remaining_amt:.4f} â†’ market closing rest")
                                            limit_avg = fill_price
                                            market_avg = current_price
                                            try:
                                                mkt_result = await live_binance_trader.close_position(pos_symbol, pos['side'], remaining_amt)
                                                if mkt_result and mkt_result.get('average'):
                                                    market_avg = float(mkt_result['average'])
                                            except Exception as pf_err:
                                                logger.error(f"âŒ Partial fill market close error: {pf_err}")
                                            # Weighted average exit
                                            exit_avg = (filled_amt * limit_avg + remaining_amt * market_avg) / (filled_amt + remaining_amt) if (filled_amt + remaining_amt) > 0 else fill_price
                                        else:
                                            exit_avg = fill_price
                                        
                                        logger.warning(f"âœ… LIMIT_FILLED: {pos_symbol} {pos['side']} @ ${exit_avg:.6f} | Reason: {reason} | Elapsed: {elapsed:.0f}s")
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, exit_avg, reason)
                                        continue
                                    elif status == 'canceled' or status == 'expired':
                                        # Phase 232: Distinct reason for cancelled orders
                                        cancel_reason = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                                        logger.warning(f"âš ï¸ LIMIT_CANCELLED: {pos_symbol} order {order_id} â€” market close")
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, cancel_reason)
                                        continue
                                    elif elapsed >= timeout:
                                        # Phase 232: Distinct reason for timeout
                                        timeout_reason = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                                        logger.warning(f"â° LIMIT_TIMEOUT: {pos_symbol} {reason} not filled in {elapsed:.0f}s â†’ cancel + market")
                                        await live_binance_trader.cancel_order(pos_symbol, order_id)
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, timeout_reason)
                                        continue
                                    else:
                                        # Still open â€” skip this position's SL/TP checks
                                        continue
                                except Exception as e:
                                    logger.error(f"Limit monitor error {pos_symbol}: {e}")
                                    if elapsed >= timeout:
                                        # Timeout reached even with error â€” force market close
                                        try:
                                            await live_binance_trader.cancel_order(pos_symbol, order_id)
                                        except:
                                            pass
                                        del pos['pending_limit_close']
                                        global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                                        continue
                            
                            # Check SL/TP
                            # Phase 190: Skip if limit close is pending (breakeven or TP)
                            if pos.get('pending_limit_close'):
                                continue
                            
                            # Phase 212: Emergency SL runs BEFORE Flash Trade Guard
                            # Flash crash korumasÄ± ilk 60 saniyede de aktif olmalÄ±
                            sl_ws = pos.get('stopLoss', 0)
                            trailing_stop_ws = pos.get('trailingStop', sl_ws)
                            if check_emergency_sl_static(pos, current_price, trailing_stop_ws):
                                excess_pct = abs(current_price - trailing_stop_ws) / entry_price * 100
                                reason = 'EMERGENCY_SL'
                                logger.warning(f"ðŸš¨ EMERGENCY SL (pre-guard): {pos_symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop_ws:.6f} | AÅŸÄ±m: {excess_pct:.2f}%")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                            
                            # Phase 210: Flash Trade Guard â€” minimum 60s hold time
                            MIN_HOLD_SECONDS_WS = 60
                            open_time_ms_ws = pos.get('openTime', 0)
                            if open_time_ms_ws > 0:
                                hold_duration_ws = datetime.now().timestamp() - (open_time_ms_ws / 1000)
                                if hold_duration_ws < MIN_HOLD_SECONDS_WS:
                                    continue  # Skip all exit checks â€” too early
                            
                            # Phase 205: Use candle close price for exit DECISIONS (SL/TP/trail)
                            # Prevents false triggers from intra-candle wicks/spikes
                            candle_close_price = last_candle_close.get(pos_symbol, current_price)
                            
                            sl = pos.get('stopLoss', 0)
                            tp = pos.get('takeProfit', 0)
                            trailing_stop = pos.get('trailingStop', sl)
                            
                            # Phase 221: Breakeven SL varsa, trailing_stop'u breakeven seviyesinde tut
                            if pos.get('breakeven_activated', False) and sl > 0:
                                if pos['side'] == 'LONG':
                                    trailing_stop = max(trailing_stop, sl)
                                else:
                                    trailing_stop = min(trailing_stop, sl)
                                pos['trailingStop'] = trailing_stop
                            
                            # =========================================================
                            # Phase 202: STEPPED SL LOCK for Trend Mode positions
                            # Freqtrade custom_stoploss pattern â€” lock profits as they grow
                            # =========================================================
                            # Phase 221: Stepped SL tÃ¼m trail-aktif pozisyonlara uygulanÄ±r (was trend_mode only)
                            if pos.get('isTrailingActive', False) and entry_price > 0:
                                if pos['side'] == 'LONG':
                                    current_roi = (candle_close_price - entry_price) / entry_price * 100
                                else:
                                    current_roi = (entry_price - candle_close_price) / entry_price * 100
                                
                                stepped_sl = None
                                if current_roi >= 10:
                                    # Lock %7 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.07
                                    else:
                                        stepped_sl = entry_price * 0.93
                                elif current_roi >= 5:
                                    # Lock %3 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.03
                                    else:
                                        stepped_sl = entry_price * 0.97
                                elif current_roi >= 2:
                                    # Lock %1 profit
                                    if pos['side'] == 'LONG':
                                        stepped_sl = entry_price * 1.01
                                    else:
                                        stepped_sl = entry_price * 0.99
                                elif current_roi >= 0.5:
                                    # Breakeven lock
                                    stepped_sl = entry_price
                                
                                if stepped_sl is not None:
                                    # Only ratchet UP (LONG) or DOWN (SHORT) â€” never weaken
                                    if pos['side'] == 'LONG' and stepped_sl > trailing_stop:
                                        old_sl = trailing_stop
                                        trailing_stop = stepped_sl
                                        pos['trailingStop'] = stepped_sl
                                        if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                                            logger.info(f"ðŸ”’ STEPPED_SL: {pos.get('symbol','?')} LONG ROI={current_roi:.1f}% | SL ${old_sl:.6f} â†’ ${stepped_sl:.6f}")
                                    elif pos['side'] == 'SHORT' and stepped_sl < trailing_stop:
                                        old_sl = trailing_stop
                                        trailing_stop = stepped_sl
                                        pos['trailingStop'] = stepped_sl
                                        if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                                            logger.info(f"ðŸ”’ STEPPED_SL: {pos.get('symbol','?')} SHORT ROI={current_roi:.1f}% | SL ${old_sl:.6f} â†’ ${stepped_sl:.6f}")
                            
                            # =========================================================
                            # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                            # SL triggers ONLY after 5 consecutive ticks AND 30 seconds
                            # of sustained breach. Protects against 1-min wick spikes.
                            # =========================================================
                            SL_CONFIRMATION_TICKS = 5  # Ticks required
                            SL_CONFIRMATION_SECONDS = 15  # Minimum seconds in SL zone
                            
                            # Initialize confirmation state
                            if 'slConfirmCount' not in pos:
                                pos['slConfirmCount'] = 0
                            if 'slBreachStartTime' not in pos:
                                pos['slBreachStartTime'] = 0
                            
                            # Check if price is in SL zone (candle close based)
                            sl_breached = False
                            if pos['side'] == 'LONG' and candle_close_price <= trailing_stop:
                                sl_breached = True
                            elif pos['side'] == 'SHORT' and candle_close_price >= trailing_stop:
                                sl_breached = True
                            
                            # =========================================================
                            # Phase 205b: EMERGENCY SL â€” tick price WAY past SL
                            # If current_price exceeds SL by >1.5% of entry, close
                            # immediately. Bypasses both candle close AND spike confirm.
                            # Protects against major crashes mid-candle.
                            # =========================================================
                            if check_emergency_sl_static(pos, current_price, trailing_stop):
                                excess_pct = abs(current_price - trailing_stop) / entry_price * 100
                                reason = 'EMERGENCY_SL'
                                logger.warning(f"ðŸš¨ EMERGENCY SL: {pos_symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop:.6f} | AÅŸÄ±m: {excess_pct:.2f}% | Candle close: ${candle_close_price:.6f}")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                            
                            now_ts = datetime.now().timestamp()
                            if sl_breached:
                                # Phase 231c: Trail hit â†’ immediate close (no confirmation delay)
                                # Trail is profit protection â€” delay loses money
                                if pos.get('isTrailingActive', False):
                                    reason = 'TRAIL_EXIT'
                                    logger.info(f"ðŸ”´ TRAIL EXIT (immediate): {pos_symbol} {pos['side']} @ ${current_price:.6f} | Trail ${trailing_stop:.6f}")
                                    global_paper_trader.close_position(pos, current_price, reason)
                                    continue
                                
                                # Start timer on first breach (SL only, not trail)
                                if pos['slConfirmCount'] == 0:
                                    pos['slBreachStartTime'] = now_ts
                                pos['slConfirmCount'] += 1
                                breach_duration = now_ts - pos['slBreachStartTime']
                                logger.debug(f"SL breach tick {pos['slConfirmCount']}/{SL_CONFIRMATION_TICKS} ({breach_duration:.0f}s/{SL_CONFIRMATION_SECONDS}s) for {pos.get('symbol', '?')}")
                                
                                # Close only if BOTH conditions met: enough ticks AND enough time
                                if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                                    # Phase 183: Hybrid â€” limit for liquid, market for illiquid
                                    spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                                    is_trailing_hit = pos.get('isTrailingActive', False)
                                    
                                    if is_trailing_hit and spread_level in ('Very Low', 'Low') and pos.get('isLive', False) and live_binance_trader.enabled and not pos.get('pending_limit_close'):
                                        # Liquid coin trailing stop â†’ try limit order
                                        try:
                                            contracts = abs(pos.get('contracts', pos.get('size', 0)))
                                            limit_result = await live_binance_trader.close_position_limit(
                                                pos_symbol, pos['side'], contracts, trailing_stop
                                            )
                                            if limit_result and limit_result.get('id'):
                                                pos['pending_limit_close'] = {
                                                    'order_id': limit_result['id'],
                                                    'placed_at': datetime.now().timestamp(),
                                                    'limit_price': trailing_stop,
                                                    'reason': 'TRAIL_EXIT',
                                                    'timeout_seconds': 45,
                                                }
                                                logger.warning(f"ðŸ“™ TRAIL_LIMIT: {pos_symbol} {pos['side']} limit @ ${trailing_stop:.6f} (liquid coin, saves slippage)")
                                                continue
                                            else:
                                                logger.warning(f"ðŸ“™ TRAIL_LIMIT_FAIL: {pos_symbol} limit failed, market close")
                                                global_paper_trader.close_position(pos, current_price, 'TRAIL_EXIT')
                                                continue
                                        except Exception as e:
                                            logger.error(f"Trail limit error {pos_symbol}: {e}")
                                            global_paper_trader.close_position(pos, current_price, 'TRAIL_EXIT')
                                            continue
                                    else:
                                        # Illiquid coin or regular SL â†’ market close (execution certainty)
                                        logger.info(f"ðŸ”´ SL CONFIRMED: {pos.get('symbol', '?')} after {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                                        # ROI negatifse SL'den kapanmÄ±ÅŸ â€” trailing aktif olsa bile etiket SL_HIT
                                        pos_roi = pos.get('unrealizedPnlPercent', 0)
                                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive', False) and pos_roi >= 0) else 'SL_HIT'
                                        global_paper_trader.close_position(pos, current_price, reason)
                                        continue
                            else:
                                # Price recovered - reset counter (spike bypassed!)
                                if pos['slConfirmCount'] > 0:
                                    bypass_duration = now_ts - pos['slBreachStartTime']
                                    logger.info(f"âš¡ Spike bypassed for {pos.get('symbol', '?')} after {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
                                pos['slConfirmCount'] = 0
                                pos['slBreachStartTime'] = 0
                            
                            # =========================================================
                            # Phase 183: TP_HIT â†’ Limit Order (saves slippage)
                            # Place limit at TP price. If unfilled, price went higher = more profit.
                            # Market fallback after 60 seconds.
                            # =========================================================
                            tp_hit = False
                            if pos['side'] == 'LONG' and candle_close_price >= tp:
                                tp_hit = True
                            elif pos['side'] == 'SHORT' and candle_close_price <= tp:
                                tp_hit = True
                            
                            if tp_hit and not pos.get('pending_limit_close'):
                                if pos.get('isLive', False) and live_binance_trader.enabled:
                                    try:
                                        contracts = abs(pos.get('contracts', pos.get('size', 0)))
                                        limit_result = await live_binance_trader.close_position_limit(
                                            pos_symbol, pos['side'], contracts, tp
                                        )
                                        if limit_result and limit_result.get('id'):
                                            pos['pending_limit_close'] = {
                                                'order_id': limit_result['id'],
                                                'placed_at': datetime.now().timestamp(),
                                                'limit_price': tp,
                                                'reason': 'TP_HIT',
                                                'timeout_seconds': 60,
                                            }
                                            logger.warning(f"ðŸ“— TP_LIMIT: {pos_symbol} {pos['side']} limit @ ${tp:.6f} (saves slippage vs market)")
                                            continue
                                        else:
                                            # Limit failed â†’ immediate market close
                                            logger.warning(f"ðŸ“— TP_LIMIT_FAIL: {pos_symbol} limit failed, falling back to market")
                                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                            continue
                                    except Exception as e:
                                        logger.error(f"TP limit error {pos_symbol}: {e}")
                                        global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                        continue
                                else:
                                    # Paper trading â†’ immediate close
                                    global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                                    continue
                            
                            # ===================================================================
                            # Phase 214: FAILED CONTINUATION DETECTOR
                            # N kez kÃ¢ra geÃ§ip entry'ye geri dÃ¶nen pozisyonlarÄ± breakeven'da kapat
                            # ===================================================================
                            fc_result = check_failed_continuation(pos, candle_close_price)
                            if fc_result == 'FAILED_CONTINUATION':
                                fc_count = pos.get('fc_failed_count', 0)
                                logger.warning(f"ðŸ“Š FAILED_CONTINUATION: {pos_symbol} {pos['side']} â€” {fc_count} baÅŸarÄ±sÄ±z deneme, breakeven kapatÄ±lÄ±yor")
                                # Breakeven close: dynamic buffer (Phase 238A)
                                _be_spread = pos.get('spreadPct', 0.05)
                                _be_buf = compute_breakeven_buffer_pct(spread_pct=_be_spread, spread_level=pos.get('spreadLevel', 'LOW'), reason='FAILED_CONTINUATION')
                                be_exit_price = entry_price * (1 + _be_buf) if pos['side'] == 'LONG' else entry_price * (1 - _be_buf)
                                pos['beBufferPct'] = round(_be_buf * 100, 4)
                                pos['beBufferSource'] = 'dynamic'
                                logger.info(f"BE_BUFFER: {pos_symbol} {pos['side']} reason=FC spread={_be_spread}% â†’ buffer={_be_buf*100:.3f}%")
                                global_paper_trader.close_position(pos, be_exit_price, 'FAILED_CONTINUATION')
                                continue
                            
                            # Update trailing stop if in profit
                            trail_activation = pos.get('trailActivation', entry_price)
                            trail_distance = pos.get('trailDistance', 0)
                            
                            # Hybrid dynamic trail distance (includes exit_tightness multiplier).
                            pos_atr = pos.get('atr', entry_price * 0.02)
                            pnl_pct = pos.get('unrealizedPnlPercent', 0)
                            pos_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
                            if not pos_atr_pct and entry_price > 0:
                                pos_atr_pct = (pos_atr / entry_price) * 100
                            pos_atr_pct = pos_atr_pct or 2.0
                            pos_spread = pos.get('spreadPct', 0.05)
                            pos_vol_ratio = pos.get('volumeRatio', 1.0)
                            effective_et = global_paper_trader.get_effective_exit_tightness(pos) if global_paper_trader else 1.0
                            dynamic_trail_distance = get_hybrid_runtime_trail_distance(
                                base_trail_distance=trail_distance,
                                atr_pct=pos_atr_pct,
                                spread_pct=pos_spread,
                                volume_ratio=pos_vol_ratio,
                                roi_pct=pnl_pct,
                                exit_tightness=effective_et,
                                hurst=pos.get('hurst', 0.5),
                                adx=pos.get('adx', 20.0),
                            )
                            
                            # Phase 231d: Dynamic trail activation threshold (ATR + spread + volume)
                            leverage = pos.get('leverage', 10)
                            if pos['side'] == 'LONG':
                                price_move_pct = ((candle_close_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                            else:
                                price_move_pct = ((entry_price - candle_close_price) / entry_price) * 100 if entry_price > 0 else 0
                            roi_pct = price_move_pct * leverage
                            
                            # Dynamic thresholds from market conditions
                            threshold_mult = math.sqrt(_clamp(effective_et, 0.3, 15.0))
                            min_price_move_for_trail, min_roi_for_trail = get_dynamic_trail_activation_threshold(
                                pos_atr_pct, pos_spread, pos_vol_ratio, leverage, threshold_mult=threshold_mult
                            )
                            update_runtime_trail_telemetry(
                                pos=pos,
                                dynamic_trail_distance=dynamic_trail_distance,
                                effective_exit_tightness=effective_et,
                                min_price_move_pct=min_price_move_for_trail,
                                min_roi_pct=min_roi_for_trail,
                                threshold_mult=threshold_mult,
                                entry_price=entry_price,
                            )
                            
                            # Phase 231h â†’ 238A: Dynamic fee buffer for breakeven
                            _sc_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP')
                            be_long = entry_price * (1 + _sc_buf)
                            be_short = entry_price * (1 - _sc_buf)
                            
                            if pos['side'] == 'LONG':
                                trail_already_active = pos.get('isTrailingActive', False)
                                # Hybrid rule: price_move >= min OR (roi >= min_roi AND price_move >= min*0.6)
                                trail_should_activate = (
                                    price_move_pct >= min_price_move_for_trail or
                                    (roi_pct >= min_roi_for_trail and price_move_pct >= min_price_move_for_trail * 0.6)
                                )
                                if trail_should_activate or trail_already_active:
                                    new_trailing = candle_close_price - dynamic_trail_distance
                                    # Phase 231h: Clamp â€” trail stop never below breakeven
                                    new_trailing = max(new_trailing, be_long)
                                    if new_trailing > trailing_stop:
                                        pos['trailingStop'] = new_trailing
                                        if not trail_already_active:
                                            pos['isTrailingActive'] = True
                                            # Breakeven SL on first activation
                                            pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                                            logger.info(f"ðŸ“Š TRAIL_DYN: {pos_symbol} LONG trail ON | move={price_move_pct:.2f}% roi={roi_pct:.1f}% | thresh: move>={min_price_move_for_trail:.2f}% roi>={min_roi_for_trail:.1f}% | vr={pos_vol_ratio:.1f} sp={pos_spread:.3f}% atr={pos_atr_pct:.1f}%")
                            elif pos['side'] == 'SHORT':
                                trail_already_active = pos.get('isTrailingActive', False)
                                trail_should_activate = (
                                    price_move_pct >= min_price_move_for_trail or
                                    (roi_pct >= min_roi_for_trail and price_move_pct >= min_price_move_for_trail * 0.6)
                                )
                                if trail_should_activate or trail_already_active:
                                    new_trailing = candle_close_price + dynamic_trail_distance
                                    # Phase 231h: Clamp â€” trail stop never above breakeven
                                    new_trailing = min(new_trailing, be_short)
                                    if new_trailing < trailing_stop:
                                        pos['trailingStop'] = new_trailing
                                        if not trail_already_active:
                                            pos['isTrailingActive'] = True
                                            pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                                            logger.info(f"ðŸ“Š TRAIL_DYN: {pos_symbol} SHORT trail ON | move={price_move_pct:.2f}% roi={roi_pct:.1f}% | thresh: move>={min_price_move_for_trail:.2f}% roi>={min_roi_for_trail:.1f}% | vr={pos_vol_ratio:.1f} sp={pos_spread:.3f}% atr={pos_atr_pct:.1f}%")
                                    
                    except Exception as pos_error:
                        logger.debug(f"Position update error: {pos_error}")
                        continue
                
                # =====================================================================
                # Phase 231: TIME-BASED POSITION MANAGEMENT (moved here from before price update)
                # Now runs AFTER position prices/PnL are updated â€” fixes stale partial TP check
                # =====================================================================
                if global_paper_trader.enabled and global_paper_trader.positions:
                    logger.info(f"ðŸ“Š TIME_MANAGER_CALL: positions={len(global_paper_trader.positions)}")
                    time_actions = await time_based_position_manager.check_positions(global_paper_trader)
                    if time_actions.get('trail_activated') or time_actions.get('time_reduced') or time_actions.get('partial_tp'):
                        logger.info(f"ðŸ“Š Time Manager Actions: Trail={time_actions['trail_activated']}, Reduced={time_actions['time_reduced']}, TP={time_actions.get('partial_tp', [])}")
                
                # =====================================================================
                # PHASE 34: CHECK PENDING ORDERS FOR EXECUTION
                # =====================================================================
                # Phase 50: Calculate dynamic min score before processing signals
                global_paper_trader.calculate_dynamic_min_score()
                
                await global_paper_trader.check_pending_orders(opportunities)
                
                # Phase 237D: Evaluate reject attribution with current prices
                if REJECT_ATTRIBUTION_ENABLED:
                    try:
                        _current_prices = {}
                        for opp in opportunities:
                            _s = opp.get('symbol', '')
                            _p = opp.get('currentPrice', opp.get('price', 0))
                            if _s and _p:
                                _current_prices[_s] = float(_p)
                        if _current_prices:
                            evaluate_reject_attribution(_current_prices)
                    except Exception:
                        pass
                
                # Broadcast position updates to UI (throttled)
                if global_paper_trader.positions:
                    await ui_ws_manager.broadcast_price_update(global_paper_trader.positions)
                
                # Log periodic status (every 5 minutes = 30 iterations)
                if int(datetime.now().timestamp()) % 300 < scan_interval:
                    long_count = stats.get('longSignals', 0)
                    short_count = stats.get('shortSignals', 0)
                    pending_count = len(global_paper_trader.pending_orders)
                    tracking_count = len(post_trade_tracker.tracking)
                    logger.info(f"ðŸ“Š Scanner Status: {stats.get('analyzedCoins', 0)} coins | L:{long_count} S:{short_count} | Pending: {pending_count} | Tracking: {tracking_count}")
                
                # Phase 52: Update post-trade tracker with current prices (EVERY scan cycle for accurate tracking)
                try:
                    if post_trade_tracker.tracking:  # Only if we have trades to track
                        current_prices = {opp['symbol']: opp.get('currentPrice', 0) for opp in opportunities}
                        completed_analyses = post_trade_tracker.update_prices(current_prices)
                        if completed_analyses:
                            logger.info(f"ðŸ“Š Post-trade: {len(completed_analyses)} trade analizi tamamlandÄ±")
                except Exception as pt_error:
                    logger.debug(f"Post-trade update error: {pt_error}")
                
                # Phase 224D: Detect market regime periodically (every scan cycle)
                try:
                    market_regime_manager.detect_regime()
                except Exception as mr_err:
                    logger.debug(f"Regime detection error: {mr_err}")
                
                # Phase 224C3: Apply PostTradeTracker tuning recommendations every 15 min
                if int(datetime.now().timestamp()) % 900 < scan_interval:
                    try:
                        tuning = post_trade_tracker.get_tuning_recommendations()
                        if tuning:
                            regime_profile = market_regime_manager.get_profile()
                            # Store tuning for use in update loop
                            global_paper_trader._tuning_recs = tuning
                            logger.info(f"ðŸ“Š Applied tuning: {tuning} regime={market_regime_manager.current_regime}")
                    except Exception as tune_err:
                        logger.debug(f"Tuning recommendations error: {tune_err}")
                
                # Phase 52: Run optimizer every 15 minutes (900 seconds)
                if int(datetime.now().timestamp()) % 900 < scan_interval:
                    logger.info("ðŸ¤– AI Optimizer check triggered (15-min interval)")
                    try:
                        # Phase 53: Update market regime with BTC price
                        btc_opp = next((o for o in opportunities if o['symbol'] == 'BTCUSDT'), None)
                        if btc_opp:
                            market_regime_detector.update_btc_price(btc_opp.get('currentPrice', 0))
                        regime = market_regime_detector.detect_regime()
                        regime_params = market_regime_detector.get_regime_params()
                        
                        pt_stats = post_trade_tracker.get_stats()
                        analysis = performance_analyzer.analyze(global_paper_trader.trades, pt_stats)
                        
                        # Add market regime to analysis
                        if analysis:
                            analysis['market_regime'] = regime
                            analysis['regime_params'] = regime_params
                        
                        if analysis:
                            current_settings = {
                                'z_score_threshold': global_paper_trader.z_score_threshold,
                                'min_score_low': global_paper_trader.min_score_low,
                                'min_score_high': global_paper_trader.min_score_high,
                                'entry_tightness': global_paper_trader.entry_tightness,
                                'max_positions': global_paper_trader.max_positions,
                            }
                            optimization = parameter_optimizer.optimize(analysis, current_settings)
                            
                            # Log AI analysis
                            total_pnl = analysis.get('total_pnl', 0)
                            corr_count = optimization.get('correlations_count', 0)
                            snapshots = optimization.get('trades_with_snapshot', 0)
                            logger.info(f"ðŸ¤– AI: PnL ${total_pnl:.0f} | WR {analysis.get('win_rate', 0):.0f}% | Correlations: {corr_count} | Snapshots: {snapshots}")
                            global_paper_trader.add_log(f"ðŸ¤– AI: PnL ${total_pnl:.0f} | WR {analysis.get('win_rate', 0):.0f}% | PF {analysis.get('profit_factor', 0):.2f}")
                            
                            if optimization.get('changes'):
                                global_paper_trader.add_log(f"ðŸ¤– Ã–neri: {', '.join(optimization.get('changes', [])[:3])}")
                            
                            if optimization.get('recommendations') and parameter_optimizer.enabled:
                                applied = parameter_optimizer.apply_recommendations(global_paper_trader, optimization['recommendations'])
                                if applied:
                                    logger.info(f"ðŸ¤– AI Optimizer: Applied {list(applied.keys())}")
                                    global_paper_trader.add_log(f"ðŸ¤– Ayarlar gÃ¼ncellendi âœ…")
                        else:
                            logger.info("ðŸ¤– AI Optimizer: No analysis data available")
                    except Exception as opt_error:
                        logger.error(f"ðŸ¤– AI Optimizer error: {opt_error}")
                
                await asyncio.sleep(scan_interval)
                
            except Exception as loop_error:
                import traceback
                logger.error(f"ðŸ”´ Scanner loop error: {loop_error}")
                logger.error(f"ðŸ”´ Traceback:\n{traceback.format_exc()}")
                await asyncio.sleep(5)  # Wait before retry
                
    except asyncio.CancelledError:
        logger.info("Background Scanner Loop cancelled")
        multi_coin_scanner.running = False
    except Exception as e:
        import traceback
        logger.error(f"ðŸ”´ Scanner FATAL error: {e}")
        logger.error(f"ðŸ”´ Traceback:\n{traceback.format_exc()}")
        logger.error(f"Background scanner fatal error: {e}")
        multi_coin_scanner.running = False

# ============================================================================
# PHASE 191: REAL-TIME WEBSOCKET POSITION PRICE CALLBACK
# ============================================================================

async def on_position_price_update(symbol: str, ticker: dict):
    """
    Phase 191: WebSocket'ten gelen her fiyat gÃ¼ncellemesinde Ã§aÄŸrÄ±lÄ±r (~100ms).
    Aktif pozisyonun fiyatÄ±nÄ± gÃ¼nceller ve SL/TP/trailing kontrol eder.
    """
    current_price = ticker.get('last', 0)
    if current_price <= 0:
        return
    
    for pos in list(global_paper_trader.positions):
        if pos.get('symbol') != symbol:
            continue
        
        # ---- Fiyat + PnL gÃ¼ncelle ----
        entry_price = pos.get('entryPrice', current_price)
        size = pos.get('size', 0)
        size_usd = pos.get('sizeUsd', 0)
        leverage = pos.get('leverage', 1)
        
        if pos['side'] == 'LONG':
            pnl = (current_price - entry_price) * size
        else:
            pnl = (entry_price - current_price) * size
        
        pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
        
        pos['currentPrice'] = current_price
        pos['unrealizedPnl'] = round(pnl, 6)
        pos['unrealizedPnlPercent'] = round(pnl_percent, 2)

        # Keep UI cache hot between scanner cycles for faster frontend updates.
        try:
            for cached_pos in ui_state_cache.positions:
                if cached_pos.get('symbol') != symbol:
                    continue
                cached_pos['currentPrice'] = current_price
                cached_pos['markPrice'] = current_price
                cached_pos['unrealizedPnl'] = round(pnl, 6)
                cached_pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
        except Exception:
            pass
        
        # ---- Pending limit close varsa SL/TP atla ----
        pending = pos.get('pending_limit_close')
        if pending and pos.get('isLive', False) and live_binance_trader.enabled:
            order_id = pending.get('order_id')
            placed_at = pending.get('placed_at', 0)
            timeout = pending.get('timeout_seconds', 60)
            reason = pending.get('reason', 'TP_HIT')
            elapsed = datetime.now().timestamp() - placed_at
            
            try:
                order_check = await live_binance_trader.check_order_status(symbol, order_id)
                chk_status = order_check.get('status', 'unknown')
                
                if chk_status == 'closed':
                    fill_price = order_check.get('average', pending.get('limit_price', current_price))
                    remaining_amt = order_check.get('remaining', 0)
                    filled_amt_ws = order_check.get('filled', 0)
                    if remaining_amt > 0:
                        limit_avg_ws = fill_price
                        market_avg_ws = current_price
                        try:
                            mkt_r = await live_binance_trader.close_position(symbol, pos['side'], remaining_amt)
                            if mkt_r and mkt_r.get('average'):
                                market_avg_ws = float(mkt_r['average'])
                        except:
                            pass
                        exit_avg_ws = (filled_amt_ws * limit_avg_ws + remaining_amt * market_avg_ws) / (filled_amt_ws + remaining_amt) if (filled_amt_ws + remaining_amt) > 0 else fill_price
                    else:
                        exit_avg_ws = fill_price
                    logger.warning(f"âœ… WS_LIMIT_FILLED: {symbol} @ ${exit_avg_ws:.6f} | {reason} | {elapsed:.0f}s")
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, exit_avg_ws, reason)
                    continue
                elif chk_status in ('canceled', 'expired'):
                    cancel_reason_ws = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, cancel_reason_ws)
                    continue
                elif elapsed >= timeout:
                    timeout_reason_ws = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                    logger.warning(f"â° WS_TIMEOUT: {symbol} {reason} {elapsed:.0f}s â†’ market")
                    await live_binance_trader.cancel_order(symbol, order_id)
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, timeout_reason_ws)
                    continue
                else:
                    continue  # Still pending â€” skip SL/TP
            except Exception as pe:
                if elapsed >= timeout:
                    try:
                        await live_binance_trader.cancel_order(symbol, order_id)
                    except:
                        pass
                    del pos['pending_limit_close']
                    global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                    continue
            continue  # pending_limit_close aktif, SL/TP atla
        
        if pos.get('pending_limit_close'):
            continue
        
        # ---- SL/TP KontrolÃ¼ (Spike Bypass ile) ----
        # Phase 205: Use candle close price for exit DECISIONS
        candle_close_price = last_candle_close.get(symbol, current_price)
        
        sl = pos.get('stopLoss', 0)
        tp = pos.get('takeProfit', 0)
        trailing_stop = pos.get('trailingStop', sl)
        
        # Phase 231i: Stepped SL for ALL trail-active positions (was trend_mode only)
        # Aligned with scanner path (L7816) which already uses isTrailingActive
        if pos.get('isTrailingActive', False) and entry_price > 0:
            if pos['side'] == 'LONG':
                current_roi = (candle_close_price - entry_price) / entry_price * 100
            else:
                current_roi = (entry_price - candle_close_price) / entry_price * 100
            
            stepped_sl = None
            if current_roi >= 10:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.07
                else:
                    stepped_sl = entry_price * 0.93
            elif current_roi >= 5:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.03
                else:
                    stepped_sl = entry_price * 0.97
            elif current_roi >= 2:
                if pos['side'] == 'LONG':
                    stepped_sl = entry_price * 1.01
                else:
                    stepped_sl = entry_price * 0.99
            elif current_roi >= 0.5:
                stepped_sl = entry_price
            
            if stepped_sl is not None:
                if pos['side'] == 'LONG' and stepped_sl > trailing_stop:
                    old_sl = trailing_stop
                    trailing_stop = stepped_sl
                    pos['trailingStop'] = stepped_sl
                    if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                        logger.info(f"ðŸ”’ STEPPED_SL(WS): {symbol} LONG ROI={current_roi:.1f}% | SL ${old_sl:.6f} â†’ ${stepped_sl:.6f}")
                elif pos['side'] == 'SHORT' and stepped_sl < trailing_stop:
                    old_sl = trailing_stop
                    trailing_stop = stepped_sl
                    pos['trailingStop'] = stepped_sl
                    if abs(old_sl - stepped_sl) / entry_price * 100 > 0.5:
                        logger.info(f"ðŸ”’ STEPPED_SL(WS): {symbol} SHORT ROI={current_roi:.1f}% | SL ${old_sl:.6f} â†’ ${stepped_sl:.6f}")
        
        SL_CONFIRMATION_TICKS = 3
        SL_CONFIRMATION_SECONDS = 15
        SL_MAX_WAIT_SECONDS = 60  # Phase 217: Sakin piyasada max bekleme
        
        if 'slConfirmCount' not in pos:
            pos['slConfirmCount'] = 0
        if 'slBreachStartTime' not in pos:
            pos['slBreachStartTime'] = 0
        
        sl_breached = False
        if pos['side'] == 'LONG' and candle_close_price <= trailing_stop:
            sl_breached = True
        elif pos['side'] == 'SHORT' and candle_close_price >= trailing_stop:
            sl_breached = True
        
        # Phase 205b: EMERGENCY SL â€” tick price WAY past SL
        if check_emergency_sl_static(pos, current_price, trailing_stop):
            excess_pct = abs(current_price - trailing_stop) / entry_price * 100
            logger.warning(f"ðŸš¨ EMERGENCY SL (WS): {symbol} {pos['side']} @ ${current_price:.6f} | SL ${trailing_stop:.6f} | AÅŸÄ±m: {excess_pct:.2f}%")
            global_paper_trader.close_position(pos, current_price, 'EMERGENCY_SL')
            continue
        
        now_ts = datetime.now().timestamp()
        if sl_breached:
            # Phase 231c: Trail hit â†’ immediate close (no confirmation delay)
            if pos.get('isTrailingActive', False):
                reason = 'TRAIL_EXIT'
                logger.info(f"ðŸ”´ TRAIL EXIT (immediate, WS): {symbol} {pos['side']} @ ${current_price:.6f} | Trail ${trailing_stop:.6f}")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
            
            if pos['slConfirmCount'] == 0:
                pos['slBreachStartTime'] = now_ts
            pos['slConfirmCount'] += 1
            breach_duration = now_ts - pos['slBreachStartTime']
            if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                reason = 'SL_HIT'
                logger.info(f"ðŸ”´ SL CONFIRMED (WS): {symbol} @ ${current_price:.6f} | {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
            elif breach_duration >= SL_MAX_WAIT_SECONDS:
                # Phase 217: Sakin piyasada tick gelmese bile sÃ¼re doldu
                reason = 'TRAIL_EXIT' if pos.get('isTrailingActive', False) else 'SL_HIT'
                logger.info(f"ðŸ”´ SL TIMEOUT (WS): {symbol} @ ${current_price:.6f} | {breach_duration:.0f}s timeout")
                global_paper_trader.close_position(pos, current_price, reason)
                continue
        else:
            if pos['slConfirmCount'] > 0:
                bypass_duration = now_ts - pos['slBreachStartTime']
                logger.info(f"âš¡ Spike bypassed (WS): {symbol} | {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
            pos['slConfirmCount'] = 0
            pos['slBreachStartTime'] = 0
        
        # TP Hit Check (anÄ±nda â€” kar iÃ§in onay gerekmez)
        # Phase 205: Use candle close for TP decision
        if pos['side'] == 'LONG' and candle_close_price >= tp:
            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
            logger.info(f"âœ… TP triggered (WS): LONG {symbol} @ ${current_price:.6f} (candle close ${candle_close_price:.6f})")
            continue
        elif pos['side'] == 'SHORT' and candle_close_price <= tp:
            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
            logger.info(f"âœ… TP triggered (WS): SHORT {symbol} @ ${current_price:.6f} (candle close ${candle_close_price:.6f})")
            continue
        
        # ---- Phase 214: FAILED CONTINUATION DETECTOR (WS) ----
        fc_result_ws = check_failed_continuation(pos, candle_close_price)
        if fc_result_ws == 'FAILED_CONTINUATION':
            fc_count_ws = pos.get('fc_failed_count', 0)
            logger.warning(f"ðŸ“Š FAILED_CONTINUATION (WS): {symbol} {pos['side']} â€” {fc_count_ws} baÅŸarÄ±sÄ±z deneme")
            _be_spread_ws = pos.get('spreadPct', 0.05)
            _be_buf_ws = compute_breakeven_buffer_pct(spread_pct=_be_spread_ws, spread_level=pos.get('spreadLevel', 'LOW'), reason='FAILED_CONTINUATION')
            be_exit_ws = entry_price * (1 + _be_buf_ws) if pos['side'] == 'LONG' else entry_price * (1 - _be_buf_ws)
            pos['beBufferPct'] = round(_be_buf_ws * 100, 4)
            pos['beBufferSource'] = 'dynamic'
            logger.info(f"BE_BUFFER: {symbol} {pos['side']} reason=FC(WS) spread={_be_spread_ws}% â†’ buffer={_be_buf_ws*100:.3f}%")
            global_paper_trader.close_position(pos, be_exit_ws, 'FAILED_CONTINUATION')
            continue
        
        # ---- Trailing Stop GÃ¼ncelle ----
        trail_activation = pos.get('trailActivation', entry_price)
        trail_distance = pos.get('trailDistance', 0)
        
        pos_atr = pos.get('atr', entry_price * 0.02)
        ws_pnl_pct = pos.get('unrealizedPnlPercent', 0)
        
        # Dynamic trail activation threshold (ATR + spread + volume)
        ws_leverage = pos.get('leverage', 10)
        if pos['side'] == 'LONG':
            ws_price_move_pct = ((candle_close_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
        else:
            ws_price_move_pct = ((entry_price - candle_close_price) / entry_price) * 100 if entry_price > 0 else 0
        ws_roi_pct = ws_price_move_pct * ws_leverage
        
        ws_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
        if not ws_atr_pct and entry_price > 0:
            ws_atr_pct = (pos_atr / entry_price) * 100
        ws_atr_pct = ws_atr_pct or 2.0
        ws_spread = pos.get('spreadPct', 0.05)
        ws_vol_ratio = pos.get('volumeRatio', 1.0)
        effective_et = global_paper_trader.get_effective_exit_tightness(pos) if global_paper_trader else 1.0
        dynamic_trail_distance = get_hybrid_runtime_trail_distance(
            base_trail_distance=trail_distance,
            atr_pct=ws_atr_pct,
            spread_pct=ws_spread,
            volume_ratio=ws_vol_ratio,
            roi_pct=ws_pnl_pct,
            exit_tightness=effective_et,
            hurst=pos.get('hurst', 0.5),
            adx=pos.get('adx', 20.0),
        )
        threshold_mult = math.sqrt(_clamp(effective_et, 0.3, 15.0))
        ws_min_price_move, ws_min_roi = get_dynamic_trail_activation_threshold(
            ws_atr_pct, ws_spread, ws_vol_ratio, ws_leverage, threshold_mult=threshold_mult
        )
        update_runtime_trail_telemetry(
            pos=pos,
            dynamic_trail_distance=dynamic_trail_distance,
            effective_exit_tightness=effective_et,
            min_price_move_pct=ws_min_price_move,
            min_roi_pct=ws_min_roi,
            threshold_mult=threshold_mult,
            entry_price=entry_price,
        )
        
        # Phase 231h â†’ 238A: Dynamic fee buffer for breakeven
        _ws_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP_WS')
        be_long = entry_price * (1 + _ws_buf)
        be_short = entry_price * (1 - _ws_buf)
        
        ws_trail_already_active = pos.get('isTrailingActive', False)
        if pos['side'] == 'LONG':
            # Hybrid rule: price_move >= min OR (roi >= min_roi AND price_move >= min*0.6)
            ws_should_activate = (
                ws_price_move_pct >= ws_min_price_move or
                (ws_roi_pct >= ws_min_roi and ws_price_move_pct >= ws_min_price_move * 0.6)
            )
            if ws_should_activate or ws_trail_already_active:
                new_trailing = candle_close_price - dynamic_trail_distance
                # Phase 231h: Clamp â€” trail stop never below breakeven
                new_trailing = max(new_trailing, be_long)
                if new_trailing > trailing_stop:
                    pos['trailingStop'] = new_trailing
                    if not ws_trail_already_active:
                        pos['isTrailingActive'] = True
                        pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                        logger.info(f"ðŸ“Š TRAIL_DYN(WS): {pos.get('symbol')} LONG trail ON | move={ws_price_move_pct:.2f}% roi={ws_roi_pct:.1f}% | thresh: move>={ws_min_price_move:.2f}% roi>={ws_min_roi:.1f}% | vr={ws_vol_ratio:.1f} sp={ws_spread:.3f}%")
        elif pos['side'] == 'SHORT':
            ws_should_activate = (
                ws_price_move_pct >= ws_min_price_move or
                (ws_roi_pct >= ws_min_roi and ws_price_move_pct >= ws_min_price_move * 0.6)
            )
            if ws_should_activate or ws_trail_already_active:
                new_trailing = candle_close_price + dynamic_trail_distance
                new_trailing = min(new_trailing, be_short)
                if new_trailing < trailing_stop:
                    pos['trailingStop'] = new_trailing
                    if not ws_trail_already_active:
                        pos['isTrailingActive'] = True
                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                        logger.info(f"ðŸ“Š TRAIL_DYN(WS): {pos.get('symbol')} SHORT trail ON | move={ws_price_move_pct:.2f}% roi={ws_roi_pct:.1f}% | thresh: move>={ws_min_price_move:.2f}% roi>={ws_min_roi:.1f}% | vr={ws_vol_ratio:.1f} sp={ws_spread:.3f}%")


# ============================================================================
# PHASE 35: HIGH-FREQUENCY POSITION PRICE UPDATER (BACKUP)
# ============================================================================

async def position_price_update_loop():
    """
    High-frequency position price updater.
    Runs every 2 seconds to update prices ONLY for coins with open positions.
    This is 5x faster than the main scanner loop for critical position monitoring.
    """
    logger.info("âš¡ Position Price Updater started - 1.5s interval (Phase 185)")
    
    update_interval = 5.0  # Phase 191: Backup only â€” ana gÃ¼ncelleme WS callback'te
    
    # Wait for app to fully initialize
    await asyncio.sleep(5)
    
    try:
        while True:
            try:
                # Skip if no open positions
                if not global_paper_trader.positions:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Get unique symbols with open positions
                position_symbols = list(set(p.get('symbol', '') for p in global_paper_trader.positions if p.get('symbol')))
                
                if not position_symbols:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Get instant prices from WebSocket (no API call needed)
                tickers = binance_ws_manager.get_tickers(position_symbols)
                
                if not tickers:
                    await asyncio.sleep(update_interval)
                    continue
                
                # Update each open position with real-time price
                for pos in list(global_paper_trader.positions):
                    try:
                        symbol = pos.get('symbol', '')
                        ticker = tickers.get(symbol)
                        
                        if not ticker:
                            continue
                        
                        current_price = ticker.get('last', 0)
                        if current_price <= 0:
                            continue
                        
                        # Calculate unrealized PnL
                        entry_price = pos.get('entryPrice', current_price)
                        size = pos.get('size', 0)
                        size_usd = pos.get('sizeUsd', 0)
                        leverage = pos.get('leverage', 1)
                        
                        if pos['side'] == 'LONG':
                            pnl = (current_price - entry_price) * size
                        else:
                            pnl = (entry_price - current_price) * size
                        
                        pnl_percent = (pnl / size_usd) * 100 * leverage if size_usd > 0 else 0
                        
                        # Update position data
                        pos['unrealizedPnl'] = round(pnl, 6)
                        pos['unrealizedPnlPercent'] = round(pnl_percent, 2)
                        pos['currentPrice'] = current_price
                        
                        # Phase 185: Check pending limit closes in fast loop
                        pending = pos.get('pending_limit_close')
                        if pending and pos.get('isLive', False) and live_binance_trader.enabled:
                            order_id = pending.get('order_id')
                            placed_at = pending.get('placed_at', 0)
                            timeout = pending.get('timeout_seconds', 60)
                            reason = pending.get('reason', 'TP_HIT')
                            elapsed = datetime.now().timestamp() - placed_at
                            
                            try:
                                order_check = await live_binance_trader.check_order_status(symbol, order_id)
                                chk_status = order_check.get('status', 'unknown')
                                
                                if chk_status == 'closed':
                                    fill_price = order_check.get('average', pending.get('limit_price', current_price))
                                    remaining_amt = order_check.get('remaining', 0)
                                    filled_amt_fast = order_check.get('filled', 0)
                                    if remaining_amt > 0:
                                        logger.warning(f"âš ï¸ FAST_PARTIAL: {symbol} remaining={remaining_amt:.4f} â†’ market close")
                                        limit_avg_fast = fill_price
                                        market_avg_fast = current_price
                                        try:
                                            mkt_rf = await live_binance_trader.close_position(symbol, pos['side'], remaining_amt)
                                            if mkt_rf and mkt_rf.get('average'):
                                                market_avg_fast = float(mkt_rf['average'])
                                        except:
                                            pass
                                        exit_avg_fast = (filled_amt_fast * limit_avg_fast + remaining_amt * market_avg_fast) / (filled_amt_fast + remaining_amt) if (filled_amt_fast + remaining_amt) > 0 else fill_price
                                    else:
                                        exit_avg_fast = fill_price
                                    logger.warning(f"âœ… FAST_LIMIT_FILLED: {symbol} @ ${exit_avg_fast:.6f} | {reason} | {elapsed:.0f}s")
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, exit_avg_fast, reason)
                                    continue
                                elif chk_status in ('canceled', 'expired'):
                                    cancel_reason_fast = f"LIMIT_CANCELLED_MARKET_FALLBACK({reason})"
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, cancel_reason_fast)
                                    continue
                                elif elapsed >= timeout:
                                    timeout_reason_fast = f"{'TP_TIMEOUT' if 'TP' in reason else 'TRAIL_TIMEOUT'}_MARKET_FALLBACK({reason})"
                                    logger.warning(f"â° FAST_TIMEOUT: {symbol} {reason} {elapsed:.0f}s â†’ market")
                                    await live_binance_trader.cancel_order(symbol, order_id)
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, timeout_reason_fast)
                                    continue
                                else:
                                    continue  # Still pending â€” skip SL/TP checks
                            except Exception as pe:
                                if elapsed >= timeout:
                                    try:
                                        await live_binance_trader.cancel_order(symbol, order_id)
                                    except:
                                        pass
                                    del pos['pending_limit_close']
                                    global_paper_trader.close_position(pos, current_price, f"ERROR_TIMEOUT_MARKET_FALLBACK({reason})")
                                    continue
                        
                        # Check SL/TP exits with SPIKE BYPASS
                        # Phase 190: Skip if limit close is pending (breakeven or TP)
                        if pos.get('pending_limit_close'):
                            continue
                        sl = pos.get('stopLoss', 0)
                        tp = pos.get('takeProfit', 0)
                        trailing_stop = pos.get('trailingStop', sl)
                        
                        # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation
                        SL_CONFIRMATION_TICKS = 5
                        SL_CONFIRMATION_SECONDS = 15
                        
                        if 'slConfirmCount' not in pos:
                            pos['slConfirmCount'] = 0
                        if 'slBreachStartTime' not in pos:
                            pos['slBreachStartTime'] = 0
                        
                        sl_breached = False
                        if pos['side'] == 'LONG' and current_price <= trailing_stop:
                            sl_breached = True
                        elif pos['side'] == 'SHORT' and current_price >= trailing_stop:
                            sl_breached = True
                        
                        now_ts = datetime.now().timestamp()
                        if sl_breached:
                            if pos['slConfirmCount'] == 0:
                                pos['slBreachStartTime'] = now_ts
                            pos['slConfirmCount'] += 1
                            breach_duration = now_ts - pos['slBreachStartTime']
                            if pos['slConfirmCount'] >= SL_CONFIRMATION_TICKS and breach_duration >= SL_CONFIRMATION_SECONDS:
                                reason = 'TRAIL_EXIT' if pos.get('isTrailingActive', False) else 'SL_HIT'
                                logger.info(f"ðŸ”´ SL CONFIRMED (fast): {symbol} @ ${current_price:.6f} | {pos['slConfirmCount']} ticks / {breach_duration:.0f}s")
                                global_paper_trader.close_position(pos, current_price, reason)
                                continue
                        else:
                            if pos['slConfirmCount'] > 0:
                                bypass_duration = now_ts - pos['slBreachStartTime']
                                logger.info(f"âš¡ Spike bypassed (fast): {symbol} | {pos['slConfirmCount']} ticks / {bypass_duration:.0f}s")
                            pos['slConfirmCount'] = 0
                            pos['slBreachStartTime'] = 0
                        
                        # TP Hit Check (immediate - no confirmation for profits)
                        if pos['side'] == 'LONG' and current_price >= tp:
                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                            logger.info(f"âœ… TP triggered: LONG {symbol} @ ${current_price:.6f}")
                            continue
                        elif pos['side'] == 'SHORT' and current_price <= tp:
                            global_paper_trader.close_position(pos, current_price, 'TP_HIT')
                            logger.info(f"âœ… TP triggered: SHORT {symbol} @ ${current_price:.6f}")
                            continue
                        
                        # ---- Phase 214: FAILED CONTINUATION DETECTOR (backup) ----
                        # Phase 214 fix: Use candle close price, not tick price
                        fc_candle_close_bu = last_candle_close.get(symbol, current_price)
                        fc_result_bu = check_failed_continuation(pos, fc_candle_close_bu)
                        if fc_result_bu == 'FAILED_CONTINUATION':
                            fc_count_bu = pos.get('fc_failed_count', 0)
                            logger.warning(f"ðŸ“Š FAILED_CONTINUATION (backup): {symbol} {pos['side']} â€” {fc_count_bu} baÅŸarÄ±sÄ±z deneme")
                            _be_spread_bu = pos.get('spreadPct', 0.05)
                            _be_buf_bu = compute_breakeven_buffer_pct(spread_pct=_be_spread_bu, spread_level=pos.get('spreadLevel', 'LOW'), reason='FAILED_CONTINUATION')
                            be_exit_bu = entry_price * (1 + _be_buf_bu) if pos['side'] == 'LONG' else entry_price * (1 - _be_buf_bu)
                            pos['beBufferPct'] = round(_be_buf_bu * 100, 4)
                            pos['beBufferSource'] = 'dynamic'
                            logger.info(f"BE_BUFFER: {symbol} {pos['side']} reason=FC(backup) spread={_be_spread_bu}% â†’ buffer={_be_buf_bu*100:.3f}%")
                            global_paper_trader.close_position(pos, be_exit_bu, 'FAILED_CONTINUATION')
                            continue
                        
                        # Update trailing stop if in profit
                        trail_activation = pos.get('trailActivation', entry_price)
                        trail_distance = pos.get('trailDistance', 0)
                        
                        pos_atr = pos.get('atr', entry_price * 0.02)
                        fast_pnl_pct = pos.get('unrealizedPnlPercent', 0)
                        
                        # Dynamic trail activation threshold (ATR + spread + volume)
                        fast_leverage = pos.get('leverage', 10)
                        if pos['side'] == 'LONG':
                            fast_price_move = ((current_price - entry_price) / entry_price) * 100 if entry_price > 0 else 0
                        else:
                            fast_price_move = ((entry_price - current_price) / entry_price) * 100 if entry_price > 0 else 0
                        fast_roi = fast_price_move * fast_leverage
                        
                        fast_atr_pct = pos.get('volatility_pct', 0) or pos.get('volatilityPct', 0)
                        if not fast_atr_pct and entry_price > 0:
                            fast_atr_pct = (pos_atr / entry_price) * 100
                        fast_atr_pct = fast_atr_pct or 2.0
                        fast_spread = pos.get('spreadPct', 0.05)
                        fast_vol_ratio = pos.get('volumeRatio', 1.0)
                        effective_et = global_paper_trader.get_effective_exit_tightness(pos) if global_paper_trader else 1.0
                        dynamic_trail_distance = get_hybrid_runtime_trail_distance(
                            base_trail_distance=trail_distance,
                            atr_pct=fast_atr_pct,
                            spread_pct=fast_spread,
                            volume_ratio=fast_vol_ratio,
                            roi_pct=fast_pnl_pct,
                            exit_tightness=effective_et,
                            hurst=pos.get('hurst', 0.5),
                            adx=pos.get('adx', 20.0),
                        )
                        threshold_mult = math.sqrt(_clamp(effective_et, 0.3, 15.0))
                        fast_min_price_move, fast_min_roi = get_dynamic_trail_activation_threshold(
                            fast_atr_pct, fast_spread, fast_vol_ratio, fast_leverage, threshold_mult=threshold_mult
                        )
                        update_runtime_trail_telemetry(
                            pos=pos,
                            dynamic_trail_distance=dynamic_trail_distance,
                            effective_exit_tightness=effective_et,
                            min_price_move_pct=fast_min_price_move,
                            min_roi_pct=fast_min_roi,
                            threshold_mult=threshold_mult,
                            entry_price=entry_price,
                        )
                        
                        # Phase 231h â†’ 238A: Dynamic fee buffer for breakeven
                        _fast_buf = compute_breakeven_buffer_pct(spread_pct=pos.get('spreadPct', 0.05), spread_level=pos.get('spreadLevel', 'Low'), reason='TRAIL_CLAMP_FAST')
                        be_long = entry_price * (1 + _fast_buf)
                        be_short = entry_price * (1 - _fast_buf)
                        
                        fast_trail_already_active = pos.get('isTrailingActive', False)
                        if pos['side'] == 'LONG':
                            fast_should_activate = (
                                fast_price_move >= fast_min_price_move or
                                (fast_roi >= fast_min_roi and fast_price_move >= fast_min_price_move * 0.6)
                            )
                            if fast_should_activate or fast_trail_already_active:
                                new_trailing = current_price - dynamic_trail_distance
                                # Phase 231h: Clamp â€” trail stop never below breakeven
                                new_trailing = max(new_trailing, be_long)
                                if new_trailing > trailing_stop:
                                    pos['trailingStop'] = new_trailing
                                    if not fast_trail_already_active:
                                        pos['isTrailingActive'] = True
                                        pos['stopLoss'] = max(pos.get('stopLoss', 0), be_long)
                        elif pos['side'] == 'SHORT':
                            fast_should_activate = (
                                fast_price_move >= fast_min_price_move or
                                (fast_roi >= fast_min_roi and fast_price_move >= fast_min_price_move * 0.6)
                            )
                            if fast_should_activate or fast_trail_already_active:
                                new_trailing = current_price + dynamic_trail_distance
                                new_trailing = min(new_trailing, be_short)
                                if new_trailing < trailing_stop:
                                    pos['trailingStop'] = new_trailing
                                    if not fast_trail_already_active:
                                        pos['isTrailingActive'] = True
                                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), be_short)
                                
                    except Exception as pos_error:
                        logger.debug(f"Position update error for {symbol}: {pos_error}")
                        continue
                
                await asyncio.sleep(update_interval)
                
            except Exception as loop_error:
                logger.error(f"Position updater loop error: {loop_error}")
                await asyncio.sleep(update_interval)
                
    except asyncio.CancelledError:
        logger.info("Position Price Updater cancelled")
    except Exception as e:
        logger.error(f"Position updater fatal error: {e}")

async def process_signal_for_paper_trading(signal: dict, price: float):
    """Process a signal for paper trading execution."""
    if not global_paper_trader.enabled:
        return

    action = signal.get('action', 'NONE')
    if action == 'NONE':
        return

    symbol = signal.get('symbol', global_paper_trader.symbol)

    def reject_feedback(reason: str):
        try:
            global_paper_trader.set_execution_feedback(symbol, reason)
        except Exception:
            pass
    
    # ================================================================
    # Phase 142: Block signals during recovery cooldown
    # ================================================================
    if portfolio_recovery_manager.is_in_cooldown():
        cooldown_remaining = portfolio_recovery_manager.get_cooldown_remaining()
        logger.info(f"â¸ï¸ RECOVERY COOLDOWN: Skipping signal {signal.get('symbol', '?')}, {cooldown_remaining:.1f}h remaining")
        reject_feedback("RECOVERY_COOLDOWN")
        return None
    
    # Phase 225: Block signals during price shock (trade execution level gate)
    try:
        shock_blocked, shock_reason = price_shock_manager.should_block_signal(action, signal.get('symbol', ''))
        if shock_blocked:
            logger.info(f"âš¡ SHOCK_BLOCK: {signal.get('symbol', '?')} {action} blocked at execution â€” {shock_reason}")
            reject_feedback(f"SHOCK_BLOCK:{shock_reason}")
            return None
    except Exception:
        pass

    atr = signal.get('atr', 0)
    
    # Phase 127: Log signal processing entry for tracing
    logger.info(f"ðŸ”„ PROC_SIGNAL: Processing {symbol} {action} @ ${price:.4f}")
    
    # Prepare signal data for logging
    signal_log_data = {
        'symbol': symbol,
        'action': action,
        'price': price,
        'zscore': signal.get('zscore', 0),
        'hurst': signal.get('hurst', 0),
        'atr': atr,
        'signal_score': signal.get('confidenceScore', 0),
        'z_threshold': global_paper_trader.z_score_threshold,
        'min_confidence': global_paper_trader.min_confidence_score,
        'entry_tightness': global_paper_trader.entry_tightness,
        'exit_tightness': global_paper_trader.exit_tightness,
        'timestamp': int(datetime.now().timestamp() * 1000),
        'accepted': False,
        'reject_reason': '',
        'mtf_confirmed': True,
        'mtf_reason': '',
        'htf_trend': 'NEUTRAL',
        'blacklisted': False,
        'obi_value': 0.0,  # Phase 211: OBI depth value (updated before save)
        'telemetry': signal.get('telemetry', {}), # Phase 211: Full parameter telemetry
    }
    signal_memory_ctx = {
        "reinforce_count": 0,
        "score_bonus": 0,
        "thinbook_scale": 1.0,
        "pending_extend_sec": 0,
        "flip_recent": False,
    }
    
    # Check if we already have a position in this symbol
    existing_position = None
    for pos in global_paper_trader.positions:
        if pos.get('symbol') == symbol:
            existing_position = pos
            break
    
    # Don't open new position if we already have one in this symbol
    if existing_position:
        existing_side = existing_position.get('side', '')
        
        # Phase 200: Counter-signal detection â€” ters sinyal varsa exit_tightness modifier uygula
        if existing_side != action:
            # Ters sinyal! Skor bazlÄ± modifier hesapla
            signal_score = signal.get('confidenceScore', 0)  # Phase 223: was 'score' (field didn't exist)
            if signal_score >= 90:
                modifier = 0.4
            elif signal_score >= 80:
                modifier = 0.55
            elif signal_score >= 65:
                modifier = 0.7
            elif signal_score >= 50:
                modifier = 0.85
            else:
                modifier = 1.0  # ZayÄ±f sinyal, etki yok
            
            if modifier < 1.0:
                existing_position['counter_signal_modifier'] = modifier
                existing_position['counter_signal_time'] = datetime.now().timestamp()
                effective_et = global_paper_trader.exit_tightness * modifier
                logger.info(f"âš¡ COUNTER SIGNAL: {symbol} {action} (skor:{signal_score}) vs aÃ§Ä±k {existing_side} â†’ exit_tightness {global_paper_trader.exit_tightness:.1f}â†’{effective_et:.1f} (x{modifier})")
        
        signal_log_data['reject_reason'] = 'EXISTING_POSITION'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        reject_feedback("EXISTING_POSITION")
        logger.info(f"ðŸš« SKIPPING {symbol}: Already have position ({existing_position.get('side', 'UNKNOWN')})")
        return
    
    # Check max positions
    if len(global_paper_trader.positions) >= global_paper_trader.max_positions:
        signal_log_data['reject_reason'] = 'MAX_POSITIONS'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        reject_feedback("MAX_POSITIONS")
        logger.info(f"ðŸš« SKIPPING {symbol}: Max positions reached ({len(global_paper_trader.positions)})")
        return
    
    # Phase 219: USDT-based directional exposure limit â€” early reject
    MAX_DIRECTION_EXPOSURE_PCT = 0.40
    signal_side = 'LONG' if action in ('BUY', 'LONG') else 'SHORT'
    same_dir_margin = sum(
        p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
        for p in global_paper_trader.positions if p.get('side') == signal_side
    )
    same_dir_margin += sum(
        p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
        for p in global_paper_trader.pending_orders if p.get('side') == signal_side
    )
    max_dir_exposure = global_paper_trader.balance * MAX_DIRECTION_EXPOSURE_PCT
    if same_dir_margin >= max_dir_exposure:
        signal_log_data['reject_reason'] = 'DIRECTION_EXPOSURE'
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        reject_feedback("DIRECTION_EXPOSURE")
        logger.info(f"ðŸš« SKIPPING {symbol}: {signal_side} exposure ${same_dir_margin:.2f} >= ${max_dir_exposure:.2f} ({MAX_DIRECTION_EXPOSURE_PCT*100:.0f}% of balance)")
        return
    
    # Check blacklist
    if global_paper_trader.is_coin_blacklisted(symbol):
        signal_log_data['reject_reason'] = 'BLACKLISTED'
        signal_log_data['blacklisted'] = True
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        reject_feedback("BLACKLISTED")
        logger.info(f"ðŸš« SKIPPING {symbol}: Blacklisted")
        return
    
    # =====================================================
    # BTC TREND FILTER (Cloud Scanner)
    # =====================================================
    try:
        btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
            symbol, action,
            coin_change_pct=signal.get('priceChange24h', 0),
            volume_24h=signal.get('volume24h', 0),
            zscore=signal.get('zscore', 0),
            spread_pct=signal.get('spreadPct', 0)
        )
        
        if not btc_allowed:
            signal_log_data['reject_reason'] = f'BTC_FILTER:{btc_reason}'
            safe_create_task(sqlite_manager.save_signal(signal_log_data))
            reject_feedback(f"BTC_FILTER:{btc_reason}")
            logger.info(f"ðŸš« BTC FILTER RED: {action} {symbol} - {btc_reason}")
            return
        
        # Phase 230B: Override risk caps (leverage 3x, size 50%)
        if btc_filter.last_override:
            signal['overrideLeverageCap'] = 3
            signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), 0.5)
            # Phase 238B: Leverage pipeline
            signal['leverageCapApplied'] = True
            signal['leverageCapValue'] = 3
            signal['leverageCapReason'] = 'BTC_FILTER:EXTREME'
            logger.info(f"ðŸ’ª OVERRIDE CAPS: {symbol} | leverageâ‰¤3x, sizeâ‰¤0.5x")
        
        # Apply penalty to signal score and size
        if btc_penalty > 0:
            # Score penalty: 0.5 penalty = -50% score adjustment
            original_score = signal.get('confidenceScore', 60)
            score_penalty = int(original_score * btc_penalty)
            signal['confidenceScore'] = max(40, original_score - score_penalty)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 - btc_penalty)
            cap_lev, cap_size = get_btc_penalty_risk_caps(btc_penalty)
            if cap_lev:
                existing_cap = signal.get('overrideLeverageCap')
                signal['overrideLeverageCap'] = min(existing_cap, cap_lev) if existing_cap else cap_lev
                # Phase 238B: Leverage pipeline
                signal['leverageCapApplied'] = True
                signal['leverageCapValue'] = signal['overrideLeverageCap']
                signal['leverageCapReason'] = f"BTC_FILTER:{btc_reason.split(':')[0] if ':' in btc_reason else 'MODERATE'}"
            if cap_size:
                signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), cap_size)
            signal['btc_adjustment'] = btc_reason
            logger.info(f"âš ï¸ BTC PENALTY: {action} {symbol} | Score: -{score_penalty} | Size: -{btc_penalty*100:.0f}%")
        elif btc_penalty < 0:
            # Bonus for aligned signals
            bonus = abs(btc_penalty)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + bonus)
            signal['btc_adjustment'] = btc_reason
            logger.info(f"âœ… BTC BONUS: {action} {symbol} | Size: +{bonus*100:.0f}%")
        else:
            # Phase 127: Log pass when no penalty/bonus
            logger.info(f"âœ… BTC_FILTER PASS: {symbol} {action}")
            
    except Exception as btc_err:
        logger.warning(f"BTC Filter error: {btc_err}")

    # =====================================================
    # SIGNAL MEMORY / REINFORCEMENT
    # AynÄ± coin'de ardÄ±ÅŸÄ±k sinyaller iÃ§in score + timeout + depth adaptasyonu
    # =====================================================
    try:
        signal_memory_ctx = global_paper_trader.register_signal_memory(
            symbol=symbol,
            side=action,
            score=float(signal.get('confidenceScore', 0) or 0),
            volume_ratio=float(signal.get('volumeRatio', 1.0) or 1.0),
            spread_pct=float(signal.get('spreadPct', 0.05) or 0.05),
        )
        reinforce_count = int(signal_memory_ctx.get("reinforce_count", 0))
        score_bonus = int(signal_memory_ctx.get("score_bonus", 0))
        if score_bonus > 0:
            before_score = int(signal.get('confidenceScore', 0) or 0)
            signal['confidenceScore'] = before_score + score_bonus
            logger.info(
                f"ðŸ§  SIG_MEMORY: {symbol} {action} reinforce={reinforce_count} "
                f"score {before_score}->{signal['confidenceScore']} (+{score_bonus})"
            )
        signal['signalReinforceCount'] = reinforce_count
        signal['memoryThinBookScale'] = float(signal_memory_ctx.get("thinbook_scale", 1.0) or 1.0)
        signal['memoryExtensionSec'] = int(signal_memory_ctx.get("pending_extend_sec", 0) or 0)
        signal['memoryFlipRecent'] = bool(signal_memory_ctx.get("flip_recent", False))
        signal_log_data['memory_reinforce_count'] = reinforce_count
        signal_log_data['memory_score_bonus'] = score_bonus
    except Exception as mem_err:
        logger.debug(f"Signal memory error: {mem_err}")
    
    # =====================================================
    # Phase 211: OBI DEPTH FILTER â€” L2 Order Book Pressure
    # Sadece sinyal Ã¼retilmiÅŸ coinler iÃ§in depth Ã§ekilir (rate limit safe)
    # Tiered: |OBI| > 0.6 = VETO, 0.3-0.6 = -15 penalty, < 0.3 = neutral
    # =====================================================
    try:
        obi_value = await obi_detector.get_obi(symbol)
        
        # Phase 212: Thin Order Book Guard â€” min bid+ask depth (Phase EQG: $50K â†’ $120K)
        try:
            depth_data = obi_detector.obi_cache.get(symbol, {})
            total_depth = depth_data.get('total_bid_usd', 0) + depth_data.get('total_ask_usd', 0)
            signal_score = signal.get('confidenceScore', 0)
            signal_leverage = int(signal.get('leverage', 10) or 10)
            dynamic_depth_threshold = get_dynamic_depth_threshold(
                spread_pct=float(signal.get('spreadPct', 0.05) or 0.05),
                volume_24h=float(signal.get('volume24h', 0) or 0),
                signal_score=float(signal_score),
                leverage=signal_leverage
            )
            memory_scale = _clamp(float(signal.get('memoryThinBookScale', 1.0) or 1.0), 0.6, 1.0)
            reinforce_count = int(signal.get('signalReinforceCount', 0) or 0)
            strategy_mode_upper = str(signal.get('strategyMode', STRATEGY_MODE_LEGACY)).upper()
            eq_count = len(signal.get('entryQualityReasons') or [])
            exec_score = float(signal.get('entryExecScore', signal_score) or signal_score)
            signal_spread = float(signal.get('spreadPct', 0.2) or 0.2)
            signal_volume_ratio = float(signal.get('volumeRatio', 1.0) or 1.0)
            # Legacy mode must stay tradable on mid-cap / thinner books.
            # SMART_V2 keeps stricter thresholding; LEGACY gets controlled relax.
            depth_mode_scale = 1.0
            if strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2):
                if signal_score >= 110:
                    depth_mode_scale = 0.22
                elif signal_score >= 95:
                    depth_mode_scale = 0.26
                else:
                    depth_mode_scale = 0.30
            dynamic_depth_threshold *= (memory_scale * depth_mode_scale)
            near_threshold_soft_pass = (
                reinforce_count >= 2
                and signal_score >= 95
                and total_depth >= dynamic_depth_threshold * 0.82
            )
            legacy_soft_pass = (
                strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)
                and signal_score >= 95
                and eq_count >= 1
                and signal_spread <= 0.24
                and total_depth >= dynamic_depth_threshold * 0.30
            )
            legacy_micro_soft_pass = (
                strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)
                and signal_score >= 90
                and eq_count >= 1
                and signal_spread <= 0.12
                and total_depth >= 1_200
            )
            smart_soft_pass = (
                THIN_BOOK_SMART_SOFTPASS_ENABLED
                and strategy_mode_upper == STRATEGY_MODE_SMART_V2
                and signal_score >= THIN_BOOK_SMART_SOFTPASS_MIN_SCORE
                and eq_count >= THIN_BOOK_SMART_SOFTPASS_MIN_EQ
                and exec_score >= THIN_BOOK_SMART_SOFTPASS_MIN_EXEC
                and signal_spread <= THIN_BOOK_SMART_SOFTPASS_MAX_SPREAD
                and total_depth >= dynamic_depth_threshold * THIN_BOOK_SMART_SOFTPASS_DEPTH_RATIO
            )
            super_soft_pass = (
                THIN_BOOK_SUPER_SOFTPASS_ENABLED
                and strategy_mode_upper == STRATEGY_MODE_SMART_V2
                and signal_score >= THIN_BOOK_SUPER_SOFTPASS_MIN_SCORE
                and eq_count >= THIN_BOOK_SUPER_SOFTPASS_MIN_EQ
                and exec_score >= THIN_BOOK_SUPER_SOFTPASS_MIN_EXEC
                and signal_spread <= THIN_BOOK_SUPER_SOFTPASS_MAX_SPREAD
                and signal_volume_ratio >= THIN_BOOK_SUPER_SOFTPASS_MIN_VOL_RATIO
                and total_depth >= dynamic_depth_threshold * THIN_BOOK_SUPER_SOFTPASS_DEPTH_RATIO
            )
            if 0 < total_depth < dynamic_depth_threshold and not (near_threshold_soft_pass or legacy_soft_pass or legacy_micro_soft_pass or smart_soft_pass or super_soft_pass):
                # Phase 237: Soft Risk Gate fallback before hard reject
                if SOFT_RISK_GATE_ENABLED:
                    _rg = evaluate_risk_gate(signal, {
                        'gate_type': 'THIN_BOOK',
                        'depth_ratio': total_depth / max(1, dynamic_depth_threshold),
                        'eq_count': eq_count,
                        'exec_score': exec_score,
                        'spread_pct': signal_spread,
                        'strategy_mode': strategy_mode_upper,
                    })
                    if _rg['decision'] == 'SOFT_PASS':
                        _old_s = signal.get('confidenceScore', 60)
                        signal['confidenceScore'] = max(40, int(_old_s) - _rg['score_penalty'])
                        signal['sizeMultiplier'] = float(signal.get('sizeMultiplier', 1.0) or 1.0) * _rg['size_mult']
                        if _rg['leverage_cap']:
                            signal['leverage'] = max(3, min(int(signal.get('leverage', 10) or 10), _rg['leverage_cap']))
                            # Phase 238B: Leverage pipeline
                            signal['leverageCapApplied'] = True
                            signal['leverageCapValue'] = _rg['leverage_cap']
                            signal['leverageCapReason'] = f"RISK_GATE:THIN_BOOK:{_rg.get('reason_code','')}"
                        global_paper_trader.pipeline_metrics['risk_gate_soft_pass'] += 1
                        global_paper_trader.pipeline_metrics['soft_pass_count'] += 1
                        logger.info(f"ðŸ›¡ï¸ RISK_GATE: {action} {symbol} THIN_BOOKâ†’SOFT_PASS score {_old_s}â†’{signal['confidenceScore']} {_rg['reason_code']}")
                    else:
                        signal_log_data['reject_reason'] = f'THIN_BOOK:depth_${total_depth:.0f}'
                        signal_log_data['obi_value'] = round(obi_value, 4)
                        safe_create_task(sqlite_manager.save_signal(signal_log_data))
                        global_paper_trader.pipeline_metrics['thin_book_rejected'] += 1
                        global_paper_trader.pipeline_metrics['hard_reject_count'] += 1
                        reject_feedback(f"THIN_BOOK:${total_depth:.0f}<${dynamic_depth_threshold:.0f}")
                        logger.info(
                            f"ðŸ“Š THIN_BOOK: {action} {symbol} | Depth=${total_depth:.0f} < ${dynamic_depth_threshold/1000:.0f}K "
                            f"(score={signal_score}, lev={signal_leverage}x) â†’ BLOCKED"
                        )
                        track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal_score, 'THIN_BOOK', signal.get('atr', 0))
                        return
                else:
                    signal_log_data['reject_reason'] = f'THIN_BOOK:depth_${total_depth:.0f}'
                    signal_log_data['obi_value'] = round(obi_value, 4)
                    safe_create_task(sqlite_manager.save_signal(signal_log_data))
                    global_paper_trader.pipeline_metrics['thin_book_rejected'] += 1
                    reject_feedback(f"THIN_BOOK:${total_depth:.0f}<${dynamic_depth_threshold:.0f}")
                    logger.info(
                        f"ðŸ“Š THIN_BOOK: {action} {symbol} | Depth=${total_depth:.0f} < ${dynamic_depth_threshold/1000:.0f}K "
                        f"(score={signal_score}, lev={signal_leverage}x) â†’ BLOCKED"
                    )
                    track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal_score, 'THIN_BOOK', signal.get('atr', 0))
                    return
            elif near_threshold_soft_pass or legacy_soft_pass or legacy_micro_soft_pass or smart_soft_pass or super_soft_pass:
                original_score = signal.get('confidenceScore', 60)
                if near_threshold_soft_pass:
                    score_penalty = 6
                elif legacy_micro_soft_pass:
                    score_penalty = 9
                elif legacy_soft_pass:
                    score_penalty = 5
                elif super_soft_pass:
                    score_penalty = THIN_BOOK_SUPER_SOFTPASS_PENALTY
                else:
                    score_penalty = THIN_BOOK_SMART_SOFTPASS_PENALTY
                signal['confidenceScore'] = max(40, int(original_score) - score_penalty)
                global_paper_trader.pipeline_metrics['memory_soft_pass'] += 1
                if super_soft_pass:
                    global_paper_trader.pipeline_metrics['thin_book_super_override'] = (
                        global_paper_trader.pipeline_metrics.get('thin_book_super_override', 0) + 1
                    )
                    logger.info(
                        f"ðŸŸ¨ THIN_BOOK_SUPER_PASS: {action} {symbol} depth=${total_depth:.0f} "
                        f"th=${dynamic_depth_threshold:.0f} eq={eq_count}/3 exec={exec_score:.0f} vr={signal_volume_ratio:.2f} "
                        f"score {original_score}->{signal['confidenceScore']}"
                    )
                elif smart_soft_pass:
                    global_paper_trader.pipeline_metrics['thin_book_soft_override'] = (
                        global_paper_trader.pipeline_metrics.get('thin_book_soft_override', 0) + 1
                    )
                    logger.info(
                        f"ðŸŸ¨ THIN_BOOK_SMART_PASS: {action} {symbol} depth=${total_depth:.0f} "
                        f"th=${dynamic_depth_threshold:.0f} eq={eq_count}/3 exec={exec_score:.0f} "
                        f"score {original_score}->{signal['confidenceScore']}"
                    )
                elif legacy_soft_pass:
                    logger.info(
                        f"ðŸŸ¨ THIN_BOOK_LEGACY_PASS: {action} {symbol} depth=${total_depth:.0f} "
                        f"th=${dynamic_depth_threshold:.0f} eq={eq_count}/3 score {original_score}->{signal['confidenceScore']}"
                    )
                elif legacy_micro_soft_pass:
                    old_lev = int(signal.get('leverage', 10) or 10)
                    signal['leverage'] = max(3, min(old_lev, 12))
                    signal['sizeMultiplier'] = min(float(signal.get('sizeMultiplier', 1.0) or 1.0), 0.70)
                    # Phase 238B: Leverage pipeline
                    if signal['leverage'] < old_lev:
                        signal['leverageCapApplied'] = True
                        signal['leverageCapValue'] = 12
                        signal['leverageCapReason'] = 'THIN_BOOK_LEGACY_MICRO'
                    logger.info(
                        f"ðŸŸ¨ THIN_BOOK_LEGACY_MICRO_PASS: {action} {symbol} depth=${total_depth:.0f} "
                        f"th=${dynamic_depth_threshold:.0f} lev {old_lev}x->{signal['leverage']}x "
                        f"score {original_score}->{signal['confidenceScore']}"
                    )
                else:
                    logger.info(
                        f"ðŸŸ¨ THIN_BOOK_SOFT_PASS: {action} {symbol} depth=${total_depth:.0f} "
                        f"th=${dynamic_depth_threshold:.0f} reinforce={reinforce_count} "
                        f"score {original_score}->{signal['confidenceScore']}"
                    )
        except Exception:
            pass  # depth data may not always be available
        
        # Determine if OBI opposes or aligns with signal direction
        is_opposing = False
        is_aligned = False
        
        if obi_value > 0.3:  # Buying pressure (bid heavy)
            if action == "SHORT":
                is_opposing = True
            elif action == "LONG":
                is_aligned = True
        elif obi_value < -0.3:  # Selling pressure (ask heavy)
            if action == "LONG":
                is_opposing = True
            elif action == "SHORT":
                is_aligned = True
        
        if is_opposing:
            if abs(obi_value) > EQ_OBI_OPPOSE_VETO:  # Phase EQG: 0.6 â†’ 0.35
                # Strong opposing pressure â†’ VETO
                signal_log_data['reject_reason'] = f'OBI_VETO:opposing_{obi_value:.3f}'
                signal_log_data['obi_value'] = round(obi_value, 4)
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                reject_feedback(f"OBI_VETO:{obi_value:+.3f}")
                logger.info(f"ðŸ“Š OBI_VETO: {action} {symbol} | OBI={obi_value:+.3f} > {EQ_OBI_OPPOSE_VETO} | Opposing pressure â†’ BLOCKED")
                return
            else:
                # Moderate opposing pressure â†’ Soft penalty (-15)
                original_score = signal.get('confidenceScore', 60)
                signal['confidenceScore'] = max(40, original_score - 15)
                signal_log_data['obi_value'] = round(obi_value, 4)
                logger.info(f"ðŸ“Š OBI_PENALTY: {action} {symbol} | OBI={obi_value:+.3f} | Score: {original_score} â†’ {signal['confidenceScore']} (-15)")
        elif is_aligned:
            signal_log_data['obi_value'] = round(obi_value, 4)
            logger.info(f"ðŸ“Š OBI_CONFIRM: {action} {symbol} | OBI={obi_value:+.3f} | Order book aligned âœ…")
        else:
            # Phase EQG: Neutral OBI + dÃ¼ÅŸÃ¼k hacim ise reject
            signal_log_data['obi_value'] = round(obi_value, 4)
            vol_ratio_val = signal.get('volumeRatio', 1.0)
            strategy_mode_upper = str(signal.get('strategyMode', STRATEGY_MODE_LEGACY)).upper()
            adaptive_mode = strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)
            neutral_obi_limit = 0.10 if adaptive_mode else 0.12
            neutral_vol_limit = 0.9 if adaptive_mode else 1.2
            if abs(obi_value) < neutral_obi_limit and vol_ratio_val < neutral_vol_limit:
                reinforce_count = int(signal.get('signalReinforceCount', 0) or 0)
                eq_count_local = len(signal.get('entryQualityReasons') or [])
                legacy_soft_pass = (
                    adaptive_mode
                    and signal.get('confidenceScore', 0) >= 92
                    and eq_count_local >= 1
                )
                if (reinforce_count >= 2 and signal.get('confidenceScore', 0) >= 95) or legacy_soft_pass:
                    original_score = signal.get('confidenceScore', 60)
                    penalty = 6 if legacy_soft_pass else 8
                    signal['confidenceScore'] = max(40, int(original_score) - penalty)
                    global_paper_trader.pipeline_metrics['memory_soft_pass'] += 1
                    logger.info(
                        f"ðŸŸ¨ OBI_NEUTRAL_SOFT_PASS: {action} {symbol} OBI={obi_value:+.3f} vr={vol_ratio_val:.1f} "
                        f"reinforce={reinforce_count} eq={eq_count_local}/3 score {original_score}->{signal['confidenceScore']}"
                    )
                else:
                    # Phase 237: Soft Risk Gate fallback for OBI
                    if SOFT_RISK_GATE_ENABLED:
                        _rg_obi = evaluate_risk_gate(signal, {
                            'gate_type': 'OBI_NEUTRAL_LOW_VOL',
                            'obi_value': obi_value,
                            'vol_ratio': vol_ratio_val,
                            'eq_count': eq_count_local,
                            'spread_pct': signal.get('spreadPct', 0.05),
                            'strategy_mode': strategy_mode_upper,
                        })
                        if _rg_obi['decision'] == 'SOFT_PASS':
                            _old_s = signal.get('confidenceScore', 60)
                            signal['confidenceScore'] = max(40, int(_old_s) - _rg_obi['score_penalty'])
                            signal['sizeMultiplier'] = float(signal.get('sizeMultiplier', 1.0) or 1.0) * _rg_obi['size_mult']
                            if _rg_obi['leverage_cap']:
                                signal['leverage'] = max(3, min(int(signal.get('leverage', 10) or 10), _rg_obi['leverage_cap']))
                                # Phase 238B: Leverage pipeline
                                signal['leverageCapApplied'] = True
                                signal['leverageCapValue'] = _rg_obi['leverage_cap']
                                signal['leverageCapReason'] = f"RISK_GATE:OBI_NEUTRAL:{_rg_obi.get('reason_code','')}"
                            global_paper_trader.pipeline_metrics['risk_gate_soft_pass'] += 1
                            global_paper_trader.pipeline_metrics['soft_pass_count'] += 1
                            logger.info(f"ðŸ›¡ï¸ RISK_GATE: {action} {symbol} OBIâ†’SOFT_PASS score {_old_s}â†’{signal['confidenceScore']} {_rg_obi['reason_code']}")
                        else:
                            signal_log_data['reject_reason'] = f'OBI_NEUTRAL_LOW_VOL:obi={obi_value:.3f},vr={vol_ratio_val:.1f}'
                            safe_create_task(sqlite_manager.save_signal(signal_log_data))
                            global_paper_trader.pipeline_metrics['hard_reject_count'] += 1
                            reject_feedback(f"OBI_NEUTRAL_LOW_VOL:obi={obi_value:.3f},vr={vol_ratio_val:.1f}")
                            logger.info(f"ðŸ“Š OBI_NEUTRAL_LOW_VOL: {action} {symbol} | OBI={obi_value:+.3f} vol_ratio={vol_ratio_val:.1f} â†’ BLOCKED")
                            track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal.get('confidenceScore', 0), 'OBI_NEUTRAL_LOW_VOL', signal.get('atr', 0))
                            return
                    else:
                        signal_log_data['reject_reason'] = f'OBI_NEUTRAL_LOW_VOL:obi={obi_value:.3f},vr={vol_ratio_val:.1f}'
                        safe_create_task(sqlite_manager.save_signal(signal_log_data))
                        reject_feedback(f"OBI_NEUTRAL_LOW_VOL:obi={obi_value:.3f},vr={vol_ratio_val:.1f}")
                        logger.info(f"ðŸ“Š OBI_NEUTRAL_LOW_VOL: {action} {symbol} | OBI={obi_value:+.3f} vol_ratio={vol_ratio_val:.1f} â†’ BLOCKED")
                        track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal.get('confidenceScore', 0), 'OBI_NEUTRAL_LOW_VOL', signal.get('atr', 0))
                        return
            logger.debug(f"ðŸ“Š OBI_NEUTRAL: {action} {symbol} | OBI={obi_value:+.3f}")
        
    except Exception as obi_err:
        logger.debug(f"OBI filter error for {symbol}: {obi_err}")
    
    # =====================================================
    # Phase 60: MARKET REGIME FILTER
    # TRENDING_DOWN durumunda LONG sinyallere ek kontrol
    # =====================================================
    try:
        current_regime = market_regime_detector.current_regime
        regime_params = market_regime_detector.get_regime_params()
        
        # TRENDING_DOWN durumunda LONG sinyallere aÄŸÄ±r penalty
        if current_regime == "TRENDING_DOWN" and action == "LONG":
            long_penalty = regime_params.get('long_penalty', 0.5)
            
            # %50+ penalty varsa sinyali reddet
            if long_penalty >= 0.5:
                signal_log_data['reject_reason'] = f'REGIME_BLOCKED:TRENDING_DOWN'
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                reject_feedback("REGIME_BLOCKED:TRENDING_DOWN")
                logger.info(f"ðŸš« REGIME BLOCK: {action} {symbol} - TRENDING_DOWN blocks LONGs")
                return
            else:
                # DÃ¼ÅŸÃ¼k penalty - sadece uyar
                original_score = signal.get('confidenceScore', 60)
                penalty_amount = int(original_score * long_penalty)
                signal['confidenceScore'] = max(40, original_score - penalty_amount)
                signal['regime_adjustment'] = f"TRENDING_DOWN penalty -{penalty_amount}"
                logger.info(f"âš ï¸ REGIME PENALTY: {action} {symbol} | Score: -{penalty_amount}")
        
        # TRENDING_UP durumunda SHORT sinyallere uyarÄ±
        elif current_regime == "TRENDING_UP" and action == "SHORT":
            short_penalty = regime_params.get('short_penalty', 0.2)
            original_score = signal.get('confidenceScore', 60)
            penalty_amount = int(original_score * short_penalty)
            signal['confidenceScore'] = max(40, original_score - penalty_amount)
            signal['regime_adjustment'] = f"TRENDING_UP penalty -{penalty_amount}"
            logger.info(f"âš ï¸ REGIME PENALTY: {action} {symbol} | Score: -{penalty_amount}")
        
        # TRENDING_UP + LONG veya TRENDING_DOWN + SHORT = bonus
        elif (current_regime == "TRENDING_UP" and action == "LONG"):
            long_bonus = regime_params.get('long_bonus', 0.15)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + long_bonus)
            signal['regime_adjustment'] = f"TRENDING_UP bonus +{int(long_bonus*100)}%"
            logger.info(f"âœ… REGIME BONUS: {action} {symbol} | Size: +{int(long_bonus*100)}%")
        elif (current_regime == "TRENDING_DOWN" and action == "SHORT"):
            short_bonus = regime_params.get('short_bonus', 0.2)
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + short_bonus)
            signal['regime_adjustment'] = f"TRENDING_DOWN bonus +{int(short_bonus*100)}%"
            logger.info(f"âœ… REGIME BONUS: {action} {symbol} | Size: +{int(short_bonus*100)}%")
    except Exception as regime_err:
        logger.debug(f"Market Regime Filter error: {regime_err}")
    
    # ================================================================
    # Phase 215: MA ALIGNMENT HARD VETO
    # 4H + 1D + Supertrend Ã¼Ã§Ã¼ aynÄ± yÃ¶nde â†’ ters sinyal HARD REJECT
    # ================================================================
    ma_vetoed, ma_veto_reason = check_ma_alignment_veto(symbol, action)
    if ma_vetoed:
        signal_log_data['reject_reason'] = f"MA_ALIGNMENT_VETO:{ma_veto_reason}"
        safe_create_task(sqlite_manager.save_signal(signal_log_data))
        reject_feedback(f"MA_ALIGNMENT_VETO:{ma_veto_reason}")
        logger.warning(f"ðŸš« MA_VETO: {action} {symbol} â€” {ma_veto_reason}")
        return
    
    # MULTI-TIMEFRAME CONFIRMATION CHECK
    # Verify signal aligns with higher timeframe (1h) trend
    mtf_result = mtf_confirmation.confirm_signal(symbol, action)
    signal_log_data['htf_trend'] = mtf_result.get('htf_trend', 'NEUTRAL')
    signal_log_data['mtf_confirmed'] = mtf_result['confirmed']
    signal_log_data['mtf_reason'] = mtf_result.get('reason', '')
    
    if not mtf_result['confirmed']:
        signal_score = int(signal.get('confidenceScore', 0) or 0)
        eq_count = len(signal.get('entryQualityReasons') or [])
        strategy_mode_upper = str(signal.get('strategyMode', STRATEGY_MODE_LEGACY)).upper()
        exec_score = float(signal.get('entryExecScore', signal_score) or signal_score)
        adaptive_mode = strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)
        smart_relax_enabled = (
            adaptive_mode
            and bool(signal.get('entryQualityPass', False))
            and exec_score >= EXEC_QUALITY_STRICT_MIN_SCORE
        )
        mtf_min_score = int(MTF_SOFT_OVERRIDE_MIN_SCORE)
        mtf_min_eq = int(MTF_SOFT_OVERRIDE_MIN_EQ)
        if adaptive_mode:
            mtf_min_score = max(88, mtf_min_score - 6)
            mtf_min_eq = max(1, mtf_min_eq - 1)
        if smart_relax_enabled:
            mtf_min_score = max(85, mtf_min_score - int(MTF_SOFT_OVERRIDE_SMART_SCORE_RELAX))
            mtf_min_eq = int(MTF_SOFT_OVERRIDE_SMART_MIN_EQ)

        mtf_score_raw = int(mtf_result.get('mtf_score', 0) or 0)
        mtf_reason = str(mtf_result.get('reason', '') or '')
        strong_countertrend = (mtf_score_raw <= -70) or ("Ã§ok gÃ¼Ã§lÃ¼ karÅŸÄ± trend" in mtf_reason)

        soft_override_ok = (
            MTF_SOFT_OVERRIDE_ENABLED
            and signal_score >= mtf_min_score
            and eq_count >= mtf_min_eq
        )
        counter_soft_override_ok = (
            MTF_COUNTERTREND_SOFTPASS_ENABLED
            and adaptive_mode
            and signal_score >= MTF_COUNTERTREND_SOFTPASS_MIN_SCORE
            and eq_count >= MTF_COUNTERTREND_SOFTPASS_MIN_EQ
            and exec_score >= MTF_COUNTERTREND_SOFTPASS_MIN_EXEC
        )
        if strong_countertrend:
            counter_soft_override_ok = (
                counter_soft_override_ok
                and signal_score >= (MTF_COUNTERTREND_SOFTPASS_MIN_SCORE + 6)
            )

        if soft_override_ok:
            old_score = signal_score
            signal['confidenceScore'] = max(40, signal_score - MTF_SOFT_OVERRIDE_PENALTY)
            signal['mtf_override'] = True
            signal['mtf_override_reason'] = mtf_result.get('reason', '')
            global_paper_trader.pipeline_metrics['mtf_soft_override'] += 1
            logger.warning(
                f"âš ï¸ MTF_SOFT_OVERRIDE: {action} {symbol} score {old_score}->{signal['confidenceScore']} "
                f"(eq={eq_count}/3, min={mtf_min_score}, smart_relax={smart_relax_enabled}) | {mtf_result.get('reason', '')}"
            )
        elif counter_soft_override_ok:
            old_score = signal_score
            penalty = int(MTF_COUNTERTREND_SOFTPASS_PENALTY)
            if strong_countertrend:
                penalty += int(MTF_COUNTERTREND_SOFTPASS_STRONG_EXTRA_PENALTY)
            signal['confidenceScore'] = max(40, signal_score - penalty)
            signal['mtf_override'] = True
            signal['mtf_override_reason'] = mtf_result.get('reason', '')
            signal['sizeMultiplier'] = float(signal.get('sizeMultiplier', 1.0) or 1.0) * MTF_COUNTERTREND_SOFTPASS_SIZE_MULT
            old_lev = int(signal.get('leverage', 10) or 10)
            signal['leverage'] = max(3, min(old_lev, int(MTF_COUNTERTREND_SOFTPASS_MAX_LEVERAGE)))
            # Phase 238B: Leverage pipeline
            if signal['leverage'] < old_lev:
                signal['leverageCapApplied'] = True
                signal['leverageCapValue'] = int(MTF_COUNTERTREND_SOFTPASS_MAX_LEVERAGE)
                signal['leverageCapReason'] = 'MTF_COUNTERTREND'
            global_paper_trader.pipeline_metrics['mtf_soft_override'] += 1
            logger.warning(
                f"âš ï¸ MTF_COUNTER_SOFT_OVERRIDE: {action} {symbol} score {old_score}->{signal['confidenceScore']} "
                f"lev {old_lev}x->{signal['leverage']}x eq={eq_count}/3 exec={exec_score:.0f} "
                f"strong={strong_countertrend} | {mtf_result.get('reason', '')}"
            )
        else:
            # Phase 237: Soft Risk Gate fallback for MTF
            if SOFT_RISK_GATE_ENABLED:
                _rg_mtf = evaluate_risk_gate(signal, {
                    'gate_type': 'MTF_REJECT',
                    'mtf_score': int(mtf_result.get('mtf_score', -100) or -100),
                    'eq_count': eq_count,
                    'exec_score': exec_score,
                    'spread_pct': signal.get('spreadPct', 0.05),
                    'strategy_mode': strategy_mode_upper,
                })
                if _rg_mtf['decision'] == 'SOFT_PASS':
                    _old_s = signal.get('confidenceScore', 60)
                    signal['confidenceScore'] = max(40, int(_old_s) - _rg_mtf['score_penalty'])
                    signal['sizeMultiplier'] = float(signal.get('sizeMultiplier', 1.0) or 1.0) * _rg_mtf['size_mult']
                    if _rg_mtf['leverage_cap']:
                        signal['leverage'] = max(3, min(int(signal.get('leverage', 10) or 10), _rg_mtf['leverage_cap']))
                        # Phase 238B: Leverage pipeline
                        signal['leverageCapApplied'] = True
                        signal['leverageCapValue'] = _rg_mtf['leverage_cap']
                        signal['leverageCapReason'] = f"RISK_GATE:MTF:{_rg_mtf.get('reason_code','')}"
                    signal['mtf_override'] = True
                    signal['mtf_override_reason'] = mtf_result.get('reason', '')
                    global_paper_trader.pipeline_metrics['risk_gate_soft_pass'] += 1
                    global_paper_trader.pipeline_metrics['soft_pass_count'] += 1
                    logger.info(f"ðŸ›¡ï¸ RISK_GATE: {action} {symbol} MTFâ†’SOFT_PASS score {_old_s}â†’{signal['confidenceScore']} {_rg_mtf['reason_code']}")
                else:
                    signal_log_data['reject_reason'] = f"MTF_REJECTED:{mtf_result['reason']}"
                    safe_create_task(sqlite_manager.save_signal(signal_log_data))
                    global_paper_trader.pipeline_metrics['mtf_rejected'] += 1
                    global_paper_trader.pipeline_metrics['hard_reject_count'] += 1
                    reject_feedback(f"MTF_REJECTED:{mtf_result['reason']}")
                    logger.info(f"ðŸš« MTF RED: {action} {symbol} (skor: {mtf_result.get('mtf_score', 0)}) - {mtf_result['reason']}")
                    track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal_score, 'MTF_REJECTED', signal.get('atr', 0))
                    return
            else:
                signal_log_data['reject_reason'] = f"MTF_REJECTED:{mtf_result['reason']}"
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                global_paper_trader.pipeline_metrics['mtf_rejected'] += 1
                reject_feedback(f"MTF_REJECTED:{mtf_result['reason']}")
                logger.info(f"ðŸš« MTF RED: {action} {symbol} (skor: {mtf_result.get('mtf_score', 0)}) - {mtf_result['reason']}")
                track_reject_for_attribution(symbol, action, signal.get('entryPrice', signal.get('entry', 0)), signal_score, 'MTF_REJECTED', signal.get('atr', 0))
                return
    
    # Phase 127: Log MTF confirmation pass
    logger.info(f"âœ… MTF_CONFIRMATION PASS: {symbol} {action} (score: {mtf_result.get('mtf_score', 0)})")
    
    # Phase 237B: Entry Tradeability Score â€” BEFORE marking accepted
    if ENTRY_TRADEABILITY_ENABLED:
        try:
            _td = compute_entry_tradeability(signal, {
                'spread_pct': signal.get('spreadPct', 0.05),
                'depth_ratio': total_depth / max(1, dynamic_depth_threshold) if total_depth > 0 else 1.0,
                'obi_value': obi_value,
                'obi_direction_stable': True,
                'volume_ratio': signal.get('volumeRatio', 1.0),
                'is_volume_spike': signal.get('isVolumeSpike', False),
                'drift_risk': 0.0,
                'market_regime': market_regime_detector.current_regime if 'market_regime_detector' in globals() else 'RANGING',
                'strategy_mode': strategy_mode_upper,
            })
            signal['tradeabilityScore'] = _td['score']
            signal['tradeabilityDecision'] = _td['decision']
            signal['tradeabilityReasons'] = _td['components']
            if _td['decision'] == 'REJECT':
                global_paper_trader.pipeline_metrics['tradeability_reject_count'] += 1
                signal_log_data['reject_reason'] = f"TRADEABILITY_REJECT:score={_td['score']}"
                signal_log_data['accepted'] = False
                safe_create_task(sqlite_manager.save_signal(signal_log_data))
                logger.info(f"ðŸ“‰ TRADEABILITY: {action} {symbol} score={_td['score']} â†’ REJECT (components={_td['components']})")
                return  # Tradeability too low
            elif _td['decision'] == 'SOFT_PASS' and SOFT_RISK_GATE_ENABLED:
                _old_s = signal.get('confidenceScore', 60)
                signal['confidenceScore'] = max(40, int(_old_s) - 4)
                signal['sizeMultiplier'] = float(signal.get('sizeMultiplier', 1.0) or 1.0) * 0.8
                global_paper_trader.pipeline_metrics['soft_pass_count'] += 1
                logger.info(f"ðŸ“‰ TRADEABILITY: {action} {symbol} score={_td['score']} â†’ SOFT_PASS (score {_old_s}â†’{signal['confidenceScore']})")
            else:
                logger.debug(f"ðŸ“ˆ TRADEABILITY: {action} {symbol} score={_td['score']} â†’ PASS")
        except Exception as _td_err:
            logger.debug(f"Tradeability error: {_td_err}")
    
    # Signal is ACCEPTED
    signal_log_data['accepted'] = True
    safe_create_task(sqlite_manager.save_signal(signal_log_data))
    global_paper_trader.clear_execution_feedback(symbol)
    
    # Log MTF score info
    mtf_score = mtf_result.get('mtf_score', 0)
    score_modifier = mtf_result.get('score_modifier', 1.0)
    if score_modifier > 1.0:
        logger.info(f"âœ… MTF BONUS: {action} {symbol} (skor: +{mtf_score}) - pozisyon +%{int((score_modifier-1)*100)} bÃ¼yÃ¼k")
    elif score_modifier < 1.0:
        logger.info(f"âš ï¸ MTF PENALTY: {action} {symbol} (skor: {mtf_score}) - pozisyon -%{int((1-score_modifier)*100)} kÃ¼Ã§Ã¼k")
    
    # Add MTF size modifier to signal for position sizing
    signal['mtf_size_modifier'] = score_modifier
    
    # Phase 202: Pass trend_mode and strong_trend data to signal
    signal['trend_mode'] = mtf_result.get('trend_mode', False)
    signal['strong_trend_size_mult'] = mtf_result.get('strong_trend_size_mult', 1.0)
    signal['adx_4h'] = mtf_result.get('adx_4h', 0)
    signal['supertrend_dir'] = mtf_result.get('supertrend_dir', 0)
    if signal['trend_mode']:
        logger.warning(f"ðŸš€ TREND_MODE SIGNAL: {action} {symbol} | ADX_4H={signal['adx_4h']:.0f} ST={signal['supertrend_dir']} SizeÃ—{signal['strong_trend_size_mult']:.0%}")
    
    # =====================================================
    # PHASE 99: MTF LEVERAGE ADJUSTMENT (Bonus/Penalty Only)
    # SignalGenerator already calculated unified leverage
    # Here we only apply MTF confirmation bonus/penalty
    # =====================================================
    try:
        # Calculate TF count from scores (positive score = aligned)
        scores = mtf_result.get('scores', {'15m': 0, '1h': 0, '4h': 0, '1d': 0})
        tf_count = sum(1 for s in scores.values() if s > 0)
        
        # Get existing leverage from SignalGenerator (unified calculation)
        current_leverage = signal.get('leverage', 25)
        
        # Apply MTF bonus/penalty (don't overwrite, just adjust)
        if tf_count >= 4:
            mtf_mult = 1.1   # +10% for all 4 TFs aligned
        elif tf_count >= 3:
            mtf_mult = 1.0   # No change for 3 TFs
        elif tf_count >= 2:
            mtf_mult = 0.8   # -20% for only 2 TFs
        else:
            mtf_mult = 0.6   # -40% for 0-1 TF aligned
        
        adjusted_leverage = int(round(current_leverage * mtf_mult))
        adjusted_leverage = max(3, min(50, adjusted_leverage))  # Phase 184: cap 75â†’50
        
        signal['leverage'] = adjusted_leverage
        signal['tf_count'] = tf_count
        signal['mtf_leverage_mult'] = mtf_mult
        # Phase 238B: Capture raw leverage before caps (first assignment = raw)
        if 'signalLeverageRaw' not in signal:
            signal['signalLeverageRaw'] = current_leverage
        
        # Log if MTF adjusted leverage
        if mtf_mult != 1.0:
            logger.info(f"ðŸ“Š MTF Adjustment: {current_leverage}x Ã— {mtf_mult:.1f} (TF:{tf_count}/4) â†’ {adjusted_leverage}x | {symbol}")
    except Exception as lev_err:
        logger.warning(f"MTF leverage adjustment error: {lev_err}")
    
    # =====================================================
    # VOLUME PROFILE BOOST (Cloud Scanner - WebSocket Parity)
    # FIX #4: Per-coin Volume Profile (accurate POC/VAH/VAL)
    # =====================================================
    try:
        # Get or create per-coin volume profiler
        if symbol not in coin_volume_profiles:
            coin_volume_profiles[symbol] = VolumeProfileAnalyzer()
        
        coin_vp = coin_volume_profiles[symbol]
        
        # Update volume profile if stale (every hour)
        if datetime.now().timestamp() - coin_vp.last_update > 3600:
            # Try to get OHLCV from scanner's exchange
            if multi_coin_scanner.exchange and signal.get('confidenceScore', 0) >= 80:
                ccxt_symbol = symbol.replace('USDT', '/USDT')
                ohlcv_4h = await asyncio.wait_for(
                    multi_coin_scanner.exchange.fetch_ohlcv(ccxt_symbol, '4h', limit=100),
                    timeout=1.5
                )
                if ohlcv_4h:
                    coin_vp.calculate_profile(ohlcv_4h)
                    logger.debug(f"Updated VP for {symbol}: POC={coin_vp.poc:.6f}")
        
        # Get boost based on price proximity to key levels
        vp_boost = coin_vp.get_signal_boost(price, action)
        if vp_boost > 0:
            signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + vp_boost)
            signal['vp_boost'] = vp_boost
            logger.info(f"ðŸ“ˆ VP BOOST: {symbol} +{vp_boost*100:.0f}% @ POC={coin_vp.poc:.6f}")
    except Exception as vp_err:
        logger.warning(f"Volume Profile error: {vp_err}")
    
    # =====================================================
    # DYNAMIC TRAIL PARAMETERS (Cloud Scanner - WebSocket Parity)
    # Calculate trail_activation and trail_distance per-coin
    # =====================================================
    try:
        # Get Hurst from signal if available
        hurst = signal.get('hurst', 0.5)
        volatility_pct = signal.get('volatility_pct', (atr / price * 100) if price > 0 else 3.0)
        spread_pct = signal.get('spreadPct', 0.05)
        
        # Calculate dynamic trail params
        trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
            volatility_pct=volatility_pct,
            hurst=hurst,
            price=price,
            spread_pct=spread_pct,
            settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
            settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
        )
        
        signal['dynamic_trail_activation'] = trail_activation_atr
        signal['dynamic_trail_distance'] = trail_distance_atr
        
        # Log if significantly different from defaults (1.5, 1.0)
        if abs(trail_activation_atr - 1.5) > 0.3 or abs(trail_distance_atr - 1.0) > 0.2:
            logger.info(f"ðŸŽ¯ Dynamic Trail: act={trail_activation_atr}x, dist={trail_distance_atr}x | {symbol} (vol:{volatility_pct:.1f}%, hurst:{hurst:.2f})")
    except Exception as trail_err:
        logger.debug(f"Dynamic trail params error: {trail_err}")
    
    # =====================================================
    # Phase 224B: SIGNAL FLIP PENALTY
    # Same coin opposite signal within 5min â†’ score penalty
    # =====================================================
    try:
        now_ts = datetime.now().timestamp()
        last_sig = global_paper_trader.last_signal_per_coin.get(symbol, {})
        if last_sig:
            time_since_last = now_ts - last_sig.get('time', 0)
            was_opposite = last_sig.get('side') != action
            if was_opposite and time_since_last < 300:  # 5dk iÃ§inde flip
                penalty = max(5, int(15 - (time_since_last / 20)))
                original_score = signal.get('confidenceScore', 60)
                signal['confidenceScore'] = max(40, original_score - penalty)
                logger.info(f"ðŸ”„ FLIP_PENALTY: {symbol} {action} -{penalty}pt (flip {time_since_last:.0f}s ago, score {original_score}â†’{signal['confidenceScore']})")
        global_paper_trader.last_signal_per_coin[symbol] = {'side': action, 'time': now_ts}
    except Exception as flip_err:
        logger.debug(f"Flip penalty error: {flip_err}")
    
    # =====================================================
    # Phase 224B: EV-BASED SIGNAL FILTER
    # Reject signals with negative expected value
    # =====================================================
    try:
        ev = global_paper_trader.calculate_signal_ev(signal)
        signal['ev'] = round(ev, 4)
        if ev <= -0.5:
            signal_log_data['reject_reason'] = f'NEGATIVE_EV:{ev:.4f}'
            safe_create_task(sqlite_manager.save_signal(signal_log_data))
            reject_feedback(f"NEGATIVE_EV:{ev:.4f}")
            logger.info(f"ðŸ“‰ EV_REJECT: {action} {symbol} | EV={ev:.4f} <= -0.5 | score={signal.get('confidenceScore', 0)}")
            return
        elif ev < 0:
            logger.info(f"âš ï¸ EV_WARNING: {action} {symbol} | EV={ev:.4f} (weak but passing)")
    except Exception as ev_err:
        logger.debug(f"EV filter error: {ev_err}")
    
    # Execute trade
    try:
        await global_paper_trader.open_position(
            side=action,
            price=price,
            atr=atr,
            signal=signal,
            symbol=symbol
        )
        trends = mtf_result.get('trends', {})
        logger.info(f"ðŸ¤– Auto-Trade: {action} {symbol} @ ${price:.4f} | MTF:{mtf_score} | Lev:{signal.get('leverage', 50)}x | 15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}, 1d:{trends.get('1d','?')}")
    except Exception as e:
        logger.error(f"Auto-trade execution error: {e}")


# ============================================================================
# PHASE 30: SESSION-BASED TRADING
# ============================================================================

TRADING_SESSIONS = {
    "asia": {
        "hours_utc": (0, 8),
        "name": "Asya",
        "volatility": "low",
        "preferred_strategy": "mean_reversion",
        "leverage_mult": 0.7,
        "risk_mult": 0.8
    },
    "europe": {
        "hours_utc": (8, 14),
        "name": "Avrupa",
        "volatility": "medium",
        "preferred_strategy": "breakout",
        "leverage_mult": 1.0,
        "risk_mult": 1.0
    },
    "us": {
        "hours_utc": (14, 22),
        "name": "Amerika",
        "volatility": "high",
        "preferred_strategy": "momentum",
        "leverage_mult": 1.2,
        "risk_mult": 1.1
    },
    "overnight": {
        "hours_utc": (22, 24),
        "name": "Gece",
        "volatility": "low",
        # Phase 59: "avoid" -> "low_volatility" - tÃ¼m saatlerde sinyal Ã¼ret
        # Gelecekte tekrar aktif etmek iÃ§in: "avoid" yapÄ±n
        "preferred_strategy": "low_volatility",  # WAS: "avoid"
        "leverage_mult": 0.5,
        "risk_mult": 0.5
    }
}


class SessionManager:
    """
    Seans bazlÄ± trading ayarlarÄ±.
    Asia/Europe/US/Overnight session'larÄ±na gÃ¶re strateji ayarla.
    """
    
    def __init__(self):
        self.sessions = TRADING_SESSIONS
        self.current_session = None
        self.current_config = None
        logger.info("SessionManager initialized")
    
    def get_current_session(self) -> tuple:
        """Mevcut session'Ä± dÃ¶ndÃ¼r."""
        hour_utc = datetime.utcnow().hour
        
        for name, config in self.sessions.items():
            start, end = config['hours_utc']
            if start <= hour_utc < end:
                self.current_session = name
                self.current_config = config
                return name, config
        
        # Fallback overnight
        self.current_session = "overnight"
        self.current_config = self.sessions["overnight"]
        return "overnight", self.sessions["overnight"]
    
    def adjust_leverage(self, base_leverage: int) -> int:
        """Session'a gÃ¶re kaldÄ±raÃ§ ayarla."""
        _, config = self.get_current_session()
        adjusted = int(base_leverage * config['leverage_mult'])
        return max(3, min(75, adjusted))
    
    def adjust_risk(self, base_risk: float) -> float:
        """Session'a gÃ¶re risk ayarla."""
        _, config = self.get_current_session()
        return base_risk * config['risk_mult']
    
    def should_trade(self) -> bool:
        """
        Bu session'da trade yapÄ±lmalÄ± mÄ±?
        
        Phase 59: Deaktive edildi - tÃ¼m saatlerde sinyal Ã¼retilecek.
        Gelecekte tekrar aktif etmek iÃ§in:
        return config['preferred_strategy'] != "avoid"
        """
        # _, config = self.get_current_session()
        # return config['preferred_strategy'] != "avoid"
        return True  # Always trade - session restriction disabled
    
    def get_session_info(self) -> dict:
        """Session bilgisi."""
        name, config = self.get_current_session()
        return {
            "session": name,
            "name_tr": config['name'],
            "volatility": config['volatility'],
            "strategy": config['preferred_strategy'],
            "leverage_mult": config['leverage_mult'],
            "risk_mult": config['risk_mult']
        }


# Global Session Manager instance
session_manager = SessionManager()


# ============================================================================
# MULTI-TIMEFRAME CONFIRMATION
# Confirms signals align with higher timeframe (1h) trends
# ============================================================================

class MultiTimeframeConfirmation:
    """
    Multi-Timeframe (MTF) Scoring System for signal validation.
    
    Checks 3 timeframes: 15m, 1h, 4h
    Each timeframe contributes points based on trend alignment:
    - 15m: 20 points (short-term momentum)
    - 1h:  30 points (main trend)
    - 4h:  50 points (major trend direction)
    
    Total possible: 100 points (fully aligned) to -100 (fully opposite)
    
    Decision thresholds:
    - Score > 50:  BONUS (+10% signal score)
    - Score 0-50:  NORMAL (proceed as usual)
    - Score 0 to -50: PENALTY (-20% signal score, but still allow)
    - Score < -50: BLOCK (too risky, strong counter-trend)
    """
    
    # Timeframe weights
    WEIGHTS = {
        '15m': 10,
        '1h': 20,
        '4h': 30,
        '1d': 40
    }
    
    def __init__(self):
        self.coin_trends = {}  # symbol -> {trend_15m, trend_1h, trend_4h, trend_1d, last_update, mtf_score}
        self.cache_ttl = 300  # 5 minutes cache per coin
        logger.info("ðŸ“Š MTF Scoring System initialized (15m:10, 1h:20, 4h:30, 1d:40)")
    
    def get_trend_from_closes(self, closes: list) -> dict:
        """Calculate trend from close prices using EMA and price change."""
        if len(closes) < 10:
            return {"trend": "NEUTRAL", "strength": 0.0}
        
        # Use full available closes (up to 100) for proper EMA warmup
        closes_arr = np.array(closes[-100:] if len(closes) >= 100 else closes)
        
        # Simple EMA10 with proper SMA warm-up
        period = 10
        if len(closes_arr) <= period:
            ema = np.mean(closes_arr)
        else:
            ema = np.mean(closes_arr[:period])
            alpha = 2 / (period + 1)
            for c in closes_arr[period:]:
                ema = alpha * c + (1 - alpha) * ema
        
        current_price = closes_arr[-1]
        
        # % change over last 4 candles
        if len(closes_arr) >= 4:
            change_pct = ((closes_arr[-1] - closes_arr[-4]) / closes_arr[-4]) * 100
        else:
            change_pct = 0
        
        # Determine trend
        if current_price > ema and change_pct > 0.2:
            if change_pct > 1.0:
                return {"trend": "STRONG_BULLISH", "strength": min(1.0, change_pct / 3.0)}
            return {"trend": "BULLISH", "strength": min(1.0, change_pct / 2.0)}
        elif current_price < ema and change_pct < -0.2:
            if change_pct < -1.0:
                return {"trend": "STRONG_BEARISH", "strength": min(1.0, abs(change_pct) / 3.0)}
            return {"trend": "BEARISH", "strength": min(1.0, abs(change_pct) / 2.0)}
        else:
            return {"trend": "NEUTRAL", "strength": 0.0}
    
    def calculate_trend_score(self, trend: str, signal_action: str, weight: int) -> int:
        """Calculate score contribution for a single timeframe."""
        # For LONG signals: Bullish trend = positive, Bearish = negative
        # For SHORT signals: Bearish trend = positive, Bullish = negative
        
        if signal_action == 'LONG':
            if trend in ['BULLISH', 'STRONG_BULLISH']:
                return weight  # Full positive
            elif trend in ['BEARISH', 'STRONG_BEARISH']:
                return -weight  # Full negative
            else:
                return 0  # Neutral
        
        elif signal_action == 'SHORT':
            if trend in ['BEARISH', 'STRONG_BEARISH']:
                return weight  # Full positive
            elif trend in ['BULLISH', 'STRONG_BULLISH']:
                return -weight  # Full negative
            else:
                return 0  # Neutral
        
        return 0
    
    def calculate_strong_trend_penalty(self, price_change_pct: float, signal_action: str, adx: float = 0) -> tuple:
        """
        Phase 143 + Phase 202: Strong Trend Filter + Pro-Trend Bonus
        
        Counter-trend: penalty + size reduction (Phase 143)
        Pro-trend: bonus + size increase + trend_mode flag (Phase 202)
        
        Returns:
            (score_modifier: int, size_multiplier: float, is_trend_mode: bool)
        """
        abs_change = abs(price_change_pct)
        
        # Trend yÃ¶nÃ¼ belirle
        is_bullish = price_change_pct > 0
        is_counter_trend = (is_bullish and signal_action == "SHORT") or \
                           (not is_bullish and signal_action == "LONG")
        is_pro_trend = (is_bullish and signal_action == "LONG") or \
                       (not is_bullish and signal_action == "SHORT")
        
        # ========== Phase 202: Pro-Trend Bonus ==========
        if is_pro_trend and abs_change >= 5 and adx >= 40:
            if abs_change >= 20:
                logger.warning(f"ðŸš€ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} â†’ {signal_action} BOOST (+15pts, 130% size)")
                return (+15, 1.30, True)
            elif abs_change >= 10:
                logger.warning(f"ðŸš€ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} â†’ {signal_action} BOOST (+10pts, 120% size)")
                return (+10, 1.20, True)
            elif abs_change >= 5:
                logger.info(f"ðŸš€ TREND_MODE: {price_change_pct:+.1f}% ADX={adx:.0f} â†’ {signal_action} BOOST (+5pts, 110% size)")
                return (+5, 1.10, True)
        
        # ========== Phase 143: Counter-Trend Penalty ==========
        if not is_counter_trend or abs_change < 5:
            return (0, 1.0, False)
        
        if abs_change >= 20:
            logger.warning(f"âš ï¸ STRONG_TREND: {price_change_pct:+.1f}% â†’ {signal_action} penalized (-30, 25% size)")
            return (-30, 0.25, False)
        elif abs_change >= 10:
            logger.warning(f"âš ï¸ STRONG_TREND: {price_change_pct:+.1f}% â†’ {signal_action} penalized (-20, 50% size)")
            return (-20, 0.50, False)
        elif abs_change >= 5:
            logger.info(f"ðŸ“Š STRONG_TREND: {price_change_pct:+.1f}% â†’ {signal_action} penalized (-10, 75% size)")
            return (-10, 0.75, False)
        
        return (0, 1.0, False)
    
    async def update_coin_trend(self, symbol: str, exchange) -> dict:
        """Fetch 15m, 1h, 4h, 1d candles and calculate MTF data."""
        now = datetime.now().timestamp()
        
        # Check cache
        if symbol in self.coin_trends:
            cache = self.coin_trends[symbol]
            if now - cache.get('last_update', 0) < self.cache_ttl:
                return cache
        
        result = {
            'symbol': symbol,
            'trend_15m': 'NEUTRAL',
            'trend_1h': 'NEUTRAL',
            'trend_4h': 'NEUTRAL',
            'trend_1d': 'NEUTRAL',
            'last_update': now
        }
        
        try:
            ccxt_symbol = f"{symbol[:-4]}/USDT:USDT"
            fetch_timeout = 2.0

            async def fetch_ohlcv_safe(timeframe: str):
                try:
                    return await asyncio.wait_for(
                        exchange.fetch_ohlcv(ccxt_symbol, timeframe, limit=30),
                        timeout=fetch_timeout
                    )
                except asyncio.TimeoutError:
                    logger.debug(f"MTF fetch timeout {symbol} {timeframe}")
                    return []
                except Exception as fetch_err:
                    logger.debug(f"MTF fetch error {symbol} {timeframe}: {fetch_err}")
                    return []

            # Fetch 4 TF in parallel with per-request timeout.
            ohlcv_15m, ohlcv_1h, ohlcv_4h, ohlcv_1d = await asyncio.gather(
                fetch_ohlcv_safe('15m'),
                fetch_ohlcv_safe('1h'),
                fetch_ohlcv_safe('4h'),
                fetch_ohlcv_safe('1d'),
            )
            
            # Calculate trends
            if ohlcv_15m and len(ohlcv_15m) >= 10:
                closes_15m = [c[4] for c in ohlcv_15m]
                trend_15m = self.get_trend_from_closes(closes_15m)
                result['trend_15m'] = trend_15m['trend']
            
            if ohlcv_1h and len(ohlcv_1h) >= 10:
                closes_1h = [c[4] for c in ohlcv_1h]
                trend_1h = self.get_trend_from_closes(closes_1h)
                result['trend_1h'] = trend_1h['trend']
                
                # Phase 208: SMC extraction from 1H candles
                result['smc_1h'] = extract_smc_features(ohlcv_1h)
            
            if ohlcv_4h and len(ohlcv_4h) >= 10:
                closes_4h = [c[4] for c in ohlcv_4h]
                trend_4h = self.get_trend_from_closes(closes_4h)
                result['trend_4h'] = trend_4h['trend']
                
                # Phase 143: Calculate price change over last 20 4H candles for Strong Trend Filter
                if len(ohlcv_4h) >= 20:
                    first_close = ohlcv_4h[-20][4]  # 20 candle ago
                    last_close = ohlcv_4h[-1][4]    # Current
                    price_change_pct = ((last_close - first_close) / first_close) * 100
                    result['price_change_4h_20'] = round(price_change_pct, 2)
                else:
                    result['price_change_4h_20'] = 0.0
                
                # Phase 202: Supertrend calculation for trend mode
                try:
                    if PANDAS_TA_AVAILABLE and len(ohlcv_4h) >= 14:
                        import pandas as pd
                        df_4h = pd.DataFrame(ohlcv_4h, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                        st = pta.supertrend(df_4h['high'], df_4h['low'], df_4h['close'], length=10, multiplier=3.0)
                        if st is not None and len(st) > 0:
                            st_dir = st.iloc[-1][f'SUPERTd_10_3.0']
                            result['supertrend_dir'] = int(st_dir)  # 1=bullish, -1=bearish
                        else:
                            result['supertrend_dir'] = 0
                    else:
                        result['supertrend_dir'] = 0
                except Exception as st_err:
                    logger.debug(f"Supertrend calc error {symbol}: {st_err}")
                    result['supertrend_dir'] = 0
                
                # Phase 202: ADX from 4H data for trend mode
                try:
                    highs_4h = [c[2] for c in ohlcv_4h]
                    lows_4h = [c[3] for c in ohlcv_4h]
                    closes_4h_list = [c[4] for c in ohlcv_4h]
                    adx_4h, adx_trend_4h, _, _ = calculate_adx(highs_4h, lows_4h, closes_4h_list)
                    result['adx_4h'] = adx_4h
                    result['adx_trend_4h'] = adx_trend_4h
                except Exception as adx_err:
                    logger.debug(f"ADX 4H calc error {symbol}: {adx_err}")
                    result['adx_4h'] = 0
                    result['adx_trend_4h'] = 'NEUTRAL'
            
            if ohlcv_1d and len(ohlcv_1d) >= 10:
                closes_1d = [c[4] for c in ohlcv_1d]
                trend_1d = self.get_trend_from_closes(closes_1d)
                result['trend_1d'] = trend_1d['trend']
            
            # Phase FIB: Cache OHLCV snapshots for Fibonacci swing detection
            if ohlcv_1h:
                result['ohlcv_1h'] = ohlcv_1h[-30:]
            if ohlcv_4h:
                result['ohlcv_4h'] = ohlcv_4h[-30:]
            
            self.coin_trends[symbol] = result
            logger.debug(
                f"MTF {symbol}: 15m={result['trend_15m']}, 1h={result['trend_1h']}, "
                f"4h={result['trend_4h']}, 1d={result['trend_1d']}, "
                f"4h_20_chg={result.get('price_change_4h_20', 0):.1f}%"
            )
            
        except Exception as e:
            logger.debug(f"MTF update failed for {symbol}: {e}")
            # Cache neutral fallback to avoid retry storms on every scanner cycle.
            self.coin_trends[symbol] = result
        
        return result
    
    def confirm_signal(self, symbol: str, signal_action: str) -> dict:
        """
        Calculate MTF score and determine if signal should proceed.
        
        Returns: {
            'mtf_score': int (-100 to +100),
            'confirmed': bool,
            'score_modifier': float (0.8 to 1.1),
            'reason': str,
            'trends': {15m, 1h, 4h}
        }
        """
        trend_data = self.coin_trends.get(symbol, {
            'trend_15m': 'NEUTRAL',
            'trend_1h': 'NEUTRAL', 
            'trend_4h': 'NEUTRAL'
        })
        
        # Calculate score for each timeframe
        score_15m = self.calculate_trend_score(trend_data.get('trend_15m', 'NEUTRAL'), signal_action, self.WEIGHTS['15m'])
        score_1h = self.calculate_trend_score(trend_data.get('trend_1h', 'NEUTRAL'), signal_action, self.WEIGHTS['1h'])
        score_4h = self.calculate_trend_score(trend_data.get('trend_4h', 'NEUTRAL'), signal_action, self.WEIGHTS['4h'])
        score_1d = self.calculate_trend_score(trend_data.get('trend_1d', 'NEUTRAL'), signal_action, self.WEIGHTS['1d'])
        
        total_score = score_15m + score_1h + score_4h + score_1d
        
        result = {
            'mtf_score': total_score,
            'confirmed': True,
            'score_modifier': 1.0,
            'reason': '',
            'htf_trend': trend_data.get('trend_1h', 'NEUTRAL'),  # Keep for compatibility
            'trends': {
                '15m': trend_data.get('trend_15m', 'NEUTRAL'),
                '1h': trend_data.get('trend_1h', 'NEUTRAL'),
                '4h': trend_data.get('trend_4h', 'NEUTRAL'),
                '1d': trend_data.get('trend_1d', 'NEUTRAL')
            },
            'scores': {
                '15m': score_15m,
                '1h': score_1h,
                '4h': score_4h,
                '1d': score_1d
            }
        }
        
        # Decision based on score
        if total_score > 50:
            # Strong alignment - BONUS (Phase 235: 1.15â†’1.20 pro-trend Ã¶dÃ¼llendirme)
            result['score_modifier'] = 1.20  # +20% bonus
            result['reason'] = f"MTF uyumlu (+{total_score}): 15m:{result['trends']['15m']}, 1h:{result['trends']['1h']}, 4h:{result['trends']['4h']}, 1d:{result['trends']['1d']}"
        
        elif total_score >= 0:
            # Neutral to slight positive - NORMAL
            result['score_modifier'] = 1.0
            result['reason'] = f"MTF nÃ¶tr ({total_score}): 15m:{result['trends']['15m']}, 1h:{result['trends']['1h']}, 4h:{result['trends']['4h']}, 1d:{result['trends']['1d']}"
        
        elif total_score > -25:
            # Against trend but not too strong - PENALTY (Phase 235: 0.8â†’0.85 hafifletme)
            result['score_modifier'] = 0.85  # -15% penalty
            result['reason'] = f"MTF karÅŸÄ±t ({total_score}): pozisyon aÃ§Ä±lacak ama %15 dÃ¼ÅŸÃ¼k skor"
        
        else:
            # Strongly against trend - BLOCK (< -25)
            result['confirmed'] = False
            result['score_modifier'] = 0.0
            result['reason'] = f"MTF RED ({total_score}): Ã§ok gÃ¼Ã§lÃ¼ karÅŸÄ± trend"
        
        # ================================================================
        # Phase 143 + 202: Strong Trend Filter + Pro-Trend Bonus
        # ================================================================
        price_change_4h_20 = trend_data.get('price_change_4h_20', 0.0)
        adx_4h = trend_data.get('adx_4h', 0)
        supertrend_dir = trend_data.get('supertrend_dir', 0)
        
        strong_trend_penalty, strong_trend_size_mult, is_trend_mode = self.calculate_strong_trend_penalty(
            price_change_4h_20, signal_action, adx=adx_4h
        )
        
        # Phase 202: Validate trend_mode with Supertrend confirmation
        if is_trend_mode:
            # Supertrend must agree: LONG needs bullish(1), SHORT needs bearish(-1)
            st_confirms = (signal_action == 'LONG' and supertrend_dir == 1) or \
                          (signal_action == 'SHORT' and supertrend_dir == -1)
            if not st_confirms:
                logger.info(f"ðŸ“Š TREND_MODE downgrade: {signal_action} but Supertrend={supertrend_dir} â€” disabling trend mode")
                is_trend_mode = False
                # Keep the score bonus but don't apply wider params
        
        # Apply modifier to mtf_score
        result['mtf_score'] += strong_trend_penalty
        result['strong_trend_penalty'] = strong_trend_penalty
        result['strong_trend_size_mult'] = strong_trend_size_mult
        result['price_change_4h_20'] = price_change_4h_20
        result['trend_mode'] = is_trend_mode
        result['adx_4h'] = adx_4h
        result['supertrend_dir'] = supertrend_dir
        
        # Adjust reason
        if is_trend_mode:
            result['reason'] += f" | ðŸš€ TREND_MODE(4h:{price_change_4h_20:+.1f}% ADX:{adx_4h:.0f} ST:{supertrend_dir}): +{strong_trend_penalty}pts, {int(strong_trend_size_mult*100)}% size"
        elif strong_trend_penalty < 0:
            result['reason'] += f" | STRONG_TREND({price_change_4h_20:+.1f}%): {strong_trend_penalty}pts, {int(strong_trend_size_mult*100)}% size"
        
        return result
    
    def clean_stale_cache(self):
        """Remove old cache entries."""
        now = datetime.now().timestamp()
        stale_limit = self.cache_ttl * 3
        stale = [s for s, d in self.coin_trends.items() if now - d.get('last_update', 0) > stale_limit]
        for s in stale:
            del self.coin_trends[s]

# Global MTF Confirmation instance
mtf_confirmation = MultiTimeframeConfirmation()

# ============================================================================
# PHASE 30: BTC CORRELATION FILTER
# ============================================================================

class BTCCorrelationFilter:
    """
    ALT coin sinyallerini BTC trendiyle filtrele.
    BTC dÃ¼ÅŸerken ALT LONG'lara dikkat, BTC yÃ¼kselirken ALT SHORT'lara dikkat.
    """
    
    def __init__(self):
        self.btc_trend = "NEUTRAL"
        self.btc_trend_daily = "NEUTRAL"  # GÃ¼nlÃ¼k trend
        self.btc_momentum = 0.0
        self.btc_price = 0.0
        self.btc_change_30m = 0.0  # Phase 60b: 30m hÄ±zlÄ± momentum
        self.btc_change_1h = 0.0
        self.btc_change_4h = 0.0
        self.btc_change_1d = 0.0  # GÃ¼nlÃ¼k deÄŸiÅŸim
        self.last_update = 0
        self.base_update_interval = 120  # 2 dakikada bir gÃ¼ncelle (was 300)
        self.update_interval = 120  # Dinamik aralÄ±k
        
        # Phase 60: Emergency Mode - Strong bearish market protection
        self.emergency_mode = False
        self.emergency_reason = ""
        self.emergency_start_time = None
        self.flash_crash_active = False  # Phase 60b: 30m hÄ±zlÄ± dÃ¼ÅŸÃ¼ÅŸ algÄ±lama
        
        # Phase 36: Pairs correlation + Phase 60c: ETH Trend Filter
        self.eth_price = 0.0
        self.eth_change_30m = 0.0  # Phase 60c
        self.eth_change_1h = 0.0
        self.eth_change_4h = 0.0   # Phase 60c
        self.eth_trend = "NEUTRAL"  # Phase 60c: ETH specific trend
        self.eth_flash_crash = False  # Phase 60c: ETH 30m hÄ±zlÄ± dÃ¼ÅŸÃ¼ÅŸ
        self.spread_history = []  # Rolling spread values
        self.spread_window = 100  # Last 100 values for Z-score
        self.beta = 0.052  # ETH typically ~5.2% of BTC price
        
        # Phase 60d: Recovery Detection - Karma YaklaÅŸÄ±m (Ä°ki YÃ¶nlÃ¼)
        # BEARISH Recovery (Flash Crash â†’ LONG)
        self.flash_crash_start_time = None  # Flash crash baÅŸlangÄ±Ã§ zamanÄ±
        self.flash_crash_active = False
        self.prev_btc_change_30m = 0.0      # Ã–nceki 30m deÄŸiÅŸim (momentum shift)
        self.prev_eth_change_30m = 0.0      # Ã–nceki ETH 30m deÄŸiÅŸim
        self.btc_momentum_improving = False  # BTC momentum iyileÅŸiyor mu? (dÃ¼ÅŸÃ¼ÅŸ yavaÅŸlÄ±yor)
        self.eth_momentum_improving = False  # ETH momentum iyileÅŸiyor mu?
        self.recovery_phase = "NORMAL"       # BLOCKED / PENALTY_HIGH / PENALTY_LOW / NORMAL
        
        # BULLISH Recovery (Flash Pump â†’ SHORT)
        self.flash_pump_active = False       # HÄ±zlÄ± yÃ¼kseliÅŸ aktif mi?
        self.flash_pump_start_time = None    # Flash pump baÅŸlangÄ±Ã§ zamanÄ±
        self.btc_momentum_weakening = False  # YÃ¼kseliÅŸ yavaÅŸlÄ±yor mu?
        self.recovery_phase_short = "NORMAL" # SHORT iÃ§in recovery phase
        
        # Phase 60e: MTF Momentum Tracking
        self.btc_change_15m = 0.0           # 15m deÄŸiÅŸim
        self.prev_btc_change_15m = 0.0      # Ã–nceki 15m deÄŸiÅŸim
        self.prev_btc_change_1h = 0.0       # Ã–nceki 1H deÄŸiÅŸim
        self.prev_btc_change_4h = 0.0       # Ã–nceki 4H deÄŸiÅŸim
        
        # Phase 230B: Coin Strength Override tracking
        self.last_override = False          # Set per should_allow_signal call
        
        logger.info("ðŸ“Š BTCCorrelationFilter initialized with MTF Recovery + Coin Strength Override")
    
    async def update_btc_state(self, exchange) -> dict:
        """BTC durumunu gÃ¼ncelle."""
        now = datetime.now().timestamp()
        
        # Rate limiting
        if now - self.last_update < self.update_interval:
            return self.get_state()
        
        try:
            # Phase 60e: BTC 15m, 30m, 1H, 4H ve 1D verileri Ã§ek
            # Rate limit fix: 100ms delay between calls
            logger.info("ðŸ“Š Fetching BTC OHLCV data...")
            ohlcv_15m = await exchange.fetch_ohlcv('BTC/USDT', '15m', limit=4)
            await asyncio.sleep(0.1)
            ohlcv_30m = await exchange.fetch_ohlcv('BTC/USDT', '30m', limit=4)
            await asyncio.sleep(0.1)
            ohlcv_1h = await exchange.fetch_ohlcv('BTC/USDT', '1h', limit=24)
            await asyncio.sleep(0.1)
            ohlcv_4h = await exchange.fetch_ohlcv('BTC/USDT', '4h', limit=12)
            await asyncio.sleep(0.1)
            ohlcv_1d = await exchange.fetch_ohlcv('BTC/USDT', '1d', limit=3)
            logger.info(f"ðŸ“Š BTC OHLCV fetched: 15m={len(ohlcv_15m) if ohlcv_15m else 0}, 30m={len(ohlcv_30m) if ohlcv_30m else 0}, 1h={len(ohlcv_1h) if ohlcv_1h else 0}, 4h={len(ohlcv_4h) if ohlcv_4h else 0}, 1d={len(ohlcv_1d) if ohlcv_1d else 0}")
            
            # Phase 60e: 15m momentum hesapla
            if ohlcv_15m and len(ohlcv_15m) >= 2:
                current = ohlcv_15m[-1][4]
                prev = ohlcv_15m[-2][4]
                self.prev_btc_change_15m = self.btc_change_15m
                self.btc_change_15m = ((current - prev) / prev) * 100
            
            # Phase 60b: 30m momentum hesapla (hÄ±zlÄ± dÃ¼ÅŸÃ¼ÅŸ algÄ±lama)
            if ohlcv_30m and len(ohlcv_30m) >= 2:
                current = ohlcv_30m[-1][4]  # Close
                prev_30m = ohlcv_30m[-2][4]
                new_change = ((current - prev_30m) / prev_30m) * 100
                
                # =================================================================
                # Phase 60d: MOMENTUM SHIFT DETECTION
                # DÃ¼ÅŸÃ¼ÅŸ yavaÅŸlÄ±yorsa momentum iyileÅŸiyor
                # =================================================================
                if self.prev_btc_change_30m < -1.0:  # Ã–nceden dÃ¼ÅŸÃ¼ÅŸteydik
                    # Yeni deÄŸer daha iyi mi? (daha az negatif veya pozitif)
                    if new_change > self.prev_btc_change_30m + 0.5:  # En az 0.5% iyileÅŸme
                        if not self.btc_momentum_improving:
                            logger.info(f"ðŸ“ˆ BTC MOMENTUM SHIFT: {self.prev_btc_change_30m:.1f}% â†’ {new_change:.1f}% (improving)")
                        self.btc_momentum_improving = True
                    else:
                        self.btc_momentum_improving = False
                else:
                    self.btc_momentum_improving = False
                
                self.prev_btc_change_30m = self.btc_change_30m  # Ã–nceki deÄŸeri sakla
                self.btc_change_30m = new_change
                
                # =================================================================
                # Phase 60d: FLASH CRASH + TIME-BASED RECOVERY
                # =================================================================
                if self.btc_change_30m < -2.0:
                    # Flash crash baÅŸladÄ± veya devam ediyor
                    if not self.flash_crash_active:
                        logger.warning(f"âš¡ FLASH CRASH DETECTED: 30m:{self.btc_change_30m:.1f}%")
                        self.flash_crash_start_time = datetime.now()
                    self.flash_crash_active = True
                    
                    # Time-based recovery phase belirleme
                    if self.flash_crash_start_time:
                        elapsed_minutes = (datetime.now() - self.flash_crash_start_time).total_seconds() / 60
                        
                        if elapsed_minutes < 10:
                            self.recovery_phase = "BLOCKED"
                        elif elapsed_minutes < 20:
                            self.recovery_phase = "PENALTY_HIGH"  # 50% penalty
                        elif elapsed_minutes < 30:
                            self.recovery_phase = "PENALTY_LOW"   # 25% penalty
                        else:
                            self.recovery_phase = "NORMAL"
                        
                        # Momentum iyileÅŸiyorsa fazÄ± hÄ±zlandÄ±r
                        if self.btc_momentum_improving and self.recovery_phase == "BLOCKED":
                            self.recovery_phase = "PENALTY_HIGH"
                            logger.info(f"ðŸ“ˆ RECOVERY ACCELERATED: Momentum improving, phase â†’ PENALTY_HIGH")
                    
                elif self.btc_change_30m > -1.0:
                    # Flash crash sona erdi
                    if self.flash_crash_active:
                        logger.info(f"âœ… FLASH CRASH ENDED: 30m recovered to {self.btc_change_30m:.1f}%")
                    self.flash_crash_active = False
                    self.flash_crash_start_time = None
                    self.recovery_phase = "NORMAL"
                
                # =================================================================
                # Phase 60d: FLASH PUMP + TIME-BASED RECOVERY (BULLISH â†’ SHORT)
                # AÅŸÄ±rÄ± yÃ¼kseliÅŸ sonrasÄ± SHORT sinyalleri iÃ§in recovery
                # =================================================================
                if self.btc_change_30m > 2.0:
                    # Flash pump baÅŸladÄ± veya devam ediyor
                    if not self.flash_pump_active:
                        logger.warning(f"ðŸš€ FLASH PUMP DETECTED: 30m:+{self.btc_change_30m:.1f}%")
                        self.flash_pump_start_time = datetime.now()
                    self.flash_pump_active = True
                    
                    # Momentum zayÄ±flama kontrolÃ¼ (yÃ¼kseliÅŸ yavaÅŸlÄ±yor mu?)
                    if self.prev_btc_change_30m > 1.0:  # Ã–nceden yÃ¼kseliÅŸteydi
                        if new_change < self.prev_btc_change_30m - 0.5:  # YavaÅŸlÄ±yor
                            if not self.btc_momentum_weakening:
                                logger.info(f"ðŸ“‰ BTC MOMENTUM WEAKENING: {self.prev_btc_change_30m:.1f}% â†’ {new_change:.1f}%")
                            self.btc_momentum_weakening = True
                        else:
                            self.btc_momentum_weakening = False
                    else:
                        self.btc_momentum_weakening = False
                    
                    # Time-based recovery phase for SHORT
                    if self.flash_pump_start_time:
                        elapsed_minutes = (datetime.now() - self.flash_pump_start_time).total_seconds() / 60
                        
                        if elapsed_minutes < 10:
                            self.recovery_phase_short = "BLOCKED"
                        elif elapsed_minutes < 20:
                            self.recovery_phase_short = "PENALTY_HIGH"
                        elif elapsed_minutes < 30:
                            self.recovery_phase_short = "PENALTY_LOW"
                        else:
                            self.recovery_phase_short = "NORMAL"
                        
                        # Momentum zayÄ±flÄ±yorsa fazÄ± hÄ±zlandÄ±r
                        if self.btc_momentum_weakening and self.recovery_phase_short == "BLOCKED":
                            self.recovery_phase_short = "PENALTY_HIGH"
                            logger.info(f"ðŸ“‰ SHORT RECOVERY ACCELERATED: Momentum weakening, phase â†’ PENALTY_HIGH")
                
                elif self.btc_change_30m < 1.0:
                    # Flash pump sona erdi
                    if self.flash_pump_active:
                        logger.info(f"âœ… FLASH PUMP ENDED: 30m cooled to {self.btc_change_30m:.1f}%")
                    self.flash_pump_active = False
                    self.flash_pump_start_time = None
                    self.recovery_phase_short = "NORMAL"
            
            if ohlcv_1h and len(ohlcv_1h) >= 2:
                current = ohlcv_1h[-1][4]  # Close
                prev_1h = ohlcv_1h[-2][4]
                self.btc_price = current
                self.prev_btc_change_1h = self.btc_change_1h  # Phase 60e: prev sakla
                self.btc_change_1h = ((current - prev_1h) / prev_1h) * 100
            
            if ohlcv_4h and len(ohlcv_4h) >= 2:
                current = ohlcv_4h[-1][4]
                prev_4h = ohlcv_4h[-2][4]
                self.prev_btc_change_4h = self.btc_change_4h  # Phase 60e: prev sakla
                self.btc_change_4h = ((current - prev_4h) / prev_4h) * 100
            
            # 1D (GÃ¼nlÃ¼k) deÄŸiÅŸim hesapla
            if ohlcv_1d and len(ohlcv_1d) >= 2:
                current = ohlcv_1d[-1][4]  # BugÃ¼nÃ¼n kapanÄ±ÅŸÄ±
                prev_1d = ohlcv_1d[-2][4]  # DÃ¼nÃ¼n kapanÄ±ÅŸÄ±
                self.btc_change_1d = ((current - prev_1d) / prev_1d) * 100
                
                # GÃ¼nlÃ¼k trend belirleme
                if self.btc_change_1d > 3.0:
                    self.btc_trend_daily = "STRONG_BULLISH"
                elif self.btc_change_1d > 1.0:
                    self.btc_trend_daily = "BULLISH"
                elif self.btc_change_1d < -3.0:
                    self.btc_trend_daily = "STRONG_BEARISH"
                elif self.btc_change_1d < -1.0:
                    self.btc_trend_daily = "BEARISH"
                else:
                    self.btc_trend_daily = "NEUTRAL"
            
            # =================================================================
            # Phase 60b: IMPROVED STRONG_BEARISH Detection
            # 1H eÅŸiÄŸi gevÅŸetildi (-0.5% â†’ -1.5%), 30m flash crash eklendi
            # =================================================================
            
            # STRONG_BULLISH: 1H ve 4H ikisi de pozitif
            if self.btc_change_1h > 1.5 and self.btc_change_4h > 2.0:
                self.btc_trend = "STRONG_BULLISH"
                self.btc_momentum = 1.0
            elif self.btc_change_1h > 0.5:
                self.btc_trend = "BULLISH"
                self.btc_momentum = 0.5
            # FLASH CRASH: 30m'de %2+ dÃ¼ÅŸÃ¼ÅŸ = anlÄ±k STRONG_BEARISH
            elif self.flash_crash_active or self.btc_change_30m < -1.5:
                self.btc_trend = "STRONG_BEARISH"
                self.btc_momentum = -1.0
            # STRONG_BEARISH: 1H < -1.5% VEYA 4H < -3.0% (gevÅŸetildi)
            elif self.btc_change_1h < -1.5 or self.btc_change_4h < -3.0:
                self.btc_trend = "STRONG_BEARISH"
                self.btc_momentum = -1.0
            # BEARISH: 1H < -0.5% VEYA 4H < -1.5% (gevÅŸetildi)
            elif self.btc_change_1h < -0.5 or self.btc_change_4h < -1.5:
                self.btc_trend = "BEARISH"
                self.btc_momentum = -0.5
            elif self.btc_change_1h < -0.2:
                self.btc_trend = "BEARISH"
                self.btc_momentum = -0.3
            else:
                self.btc_trend = "NEUTRAL"
                self.btc_momentum = 0.0
            
            # =================================================================
            # Phase 60c: ETH TREND TRACKING
            # BTC stabil ama ETH/ALT'lar dÃ¼ÅŸerse koruma saÄŸlar
            # =================================================================
            try:
                # Rate limit fix: 100ms delay between calls
                eth_30m = await exchange.fetch_ohlcv('ETH/USDT', '30m', limit=4)
                await asyncio.sleep(0.1)
                eth_1h = await exchange.fetch_ohlcv('ETH/USDT', '1h', limit=4)
                await asyncio.sleep(0.1)
                eth_4h = await exchange.fetch_ohlcv('ETH/USDT', '4h', limit=4)
                
                if eth_30m and len(eth_30m) >= 2:
                    curr = eth_30m[-1][4]
                    prev = eth_30m[-2][4]
                    new_eth_change = ((curr - prev) / prev) * 100
                    self.eth_price = curr
                    
                    # Phase 60d: ETH Momentum Shift Detection
                    if self.prev_eth_change_30m < -1.5:
                        if new_eth_change > self.prev_eth_change_30m + 0.5:
                            if not self.eth_momentum_improving:
                                logger.info(f"ðŸ“ˆ ETH MOMENTUM SHIFT: {self.prev_eth_change_30m:.1f}% â†’ {new_eth_change:.1f}%")
                            self.eth_momentum_improving = True
                        else:
                            self.eth_momentum_improving = False
                    else:
                        self.eth_momentum_improving = False
                    
                    self.prev_eth_change_30m = self.eth_change_30m
                    self.eth_change_30m = new_eth_change
                    
                    # ETH Flash crash: 30m'de %3+ dÃ¼ÅŸÃ¼ÅŸ
                    if self.eth_change_30m < -3.0:
                        if not self.eth_flash_crash:
                            logger.warning(f"âš¡ ETH FLASH CRASH: 30m:{self.eth_change_30m:.1f}%")
                        self.eth_flash_crash = True
                    elif self.eth_change_30m > -1.5:
                        self.eth_flash_crash = False
                
                if eth_1h and len(eth_1h) >= 2:
                    curr = eth_1h[-1][4]
                    prev = eth_1h[-2][4]
                    self.eth_change_1h = ((curr - prev) / prev) * 100
                
                if eth_4h and len(eth_4h) >= 2:
                    curr = eth_4h[-1][4]
                    prev = eth_4h[-2][4]
                    self.eth_change_4h = ((curr - prev) / prev) * 100
                
                # ETH Trend belirleme
                if self.eth_flash_crash or self.eth_change_30m < -2.0:
                    self.eth_trend = "STRONG_BEARISH"
                elif self.eth_change_1h < -2.0 or self.eth_change_4h < -4.0:
                    self.eth_trend = "STRONG_BEARISH"
                elif self.eth_change_1h < -1.0 or self.eth_change_4h < -2.0:
                    self.eth_trend = "BEARISH"
                elif self.eth_change_1h > 2.0 and self.eth_change_4h > 3.0:
                    self.eth_trend = "STRONG_BULLISH"
                elif self.eth_change_1h > 1.0:
                    self.eth_trend = "BULLISH"
                else:
                    self.eth_trend = "NEUTRAL"
                
                # ETH State log
                logger.info(f"ðŸ“Š ETH State: {self.eth_trend} | 30m:{self.eth_change_30m:.2f}% | 1H:{self.eth_change_1h:.2f}% | 4H:{self.eth_change_4h:.2f}% | Price:${self.eth_price:.2f}")
                    
            except Exception as eth_err:
                logger.debug(f"ETH fetch error: {eth_err}")
            
            # =================================================================
            # Phase 178: SMT Divergence with candle-based data
            # Uses BTC 15m and ETH 30m OHLCV for proper swing high/low detection
            # (Moved from WS ticker which used 24H high/low = wrong)
            # =================================================================
            try:
                if ohlcv_15m and len(ohlcv_15m) >= 2:
                    # Clear old ticker-based data and feed candle data
                    for i, btc_candle in enumerate(ohlcv_15m):
                        _, _, btc_h, btc_l, btc_c, _ = btc_candle
                        # Use ETH 30m if available, otherwise estimate from ticker
                        eth_h, eth_l, eth_c = btc_h, btc_l, btc_c  # fallback
                        if eth_30m and i < len(eth_30m):
                            _, _, eth_h, eth_l, eth_c, _ = eth_30m[i]
                        elif eth_1h and len(eth_1h) > 0:
                            _, _, eth_h, eth_l, eth_c, _ = eth_1h[-1]
                        
                        smt_divergence_detector.update_prices(
                            btc_high=btc_h, btc_low=btc_l, btc_close=btc_c,
                            eth_high=eth_h, eth_low=eth_l, eth_close=eth_c
                        )
                    smt_divergence_detector.detect_divergence()
            except Exception as smt_err:
                logger.debug(f"SMT update error: {smt_err}")
            
            # =================================================================
            # Phase 60: EMERGENCY MODE - Extreme market conditions
            # BEARISH: 4H'da %5+ dÃ¼ÅŸÃ¼ÅŸ veya 1D'da %6+ dÃ¼ÅŸÃ¼ÅŸ = Emergency Bearish
            # BULLISH: 4H'da %5+ yÃ¼kseliÅŸ veya 1D'da %6+ yÃ¼kseliÅŸ = Emergency Bullish
            # =================================================================
            prev_emergency = self.emergency_mode
            
            # Emergency BEARISH (Strong dÃ¼ÅŸÃ¼ÅŸ)
            if self.btc_change_4h < -5.0 or self.btc_change_1d < -6.0:
                self.emergency_mode = "BEARISH"
                self.emergency_reason = f"ðŸš¨ EMERGENCY BEARISH: 4H:{self.btc_change_4h:.1f}%, 1D:{self.btc_change_1d:.1f}%"
                if prev_emergency != "BEARISH":
                    self.emergency_start_time = datetime.now()
                    logger.warning(f"ðŸš¨ðŸš¨ðŸš¨ EMERGENCY BEARISH ACTIVATED: {self.emergency_reason}")
            # Emergency BULLISH (Strong yÃ¼kseliÅŸ)
            elif self.btc_change_4h > 5.0 or self.btc_change_1d > 6.0:
                self.emergency_mode = "BULLISH"
                self.emergency_reason = f"ðŸš€ EMERGENCY BULLISH: 4H:+{self.btc_change_4h:.1f}%, 1D:+{self.btc_change_1d:.1f}%"
                if prev_emergency != "BULLISH":
                    self.emergency_start_time = datetime.now()
                    logger.warning(f"ðŸš€ðŸš€ðŸš€ EMERGENCY BULLISH ACTIVATED: {self.emergency_reason}")
            elif abs(self.btc_change_4h) < 3.0 and abs(self.btc_change_1d) < 4.0:
                # Normal piyasa - emergency moddan Ã§Ä±k
                if prev_emergency:
                    logger.info(f"âœ… Emergency Mode deactivated - market normalized")
                self.emergency_mode = False
                self.emergency_reason = ""
            else:
                # Orta seviye - mevcut durumu koru
                pass
            
            # =================================================================
            # Phase 60: DYNAMIC UPDATE INTERVAL
            # Volatil dÃ¶nemlerde gÃ¼ncelleme hÄ±zÄ±nÄ± artÄ±r
            # =================================================================
            if abs(self.btc_change_1h) > 2.0 or abs(self.btc_change_4h) > 4.0:
                self.update_interval = 60  # HÄ±zlÄ± hareket: 1 dakika
            elif abs(self.btc_change_1h) > 1.0 or abs(self.btc_change_4h) > 2.0:
                self.update_interval = 90  # Orta hareket: 1.5 dakika
            else:
                self.update_interval = self.base_update_interval  # Normal: 2 dakika
            
            self.last_update = now
            # Her zaman INFO seviyesinde logla (debug gÃ¶rÃ¼nmÃ¼yor)
            logger.info(f"ðŸ“Š BTC State: {self.btc_trend} | Daily:{self.btc_trend_daily} | 1H:{self.btc_change_1h:.2f}% | 4H:{self.btc_change_4h:.2f}% | 1D:{self.btc_change_1d:.2f}% | Emergency:{self.emergency_mode} | Interval:{self.update_interval}s")
            
        except Exception as e:
            logger.warning(f"BTC state update failed: {e}")
        
        return self.get_state()
    
    def should_allow_signal(self, symbol: str, signal_action: str, 
                            coin_change_pct: float = 0.0, volume_24h: float = 0.0,
                            zscore: float = 0.0, spread_pct: float = 0.0) -> tuple:
        """
        Phase 230B (Codex): Multi-factor coin strength override.
        Returns: (allowed: bool, penalty: float, reason: str)
        Sets self.last_override = True when coin strength exception fires.
        """
        self.last_override = False  # Reset per call
        # BTC kendisi ise filtreleme yok
        if 'BTC' in symbol:
            return (True, 0.0, "BTC no filter")
        
        # ===================================================================
        # Phase 60b: BTC VERÄ°SÄ° KONTROLÃœ
        # BTC verisi henÃ¼z gÃ¼ncellenmemiÅŸse sinyali reddet (gÃ¼venlik Ã¶nlemi)
        # ===================================================================
        if self.last_update == 0:
            logger.warning(f"âš ï¸ BTC DATA NOT READY: {symbol} {signal_action} blocked - waiting for BTC state update")
            return (False, 1.0, "âš ï¸ BTC Data Not Ready - Signal Blocked")
        
        # ===================================================================
        # Phase 60d: FLASH CRASH + RECOVERY DETECTION (Karma YaklaÅŸÄ±m)
        # Tam blokaj yerine kademeli penalty sistemi
        # ===================================================================
        if self.flash_crash_active and signal_action == "LONG":
            if self.recovery_phase == "BLOCKED":
                # Ä°lk 10 dk veya momentum kÃ¶tÃ¼leÅŸiyor = tam blokaj
                if not self.btc_momentum_improving:
                    logger.warning(f"âš¡ FLASH CRASH BLOCKED: {symbol} LONG rejected - Phase:{self.recovery_phase}, Momentum:{self.btc_momentum_improving}")
                    return (False, 1.0, f"âš¡ Flash Crash [{self.recovery_phase}] - LONG BLOCKED")
                else:
                    # Momentum iyileÅŸiyor ama henÃ¼z erken - yÃ¼ksek penalty ile izin ver
                    logger.info(f"ðŸ“ˆ RECOVERY LONG: {symbol} - Momentum improving, penalty=50%")
                    return (True, 0.5, f"ðŸ“ˆ Recovery Phase (momentum improving) - 50% penalty")
            
            elif self.recovery_phase == "PENALTY_HIGH":
                # 10-20 dk arasÄ± = %50 penalty ile izin ver
                logger.info(f"ðŸ“ˆ RECOVERY LONG: {symbol} - Phase:{self.recovery_phase}, penalty=50%")
                return (True, 0.5, f"ðŸ“ˆ Recovery Phase [{self.recovery_phase}] - 50% penalty")
            
            elif self.recovery_phase == "PENALTY_LOW":
                # 20-30 dk arasÄ± = %25 penalty ile izin ver
                logger.info(f"ðŸ“ˆ RECOVERY LONG: {symbol} - Phase:{self.recovery_phase}, penalty=25%")
                return (True, 0.25, f"ðŸ“ˆ Recovery Phase [{self.recovery_phase}] - 25% penalty")
            
            else:
                # 30+ dk = normal
                pass
        
        # ===================================================================
        # Phase 60d: FLASH PUMP + RECOVERY DETECTION (BULLISH â†’ SHORT)
        # AÅŸÄ±rÄ± yÃ¼kseliÅŸ sonrasÄ± SHORT sinyalleri iÃ§in kademeli izin
        # ===================================================================
        if self.flash_pump_active and signal_action == "SHORT":
            if self.recovery_phase_short == "BLOCKED":
                # Ä°lk 10 dk veya momentum gÃ¼Ã§lenmeye devam ediyor = tam blokaj
                if not self.btc_momentum_weakening:
                    logger.warning(f"ðŸš€ FLASH PUMP BLOCKED: {symbol} SHORT rejected - Phase:{self.recovery_phase_short}")
                    return (False, 1.0, f"ðŸš€ Flash Pump [{self.recovery_phase_short}] - SHORT BLOCKED")
                else:
                    # Momentum zayÄ±flÄ±yor ama henÃ¼z erken - yÃ¼ksek penalty ile izin ver
                    logger.info(f"ðŸ“‰ RECOVERY SHORT: {symbol} - Momentum weakening, penalty=50%")
                    return (True, 0.5, f"ðŸ“‰ Recovery Phase (momentum weakening) - 50% penalty")
            
            elif self.recovery_phase_short == "PENALTY_HIGH":
                # 10-20 dk arasÄ± = %50 penalty ile izin ver
                logger.info(f"ðŸ“‰ RECOVERY SHORT: {symbol} - Phase:{self.recovery_phase_short}, penalty=50%")
                return (True, 0.5, f"ðŸ“‰ Recovery Phase [{self.recovery_phase_short}] - 50% penalty")
            
            elif self.recovery_phase_short == "PENALTY_LOW":
                # 20-30 dk arasÄ± = %25 penalty ile izin ver
                logger.info(f"ðŸ“‰ RECOVERY SHORT: {symbol} - Phase:{self.recovery_phase_short}, penalty=25%")
                return (True, 0.25, f"ðŸ“‰ Recovery Phase [{self.recovery_phase_short}] - 25% penalty")
            
            else:
                # 30+ dk = normal
                pass
        
        # ===================================================================
        # Phase 60c: ETH DIVERGENCE FILTER
        # BTC stabil ama ETH dÃ¼ÅŸÃ¼yorsa ALT LONG'larÄ± bloke et
        # ===================================================================
        # ETH kendisi ise filtreleme yok
        if 'ETH' in symbol:
            pass  # ETH iÃ§in sadece BTC filter yeterli
        elif self.eth_flash_crash and signal_action == "LONG":
            logger.warning(f"âš¡ ETH FLASH CRASH BLOCK: {symbol} LONG rejected - ETH 30m:{self.eth_change_30m:.1f}%")
            return (False, 1.0, f"âš¡ ETH Flash Crash (30m:{self.eth_change_30m:.1f}%) - ALT LONG BLOCKED")
        elif self.eth_trend == "STRONG_BEARISH" and signal_action == "LONG":
            # ETH strong bearish ama BTC normal ise - ALT'lar genelde ETH'yi takip eder
            if self.btc_trend not in ["STRONG_BEARISH", "BEARISH"]:
                logger.info(f"ðŸ”» ETH DIVERGENCE: {symbol} LONG penalty - ETH:{self.eth_trend}, BTC:{self.btc_trend}")
                return (True, 0.3, f"ETH Divergence (ETH bearish, BTC stable) - HIGH RISK")
        
        # ETH BULLISH iken SHORT sinyallere dikkat
        elif self.eth_trend == "STRONG_BULLISH" and signal_action == "SHORT":
            if self.btc_trend not in ["STRONG_BULLISH", "BULLISH"]:
                logger.info(f"ðŸ”º ETH DIVERGENCE: {symbol} SHORT penalty - ETH:{self.eth_trend}, BTC:{self.btc_trend}")
                return (True, 0.3, f"ETH Divergence (ETH bullish, BTC stable) - HIGH RISK")
        
        # Phase 60e: EMERGENCY MODE + MTF RECOVERY
        # MTF skor bazlÄ± kademeli recovery
        # ===================================================================
        if self.emergency_mode == "BEARISH":
            if signal_action == "LONG":
                # MTF Momentum Score hesapla
                mtf_score = self.calculate_mtf_momentum_score("LONG")
                
                if mtf_score == 0:
                    # HiÃ§bir TF iyileÅŸmiyor = tam blokaj
                    logger.warning(f"ðŸš¨ EMERGENCY BEARISH BLOCK: {symbol} LONG - MTF:{mtf_score}/7")
                    return (False, 1.0, f"ðŸš¨ Emergency BEARISH (MTF:{mtf_score}/7) - LONG BLOCKED")
                elif mtf_score <= 2:
                    # Sadece kÄ±sa vade = 60% penalty
                    logger.info(f"ðŸ“ˆ MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=60%")
                    return (True, 0.6, f"ðŸ“ˆ MTF Recovery ({mtf_score}/7) - 60% penalty")
                elif mtf_score <= 4:
                    # Orta vade = 40% penalty
                    logger.info(f"ðŸ“ˆ MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=40%")
                    return (True, 0.4, f"ðŸ“ˆ MTF Recovery ({mtf_score}/7) - 40% penalty")
                else:
                    # GÃ¼Ã§lÃ¼ dÃ¶nÃ¼ÅŸ = 25% penalty
                    logger.info(f"ðŸ“ˆ STRONG MTF RECOVERY: {symbol} LONG - Score:{mtf_score}/7, penalty=25%")
                    return (True, 0.25, f"ðŸ“ˆ Strong MTF Recovery ({mtf_score}/7) - 25% penalty")
            else:
                # SHORT sinyallere bonus ver
                return (True, -0.25, f"âœ… Emergency SHORT allowed - trend aligned")
        
        elif self.emergency_mode == "BULLISH":
            if signal_action == "SHORT":
                # MTF Momentum Score hesapla
                mtf_score = self.calculate_mtf_momentum_score("SHORT")
                
                if mtf_score == 0:
                    # HiÃ§bir TF zayÄ±flamÄ±yor = tam blokaj
                    logger.warning(f"ðŸš€ EMERGENCY BULLISH BLOCK: {symbol} SHORT - MTF:{mtf_score}/7")
                    return (False, 1.0, f"ðŸš€ Emergency BULLISH (MTF:{mtf_score}/7) - SHORT BLOCKED")
                elif mtf_score <= 2:
                    logger.info(f"ðŸ“‰ MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=60%")
                    return (True, 0.6, f"ðŸ“‰ MTF Recovery ({mtf_score}/7) - 60% penalty")
                elif mtf_score <= 4:
                    logger.info(f"ðŸ“‰ MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=40%")
                    return (True, 0.4, f"ðŸ“‰ MTF Recovery ({mtf_score}/7) - 40% penalty")
                else:
                    logger.info(f"ðŸ“‰ STRONG MTF RECOVERY: {symbol} SHORT - Score:{mtf_score}/7, penalty=25%")
                    return (True, 0.25, f"ðŸ“‰ Strong MTF Recovery ({mtf_score}/7) - 25% penalty")
            else:
                # LONG sinyallere bonus ver
                return (True, -0.25, f"âœ… Emergency LONG allowed - trend aligned")
        
        penalty = 0.0
        reason = ""
        
        # ===================================================================
        # Phase 60: FULL ALIGNMENT VETO
        # Daily + Short-term trend aynÄ± yÃ¶ndeyse, ters sinyal mutlak veto
        # ===================================================================
        full_bearish = (self.btc_trend_daily in ["BEARISH", "STRONG_BEARISH"] and 
                        self.btc_trend in ["BEARISH", "STRONG_BEARISH"])
        full_bullish = (self.btc_trend_daily in ["BULLISH", "STRONG_BULLISH"] and 
                        self.btc_trend in ["BULLISH", "STRONG_BULLISH"])
        
        if full_bearish and signal_action == "LONG":
            # Phase 230B: Multi-factor coin strength check
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                logger.warning(f"ðŸ’ª COIN STRENGTH OVERRIDE: {symbol} LONG (coin:{coin_change_pct:+.1f}%) despite Full Bearish | {factors_detail}")
                return (True, 0.30, f"ðŸ’ª Override ({coin_change_pct:+.1f}%) [{factors_detail}] - Full Bearish bypassed")
            else:
                # Phase 230B: Soft veto â€” 75% penalty instead of hard block
                logger.info(f"ðŸš« FULL ALIGNMENT PENALTY: {symbol} LONG (coin:{coin_change_pct:+.1f}%, {factors_detail}) | penalty=0.75")
                return (True, 0.75, f"ðŸš« Full Bearish Alignment - 75% penalty ({factors_detail})")
        
        if full_bullish and signal_action == "SHORT":
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                logger.warning(f"ðŸ’ª COIN STRENGTH OVERRIDE: {symbol} SHORT (coin:{coin_change_pct:+.1f}%) despite Full Bullish | {factors_detail}")
                return (True, 0.30, f"ðŸ’ª Override ({coin_change_pct:+.1f}%) [{factors_detail}] - Full Bullish bypassed")
            else:
                logger.info(f"ðŸš« FULL ALIGNMENT PENALTY: {symbol} SHORT (coin:{coin_change_pct:+.1f}%, {factors_detail}) | penalty=0.75")
                return (True, 0.75, f"ðŸš« Full Bullish Alignment - 75% penalty ({factors_detail})")
        
        # ===================================================================
        # GÃœNLÃœK TREND FÄ°LTRESÄ° (EN GÃœÃ‡LÃœ)
        # Sadece ekstrem durumda blokaj; diÄŸer durumlarda yÃ¼ksek penalty + risk cap
        # ===================================================================
        if self.btc_trend_daily == "STRONG_BEARISH" and signal_action == "LONG":
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                return (True, 0.35, f"ðŸ’ª Daily Strong Bearish override ({factors_detail})")
            is_extreme_bear = (
                self.emergency_mode == "BEARISH"
                or self.flash_crash_active
                or self.btc_change_1h <= -2.5
                or self.btc_change_4h <= -4.5
                or self.btc_change_1d <= -6.0
            )
            if is_extreme_bear and not self.btc_momentum_improving:
                return (False, 1.0, "ðŸš« Daily STRONG_BEARISH + weak momentum - LONG blocked")
            return (True, 0.60, "Daily STRONG_BEARISH - LONG high risk")
        
        if self.btc_trend_daily == "STRONG_BULLISH" and signal_action == "SHORT":
            override_allowed, factors_detail = self._check_coin_strength_override(
                symbol, signal_action, coin_change_pct, volume_24h, zscore, spread_pct
            )
            if override_allowed:
                self.last_override = True
                return (True, 0.35, f"ðŸ’ª Daily Strong Bullish override ({factors_detail})")
            is_extreme_bull = (
                self.emergency_mode == "BULLISH"
                or self.flash_pump_active
                or self.btc_change_1h >= 2.5
                or self.btc_change_4h >= 4.5
                or self.btc_change_1d >= 6.0
            )
            if is_extreme_bull and not self.btc_momentum_weakening:
                return (False, 1.0, "ðŸš« Daily STRONG_BULLISH + strong momentum - SHORT blocked")
            return (True, 0.60, "Daily STRONG_BULLISH - SHORT high risk")
        
        # GÃ¼nlÃ¼k trend orta dÃ¼zeyde ters ise yÃ¼ksek ceza
        if self.btc_trend_daily == "BEARISH" and signal_action == "LONG":
            penalty = 0.5  # %50 skor dÃ¼ÅŸÃ¼r (sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ±)
            reason = "Daily BEARISH - LONG risky"
        elif self.btc_trend_daily == "BULLISH" and signal_action == "SHORT":
            penalty = 0.5  # %50 skor dÃ¼ÅŸÃ¼r (sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ±)
            reason = "Daily BULLISH - SHORT risky"
        
        # KÄ±sa vadeli trend kontrolÃ¼ (1H + 4H)
        # BTC STRONG_BEARISH iken ALT LONG risky
        if self.btc_trend == "STRONG_BEARISH" and signal_action == "LONG":
            penalty = max(penalty, 0.4)  # %40 skor dÃ¼ÅŸÃ¼r (was 0.3)
            reason = reason or "BTC Strong Bearish - ALT LONG risky"
        
        # BTC BEARISH iken ALT LONG dikkat
        elif self.btc_trend == "BEARISH" and signal_action == "LONG":
            penalty = max(penalty, 0.2)  # %20 (was 0.15)
            reason = reason or "BTC Bearish - ALT LONG caution"
        
        # BTC STRONG_BULLISH iken ALT SHORT risky
        elif self.btc_trend == "STRONG_BULLISH" and signal_action == "SHORT":
            penalty = max(penalty, 0.4)  # %40 (was 0.3)
            reason = reason or "BTC Strong Bullish - ALT SHORT risky"
        
        # BTC BULLISH iken ALT SHORT dikkat
        elif self.btc_trend == "BULLISH" and signal_action == "SHORT":
            penalty = max(penalty, 0.2)  # %20 (was 0.15)
            reason = reason or "BTC Bullish - ALT SHORT caution"
        
        # AynÄ± yÃ¶nde ise bonus
        elif (self.btc_trend in ["BULLISH", "STRONG_BULLISH"] and signal_action == "LONG") or \
             (self.btc_trend in ["BEARISH", "STRONG_BEARISH"] and signal_action == "SHORT"):
            penalty = -0.2  # GÃ¼nlÃ¼k aynÄ± yÃ¶ndeyse daha bÃ¼yÃ¼k bonus (was -0.15)
            reason = "âœ… BTC trend aligned with signal"
        
        # YÃ¼ksek penalty ise reddet (orta seviye terslikte artÄ±k penalty+risk cap ile izin ver)
        allowed = penalty < 0.55
        
        return (allowed, penalty, reason)
    
    def _check_coin_strength_override(self, symbol: str, signal_action: str,
                                       coin_change_pct: float, volume_24h: float,
                                       zscore: float, spread_pct: float) -> tuple:
        """
        Phase 230B (Codex): Multi-factor coin strength validation.
        Requires at least 3 of 4 factors to pass for override.
        Returns: (override_allowed: bool, factors_detail: str)
        """
        factors_passed = 0
        factors_labels = []
        
        # Factor 1: Price Momentum â€” coin moving strongly in signal direction
        if signal_action == "LONG":
            momentum_ok = coin_change_pct > 5.0
        else:
            momentum_ok = coin_change_pct < -5.0
        if momentum_ok:
            factors_passed += 1
            factors_labels.append(f"âœ…MOM({coin_change_pct:+.1f}%)")
        else:
            factors_labels.append(f"âŒMOM({coin_change_pct:+.1f}%)")
        
        # Factor 2: Volume â€” healthy liquidity (>$500K daily volume)
        volume_ok = volume_24h > 500_000
        if volume_ok:
            factors_passed += 1
            factors_labels.append(f"âœ…VOL(${volume_24h/1e6:.1f}M)")
        else:
            factors_labels.append(f"âŒVOL(${volume_24h/1e6:.1f}M)")
        
        # Factor 3: Z-score not extreme â€” avoid buying tops or selling bottoms
        if signal_action == "LONG":
            zscore_ok = zscore < 2.5  # Not overbought
        else:
            zscore_ok = zscore > -2.5  # Not oversold
        if zscore_ok:
            factors_passed += 1
            factors_labels.append(f"âœ…Z({zscore:.1f})")
        else:
            factors_labels.append(f"âŒZ({zscore:.1f})")
        
        # Factor 4: Spread acceptable â€” entry cost reasonable
        spread_ok = spread_pct < 0.5  # Less than 0.5% spread
        if spread_ok:
            factors_passed += 1
            factors_labels.append(f"âœ…SPR({spread_pct:.2f}%)")
        else:
            factors_labels.append(f"âŒSPR({spread_pct:.2f}%)")
        
        detail = f"{factors_passed}/4 [{' '.join(factors_labels)}]"
        override_allowed = factors_passed >= 3
        
        return (override_allowed, detail)
    
    def calculate_mtf_momentum_score(self, direction: str = "LONG") -> int:
        """
        Phase 60e: MTF Momentum Score hesapla.
        direction: "LONG" = dÃ¼ÅŸÃ¼ÅŸten dÃ¶nÃ¼ÅŸ, "SHORT" = yÃ¼kseliÅŸten dÃ¶nÃ¼ÅŸ
        Returns: 0-7 arasÄ± skor (7 = gÃ¼Ã§lÃ¼ dÃ¶nÃ¼ÅŸ sinyali)
        """
        score = 0
        
        if direction == "LONG":  # DÃ¼ÅŸÃ¼ÅŸten dÃ¶nÃ¼ÅŸ - deÄŸerler iyileÅŸiyor mu?
            # 15m: +0.3% iyileÅŸme = 1 puan
            if self.btc_change_15m > self.prev_btc_change_15m + 0.3:
                score += 1
            # 30m: +0.5% iyileÅŸme = 1 puan
            if self.btc_change_30m > self.prev_btc_change_30m + 0.5:
                score += 1
            # 1H: +0.5% iyileÅŸme = 2 puan
            if self.btc_change_1h > self.prev_btc_change_1h + 0.5:
                score += 2
            # 4H: +1.0% iyileÅŸme = 3 puan
            if self.btc_change_4h > self.prev_btc_change_4h + 1.0:
                score += 3
        else:  # SHORT - yÃ¼kseliÅŸten dÃ¶nÃ¼ÅŸ - deÄŸerler zayÄ±flÄ±yor mu?
            # 15m: -0.3% zayÄ±flama = 1 puan
            if self.btc_change_15m < self.prev_btc_change_15m - 0.3:
                score += 1
            # 30m: -0.5% zayÄ±flama = 1 puan
            if self.btc_change_30m < self.prev_btc_change_30m - 0.5:
                score += 1
            # 1H: -0.5% zayÄ±flama = 2 puan
            if self.btc_change_1h < self.prev_btc_change_1h - 0.5:
                score += 2
            # 4H: -1.0% zayÄ±flama = 3 puan
            if self.btc_change_4h < self.prev_btc_change_4h - 1.0:
                score += 3
        
        return score
    
    def get_state(self) -> dict:
        """BTC ve ETH durumu."""
        return {
            "trend": self.btc_trend,
            "trend_daily": self.btc_trend_daily,
            "momentum": self.btc_momentum,
            "price": self.btc_price,
            "change_30m": round(self.btc_change_30m, 2),
            "change_1h": round(self.btc_change_1h, 2),
            "change_4h": round(self.btc_change_4h, 2),
            "change_1d": round(self.btc_change_1d, 2),
            "flash_crash_active": self.flash_crash_active,
            "emergency_mode": self.emergency_mode,
            "emergency_reason": self.emergency_reason,
            "update_interval": self.update_interval,
            # Phase 60c: ETH State
            "eth_trend": self.eth_trend,
            "eth_price": round(self.eth_price, 2),
            "eth_change_30m": round(self.eth_change_30m, 2),
            "eth_change_1h": round(self.eth_change_1h, 2),
            "eth_change_4h": round(self.eth_change_4h, 2),
            "eth_flash_crash": self.eth_flash_crash,
            # Phase 60d: Recovery Detection (Bidirectional)
            "recovery_phase": self.recovery_phase,
            "recovery_phase_short": self.recovery_phase_short,
            "btc_momentum_improving": self.btc_momentum_improving,
            "btc_momentum_weakening": self.btc_momentum_weakening,
            "eth_momentum_improving": self.eth_momentum_improving,
            "flash_crash_active": self.flash_crash_active,
            "flash_pump_active": self.flash_pump_active,
            "flash_crash_start_time": self.flash_crash_start_time.isoformat() if self.flash_crash_start_time else None,
            "flash_pump_start_time": self.flash_pump_start_time.isoformat() if self.flash_pump_start_time else None,
            # Phase 60e: MTF Recovery
            "change_15m": round(self.btc_change_15m, 2),
            "mtf_score_long": self.calculate_mtf_momentum_score("LONG"),
            "mtf_score_short": self.calculate_mtf_momentum_score("SHORT")
        }
    
    # =========================================================================
    # PHASE 36: BTC-ETH PAIRS CORRELATION
    # =========================================================================
    
    def calculate_pairs_spread(self) -> float:
        """
        Calculate BTC-ETH spread using cointegration formula.
        Spread = ETH - (Î² Ã— BTC)
        """
        if self.btc_price <= 0 or self.eth_price <= 0:
            return 0.0
        
        expected_eth = self.beta * self.btc_price
        spread = self.eth_price - expected_eth
        return spread
    
    def calculate_spread_zscore(self) -> float:
        """
        Calculate Z-Score of the spread for mean reversion signals.
        Z = (Spread - Î¼) / Ïƒ
        """
        if len(self.spread_history) < 20:
            return 0.0
        
        # numpy already imported globally
        spread_array = np.array(self.spread_history[-self.spread_window:])
        mean = np.mean(spread_array)
        std = np.std(spread_array)
        
        if std == 0:
            return 0.0
        
        current_spread = self.calculate_pairs_spread()
        zscore = (current_spread - mean) / std
        
        return round(zscore, 2)
    
    async def update_eth_price(self, exchange) -> None:
        """Update ETH price for pairs calculation."""
        try:
            ohlcv = await exchange.fetch_ohlcv('ETH/USDT', '1h', limit=2)
            if ohlcv and len(ohlcv) >= 2:
                self.eth_price = ohlcv[-1][4]
                prev = ohlcv[-2][4]
                self.eth_change_1h = ((self.eth_price - prev) / prev) * 100
                
                # Update spread history
                spread = self.calculate_pairs_spread()
                self.spread_history.append(spread)
                if len(self.spread_history) > self.spread_window * 2:
                    self.spread_history = self.spread_history[-self.spread_window:]
                    
        except Exception as e:
            logger.debug(f"ETH price update failed: {e}")
    
    def get_pairs_signal(self) -> Optional[str]:
        """
        Get pairs trading signal based on spread Z-score.
        
        Returns:
            "LONG_ETH" if Z < -2 (ETH underpriced)
            "SHORT_ETH" if Z > 2 (ETH overpriced)
            None if no clear signal
        """
        zscore = self.calculate_spread_zscore()
        
        if zscore > 2.0:
            return "SHORT_ETH"  # ETH overpriced relative to BTC
        elif zscore < -2.0:
            return "LONG_ETH"  # ETH underpriced relative to BTC
        
        return None
    
    def get_pairs_state(self) -> dict:
        """Get pairs correlation state for UI."""
        return {
            "btc_price": self.btc_price,
            "eth_price": self.eth_price,
            "beta": self.beta,
            "spread": round(self.calculate_pairs_spread(), 2),
            "spread_zscore": self.calculate_spread_zscore(),
            "pairs_signal": self.get_pairs_signal(),
            "history_length": len(self.spread_history)
        }


# Global BTC Correlation Filter instance
btc_filter = BTCCorrelationFilter()


# ============================================================================
# PHASE 28: DYNAMIC COIN PROFILER
# ============================================================================

class CoinProfiler:
    """
    Coin-bazlÄ± dinamik parametre optimizasyonu.
    Her coin iÃ§in tarihsel veri analizi yaparak optimal eÅŸikleri hesaplar.
    
    Analiz Metrikleri:
    - Ortalama ATR %
    - Z-Score standart sapmasÄ± ve 95. persentil
    - Optimal threshold (sinyal Ã¼retim eÅŸiÄŸi)
    - Dinamik minimum skor
    """
    
    def __init__(self):
        self.profiles = {}  # Cache: {symbol: profile_data}
        self.profile_expiry = 3600  # 1 saat cache sÃ¼resi (saniye)
        logger.info("CoinProfiler initialized - Dynamic parameter optimization enabled")
    
    async def analyze_coin(self, symbol: str, exchange) -> dict:
        """
        Coin iÃ§in istatistiksel analiz yap ve optimal parametreleri dÃ¶ndÃ¼r.
        
        Args:
            symbol: Coin sembolÃ¼ (Ã¶rn. "BTC/USDT")
            exchange: CCXT exchange instance
            
        Returns:
            dict: Coin profil verileri ve optimal parametreler
        """
        try:
            logger.info(f"ðŸ” Analyzing coin profile for {symbol}...")
            
            # 1. Son 500 mum verisi al (4H timeframe - ~83 gÃ¼n)
            ohlcv = await exchange.fetch_ohlcv(symbol, '4h', limit=500)
            
            if not ohlcv or len(ohlcv) < 100:
                logger.warning(f"Insufficient data for {symbol}, using default profile")
                return self._get_default_profile(symbol)
            
            # 2. Veriyi parse et
            closes = np.array([float(c[4]) for c in ohlcv])
            highs = np.array([float(c[2]) for c in ohlcv])
            lows = np.array([float(c[3]) for c in ohlcv])
            
            # 3. ATR % hesapla (volatilite metriÄŸi)
            atr_values = []
            for i in range(14, len(closes)):
                tr = max(
                    highs[i] - lows[i],
                    abs(highs[i] - closes[i-1]),
                    abs(lows[i] - closes[i-1])
                )
                atr_pct = (tr / closes[i]) * 100 if closes[i] > 0 else 0
                atr_values.append(atr_pct)
            
            avg_atr_pct = np.mean(atr_values) if atr_values else 2.0
            
            # 4. Z-Score aralÄ±ÄŸÄ± hesapla
            zscore_values = []
            for i in range(20, len(closes)):
                sma = np.mean(closes[i-20:i])
                spread = closes[i] - sma
                std = np.std(closes[i-20:i])
                zscore = spread / std if std > 0 else 0
                zscore_values.append(abs(zscore))
            
            if zscore_values:
                zscore_95th = float(np.percentile(zscore_values, 95))
                zscore_std = float(np.std(zscore_values))
                zscore_mean = float(np.mean(zscore_values))
            else:
                zscore_95th = 2.0
                zscore_std = 0.5
                zscore_mean = 0.8
            
            # 5. Optimal parametreleri hesapla
            # Threshold: %95 persentil / 1.5 (sinyal frekansÄ± iÃ§in)
            # Alt limit 0.8, Ã¼st limit 2.0
            raw_threshold = zscore_95th / 1.5
            optimal_threshold = max(0.8, min(2.0, raw_threshold))
            
            # Minimum skor: Volatil coinler iÃ§in daha dÃ¼ÅŸÃ¼k
            if avg_atr_pct > 4.0:  # Ã‡ok volatil (DOGE, SHIB, PEPE)
                min_score = 55
            elif avg_atr_pct > 2.5:  # Volatil (SOL, MATIC)
                min_score = 65
            else:  # Normal (BTC, ETH)
                min_score = 75
            
            # ATR Ã§arpanlarÄ± (volatiliteye gÃ¶re)
            if avg_atr_pct > 3.0:
                sl_atr = 1.5  # Volatil coinler iÃ§in sÄ±kÄ± SL
                tp_atr = 4.0  # GeniÅŸ TP
            else:
                sl_atr = 2.0
                tp_atr = 3.0
            
            # Phase 207: Coin Type SÄ±nÄ±flandÄ±rmasÄ±
            symbol_upper = symbol.upper()
            if symbol_upper.startswith(('BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'ADA', 'AVAX')):
                coin_type = "MAJOR"
            elif avg_atr_pct > 3.5 or any(meme in symbol_upper for meme in ['PEPE', 'SHIB', 'DOGE', 'FLOKI', 'BONK', 'WIF', 'BOME', 'MEME', 'TURBO', '1000']):
                coin_type = "MEME"
            else:
                coin_type = "ALTCOIN"
            
            profile = {
                'symbol': symbol,
                'coin_type': coin_type,
                'avg_atr_pct': round(avg_atr_pct, 4),
                'zscore_95th': round(zscore_95th, 4),
                'zscore_std': round(zscore_std, 4),
                'zscore_mean': round(zscore_mean, 4),
                'optimal_threshold': round(optimal_threshold, 2),
                'min_score': min_score,
                'sl_atr': sl_atr,
                'tp_atr': tp_atr,
                'data_points': len(ohlcv),
                'updated_at': datetime.now().timestamp()
            }
            
            logger.info(f"âœ… Coin Profile for {symbol}: Threshold={optimal_threshold:.2f}, MinScore={min_score}, ATR%={avg_atr_pct:.2f}")
            
            return profile
            
        except Exception as e:
            logger.error(f"Error analyzing {symbol}: {e}")
            return self._get_default_profile(symbol)
    
    def _get_default_profile(self, symbol: str) -> dict:
        """VarsayÄ±lan profil (analiz baÅŸarÄ±sÄ±z olursa)."""
        symbol_upper = symbol.upper()
        if symbol_upper.startswith(('BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'ADA', 'AVAX')):
            coin_type = "MAJOR"
        elif any(meme in symbol_upper for meme in ['PEPE', 'SHIB', 'DOGE', 'FLOKI', 'BONK', 'WIF', 'BOME', 'MEME', 'TURBO', '1000']):
            coin_type = "MEME"
        else:
            coin_type = "ALTCOIN"
            
        return {
            'symbol': symbol,
            'coin_type': coin_type,
            'avg_atr_pct': 2.0,
            'zscore_95th': 2.0,
            'zscore_std': 0.5,
            'zscore_mean': 0.8,
            'optimal_threshold': 1.4,
            'min_score': 70,
            'sl_atr': 2.0,
            'tp_atr': 3.0,
            'data_points': 0,
            'updated_at': datetime.now().timestamp(),
            'is_default': True
        }
    
    async def get_or_update(self, symbol: str, exchange) -> dict:
        """
        Cache'den profili al veya yeni analiz yap.
        
        Args:
            symbol: Coin sembolÃ¼
            exchange: CCXT exchange instance
            
        Returns:
            dict: Coin profil verileri
        """
        now = datetime.now().timestamp()
        
        # Cache'de var mÄ± ve sÃ¼resi dolmamÄ±ÅŸ mÄ± kontrol et
        if symbol in self.profiles:
            cached = self.profiles[symbol]
            age = now - cached.get('updated_at', 0)
            
            if age < self.profile_expiry:
                logger.debug(f"Using cached profile for {symbol} (age: {age:.0f}s)")
                return cached
        
        # Yeni analiz yap
        profile = await self.analyze_coin(symbol, exchange)
        self.profiles[symbol] = profile
        
        return profile
    
    def get_cached(self, symbol: str) -> Optional[dict]:
        """Cache'deki profili dÃ¶ndÃ¼r (yoksa None)."""
        return self.profiles.get(symbol)


# Global CoinProfiler instance
coin_profiler = CoinProfiler()

# ============================================================================
# PHASE 207: JESSE-INSPIRED STRATEGY ROUTER
# ============================================================================

class StrategyRouter:
    """
    Phase 207: Jesse-Inspired Strategy Router
    Coin'in profiline ve hacimsel/volatilite yapÄ±sÄ±na gÃ¶re en uygun stratejiyi seÃ§er 
    veya uyumsuz stratejileri bloke eder (Ã¶rn: Major coinlerde MeanReversion kÄ±sÄ±tlamasÄ±).
    """
    
    @staticmethod
    def route_strategy(coin_profile: dict, zscore: float, hurst: float, adx: float, market_regime: str) -> dict:
        """
        Gelen coin profilini ve koÅŸullarÄ± deÄŸerlendirerek strateji rotasÄ± ve skor aÄŸÄ±rlÄ±klarÄ± dÃ¶ndÃ¼rÃ¼r.
        """
        coin_type = coin_profile.get('coin_type', 'ALTCOIN')
        avg_atr = coin_profile.get('avg_atr_pct', 2.0)
        
        # VarsayÄ±lan Rota
        route = {
            'recommended_strategy': 'mixed',
            'trend_weight': 1.0,
            'mean_reversion_weight': 1.0,
            'reason': 'Normative behavior',
            'veto_mr': False,
            'veto_tf': False
        }
        
        # KURAL 1: MAJOR COINLER TEPKÄ°SELDÄ°R (Trend)
        if coin_type == "MAJOR":
            if market_regime != "RANGING" and adx > 25:
                route['recommended_strategy'] = 'trend_following'
                route['trend_weight'] = 1.2  # Phase 244: 1.3â†’1.2 (daha yumuÅŸak)
                route['mean_reversion_weight'] = 0.7  # Phase 244: 0.4â†’0.7 (sinyal Ã¼retimini boÄŸma)
                route['reason'] = 'Major Coin in Trend (Favoring TF)'
                # Phase 244: veto_mr kaldÄ±rÄ±ldÄ± â€” sinyal asla tamamen iptal edilmesin
            else:
                route['recommended_strategy'] = 'mean_reversion'
                route['trend_weight'] = 0.8
                route['mean_reversion_weight'] = 1.1
                route['reason'] = 'Major Coin in Range (Favoring MR)'
                
        # KURAL 2: MEME COINLER SERT FÄ°TÄ°L ATAR (Mean Reversion)
        elif coin_type == "MEME" or avg_atr > 4.0:
            if adx < 35:
                route['recommended_strategy'] = 'mean_reversion'
                route['trend_weight'] = 0.6  # Phase 244: 0.5â†’0.6 (biraz daha alan)
                route['mean_reversion_weight'] = 1.3  # Phase 244: 1.4â†’1.3 (biraz daha dengeli)
                route['reason'] = 'Meme/Volatile in Range (Favoring Contratrend)'
                # Phase 244: veto_tf kaldÄ±rÄ±ldÄ± â€” sinyal zayÄ±flasÄ±n ama iptal edilmesin
            else:
                route['recommended_strategy'] = 'momentum_breakout'
                route['trend_weight'] = 1.2  # Phase 244: 1.5â†’1.2
                route['mean_reversion_weight'] = 0.5  # Phase 244: 0.2â†’0.5 (tamamen kapatma)
                route['reason'] = 'Meme Coin Breakout (High Momentum)'
                # Phase 244: veto_mr kaldÄ±rÄ±ldÄ±

        # KURAL 3: DEFAULT ALTCOIN
        else:
            if adx > 25 and hurst > 0.55:
                route['recommended_strategy'] = 'trend_following'
                route['trend_weight'] = 1.2
                route['mean_reversion_weight'] = 0.8
                route['reason'] = 'Trending Altcoin'
            elif hurst < 0.45:
                route['recommended_strategy'] = 'mean_reversion'
                route['trend_weight'] = 0.8
                route['mean_reversion_weight'] = 1.2
                route['reason'] = 'Ranging Altcoin'

        return route

strategy_router = StrategyRouter()



# ============================================================================
# PHASE 29: BALANCE PROTECTOR
# ============================================================================

class BalanceProtector:
    """
    Bakiye koruma ve bÃ¼yÃ¼tme odaklÄ± karar sistemi.
    Win rate deÄŸil, toplam bakiye bÃ¼yÃ¼mesi optimizasyonu.
    
    Prensip: CÃ¼zdan bakiyesini korumak ve bÃ¼yÃ¼tmek ana hedeftir.
    """
    
    def __init__(self, initial_balance: float = 10000.0):
        self.initial_balance = initial_balance
        self.peak_balance = initial_balance
        self.drawdown_threshold = 5.0  # %5 drawdown'da agresif koruma
        self.profit_lock_threshold = 10.0  # %10 karda profit locking aktif
        self.profit_lock_ratio = 0.5  # KarÄ±n %50'sini kilitle
        logger.info(f"BalanceProtector initialized with ${initial_balance:.2f}")
    
    def update_peak(self, current_balance: float):
        """Peak balance'Ä± gÃ¼ncelle."""
        if current_balance > self.peak_balance:
            self.peak_balance = current_balance
            logger.debug(f"New peak balance: ${self.peak_balance:.2f}")
    
    def get_current_drawdown(self, current_balance: float) -> float:
        """Mevcut drawdown yÃ¼zdesini hesapla."""
        if self.peak_balance <= 0:
            return 0.0
        return ((self.peak_balance - current_balance) / self.peak_balance) * 100
    
    def get_profit_percent(self, current_balance: float) -> float:
        """BaÅŸlangÄ±Ã§tan itibaren kar yÃ¼zdesini hesapla."""
        if self.initial_balance <= 0:
            return 0.0
        return ((current_balance - self.initial_balance) / self.initial_balance) * 100
    
    def should_reduce_risk(self, current_balance: float) -> bool:
        """Bakiye dÃ¼ÅŸÃ¼ÅŸÃ¼nde risk azaltÄ±lmalÄ± mÄ±?"""
        drawdown = self.get_current_drawdown(current_balance)
        return drawdown > self.drawdown_threshold
    
    def should_lock_profits(self, current_balance: float) -> bool:
        """Kar kilitleme aktif edilmeli mi?"""
        profit_pct = self.get_profit_percent(current_balance)
        return profit_pct > self.profit_lock_threshold
    
    def calculate_position_size_multiplier(self, current_balance: float) -> float:
        """
        Bakiye durumuna gÃ¶re pozisyon boyutu Ã§arpanÄ±.
        
        Returns:
            float: 0.3 ile 1.5 arasÄ± Ã§arpan
        """
        profit_pct = self.get_profit_percent(current_balance)
        drawdown = self.get_current_drawdown(current_balance)
        
        # Drawdown durumunda defansif ol
        if drawdown > 10:
            return 0.3  # Ã‡ok defansif
        elif drawdown > 5:
            return 0.5  # Defansif
        
        # Kar durumunda
        if profit_pct > 30:
            return 1.5  # Ã‡ok agresif
        elif profit_pct > 20:
            return 1.3  # Agresif
        elif profit_pct > 10:
            return 1.1  # Hafif agresif
        
        return 1.0  # Normal
    
    def calculate_leverage_multiplier(self, current_balance: float) -> float:
        """
        Bakiye durumuna gÃ¶re kaldÄ±raÃ§ Ã§arpanÄ±.
        Drawdown'da kaldÄ±racÄ± azalt, karda artÄ±r.
        
        Returns:
            float: 0.5 ile 1.2 arasÄ± Ã§arpan
        """
        drawdown = self.get_current_drawdown(current_balance)
        profit_pct = self.get_profit_percent(current_balance)
        
        if drawdown > 10:
            return 0.5  # KaldÄ±racÄ± yarÄ±ya dÃ¼ÅŸÃ¼r
        elif drawdown > 5:
            return 0.7  # KaldÄ±racÄ± azalt
        
        if profit_pct > 20:
            return 1.2  # KaldÄ±racÄ± artÄ±r
        
        return 1.0
    
    def get_protection_status(self, current_balance: float) -> dict:
        """Koruma durumu Ã¶zeti."""
        return {
            "initial_balance": self.initial_balance,
            "peak_balance": self.peak_balance,
            "current_balance": current_balance,
            "drawdown_pct": round(self.get_current_drawdown(current_balance), 2),
            "profit_pct": round(self.get_profit_percent(current_balance), 2),
            "size_multiplier": self.calculate_position_size_multiplier(current_balance),
            "leverage_multiplier": self.calculate_leverage_multiplier(current_balance),
            "reduce_risk": self.should_reduce_risk(current_balance),
            "lock_profits": self.should_lock_profits(current_balance)
        }


# Global BalanceProtector instance
balance_protector = BalanceProtector()


# ============================================================================
# PHASE 193: STOPLOSS FREQUENCY GUARD (Freqtrade-inspired)
# Belirli sÃ¼rede Ã§ok fazla SL tetiklenirse trading'i duraklat
# Kill Switch'ten baÄŸÄ±msÄ±z, tamamlayÄ±cÄ± koruma katmanÄ±
# ============================================================================

class StoplossFrequencyGuard:
    """
    Freqtrade'in StoplossGuard pattern'inden esinlenilmiÅŸ:
    Son N dakikada X adet SL-triggered exit olmuÅŸsa, tÃ¼m trading'i duraklat.
    
    Kill Switch = margin bazlÄ± (bÃ¼yÃ¼k kayÄ±p), StoplossGuard = frekans bazlÄ± (art arda kayÄ±p).
    """
    
    def __init__(self):
        self.lookback_minutes: int = 60       # Son 60 dakika
        self.max_stoplosses: int = 3          # Max 3 SL
        self.cooldown_minutes: int = 30       # 30 dk duraklat
        self.only_per_pair: bool = False      # Global veya pair bazlÄ±
        self.enabled: bool = True
        
        # Internal tracking
        self._stoploss_events: list = []  # [(timestamp, symbol, reason), ...]
        self._lock_until: float = 0       # Global lock timestamp
        self._pair_locks: Dict[str, float] = {}  # symbol -> lock_until
        
        logger.info("StoplossFrequencyGuard initialized (lookback=60min, max_sl=3, cooldown=30min)")
    
    def record_stoploss(self, symbol: str, reason: str = "SL"):
        """Record a stoploss exit event."""
        now = time.time()
        self._stoploss_events.append((now, symbol, reason))
        
        # Cleanup old events (older than 2x lookback)
        cutoff = now - (self.lookback_minutes * 60 * 2)
        self._stoploss_events = [(t, s, r) for t, s, r in self._stoploss_events if t > cutoff]
        
        # Check if guard should trigger
        self._check_guard(symbol)
    
    def _check_guard(self, triggered_symbol: str):
        """Check if too many SLs, trigger cooldown if so."""
        now = time.time()
        lookback_start = now - (self.lookback_minutes * 60)
        
        if self.only_per_pair:
            # Per-pair check
            pair_events = [(t, s, r) for t, s, r in self._stoploss_events 
                          if t > lookback_start and s == triggered_symbol]
            if len(pair_events) >= self.max_stoplosses:
                lock_until = now + (self.cooldown_minutes * 60)
                self._pair_locks[triggered_symbol] = lock_until
                logger.warning(
                    f"ðŸ›‘ STOPLOSS_GUARD: {triggered_symbol} locked for {self.cooldown_minutes}min "
                    f"({len(pair_events)} SLs in {self.lookback_minutes}min)"
                )
        else:
            # Global check
            recent_events = [(t, s, r) for t, s, r in self._stoploss_events if t > lookback_start]
            if len(recent_events) >= self.max_stoplosses:
                lock_until = now + (self.cooldown_minutes * 60)
                self._lock_until = lock_until
                logger.warning(
                    f"ðŸ›‘ STOPLOSS_GUARD: ALL TRADING locked for {self.cooldown_minutes}min "
                    f"({len(recent_events)} SLs in {self.lookback_minutes}min)"
                )
    
    def is_locked(self, symbol: str = "") -> bool:
        """Check if trading is locked (globally or per-pair)."""
        if not self.enabled:
            return False
        
        now = time.time()
        
        # Global lock check
        if self._lock_until > now:
            return True
        
        # Per-pair lock check
        if symbol and self.only_per_pair:
            pair_lock = self._pair_locks.get(symbol, 0)
            if pair_lock > now:
                return True
        
        return False
    
    def get_lock_reason(self, symbol: str = "") -> str:
        """Get human-readable lock reason."""
        now = time.time()
        
        if self._lock_until > now:
            remaining = int((self._lock_until - now) / 60)
            return f"Global SL guard: {remaining}min remaining"
        
        if symbol and self.only_per_pair:
            pair_lock = self._pair_locks.get(symbol, 0)
            if pair_lock > now:
                remaining = int((pair_lock - now) / 60)
                return f"{symbol} SL guard: {remaining}min remaining"
        
        return ""
    
    def get_status(self) -> dict:
        """Get guard status for monitoring."""
        now = time.time()
        lookback_start = now - (self.lookback_minutes * 60)
        recent = [(t, s, r) for t, s, r in self._stoploss_events if t > lookback_start]
        
        return {
            'enabled': self.enabled,
            'global_locked': self._lock_until > now,
            'global_lock_remaining_min': max(0, int((self._lock_until - now) / 60)) if self._lock_until > now else 0,
            'recent_stoplosses': len(recent),
            'max_stoplosses': self.max_stoplosses,
            'lookback_minutes': self.lookback_minutes,
            'cooldown_minutes': self.cooldown_minutes,
            'only_per_pair': self.only_per_pair,
            'pair_locks': {s: int((t - now) / 60) for s, t in self._pair_locks.items() if t > now},
        }
    
    def update_settings(self, settings: dict):
        """Update guard settings from UI."""
        if 'sl_guard_enabled' in settings:
            self.enabled = settings['sl_guard_enabled']
        if 'sl_guard_lookback' in settings:
            self.lookback_minutes = max(5, min(240, settings['sl_guard_lookback']))
        if 'sl_guard_max_sl' in settings:
            self.max_stoplosses = max(1, min(20, settings['sl_guard_max_sl']))
        if 'sl_guard_cooldown' in settings:
            self.cooldown_minutes = max(5, min(120, settings['sl_guard_cooldown']))
        if 'sl_guard_per_pair' in settings:
            self.only_per_pair = settings['sl_guard_per_pair']
        logger.info(f"StoplossFrequencyGuard settings updated: {self.get_status()}")


# Global instance
stoploss_frequency_guard = StoplossFrequencyGuard()


# ============================================================================
# PHASE 36: POSITION-BASED KILL SWITCH (IMPROVED)
# ============================================================================

class PositionBasedKillSwitch:
    """
    Dynamic Kill Switch - thresholds calculated per-position based on leverage.
    
    Base thresholds (at 10x leverage):
    - First Reduction: -30% of invested margin â†’ close 50% of position
    - Full Close: -60% of invested margin â†’ close entire position
    
    Leverage adjustment:
    - Higher leverage (>10x): Looser thresholds (more room)
    - Lower leverage (<10x): Tighter thresholds (less room)
    
    Formula: threshold = base_threshold * sqrt(leverage / 10)
    - 25x leverage: -30% * sqrt(2.5) = -47% first, -95% full
    - 10x leverage: -30% * 1.0 = -30% first, -60% full  
    - 5x leverage: -30% * sqrt(0.5) = -21% first, -42% full
    """
    
    def __init__(self, reduction_size: float = 0.5):
        # Base thresholds at 10x leverage (reference point)
        self.base_first_reduction = -30.0  # -30% of invested margin
        self.base_full_close = -60.0       # -60% of invested margin
        self.reduction_size = reduction_size  # 50% reduction at first level
        
        # Track which positions have been partially closed
        self.partially_closed = {}  # {position_id: reduction_count}
        
        # Daily stats
        self.day_start_balance = 10000.0
        self.last_reset_date = None
        
        # Keep these for backwards compatibility (but they're not used anymore)
        self.first_reduction_pct = self.base_first_reduction
        self.full_close_pct = self.base_full_close
        
        logger.info(f"ðŸš¨ Dynamic Kill Switch initialized: Base thresholds {self.base_first_reduction}%/{self.base_full_close}% (adjusted by leverage)")
    
    def get_dynamic_thresholds(self, leverage: int) -> tuple:
        """
        Calculate dynamic thresholds based on position's leverage.
        Phase 203: Leverage factor scaling removed. 
        A 30% loss of invested margin is 30% regardless of leverage.
        Returns strict Portfolio Margin Risk thresholds.
        
        Returns: (first_reduction_pct, full_close_pct)
        """
        if leverage <= 0:
            leverage = 10  # Default
        
        # Phase 244: Restore sqrt-based leverage scaling (was factor=1.0 in Phase 204)
        # Higher leverage = looser threshold, lower leverage = tighter
        factor = max(0.8, min(1.5, (leverage / 10.0) ** 0.5))
        
        first_reduction = self.first_reduction_pct * factor
        full_close = self.full_close_pct * factor
        
        # Clamp to reasonable bounds
        first_reduction = max(-150.0, min(-20.0, first_reduction))
        full_close = max(-200.0, min(-40.0, full_close))
        
        return (first_reduction, full_close)

    
    def reset_for_new_day(self, current_balance: float):
        """Reset for new trading day."""
        # Phase 60: Use Turkey timezone (UTC+3)
        # pytz imported globally
        turkey_tz = pytz.timezone('Europe/Istanbul')
        today = datetime.now(turkey_tz).date()
        if self.last_reset_date != today:
            self.day_start_balance = current_balance
            self.last_reset_date = today
            # Phase 217: Sadece biten pozisyonlarÄ± temizle, aÃ§Ä±k pozisyonlarÄ±n durumunu koru
            try:
                active_position_ids = {p.get('id', '') for p in global_paper_trader.positions} if 'global_paper_trader' in globals() else set()
                self.partially_closed = {
                    pid: count for pid, count in self.partially_closed.items()
                    if pid in active_position_ids
                }
            except Exception:
                self.partially_closed.clear()
            logger.info(f"ðŸ“… New trading day (Turkey): Starting balance ${current_balance:.2f}")
    
    async def check_positions(self, paper_trader) -> dict:
        """
        Check all positions and apply gradual reduction or close.
        Uses POSITION-BASED UNLEVERAGED LOSS percentage: (PnL / invested_margin) * 100
        This means -10% threshold triggers when you've lost 10% of your invested capital.
        Returns summary of actions taken.
        """
        self.reset_for_new_day(paper_trader.balance)
        
        actions = {
            "reduced": [],
            "closed": [],
            "skipped_profitable": []
        }
        
        for pos in list(paper_trader.positions):
            try:
                pos_id = pos.get('id', '')
                symbol = pos.get('symbol', '')
                side = pos.get('side', '')
                entry_price = pos.get('entryPrice', 0)
                current_price = pos.get('currentPrice', entry_price)
                unrealized_pnl = pos.get('unrealizedPnl', 0)
                
                # Get invested margin (actual capital at risk, not leveraged size)
                initial_margin = pos.get('initialMargin', 0)
                leverage = pos.get('leverage', 10)
                size_usd = pos.get('sizeUsd', 0)
                
                # Calculate margin if not stored
                if initial_margin <= 0:
                    initial_margin = size_usd / leverage if leverage > 0 else size_usd
                
                # Skip if no margin (invalid position)
                if initial_margin <= 0:
                    logger.warning(f"Kill switch: {symbol} has no margin data, skipping")
                    continue
                
                # Skip profitable positions (don't touch winners!)
                if unrealized_pnl >= 0:
                    actions["skipped_profitable"].append(symbol)
                    continue
                
                # Phase 152: Use LEVERAGED ROI instead of unleveraged margin loss
                # unrealizedPnlPercent is already leveraged (pnl / sizeUsd * 100 * leverage)
                position_loss_pct = pos.get('unrealizedPnlPercent', 0)
                # Phase 221: Fallback calculation for paper positions where unrealizedPnlPercent=0
                if position_loss_pct == 0 and unrealized_pnl < 0 and initial_margin > 0:
                    position_loss_pct = (unrealized_pnl / initial_margin) * 100
                
                # Get DYNAMIC thresholds based on this position's leverage
                first_threshold, full_threshold = self.get_dynamic_thresholds(leverage)
                
                # Phase 222: Kill Switch must not trigger before SL
                sl_price = pos.get('stopLoss', 0)
                if sl_price > 0 and entry_price > 0:
                    if side == 'LONG':
                        sl_roi = ((sl_price - entry_price) / entry_price) * 100 * leverage
                    else:
                        sl_roi = ((entry_price - sl_price) / entry_price) * 100 * leverage
                    # SL ROI is negative for losses â€” if SL would close at a tighter loss than kill switch, let SL handle it
                    if -sl_roi > -full_threshold:
                        continue
                
                # Log for debugging with dynamic thresholds
                logger.info(f"ðŸŽ¯ Kill switch check {symbol} [{leverage}x]: ROI={position_loss_pct:.1f}% | Thresholds: {first_threshold:.0f}%/{full_threshold:.0f}%")
                
                # Check loss thresholds using POSITION LOSS with DYNAMIC thresholds
                if position_loss_pct <= full_threshold:
                    # Full close threshold reached
                    paper_trader.close_position(pos, current_price, 'KILL_SWITCH_FULL')
                    # Note: close_position already handles Binance close for isLive positions
                    actions["closed"].append(f"{symbol} ({position_loss_pct:.1f}%)")
                    logger.warning(f"ðŸš¨ KILL SWITCH FULL [{leverage}x]: Closed {side} {symbol} at {position_loss_pct:.1f}% loss (threshold: {full_threshold:.0f}%)")
                    # Phase 48: Record fault for this coin
                    kill_switch_fault_tracker.record_fault(symbol, 'KILL_SWITCH_FULL')
                    
                elif position_loss_pct <= first_threshold:
                    # First reduction threshold - close 50% (only once per position)
                    already_reduced = pos.get('kill_switch_reduced', False)
                    
                    if not already_reduced:
                        # First reduction - close 50%
                        pos['kill_switch_reduced'] = True  # Mark as reduced
                        await self._reduce_position(paper_trader, pos, current_price, self.reduction_size)
                        self.partially_closed[pos_id] = 1  # Keep for backwards compat
                        actions["reduced"].append(f"{symbol} ({position_loss_pct:.1f}%)")
                        logger.warning(f"âš ï¸ KILL SWITCH REDUCE [{leverage}x]: Reduced {side} {symbol} by 50% at {position_loss_pct:.1f}% loss (threshold: {first_threshold:.0f}%)")
                        # Phase 48: Record fault for this coin
                        kill_switch_fault_tracker.record_fault(symbol, 'KILL_SWITCH_PARTIAL')
                    # If already_reduced, wait for full_threshold to trigger
                        
            except Exception as e:
                logger.error(f"Kill switch check error for {pos.get('symbol', 'unknown')}: {e}")
        
        return actions
    
    async def _reduce_position(self, paper_trader, pos: dict, current_price: float, reduction_pct: float):
        """
        Reduce position size by specified percentage.
        Records partial close in trade history.
        For LIVE positions, sends actual Binance partial close order.
        """
        # Phase 141: Use contracts with size fallback for consistency
        original_size = pos.get('contracts', pos.get('size', 0))
        original_size_usd = pos.get('sizeUsd', 0)
        reduction_size = original_size * reduction_pct
        reduction_size_usd = original_size_usd * reduction_pct
        
        # Calculate PnL for the reduced portion
        entry_price = pos.get('entryPrice', current_price)
        side = pos.get('side', 'LONG')
        symbol = pos.get('symbol', '')
        
        if side == 'LONG':
            price_diff = current_price - entry_price
        else:
            price_diff = entry_price - current_price
        
        pnl = reduction_size * price_diff
        pnl_pct = (price_diff / entry_price) * 100 if entry_price > 0 else 0
        
        # LIVE positions: Execute actual Binance partial close
        if pos.get('isLive', False) and reduction_size > 0:
            try:
                result = await live_binance_trader.close_position(symbol, side, reduction_size)
                if result:
                    # Phase 188: Set cooldown to prevent Binance sync from restoring old size
                    pos['_partial_close_ts'] = datetime.now().timestamp()
                    close_oid = str(result.get('id', ''))
                    logger.warning(f"ðŸ“Š KILL_SWITCH LIVE âœ…: {symbol} reduced {reduction_pct*100:.0f}% on Binance ({reduction_size:.4f} contracts) | Order: {close_oid[:12]}")
                    # Phase 229b: Persist close order ID
                    if close_oid:
                        safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                else:
                    logger.error(f"âŒ KILL_SWITCH LIVE FAILED: {symbol} - close_position returned None")
            except Exception as e:
                logger.error(f"âŒ KILL_SWITCH LIVE ERROR: {symbol} - {e}")
        
        # Update balance with initial margin portion + PnL
        # Initial Margin = sizeUsd / leverage
        leverage = pos.get('leverage', 10)
        reduction_initial_margin = reduction_size_usd / leverage
        paper_trader.balance += reduction_initial_margin + pnl
        
        # Update position with reduced size
        pos['size'] = original_size - reduction_size
        pos['sizeUsd'] = original_size_usd - reduction_size_usd
        # Update initialMargin proportionally
        if 'initialMargin' in pos:
            pos['initialMargin'] = pos['initialMargin'] * (1 - reduction_pct)
        
        # Record partial close in trade history
        partial_trade = {
            "id": f"{pos.get('id', '')}_PARTIAL",
            "symbol": symbol,
            "side": side,
            "entryPrice": entry_price,
            "exitPrice": current_price,
            "size": reduction_size,
            "sizeUsd": reduction_size_usd,
            "pnl": pnl,
            "pnlPercent": pnl_pct,
            "openTime": pos.get('openTime', 0),
            "closeTime": int(datetime.now().timestamp() * 1000),
            "reason": "KILL_SWITCH_PARTIAL",
            "closeReason": "KILL_SWITCH_PARTIAL",
            "leverage": pos.get('leverage', 10)
        }
        paper_trader.trades.append(partial_trade)
        paper_trader.add_log(f"âš ï¸ PARTIAL CLOSE: {side} {symbol} reduced by {reduction_pct*100:.0f}% | PnL: ${pnl:.2f}")
    
    def get_status(self, current_balance: float) -> dict:
        """Get kill switch status for UI."""
        if self.day_start_balance <= 0:
            return {"first_reduction_pct": self.first_reduction_pct, "full_close_pct": self.full_close_pct}
        
        daily_pnl = current_balance - self.day_start_balance
        daily_pnl_pct = (daily_pnl / self.day_start_balance) * 100
        
        return {
            "type": "POSITION_BASED",
            "first_reduction_pct": self.first_reduction_pct,
            "full_close_pct": self.full_close_pct,
            "day_start_balance": self.day_start_balance,
            "daily_pnl": round(daily_pnl, 2),
            "daily_pnl_pct": round(daily_pnl_pct, 2),
            "partially_closed_count": len(self.partially_closed)
        }


# Global PositionBasedKillSwitch instance (replaces DailyKillSwitch)
daily_kill_switch = PositionBasedKillSwitch()


# ============================================================================
# PHASE 49: TIME-BASED POSITION MANAGER
# ============================================================================

class TimeBasedPositionManager:
    """
    Manages positions based on time elapsed without favorable movement.
    
    STAGNANT PROFITABLE POSITIONS:
    - If in profit but hasn't moved in favor for 30+ minutes, activate trailing stop early
    
    STAGNANT LOSING POSITIONS:
    - Gradually reduce position size if not recovering:
      - 1 hour without profit: reduce 10%
      - 2 hours without profit: reduce 20%
      - 4 hours without profit: reduce 20%
      - 8 hours without profit: reduce 20%
    """
    
    def __init__(self):
        # Track position reductions: {pos_id: {'1h': bool, '2h': bool, '4h': bool, '8h': bool}}
        self.time_reductions = {}
        
        # Time thresholds and reduction percentages
        # 4h = 10% reduce, 8h = 10% reduce (less aggressive with kill switch active)
        self.reduction_schedule = [
            {'hours': 4, 'reduction_pct': 0.10, 'key': '4h'},   # 4 hours: 10% reduce
            {'hours': 8, 'reduction_pct': 0.10, 'key': '8h'},   # 8 hours: 10% reduce
        ]
        
        # Trail activation settings for stagnant profitable positions
        self.early_trail_minutes = 30  # Activate trail if profitable but stagnant for 30 min
        
        logger.info("ðŸ“Š TimeBasedPositionManager initialized")
    
    async def check_positions(self, paper_trader) -> dict:
        """
        Check all positions for time-based management.
        Returns summary of actions taken.
        """
        actions = {
            "trail_activated": [],
            "time_reduced": [],
            "time_closed": [],
            "partial_tp": [],  # Phase 137: Partial take profit tracking
            "checked": 0
        }
        
        positions_to_remove = []  # Phase 56: Track positions to remove after 100% reduction
        current_time_ms = int(datetime.now().timestamp() * 1000)
        
        for pos in list(paper_trader.positions):
            try:
                pos_id = pos.get('id', '')
                symbol = pos.get('symbol', '')
                side = pos.get('side', '')
                open_time = pos.get('openTime', current_time_ms)
                unrealized_pnl = pos.get('unrealizedPnl', 0)
                is_trailing_active = pos.get('isTrailingActive', False)
                current_price = pos.get('currentPrice', pos.get('entryPrice', 0))
                entry_price = pos.get('entryPrice', current_price)
                contracts = pos.get('contracts', 0)
                
                # Calculate position age in hours
                age_hours = (current_time_ms - open_time) / (1000 * 60 * 60)
                
                actions["checked"] += 1
                
                # Phase 137 DEBUG: Trace log before CASE checks (every 100th call to reduce spam)
                if not hasattr(self, '_debug_count'):
                    self._debug_count = 0
                self._debug_count += 1
                if self._debug_count % 100 == 1:
                    logger.info(f"ðŸ“Š POS_DEBUG: {symbol} age={age_hours:.1f}h pnl={unrealized_pnl:.2f} entry={entry_price:.4f} curr={current_price:.4f}")
                
                # ===============================================
                # PHASE 137: DYNAMIC PARTIAL TAKE PROFIT
                # Spread ve volatiliteye gÃ¶re dinamik TP seviyeleri
                # ===============================================
                if unrealized_pnl > 0 and contracts > 0:
                    # Get spread level and ATR for dynamic TP calculation
                    spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223: was only 'spread_level'
                    atr = pos.get('atr', current_price * 0.02)
                    
                    # ATR as percentage of price
                    atr_pct = (atr / current_price * 100) if current_price > 0 else 2.0
                    
                    # Spread multipliers for TP levels
                    spread_mults = {
                        'Very Low': 0.5,   # BTC/ETH - tighter TPs
                        'Low': 0.75,
                        'Normal': 1.0,
                        'High': 1.5,
                        'Very High': 2.5,  # Meme coins - wider TPs
                        'Extreme': 3.5,    # Hyper-volatile
                        'Ultra': 5.0       # Extreme edge cases
                    }
                    mult = spread_mults.get(spread_level, 1.0)
                    
                    # Dynamic base for TP levels: ATR_pct * multiplier
                    base_tp_pct = atr_pct * mult
                    
                    # Phase 224C2: Leverage-normalized TP levels
                    # TP hedefleri margin-based ROI olarak tanÄ±mlanÄ±r
                    leverage = pos.get('leverage', 10)
                    
                    # ROI-based TP targets (margin Ã¼zerinden)
                    tp1_price_pct = max(base_tp_pct * 1.0, 8.0 / leverage)   # ~8% ROI
                    tp2_price_pct = max(base_tp_pct * 2.0, 20.0 / leverage)  # ~20% ROI
                    tp3_price_pct = max(base_tp_pct * 3.5, 40.0 / leverage)  # ~40% ROI
                    
                    tp_levels = [
                        {'pct': tp1_price_pct, 'close_pct': 0.40, 'key': 'tp1'},
                        {'pct': tp2_price_pct, 'close_pct': 0.30, 'key': 'tp2'},
                        {'pct': tp3_price_pct, 'close_pct': 0.30, 'key': 'tp3'},
                    ]
                    
                    # Current profit percentage
                    if entry_price > 0:
                        if side == 'LONG':
                            profit_pct = (current_price - entry_price) / entry_price * 100
                        else:  # SHORT
                            profit_pct = (entry_price - current_price) / entry_price * 100
                        
                        # Track which TPs have been hit
                        partial_tp_state = pos.get('partial_tp_state', {})
                        
                        for level in tp_levels:
                            if profit_pct >= level['pct'] and not partial_tp_state.get(level['key'], False):
                                # TP level hit - mark as closed
                                partial_tp_state[level['key']] = True
                                pos['partial_tp_state'] = partial_tp_state
                                
                                # Phase 231e: Use ORIGINAL contracts for percentage calc
                                # Prevents compounding: 40/18/12.6 â†’ correct 40/30/30
                                original_contracts = pos.get('original_contracts', contracts)
                                if original_contracts == 0:
                                    original_contracts = contracts
                                close_contracts = original_contracts * level['close_pct']
                                
                                # LIVE positions: Execute actual Binance partial close
                                if pos.get('isLive', False) and close_contracts > 0:
                                    live_success = False
                                    try:
                                        result = await live_binance_trader.close_position(symbol, side, close_contracts)
                                        if result:
                                            live_success = True
                                            # Phase 188: Set cooldown to prevent Binance sync from restoring old size
                                            pos['_partial_close_ts'] = datetime.now().timestamp()
                                            close_oid = str(result.get('id', ''))
                                            logger.warning(f"ðŸ’° PARTIAL_TP LIVE âœ…: {symbol} closed {level['close_pct']*100:.0f}% on Binance ({close_contracts:.4f} contracts) at {profit_pct:.2f}% profit | Order: {close_oid[:12]}")
                                            # Phase 229b: Persist close order ID
                                            if close_oid:
                                                safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                        else:
                                            logger.error(f"âŒ PARTIAL_TP LIVE FAILED: {symbol} - close_position returned None")
                                    except Exception as e:
                                        logger.error(f"âŒ PARTIAL_TP LIVE ERROR: {symbol} - {e}")
                                    
                                    # Phase 231: Only update local state if Binance close succeeded
                                    if not live_success:
                                        # Revert TP state â€” Binance failed, don't mark as closed
                                        partial_tp_state[level['key']] = False
                                        pos['partial_tp_state'] = partial_tp_state
                                        logger.warning(f"âš ï¸ PARTIAL_TP REVERTED: {symbol} {level['key']} â€” Binance close failed, state rolled back")
                                        continue  # Skip contract update and trail activation
                                
                                # Phase 231e: Save original values BEFORE first reduction
                                if not pos.get('original_contracts'):
                                    pos['original_contracts'] = contracts
                                    pos['original_size'] = pos.get('size', contracts)
                                    pos['original_sizeUsd'] = pos.get('sizeUsd', 0)
                                    pos['original_initialMargin'] = pos.get('initialMargin', 0)
                                
                                # Phase 231g: Clamp to prevent negative contracts
                                new_contracts = max(0, pos.get('contracts', contracts) - close_contracts)
                                pos['contracts'] = new_contracts
                                
                                # Ratio-based sync: all fields scale proportionally
                                ratio = new_contracts / contracts if contracts > 0 else 1.0
                                pos['size'] = new_contracts  # size = contracts (same unit)
                                pos['sizeUsd'] = pos.get('sizeUsd', 0) * (new_contracts / (new_contracts + close_contracts)) if (new_contracts + close_contracts) > 0 else 0
                                pos['initialMargin'] = pos.get('initialMargin', 0) * (new_contracts / (new_contracts + close_contracts)) if (new_contracts + close_contracts) > 0 else 0
                                
                                # =====================================================
                                # Phase 220: TP1 â†’ Force Trail + Breakeven SL
                                # Kalan pozisyonu trail ile koru, SL'i entry+fee'ye taÅŸÄ±
                                # =====================================================
                                if level['key'] == 'tp1':
                                    # 1) Force-activate trailing stop for remaining position
                                    trail_dist = pos.get('trailDistance', atr * 1.5)
                                    if side == 'LONG':
                                        new_trail_stop = current_price - trail_dist
                                        # Trail stop should be at least at entry
                                        new_trail_stop = max(new_trail_stop, entry_price)
                                        pos['trailingStop'] = new_trail_stop
                                    else:  # SHORT
                                        new_trail_stop = current_price + trail_dist
                                        new_trail_stop = min(new_trail_stop, entry_price)
                                        pos['trailingStop'] = new_trail_stop
                                    pos['isTrailingActive'] = True
                                    logger.warning(f"ðŸ“Š TP1_TRAIL: {symbol} {side} trail FORCED ON | stop=${pos['trailingStop']:.6f} dist=${trail_dist:.6f}")
                                    
                                    # 2) Move SL to breakeven (entry + fee buffer)
                                    fee_buffers = {
                                        'Very Low': 0.005, 'Low': 0.005, 'Normal': 0.006,
                                        'High': 0.008, 'Very High': 0.010,
                                        'Extreme': 0.015, 'Ultra': 0.020
                                    }
                                    fee_buffer = fee_buffers.get(spread_level, 0.006)
                                    if side == 'LONG':
                                        breakeven_sl = entry_price * (1 + fee_buffer)
                                        if breakeven_sl > pos.get('stopLoss', 0):
                                            pos['stopLoss'] = breakeven_sl
                                    else:  # SHORT
                                        breakeven_sl = entry_price * (1 - fee_buffer)
                                        if breakeven_sl < pos.get('stopLoss', float('inf')):
                                            pos['stopLoss'] = breakeven_sl
                                    pos['breakeven_activated'] = True
                                    logger.warning(f"ðŸ”’ TP1_BREAKEVEN: {symbol} {side} SL â†’ breakeven ${breakeven_sl:.6f} (entry+{fee_buffer*100:.1f}%)")
                                    
                                    # 3) For LIVE positions: Update SL on Binance
                                    if pos.get('isLive', False):
                                        try:
                                            remaining_contracts = pos['contracts']
                                            sl_result = await live_binance_trader.set_stop_loss(symbol, side, remaining_contracts, breakeven_sl)
                                            if sl_result:
                                                logger.warning(f"ðŸ”’ TP1_BREAKEVEN LIVE âœ…: {symbol} SL set to ${breakeven_sl:.6f} on Binance")
                                            else:
                                                logger.error(f"âŒ TP1_BREAKEVEN LIVE FAILED: {symbol} - set_stop_loss returned None")
                                        except Exception as be_err:
                                            logger.warning(f"âš ï¸ TP1_BREAKEVEN LIVE SKIP: {symbol} - {be_err} (will use internal SL)")
                                
                                # Log partial TP
                                logger.info(f"ðŸ’° PARTIAL_TP: {symbol} closed {level['close_pct']*100:.0f}% at {profit_pct:.2f}% profit (level: {level['key']}, base: {base_tp_pct:.2f}%)")
                                actions["partial_tp"].append(f"{symbol}_{level['key']}({profit_pct:.1f}%)")
                                
                                # Phase 220b: Update local contracts for next TP level calculation
                                contracts = pos['contracts']
                
                # Phase 190: REMOVED duplicate breakeven (Phase 137)
                # BreakevenStopManager handles this better with limit orders + fee buffer
                # Old code moved SL to exact entry (no buffer) â€” caused commission losses
                

                # ===============================================
                # CASE 1: PROFITABLE - DYNAMIC PULLBACK TRAIL
                # Phase 51: Spread-based dynamic pullback threshold
                # ===============================================
                if unrealized_pnl > 0 and not is_trailing_active:
                    age_minutes = age_hours * 60
                    
                    # Only consider early trail after 30 minutes
                    if age_minutes >= self.early_trail_minutes:
                        # Get ATR and spread level from position
                        atr = pos.get('atr', current_price * 0.02)  # Default 2% if no ATR
                        spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                        
                        # Dynamic pullback multiplier based on spread
                        spread_multipliers = {
                            'Very Low': 0.5,   # BTC, ETH - small pullback triggers trail
                            'Low': 0.75,
                            'Normal': 1.0,
                            'High': 1.5,
                            'Very High': 2.0,  # Meme coins - wait for larger pullback
                            'Extreme': 3.0,    # Hyper-volatile
                            'Ultra': 4.0       # Extreme edge cases
                        }
                        multiplier = spread_multipliers.get(spread_level, 1.0)
                        pullback_threshold = atr * multiplier
                        
                        # Track highest profit reached
                        highest_profit = pos.get('highestProfit', unrealized_pnl)
                        if unrealized_pnl > highest_profit:
                            pos['highestProfit'] = unrealized_pnl
                            highest_profit = unrealized_pnl
                        
                        # Calculate pullback from highest profit
                        profit_pullback = highest_profit - unrealized_pnl
                        
                        # Activate trail if pullback exceeds threshold
                        if profit_pullback >= pullback_threshold:
                            pos['isTrailingActive'] = True
                            pos['trailingStop'] = current_price
                            actions["trail_activated"].append(f"{symbol} (pullback ${profit_pullback:.2f})")
                            logger.info(f"ðŸ“Š EARLY TRAIL: {symbol} activated - pullback ${profit_pullback:.2f} >= threshold ${pullback_threshold:.2f} (spread: {spread_level})")
                
                # ===============================================
                # CASE 2: LOSING AND STAGNANT - GRADUAL REDUCTION
                # Phase 137 FIX: Changed elif to if - CASE 2 should run independently
                # Phase 188: SKIP for LIVE positions â€” Kill Switch handles risk management
                # Time-based reduction on live causes duplicate Binance orders due to sync overwrite
                # ===============================================
                # Phase 190: Enabled for LIVE positions (was paper-only)
                if unrealized_pnl < 0:
                    # Initialize tracking for this position
                    if pos_id not in self.time_reductions:
                        self.time_reductions[pos_id] = {item['key']: False for item in self.reduction_schedule}
                    
                    # Phase 137 ONE-TIME FIX: Reset broken flags from old code
                    # Old code used 'size' (always 0), never reduced, but flags got set somehow
                    # Reset flags if position has contracts but hasn't actually been reduced
                    if not hasattr(self, '_flags_reset_done'):
                        self._flags_reset_done = True
                        for p in paper_trader.positions:
                            # If position has contracts (not reduced) but flags are True, reset them
                            if p.get('contracts', 0) > 0:
                                if p.get('time_reduced_4h', False) or p.get('time_reduced_8h', False):
                                    logger.warning(f"ðŸ“Š FLAG_RESET: {p.get('symbol')} resetting broken time reduction flags")
                                    p['time_reduced_4h'] = False
                                    p['time_reduced_8h'] = False
                    
                    # Phase 137 DEBUG: Trace log for CASE 2 entry
                    logger.info(f"ðŸ“Š TIME_CHECK: {symbol} age={age_hours:.1f}h pnl={unrealized_pnl:.2f} flags={pos.get('time_reduced_4h', False)}/{pos.get('time_reduced_8h', False)}")
                    
                    # Check each time threshold
                    for schedule in self.reduction_schedule:
                        threshold_hours = schedule['hours']
                        reduction_pct = schedule['reduction_pct']
                        key = schedule['key']
                        
                        # Phase 55: Use position-internal flag to survive restarts
                        pos_flag_key = f"time_reduced_{key}"
                        already_reduced_flag = pos.get(pos_flag_key, False)
                        
                        # Check if we've passed this threshold and haven't reduced yet
                        if age_hours >= threshold_hours and not already_reduced_flag:
                            # Phase 137 FIX: Use 'contracts' (from Binance) instead of 'size'
                            position_contracts = pos.get('contracts', pos.get('size', 0))
                            position_notional = pos.get('notional', pos.get('sizeUsd', 0))
                            
                            reduction_amount = position_contracts * reduction_pct
                            reduction_usd = position_notional * reduction_pct
                            
                            if reduction_amount > 0:
                                # Calculate partial close PnL
                                if side == 'LONG':
                                    partial_pnl = (current_price - pos['entryPrice']) * reduction_amount
                                else:
                                    partial_pnl = (pos['entryPrice'] - current_price) * reduction_amount
                                
                                # Update position size
                                pos['size'] -= reduction_amount
                                pos['sizeUsd'] -= reduction_usd
                                
                                # Return margin proportionally
                                initial_margin = pos.get('initialMargin', 0)
                                margin_return = initial_margin * reduction_pct
                                pos['initialMargin'] = initial_margin - margin_return
                                paper_trader.balance += margin_return + partial_pnl
                                
                                # Mark as reduced - BOTH in dictionary and position
                                self.time_reductions[pos_id][key] = True
                                pos[pos_flag_key] = True  # Position-internal flag
                                
                                actions["time_reduced"].append(f"{symbol} {key} (-{reduction_pct*100:.0f}%)")
                                logger.warning(f"ðŸ“Š TIME REDUCE: {symbol} reduced {reduction_pct*100:.0f}% after {threshold_hours}h (PnL: ${partial_pnl:.2f})")
                                
                                # LIVE positions: Execute actual Binance partial close
                                if pos.get('isLive', False):
                                    try:
                                        result = await live_binance_trader.close_position(symbol, side, reduction_amount)
                                        if result:
                                            close_oid = str(result.get('id', ''))
                                            logger.warning(f"ðŸ“Š TIME REDUCE LIVE âœ…: {symbol} closed {reduction_pct*100:.0f}% on Binance ({reduction_amount:.4f} contracts) | Order: {close_oid[:12]}")
                                            # Phase 229b: Persist close order ID
                                            if close_oid:
                                                safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                        else:
                                            logger.error(f"âŒ TIME REDUCE LIVE FAILED: {symbol} - close_position returned None")
                                    except Exception as e:
                                        logger.error(f"âŒ TIME REDUCE LIVE ERROR: {symbol} - {e}")
                                
                                # Phase 152: Don't spam UI logs â€” summary log added at end of cycle
                                
                                # ===== RECORD AS TRADE FOR HISTORY =====
                                close_reason = f"TIME_REDUCE_{key.upper()}"
                                trade_record = {
                                    'symbol': symbol,
                                    'side': side,
                                    'entryPrice': pos['entryPrice'],
                                    'exitPrice': current_price,
                                    'size': reduction_amount,
                                    'sizeUsd': reduction_usd,
                                    'pnl': partial_pnl,
                                    'pnlPercent': (partial_pnl / margin_return * 100) if margin_return > 0 else 0,
                                    'openTime': pos.get('openTime', 0),
                                    'closeTime': int(datetime.now().timestamp() * 1000),
                                    'closeReason': close_reason,
                                    'reason': close_reason,
                                    'leverage': pos.get('leverage', 10),
                                    'margin': margin_return,
                                    'isPartialClose': reduction_pct < 1.0  # Only partial if not 100%
                                }
                                paper_trader.trades.append(trade_record)
                                paper_trader.stats['totalTrades'] += 1
                                if partial_pnl > 0:
                                    paper_trader.stats['winningTrades'] += 1  # Phase 223: was 'winTrades' (KeyError)
                                
                                # Phase 56: If 100% reduction, mark position for removal
                                if reduction_pct >= 1.0 or pos.get('size', 0) <= 0 or pos.get('sizeUsd', 0) <= 0.01:
                                    positions_to_remove.append(pos_id)
                                    logger.warning(f"ðŸ“Š TIME CLOSE: {symbol} fully closed after {threshold_hours}h (PnL: ${partial_pnl:.2f})")
                                    paper_trader.add_log(f"â° TIME CLOSE: {symbol} fully closed after {threshold_hours}h")
                                
                                paper_trader.save_state()
                
            except Exception as e:
                logger.error(f"Error in time-based position check: {e}")
        
        # Phase 56: Remove positions that were fully closed (100% reduction)
        if positions_to_remove:
            paper_trader.positions = [p for p in paper_trader.positions if p.get('id') not in positions_to_remove]
            actions["time_closed"] = positions_to_remove
            logger.info(f"ðŸ“Š TIME CLOSE: Removed {len(positions_to_remove)} fully closed positions")
            paper_trader.save_state()
        
        # Phase 152: Single summary log for UI instead of per-position spam
        if actions.get("time_reduced"):
            symbols = [r.split()[0] for r in actions["time_reduced"]]
            paper_trader.add_log(f"â° TIME REDUCE: {len(symbols)} poz kÃ¼Ã§Ã¼ltÃ¼ldÃ¼: {', '.join(symbols[:5])}{'...' if len(symbols) > 5 else ''}")
        
        # Cleanup old tracking data for closed positions
        active_pos_ids = {p.get('id') for p in paper_trader.positions}
        self.time_reductions = {k: v for k, v in self.time_reductions.items() if k in active_pos_ids}
        
        return actions
    
    def get_status(self) -> dict:
        """Get current status for UI."""
        return {
            "type": "TIME_BASED",
            "tracked_positions": len(self.time_reductions),
            "early_trail_minutes": self.early_trail_minutes,
            "reduction_schedule": [f"{s['hours']}h: {s['reduction_pct']*100:.0f}%" for s in self.reduction_schedule]
        }


# Global TimeBasedPositionManager instance
time_based_position_manager = TimeBasedPositionManager()


# ============================================================================
# PHASE 142: PORTFOLIO RECOVERY TRAILING
# ============================================================================

class PortfolioRecoveryManager:
    """
    Phase 142: Portfolio Recovery Trailing System
    
    Total Unrealized PnL 12+ saat ekside kalÄ±p artÄ±ya dÃ¶nerse,
    trailing ile tÃ¼m pozisyonlarÄ± kapatarak bakiyeyi korur.
    
    MantÄ±k:
    1. Total uPnL < 0 ise, underwater timer baÅŸlat
    2. 12+ saat underwater â†’ "Recovery Candidate" iÅŸaretle
    3. uPnL >= +$0.50 olduÄŸunda â†’ Trailing aktifleÅŸtir
    4. Trailing mesafesi = (BTC_ATR% + ETH_ATR%) / 2, min 1.5%, max 5%
    5. Peak'ten geri Ã§ekilme > trailing distance â†’ TÃœM pozisyonlarÄ± kapat
    6. Kapatma sonrasÄ± 6 saat cooldown (yeni sinyal engeli)
    """
    
    def __init__(self):
        # State tracking
        self.underwater_start_time = None      # When uPnL first went negative
        self.is_recovery_candidate = False     # 12h+ underwater flag
        self.recovery_trailing_active = False  # Trailing mode active
        self.peak_positive_pnl = 0.0          # Highest positive uPnL seen during trailing
        self.trailing_distance_pct = 2.5       # Dynamic, based on BTC/ETH ATR
        self.cooldown_until = None            # Timestamp for cooldown end
        self.should_trigger_close = False     # Flag for sync loop to close all
        self.last_total_upnl = 0.0            # Last recorded total uPnL
        
        # Configuration
        # Phase 190: Removed 12h wait â€” recovery candidate activates immediately
        self.underwater_threshold_hours = 0    # Immediate â€” artÄ±ya geÃ§ince trail baÅŸlar
        self.min_positive_pct = 0.03           # Phase 200: Margin Balance'Ä±n %3'Ã¼ (dinamik, min $5)
        self.min_trailing_pct = 5.0            # Phase 200: 5.0% minimum trailing distance (was 1.5%)
        self.max_trailing_pct = 10.0           # 10.0% maximum trailing distance
        self.cooldown_hours = 6               # Hours to wait after recovery close
        
        logger.info(f"ðŸ”„ PortfolioRecoveryManager initialized: min_positive=%3 of balance, trail=5-10%")
    
    def update(self, total_unrealized_pnl: float, btc_atr_pct: float, eth_atr_pct: float, wallet_balance: float = 100.0) -> str:
        """
        Main update method - called every sync cycle.
        
        Args:
            total_unrealized_pnl: Total unrealized PnL across all positions
            btc_atr_pct: BTC ATR as percentage of price
            eth_atr_pct: ETH ATR as percentage of price
            wallet_balance: Current wallet balance for dynamic threshold
            
        Returns:
            Status string for logging
        """
        self.last_total_upnl = total_unrealized_pnl
        self.should_trigger_close = False  # Reset each cycle
        now = datetime.now()
        
        # Check if in cooldown
        if self.is_in_cooldown():
            return "COOLDOWN"
        
        # ===== PHASE 1: UNDERWATER TRACKING =====
        if total_unrealized_pnl < 0:
            # Start or continue underwater tracking
            if self.underwater_start_time is None:
                self.underwater_start_time = now
                logger.info(f"ðŸ“Š RECOVERY TRACKING: Total uPnL negative (${total_unrealized_pnl:.2f}), starting timer")
            
            # Check if we've been underwater long enough
            hours_underwater = (now - self.underwater_start_time).total_seconds() / 3600
            
            if hours_underwater >= self.underwater_threshold_hours and not self.is_recovery_candidate:
                self.is_recovery_candidate = True
                logger.warning(f"âš ï¸ RECOVERY CANDIDATE: {hours_underwater:.1f}h underwater, waiting for positive uPnL")
            
            # Reset trailing if we're still negative
            if self.recovery_trailing_active:
                logger.info(f"ðŸ“Š RECOVERY: uPnL dropped negative again (${total_unrealized_pnl:.2f}), resetting trailing")
                self.recovery_trailing_active = False
                self.peak_positive_pnl = 0.0
            
            return f"UNDERWATER_{hours_underwater:.1f}h"
        
        # ===== PHASE 2: POSITIVE PNL CHECK =====
        # Dynamic threshold: 3% of margin balance, min $5
        dynamic_threshold = max(wallet_balance * self.min_positive_pct, 5.0)  # Min $5 floor
        if total_unrealized_pnl >= dynamic_threshold:
            
            # If we're a recovery candidate and PnL turned positive, activate trailing
            if self.is_recovery_candidate and not self.recovery_trailing_active:
                # Calculate dynamic trailing distance
                self.trailing_distance_pct = self._calculate_trailing_distance(btc_atr_pct, eth_atr_pct)
                self.recovery_trailing_active = True
                self.peak_positive_pnl = total_unrealized_pnl
                
                hours_was_underwater = (now - self.underwater_start_time).total_seconds() / 3600 if self.underwater_start_time else 0
                logger.warning(f"ðŸ”„ RECOVERY ACTIVATED: uPnL +${total_unrealized_pnl:.2f} after {hours_was_underwater:.1f}h underwater! Trail: {self.trailing_distance_pct:.2f}%")
            
            # ===== PHASE 3: TRAILING LOGIC =====
            if self.recovery_trailing_active:
                # Update peak if higher
                if total_unrealized_pnl > self.peak_positive_pnl:
                    self.peak_positive_pnl = total_unrealized_pnl
                    logger.info(f"ðŸ“ˆ RECOVERY PEAK: New peak +${self.peak_positive_pnl:.2f}")
                
                # Calculate pullback percentage
                # Pullback = (peak - current) / peak * 100
                if self.peak_positive_pnl > 0:
                    pullback_pct = ((self.peak_positive_pnl - total_unrealized_pnl) / self.peak_positive_pnl) * 100
                    
                    # Check if pullback exceeds trailing distance
                    if pullback_pct >= self.trailing_distance_pct:
                        logger.warning(f"ðŸ”´ RECOVERY TRIGGER: Pullback {pullback_pct:.2f}% >= trail {self.trailing_distance_pct:.2f}% | Peak: ${self.peak_positive_pnl:.2f} â†’ Current: ${total_unrealized_pnl:.2f}")
                        self.should_trigger_close = True
                        return "CLOSE_TRIGGERED"
                    
                    return f"TRAILING_peak={self.peak_positive_pnl:.2f}_pullback={pullback_pct:.1f}%"
        
        # Not underwater and not in trailing - reset state
        if total_unrealized_pnl >= 0 and not self.is_recovery_candidate:
            self.underwater_start_time = None
            return "NORMAL"
        
        return "MONITORING"
    
    def _calculate_trailing_distance(self, btc_atr_pct: float, eth_atr_pct: float) -> float:
        """
        Calculate dynamic trailing distance based on BTC/ETH average ATR.
        
        Higher volatility = larger trailing distance
        Lower volatility = tighter trailing distance
        """
        avg_atr = (btc_atr_pct + eth_atr_pct) / 2
        
        # Clamp to min/max bounds
        distance = max(self.min_trailing_pct, min(self.max_trailing_pct, avg_atr))
        
        logger.info(f"ðŸ“ RECOVERY TRAIL: BTC ATR={btc_atr_pct:.2f}%, ETH ATR={eth_atr_pct:.2f}% â†’ Trail={distance:.2f}%")
        return distance
    
    def should_close_all(self) -> bool:
        """Check if recovery trailing has triggered a close all signal."""
        return self.should_trigger_close
    
    def start_cooldown(self):
        """Start cooldown period after recovery close."""
        self.cooldown_until = datetime.now() + timedelta(hours=self.cooldown_hours)
        self.reset_state()
        logger.info(f"â¸ï¸ RECOVERY COOLDOWN: Started {self.cooldown_hours}h cooldown until {self.cooldown_until}")
    
    def is_in_cooldown(self) -> bool:
        """Check if new positions should be blocked."""
        if self.cooldown_until is None:
            return False
        return datetime.now() < self.cooldown_until
    
    def get_cooldown_remaining(self) -> float:
        """Get remaining cooldown time in hours."""
        if self.cooldown_until is None:
            return 0.0
        remaining = (self.cooldown_until - datetime.now()).total_seconds() / 3600
        return max(0.0, remaining)
    
    def reset_state(self):
        """Reset all tracking state."""
        self.underwater_start_time = None
        self.is_recovery_candidate = False
        self.recovery_trailing_active = False
        self.peak_positive_pnl = 0.0
        self.should_trigger_close = False
    
    def get_status(self) -> dict:
        """Get current status for UI/logging."""
        hours_underwater = 0.0
        if self.underwater_start_time:
            hours_underwater = (datetime.now() - self.underwater_start_time).total_seconds() / 3600
        
        return {
            "type": "PORTFOLIO_RECOVERY",
            "is_recovery_candidate": self.is_recovery_candidate,
            "trailing_active": self.recovery_trailing_active,
            "hours_underwater": round(hours_underwater, 1),
            "peak_pnl": round(self.peak_positive_pnl, 2),
            "trailing_distance_pct": round(self.trailing_distance_pct, 2),
            "cooldown_remaining_hours": round(self.get_cooldown_remaining(), 1),
            "last_upnl": round(self.last_total_upnl, 2)
        }


# Global PortfolioRecoveryManager instance
portfolio_recovery_manager = PortfolioRecoveryManager()


# ============================================================================
# PHASE XXX: BREAKEVEN STOP MANAGER
# Moves virtual stop to entry price when position reaches profit threshold
# ============================================================================

class BreakevenStopManager:
    """
    Breakeven Stop Management for LIVE Binance positions.
    
    When position reaches dynamic profit threshold (based on spread/volatility),
    activates a virtual stop at entry price. If price returns to entry, closes position.
    
    Thresholds:
    - Very Low spread (BTC/ETH): 0.5% profit â†’ breakeven
    - Low spread: 0.75% profit â†’ breakeven
    - Normal spread: 1.0% profit â†’ breakeven  
    - High spread: 1.5% profit â†’ breakeven
    - Very High spread (meme): 2.5% profit â†’ breakeven
    """
    
    def __init__(self):
        # Track breakeven state per position: {symbol: {active: bool, entry_price: float, activation_time: datetime}}
        self.breakeven_state = {}
        
        # Phase 203: Increased ATR-based dynamic activation thresholds
        # Increased floor and atr_mult to prevent early break-even stops due to market noise
        self.activation_config = {
            'Very Low':  {'floor': 1.0, 'atr_mult': 1.5},   # BTC: max(1.0%, ATR*1.5)
            'Low':       {'floor': 1.2, 'atr_mult': 1.5},   # SOL/AVAX
            'Normal':    {'floor': 1.5, 'atr_mult': 1.8},   # Mid-cap
            'High':      {'floor': 2.0, 'atr_mult': 2.0},   # Low liquidity
            'Very High': {'floor': 2.5, 'atr_mult': 2.5},   # Meme coins
            'Extreme':   {'floor': 3.0, 'atr_mult': 3.0},   # Hyper-volatile
            'Ultra':     {'floor': 4.0, 'atr_mult': 4.0},   # Extreme edge cases
        }
        
        # Phase 185: Fee buffer increased â€” minimum 0.5% for all levels
        # Prevents partial fills on low-liquidity coins (ZKUSDT bug)
        # Limit placed further from entry â†’ fills completely before price reverses
        self.fee_buffers = {
            'Very Low':  0.005,   # 0.50% (was 0.05%)
            'Low':       0.005,   # 0.50% (was 0.10%)
            'Normal':    0.006,   # 0.60% (was 0.15%)
            'High':      0.008,   # 0.80% (was 0.20%)
            'Very High': 0.010,   # 1.00% (was 0.30%)
            'Extreme':   0.015,   # 1.50%
            'Ultra':     0.020,   # 2.00%
        }
        
        # Phase 190: Reduced min age from 30 to 5 minutes
        self.min_breakeven_age_minutes = 5
        
        logger.info("ðŸ“Š BreakevenStopManager v2 initialized (ATR-based)")
    
    async def load_from_sqlite(self):
        """Load persisted breakeven states from SQLite on startup."""
        try:
            loaded = await sqlite_manager.load_breakeven_states()
            if loaded:
                self.breakeven_state.update(loaded)
                logger.warning(f"ðŸ”’ Restored {len(loaded)} breakeven states from SQLite: {list(loaded.keys())}")
        except Exception as e:
            logger.error(f"Failed to load breakeven states: {e}")
    
    async def check_positions(self, positions: list, live_trader) -> dict:
        """
        Check all Binance positions for breakeven conditions.
        
        Args:
            positions: List of Binance positions from live_trader.get_positions()
            live_trader: LiveBinanceTrader instance for closing positions
            
        Returns:
            Summary of actions taken
        """
        actions = {
            "breakeven_activated": [],
            "breakeven_closed": [],
            "checked": 0
        }
        
        if not live_trader or not live_trader.enabled:
            return actions
        
        for pos in positions:
            try:
                symbol = pos.get('symbol', '')
                if not symbol:
                    continue
                    
                side = pos.get('side', '')
                entry_price = float(pos.get('entryPrice', 0))
                current_price = float(pos.get('currentPrice', pos.get('markPrice', 0)))
                contracts = float(pos.get('contracts', pos.get('positionAmt', 0)))
                spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                
                if entry_price <= 0 or current_price <= 0 or contracts == 0:
                    continue
                
                actions["checked"] += 1
                
                # Calculate profit percentage
                if side == 'LONG':
                    profit_pct = (current_price - entry_price) / entry_price * 100
                else:  # SHORT
                    profit_pct = (entry_price - current_price) / entry_price * 100
                
                # Phase 182: ATR-based dynamic activation threshold
                atr = float(pos.get('atr', entry_price * 0.02))  # Default 2% if no ATR
                atr_pct = (atr / entry_price) * 100 if entry_price > 0 else 2.0
                config = self.activation_config.get(spread_level, {'floor': 2.0, 'atr_mult': 2.0})
                activation_threshold = max(config['floor'], atr_pct * config['atr_mult'])
                
                # Phase 182: Minimum hold time guard (30 min)
                open_time = pos.get('openTime', 0)
                if open_time > 0:
                    age_minutes = (datetime.now().timestamp() * 1000 - open_time) / 60000
                else:
                    age_minutes = 999  # Unknown age, don't block
                
                # State key
                state_key = f"{symbol}_{side}"
                
                # Check if breakeven already activated for this position
                state = self.breakeven_state.get(state_key, {})
                
                if not state.get('active', False):
                    # Phase 221: Phase 220 zaten breakeven set ettiyse atla
                    if pos.get('breakeven_activated', False):
                        continue
                    # Not yet activated - check if we should activate
                    if age_minutes < self.min_breakeven_age_minutes:
                        # Too young â€” skip breakeven (let trade develop)
                        continue
                    
                    if profit_pct >= activation_threshold:
                        # Phase 182: Calculate limit price with fee buffer
                        fee_buffer = self.fee_buffers.get(spread_level, 0.0015)
                        if side == 'LONG':
                            limit_price = entry_price * (1 + fee_buffer)
                        else:
                            limit_price = entry_price * (1 - fee_buffer)
                        
                        logger.warning(f"ðŸ”’ BREAKEVEN v2: {symbol} {side} profit={profit_pct:.2f}% >= {activation_threshold:.2f}% (ATR={atr_pct:.2f}%, floor={config['floor']}%, spread={spread_level}) | Limit @ ${limit_price:.6f} (entry+{fee_buffer*100:.2f}%)")
                        
                        # Place limit close order at entry + fee buffer
                        limit_result = await live_trader.close_position_limit(
                            symbol, side, abs(contracts), limit_price
                        )
                        
                        order_id = limit_result.get('id') if limit_result else None
                        
                        self.breakeven_state[state_key] = {
                            'active': True,
                            'entry_price': entry_price,
                            'activation_price': current_price,
                            'activation_time': datetime.now(),
                            'spread_level': spread_level,
                            'order_id': order_id,  # Phase 179: Track limit order
                            'contracts': abs(contracts),
                        }
                        actions["breakeven_activated"].append(symbol)
                        
                        # Phase 154: Persist to SQLite
                        safe_create_task(sqlite_manager.save_breakeven_state(
                            state_key, symbol, side, entry_price, current_price,
                            datetime.now().isoformat(), spread_level
                        ), name=f"persist_breakeven_{symbol}")
                        
                        if not limit_result:
                            logger.error(f"âŒ BREAKEVEN LIMIT ORDER FAILED: {symbol} - will retry next cycle")
                else:
                    # Phase 179: Breakeven active â€” monitor limit order status
                    order_id = state.get('order_id')
                    
                    if order_id:
                        # Check if limit order has been filled
                        order_status = await live_trader.check_order_status(symbol, order_id)
                        status = order_status.get('status', 'unknown')
                        
                        if status == 'closed':
                            # Phase 185: Check for partial fills!
                            filled_amount = order_status.get('filled', 0)
                            remaining_amount = order_status.get('remaining', 0)
                            fill_price = order_status.get('average', entry_price)
                            total_contracts = state.get('contracts', abs(contracts))
                            
                            # If remaining > 0, limit only partially filled â†’ market close the rest
                            if remaining_amount > 0 and remaining_amount > total_contracts * 0.01:
                                logger.warning(f"âš ï¸ BREAKEVEN PARTIAL FILL: {symbol} filled={filled_amount:.4f} remaining={remaining_amount:.4f} â†’ market closing remainder")
                                try:
                                    market_result = await live_trader.close_position(symbol, side, remaining_amount)
                                    if market_result:
                                        close_oid = str(market_result.get('id', ''))
                                        logger.warning(f"âœ… BREAKEVEN REMAINDER CLOSED: {symbol} {remaining_amount:.4f} contracts via market | Order: {close_oid[:12]}")
                                        # Phase 229b: Persist close order ID
                                        if close_oid:
                                            safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                    else:
                                        logger.error(f"âŒ BREAKEVEN REMAINDER FAILED: {symbol} â€” orphaned {remaining_amount:.4f} contracts!")
                                except Exception as mkt_err:
                                    logger.error(f"âŒ BREAKEVEN MARKET FALLBACK ERROR: {symbol} â€” {mkt_err}")
                            
                            # Limit order filled (fully or partially)! Record breakeven
                            # Phase 229b: Persist limit order ID for trade matching
                            if order_id:
                                safe_create_task(sqlite_manager.update_close_order_id(symbol, str(order_id)))
                            
                            # Calculate real PnL
                            if side == 'LONG':
                                real_pnl = (fill_price - entry_price) * state.get('contracts', 0)
                            else:
                                real_pnl = (entry_price - fill_price) * state.get('contracts', 0)
                            
                            logger.warning(f"âœ… BREAKEVEN LIMIT FILLED: {symbol} {side} @ ${fill_price} | PnL: ${real_pnl:.4f}")
                            
                            # Record trade with real data
                            # Phase 181: Include full trade_data so Binance sync records correctly
                            size_usd = pos.get('sizeUsd', 0)
                            leverage_val = pos.get('leverage', 10)
                            margin_val = size_usd / leverage_val if leverage_val > 0 and size_usd > 0 else 0
                            roi_val = (real_pnl / margin_val * 100) if margin_val > 0 else 0
                            
                            pending_close_reasons[symbol] = {
                                "reason": f"BREAKEVEN_CLOSE: {spread_level} spread, limit filled @ ${fill_price}",
                                "original_reason": "BREAKEVEN_CLOSE",
                                "pnl": round(real_pnl, 4),
                                "exitPrice": fill_price,
                                "timestamp": int(datetime.now().timestamp() * 1000),
                                "trade_data": {
                                    "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                                    "symbol": symbol,
                                    "side": side,
                                    "entryPrice": entry_price,
                                    "exitPrice": fill_price,
                                    "size": abs(state.get('contracts', 0)),
                                    "sizeUsd": size_usd,
                                    "pnl": round(real_pnl, 4),
                                    "pnlPercent": roi_val,
                                    "margin": round(margin_val, 4),
                                    "roi": round(roi_val, 2),
                                    "openTime": pos.get('openTime', 0),
                                    "leverage": leverage_val,
                                    "isLive": True,
                                    "closeReason": "BREAKEVEN_CLOSE",  # Phase 232c: dual field
                                }
                            }
                            safe_create_task(sqlite_manager.save_position_close({
                                'symbol': symbol,
                                'side': side,
                                'reason': f"BREAKEVEN_CLOSE: {spread_level} spread, limit filled @ ${fill_price}",
                                'original_reason': 'BREAKEVEN_CLOSE',
                                'entryPrice': entry_price,
                                'exitPrice': fill_price,
                                'pnl': round(real_pnl, 4),
                                'leverage': pos.get('leverage', 10),
                                'sizeUsd': pos.get('sizeUsd', 0),
                                'margin': round(margin_val, 4),
                                'roi': round(roi_val, 2),
                                'timestamp': int(datetime.now().timestamp() * 1000)
                            }), name=f"persist_breakeven_{symbol}")
                            
                            actions["breakeven_closed"].append(symbol)
                            del self.breakeven_state[state_key]
                            safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                            
                        elif status == 'canceled':
                            # Order was cancelled externally â€” clean up
                            logger.warning(f"âš ï¸ BREAKEVEN ORDER CANCELLED: {symbol} - clearing state")
                            del self.breakeven_state[state_key]
                            safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                            
                        elif status == 'error':
                            # Could not check â€” retry next cycle
                            logger.debug(f"â³ BREAKEVEN ORDER CHECK FAILED: {symbol} #{order_id} - will retry")
                            
                        # else: status == 'open' â€” still waiting, do nothing
                        
                    else:
                        # No order ID â€” retry placing limit order
                        logger.warning(f"ðŸ”„ BREAKEVEN RETRY: {symbol} - no order ID, placing limit order")
                        limit_result = await live_trader.close_position_limit(
                            symbol, side, abs(contracts), entry_price
                        )
                        if limit_result:
                            state['order_id'] = limit_result.get('id')
                    
                    # Safety: if position no longer exists on Binance, cancel order & clean up
                    if contracts == 0 and order_id:
                        logger.warning(f"ðŸ§¹ BREAKEVEN CLEANUP: {symbol} - position gone, cancelling order")
                        await live_trader.cancel_order(symbol, order_id)
                        if state_key in self.breakeven_state:
                            del self.breakeven_state[state_key]
                        safe_create_task(sqlite_manager.delete_breakeven_state(state_key), name=f"delete_breakeven_{symbol}")
                
            except Exception as e:
                logger.warning(f"Breakeven check error for position: {e}")
        
        return actions
    
    def get_status(self) -> dict:
        """Get current breakeven status for UI."""
        return {
            "type": "BREAKEVEN_STOP",
            "active_breakevens": len([s for s in self.breakeven_state.values() if s.get('active')]),
            "positions_tracked": list(self.breakeven_state.keys())
        }


# Global BreakevenStopManager instance
breakeven_stop_manager = BreakevenStopManager()


# ============================================================================
# PHASE XXX: LOSS RECOVERY TRAIL MANAGER  
# Trails from loss recovery - when position recovers from deep loss, trail to lock in recovery
# ============================================================================

class LossRecoveryTrailManager:
    """
    Loss Recovery Trailing for LIVE Binance positions.
    
    When position is in deep loss but starts recovering, activates trailing to lock in recovery.
    
    Logic:
    1. Position must be in significant loss (> threshold based on spread)
    2. Position must recover at least 30% of the loss
    3. Activate trailing - if gives back 50% of recovery, close
    
    Dynamic thresholds based on spread:
    - Very Low spread: -3% loss triggers, trail after -2% recovery
    - Low spread: -4% loss triggers
    - Normal spread: -5% loss triggers  
    - High spread: -7% loss triggers
    - Very High spread: -10% loss triggers
    """
    
    def __init__(self):
        # Track recovery state: {symbol: {peak_loss: float, peak_recovery: float, trail_active: bool}}
        self.recovery_state = {}
        
        # Spread-based loss thresholds (how deep loss before recovery tracking)
        self.loss_thresholds = {
            'Very Low': -3.0,   # BTC/ETH
            'Low': -4.0,
            'Normal': -5.0,
            'High': -7.0,
            'Very High': -10.0, # Meme coins - need more room
            'Extreme': -15.0,   # Hyper-volatile
            'Ultra': -20.0      # Extreme edge cases
        }
        
        # Recovery percentages
        self.recovery_activation_pct = 0.30  # Must recover 30% of loss to activate trail
        self.trail_giveback_pct = 0.50       # Close if gives back 50% of recovery
        
        logger.info("ðŸ“Š LossRecoveryTrailManager initialized")
    
    async def check_positions(self, positions: list, live_trader) -> dict:
        """
        Check all Binance positions for loss recovery conditions.
        
        Args:
            positions: List of Binance positions from live_trader.get_positions()
            live_trader: LiveBinanceTrader instance for closing positions
            
        Returns:
            Summary of actions taken
        """
        actions = {
            "recovery_tracking": [],
            "recovery_trail_activated": [],
            "recovery_closed": [],
            "checked": 0
        }
        
        if not live_trader or not live_trader.enabled:
            return actions
        
        for pos in positions:
            try:
                symbol = pos.get('symbol', '')
                if not symbol:
                    continue
                    
                side = pos.get('side', '')
                entry_price = float(pos.get('entryPrice', 0))
                current_price = float(pos.get('currentPrice', pos.get('markPrice', 0)))
                contracts = float(pos.get('contracts', pos.get('positionAmt', 0)))
                spread_level = pos.get('spreadLevel', pos.get('spread_level', 'Normal'))  # Phase 223b
                
                if entry_price <= 0 or current_price <= 0 or contracts == 0:
                    continue
                
                actions["checked"] += 1
                
                # Calculate profit percentage (negative = loss)
                if side == 'LONG':
                    pnl_pct = (current_price - entry_price) / entry_price * 100
                else:  # SHORT
                    pnl_pct = (entry_price - current_price) / entry_price * 100
                
                # Get dynamic loss threshold based on spread level
                loss_threshold = self.loss_thresholds.get(spread_level, -5.0)
                
                # State key
                state_key = f"{symbol}_{side}"
                state = self.recovery_state.get(state_key, {})
                
                # === PHASE 1: Track peak loss ===
                if pnl_pct < loss_threshold:
                    # Position is in deep loss - start tracking
                    peak_loss = min(state.get('peak_loss', 0), pnl_pct)
                    self.recovery_state[state_key] = {
                        'peak_loss': peak_loss,
                        'peak_recovery': pnl_pct,  # Will be updated if recovers
                        'trail_active': False,
                        'spread_level': spread_level
                    }
                    if state_key not in [a for a in actions["recovery_tracking"]]:
                        actions["recovery_tracking"].append(symbol)
                
                # === PHASE 2: Track recovery and activate trail ===
                elif state.get('peak_loss', 0) < loss_threshold:
                    peak_loss = state['peak_loss']
                    
                    # How much have we recovered?
                    recovery_amount = pnl_pct - peak_loss  # Always positive if recovering
                    total_loss_amount = abs(peak_loss)
                    recovery_ratio = recovery_amount / total_loss_amount if total_loss_amount > 0 else 0
                    
                    # Update peak recovery if higher
                    peak_recovery = max(state.get('peak_recovery', peak_loss), pnl_pct)
                    state['peak_recovery'] = peak_recovery
                    
                    if not state.get('trail_active', False):
                        # Check if we should activate trail
                        if recovery_ratio >= self.recovery_activation_pct:
                            state['trail_active'] = True
                            state['trail_activation_pnl'] = pnl_pct
                            self.recovery_state[state_key] = state
                            actions["recovery_trail_activated"].append(symbol)
                            logger.warning(f"ðŸ”„ RECOVERY TRAIL ACTIVATED: {symbol} {side} peak_loss={peak_loss:.2f}% current={pnl_pct:.2f}% recovered={recovery_ratio*100:.0f}%")
                    else:
                        # Trail is active - check if giving back too much
                        peak_recovery_pnl = state['peak_recovery']
                        recovery_from_peak = peak_recovery_pnl - peak_loss
                        current_recovery = pnl_pct - peak_loss
                        
                        giveback_ratio = 1 - (current_recovery / recovery_from_peak) if recovery_from_peak > 0 else 0
                        
                        if giveback_ratio >= self.trail_giveback_pct:
                            # Gave back too much - CLOSE!
                            logger.warning(f"ðŸ”„ RECOVERY TRAIL CLOSE: {symbol} {side} - gave back {giveback_ratio*100:.0f}% of recovery")
                            try:
                                # Phase 181: Set reason with full trade_data for trade history
                                size_usd = pos.get('sizeUsd', 0)
                                leverage_val = pos.get('leverage', 10)
                                margin_val = size_usd / leverage_val if leverage_val > 0 and size_usd > 0 else 0
                                
                                # Calculate actual PnL from prices
                                if side == 'LONG':
                                    actual_pnl = (current_price - entry_price) * abs(contracts)
                                else:
                                    actual_pnl = (entry_price - current_price) * abs(contracts)
                                roi_val = (actual_pnl / margin_val * 100) if margin_val > 0 else 0
                                
                                pending_close_reasons[symbol] = {
                                    "reason": f"RECOVERY_TRAIL_CLOSE: peak_loss={peak_loss:.1f}%, recovered to {peak_recovery_pnl:.1f}%, gave back {giveback_ratio*100:.0f}%",
                                    "original_reason": "RECOVERY_TRAIL_CLOSE",
                                    "pnl": round(actual_pnl, 4),
                                    "exitPrice": current_price,
                                    "timestamp": int(datetime.now().timestamp() * 1000),
                                    "trade_data": {
                                        "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
                                        "symbol": symbol,
                                        "side": side,
                                        "entryPrice": entry_price,
                                        "exitPrice": current_price,
                                        "size": abs(contracts),
                                        "sizeUsd": size_usd,
                                        "pnl": round(actual_pnl, 4),
                                        "pnlPercent": round(roi_val, 2),
                                        "margin": round(margin_val, 4),
                                        "roi": round(roi_val, 2),
                                        "openTime": pos.get('openTime', 0),
                                        "leverage": leverage_val,
                                        "isLive": True,
                                        "closeReason": "RECOVERY_TRAIL_CLOSE",  # Phase 232c: dual field
                                    }
                                }
                                # Persist to SQLite so data survives restart
                                safe_create_task(sqlite_manager.save_position_close({
                                    'symbol': symbol,
                                    'side': side,
                                    'reason': f"RECOVERY_TRAIL_CLOSE: peak_loss={peak_loss:.1f}%, recovered to {peak_recovery_pnl:.1f}%, gave back {giveback_ratio*100:.0f}%",
                                    'original_reason': 'RECOVERY_TRAIL_CLOSE',
                                    'entryPrice': entry_price,
                                    'exitPrice': current_price,
                                    'pnl': round(actual_pnl, 4),
                                    'leverage': pos.get('leverage', 10),
                                    'sizeUsd': pos.get('sizeUsd', 0),
                                    'margin': round(margin_val, 4),
                                    'roi': round(roi_val, 2),
                                    'timestamp': int(datetime.now().timestamp() * 1000)
                                }), name=f"persist_recovery_{symbol}")
                                result = await live_trader.close_position(symbol, side, abs(contracts))
                                if result:
                                    close_oid = str(result.get('id', ''))
                                    actions["recovery_closed"].append(symbol)
                                    # Clear state
                                    del self.recovery_state[state_key]
                                    logger.warning(f"âœ… RECOVERY CLOSE SUCCESS: {symbol} | Order: {close_oid[:12]}")
                                    # Phase 229b: Persist close order ID
                                    if close_oid:
                                        safe_create_task(sqlite_manager.update_close_order_id(symbol, close_oid))
                                else:
                                    logger.error(f"âŒ RECOVERY CLOSE FAILED: {symbol}")
                            except Exception as e:
                                logger.error(f"âŒ RECOVERY CLOSE ERROR: {symbol} - {e}")
                        
                        self.recovery_state[state_key] = state
                
                # === PHASE 3: Clear state if position turned profitable ===
                elif pnl_pct > 0 and state_key in self.recovery_state:
                    # Position is now profitable - clear recovery state
                    del self.recovery_state[state_key]
                    logger.info(f"ðŸ“ˆ RECOVERY CLEARED: {symbol} now profitable at {pnl_pct:.2f}%")
                
            except Exception as e:
                logger.warning(f"Recovery trail check error for position: {e}")
        
        return actions
    
    def get_status(self) -> dict:
        """Get current recovery trail status for UI."""
        return {
            "type": "LOSS_RECOVERY_TRAIL",
            "tracking_count": len(self.recovery_state),
            "trail_active_count": len([s for s in self.recovery_state.values() if s.get('trail_active')]),
            "positions_tracked": list(self.recovery_state.keys())
        }


# Global LossRecoveryTrailManager instance
loss_recovery_trail_manager = LossRecoveryTrailManager()


# ============================================================================
# PHASE 50: DOUBLE TREND CONFIRMATION
# ============================================================================

class DoubleTrendConfirmation:
    """
    Pending order doldurulmadan Ã¶nce trendin hala geÃ§erli olduÄŸunu onaylar.
    V-Reversal korumasÄ± saÄŸlar.
    
    SÃ¼reÃ§:
    1. Pending order oluÅŸturulur (sinyal geldiÄŸinde)
    2. Fiyat pullback seviyesine ulaÅŸÄ±r
    3. [BU SINIF] Ä°kinci trend onayÄ± yapÄ±lÄ±r:
       - Fiyat hala sinyal yÃ¶nÃ¼nde mi?
       - Z-Score hala threshold Ã¼stÃ¼nde mi?
       - BTC hala aynÄ± yÃ¶nde mi?
    4. Onay geÃ§erse order doldurulur, deÄŸilse iptal edilir
    """
    
    def __init__(self, confirmation_delay_seconds: int = 300):  # 5 dakika
        self.confirmation_delay = confirmation_delay_seconds
        self.pending_confirmations = {}  # order_id -> {signal_data, price_at_signal, timestamp}
        logger.info(f"ðŸ”„ DoubleTrendConfirmation initialized: {confirmation_delay_seconds}s delay")
    
    def register_pending_order(self, order_id: str, signal: dict, price_at_signal: float):
        """Pending order oluÅŸturulduÄŸunda kaydet."""
        self.pending_confirmations[order_id] = {
            'signal': signal,
            'price_at_signal': price_at_signal,
            'timestamp': datetime.now().timestamp(),
            'side': signal.get('side', 'LONG'),
            'zscore': signal.get('zscore', 0),
            'symbol': signal.get('symbol', '')
        }
        logger.info(f"ðŸ”„ Registered for double confirmation: {signal.get('symbol')} {signal.get('side')}")
    
    def check_confirmation(self, order_id: str, current_price: float, current_zscore: float, 
                          btc_trend: str = None) -> dict:
        """
        Pending order dolmadan Ã¶nce trendin hala geÃ§erli olduÄŸunu kontrol et.
        
        Returns:
            {
                'confirmed': bool,
                'reason': str,
                'checks': {price: bool, zscore: bool, btc: bool}
            }
        """
        if order_id not in self.pending_confirmations:
            # KayÄ±t yok, onay gerekmiyor (eski sistemle uyumluluk)
            return {'confirmed': True, 'reason': 'No confirmation needed', 'checks': {}}
        
        data = self.pending_confirmations[order_id]
        side = data['side']
        signal_price = data['price_at_signal']
        signal_zscore = data['zscore']
        symbol = data['symbol']
        
        checks = {
            'price_direction': False,
            'zscore_valid': False,
            'btc_aligned': True  # Default True if no BTC check
        }
        
        # CHECK 1: Fiyat hala sinyal yÃ¶nÃ¼nde mi?
        if side == 'LONG':
            # LONG iÃ§in: fiyat dÃ¼ÅŸmemeli (pullback sonrasÄ± yÃ¼kseliyor olmalÄ±)
            price_ok = current_price >= signal_price * 0.995  # %0.5 tolerans
            checks['price_direction'] = price_ok
        else:
            # SHORT iÃ§in: fiyat yÃ¼kselmemeli (pullback sonrasÄ± dÃ¼ÅŸÃ¼yor olmalÄ±)
            price_ok = current_price <= signal_price * 1.005  # %0.5 tolerans
            checks['price_direction'] = price_ok
        
        # CHECK 2: Z-Score hala threshold Ã¼stÃ¼nde mi?
        zscore_threshold = 0.8  # Daha dÃ¼ÅŸÃ¼k threshold (relaxed)
        if side == 'LONG':
            zscore_ok = current_zscore < -zscore_threshold  # Negative for oversold
        else:
            zscore_ok = current_zscore > zscore_threshold  # Positive for overbought
        checks['zscore_valid'] = zscore_ok
        
        # CHECK 3: BTC trend hala uyumlu mu?
        if btc_trend:
            if side == 'LONG':
                btc_ok = btc_trend in ['BULLISH', 'NEUTRAL']
            else:
                btc_ok = btc_trend in ['BEARISH', 'NEUTRAL']
            checks['btc_aligned'] = btc_ok
        
        # TÃ¼m kontroller geÃ§ti mi?
        all_passed = all(checks.values())
        
        if all_passed:
            # KayÄ±t temizle
            del self.pending_confirmations[order_id]
            return {
                'confirmed': True,
                'reason': 'All checks passed',
                'checks': checks
            }
        else:
            # Hangi kontroller baÅŸarÄ±sÄ±z?
            failed = [k for k, v in checks.items() if not v]
            logger.warning(f"ðŸš« Double confirmation FAILED for {symbol} {side}: {failed}")
            # KayÄ±t temizle
            del self.pending_confirmations[order_id]
            return {
                'confirmed': False,
                'reason': f"Failed: {', '.join(failed)}",
                'checks': checks
            }
    
    def cleanup_expired(self, max_age_seconds: int = 1800):
        """30 dakikadan eski kayÄ±tlarÄ± temizle."""
        now = datetime.now().timestamp()
        expired = [k for k, v in self.pending_confirmations.items() 
                   if now - v['timestamp'] > max_age_seconds]
        for k in expired:
            del self.pending_confirmations[k]
    
    def get_status(self) -> dict:
        """Get current status for UI."""
        return {
            "type": "DOUBLE_CONFIRMATION",
            "pending_count": len(self.pending_confirmations),
            "delay_seconds": self.confirmation_delay
        }


# Global DoubleTrendConfirmation instance
double_trend_confirmation = DoubleTrendConfirmation()


# ============================================================================
# PHASE 52: ADAPTIVE TRADING SYSTEM - POST-TRADE TRACKER
# ============================================================================

class PostTradeTracker:
    """
    KapatÄ±lan trade'leri 24 saat takip eder.
    Erken/geÃ§ Ã§Ä±kÄ±ÅŸ analizi yaparak optimizasyona veri saÄŸlar.
    """
    
    def __init__(self, tracking_hours: int = 24):
        self.tracking_hours = tracking_hours
        self.tracking = {}  # {trade_id: tracking_data}
        self.analysis_results = []  # Tamamlanan analizler
        self.max_results = 200  # Son 200 analiz sakla
        logger.info(f"ðŸ“Š PostTradeTracker initialized: {tracking_hours}h tracking")
    
    def start_tracking(self, closed_trade: dict):
        """Trade kapandÄ±ÄŸÄ±nda takibe al."""
        trade_id = closed_trade.get('id', str(datetime.now().timestamp()))
        
        self.tracking[trade_id] = {
            'trade': closed_trade,
            'symbol': closed_trade.get('symbol', ''),
            'side': closed_trade.get('side', ''),
            'exit_price': closed_trade.get('exitPrice', 0),
            'exit_time': datetime.now(),
            'pnl': closed_trade.get('pnl', 0),
            'reason': closed_trade.get('reason', closed_trade.get('closeReason', '')),
            'max_price_after': closed_trade.get('exitPrice', 0),
            'min_price_after': closed_trade.get('exitPrice', 0),
            'price_samples': 0,
        }
        logger.debug(f"ðŸ“Š POST-TRADE: Started tracking {closed_trade.get('symbol')} ({closed_trade.get('side')})")
    
    def update_prices(self, current_prices: dict):
        """FiyatlarÄ± gÃ¼ncelle - her 15 dakikada Ã§aÄŸrÄ±lmalÄ±."""
        now = datetime.now()
        completed = []
        
        for trade_id, data in list(self.tracking.items()):
            symbol = data['symbol']
            current_price = current_prices.get(symbol, 0)
            
            if current_price > 0:
                data['price_samples'] += 1
                data['max_price_after'] = max(data['max_price_after'], current_price)
                data['min_price_after'] = min(data['min_price_after'], current_price)
            
            # 24 saat doldu mu?
            hours_passed = (now - data['exit_time']).total_seconds() / 3600
            if hours_passed >= self.tracking_hours:
                result = self._finalize_analysis(trade_id, data)
                completed.append(result)
        
        return completed
    
    def _finalize_analysis(self, trade_id: str, data: dict) -> dict:
        """24 saat sonunda sonuÃ§larÄ± hesapla."""
        self.tracking.pop(trade_id, None)
        
        side = data['side']
        exit_price = data['exit_price']
        
        if exit_price <= 0:
            return {}
        
        if side == 'LONG':
            # LONG iÃ§in: Ã‡Ä±kÄ±ÅŸtan sonra fiyat ne kadar yÃ¼kseldi?
            best_price = data['max_price_after']
            missed_profit_pct = (best_price - exit_price) / exit_price * 100
            worst_price = data['min_price_after']
            avoided_loss_pct = (exit_price - worst_price) / exit_price * 100
        else:
            # SHORT iÃ§in: Ã‡Ä±kÄ±ÅŸtan sonra fiyat ne kadar dÃ¼ÅŸtÃ¼?
            best_price = data['min_price_after']
            missed_profit_pct = (exit_price - best_price) / exit_price * 100
            worst_price = data['max_price_after']
            avoided_loss_pct = (worst_price - exit_price) / exit_price * 100
        
        was_early = missed_profit_pct > 2  # %2'den fazla kaÃ§Ä±rÄ±ldÄ± mÄ±?
        was_correct = avoided_loss_pct > 1  # %1'den fazla zarar Ã¶nlendi mi?
        
        result = {
            'trade_id': trade_id,
            'symbol': data['symbol'],
            'side': side,
            'exit_price': exit_price,
            'best_price_24h': best_price,
            'worst_price_24h': worst_price,
            'missed_profit_pct': round(missed_profit_pct, 2),
            'avoided_loss_pct': round(avoided_loss_pct, 2),
            'was_early_exit': was_early,
            'was_correct_exit': was_correct,
            'actual_pnl': data['pnl'],
            'close_reason': data['reason'],
            'analysis_time': datetime.now().isoformat()
        }
        
        self.analysis_results.append(result)
        # Eski sonuÃ§larÄ± temizle
        if len(self.analysis_results) > self.max_results:
            self.analysis_results = self.analysis_results[-self.max_results:]
        
        status = 'ðŸ”´ ERKEN' if was_early else ('ðŸŸ¢ DOÄžRU' if was_correct else 'ðŸŸ¡ NÃ–TR')
        logger.info(f"ðŸ“Š POST-TRADE COMPLETE: {data['symbol']} {side} - {status} | KaÃ§Ä±rÄ±lan: %{missed_profit_pct:.1f} | Ã–nlenen: %{avoided_loss_pct:.1f}")
        
        return result
    
    def get_early_exit_rate(self, recent_count: int = 50) -> float:
        """Son N analizde erken Ã§Ä±kÄ±ÅŸ oranÄ±."""
        recent = self.analysis_results[-recent_count:]
        if not recent:
            return 0.0
        early_count = sum(1 for r in recent if r.get('was_early_exit', False))
        return early_count / len(recent) * 100
    
    def get_stats(self) -> dict:
        """Ã–zet istatistikler."""
        recent = self.analysis_results[-50:]
        return {
            'tracking_count': len(self.tracking),
            'completed_count': len(self.analysis_results),
            'early_exit_rate': self.get_early_exit_rate(),
            'avg_missed_profit': sum(r.get('missed_profit_pct', 0) for r in recent) / len(recent) if recent else 0,
            'avg_avoided_loss': sum(r.get('avoided_loss_pct', 0) for r in recent) / len(recent) if recent else 0,
        }

    # Phase 224C3: Exit parameter tuning recommendations
    def get_tuning_recommendations(self) -> dict:
        """Son 50 analiz sonucundan exit parametre Ã¶nerileri Ã¼ret."""
        recent = self.analysis_results[-50:]
        if len(recent) < 20:
            return {}
        
        early_exits = [r for r in recent if r.get('was_early_exit', False)]
        correct_exits = [r for r in recent if r.get('was_correct_exit', False)]
        
        recommendations = {}
        
        early_pct = len(early_exits) / len(recent)
        correct_pct = len(correct_exits) / len(recent)
        
        # %60+ erken Ã§Ä±kÄ±ÅŸ â†’ trail distance artÄ±r
        if early_pct > 0.6:
            recommendations['trail_distance_mult'] = 1.1
            recommendations['reason_trail'] = f'Erken Ã§Ä±kÄ±ÅŸ oranÄ± yÃ¼ksek: %{early_pct*100:.0f}'
        elif early_pct < 0.2:
            recommendations['trail_distance_mult'] = 0.95
            recommendations['reason_trail'] = f'Erken Ã§Ä±kÄ±ÅŸ oranÄ± dÃ¼ÅŸÃ¼k: %{early_pct*100:.0f}'
        
        # %40+ doÄŸru Ã§Ä±kÄ±ÅŸ â†’ TP'leri sÄ±kÄ±laÅŸtÄ±r (iyi Ã§alÄ±ÅŸÄ±yor)
        # %20- doÄŸru Ã§Ä±kÄ±ÅŸ â†’ TP'leri gevÅŸet (Ã§ok erken kapanÄ±yor)
        if correct_pct < 0.20:
            recommendations['tp_mult'] = 1.1
            recommendations['reason_tp'] = f'DoÄŸru Ã§Ä±kÄ±ÅŸ oranÄ± dÃ¼ÅŸÃ¼k: %{correct_pct*100:.0f}'
        elif correct_pct > 0.5:
            recommendations['tp_mult'] = 0.9
            recommendations['reason_tp'] = f'DoÄŸru Ã§Ä±kÄ±ÅŸ oranÄ± yÃ¼ksek: %{correct_pct*100:.0f}'
        
        if recommendations:
            logger.info(f"ðŸ“Š TUNING_REC: {recommendations}")
        
        return recommendations


# ============================================================================
# PHASE 224C: EXIT ARBITRATOR
# Central coordinator for exit decisions â€” logs, prioritizes, recommends
# ============================================================================

class ExitArbitrator:
    """
    Phase 224C: TÃ¼m exit kararlarÄ±nÄ± merkezi bir yerde koordine eder.
    
    Mevcut update() loop'undaki exit sÄ±rasÄ±nÄ± DEÄžÄ°ÅžTÄ°RMEZ,
    ancak her Ã§Ä±kÄ±ÅŸ kararÄ±nÄ± loglar ve analiz saÄŸlar.
    Priority: EMERGENCY > KILL_SWITCH > ADVERSE > TIME > SL > TRAIL > TP > BREAKEVEN
    """
    
    PRIORITY = {
        'EMERGENCY_SL': 1,
        'KILL_SWITCH': 2,
        'ADVERSE': 3,
        'TIME': 4,
        'SL_HIT': 5,
        'TRAIL_EXIT': 6,
        'TP_HIT': 7,
        'BREAKEVEN': 8,
        'LOSS_RECOVERY': 9,
        'PARTIAL_TP': 10,
    }
    
    def __init__(self):
        self.exit_stats = {}  # {reason: {count, total_pnl, avg_roi}}
        self.recent_exits = deque(maxlen=200)  # Son 200 Ã§Ä±kÄ±ÅŸ
        logger.info("âš–ï¸ ExitArbitrator initialized")
    
    def record_exit(self, symbol: str, reason: str, roi: float, pnl: float, decision_trace: list = None):
        """Ã‡Ä±kÄ±ÅŸ kararÄ±nÄ± kaydet ve analiz et."""
        if reason not in self.exit_stats:
            self.exit_stats[reason] = {'count': 0, 'total_pnl': 0.0, 'total_roi': 0.0}
        
        self.exit_stats[reason]['count'] += 1
        self.exit_stats[reason]['total_pnl'] += pnl
        self.exit_stats[reason]['total_roi'] += roi
        
        exit_record = {
            'symbol': symbol,
            'reason': reason,
            'roi': round(roi, 2),
            'pnl': round(pnl, 4),
            'time': datetime.now().isoformat(),
            'trace_len': len(decision_trace) if decision_trace else 0,
            'priority': self.PRIORITY.get(reason, 99),
        }
        self.recent_exits.append(exit_record)
    
    def get_stats(self) -> dict:
        """Ã‡Ä±kÄ±ÅŸ istatistikleri â€” hangi manager en Ã§ok/en az kÃ¢rlÄ±."""
        result = {}
        for reason, stats in self.exit_stats.items():
            count = stats['count']
            result[reason] = {
                'count': count,
                'avg_pnl': round(stats['total_pnl'] / max(1, count), 4),
                'avg_roi': round(stats['total_roi'] / max(1, count), 2),
                'total_pnl': round(stats['total_pnl'], 4),
            }
        return result
    
    def get_worst_exit_reasons(self, n: int = 3) -> list:
        """En kÃ¶tÃ¼ performans gÃ¶steren exit reason'lar."""
        stats = self.get_stats()
        sorted_reasons = sorted(stats.items(), key=lambda x: x[1]['avg_pnl'])
        return sorted_reasons[:n]

# Global instance
exit_arbitrator = ExitArbitrator()


# ============================================================================
# PHASE 224D: MARKET REGIME MANAGER
# VOLATILE / QUIET / TRENDING regime detection + parameter profiles
# ============================================================================

# Regime-based parameter profiles
REGIME_PROFILES = {
    'VOLATILE': {
        'min_score_offset': 10,      # Daha seÃ§ici
        'trail_distance_mult': 1.3,  # Daha geniÅŸ trail
        'tp_mult': 1.2,              # Daha geniÅŸ TP
        'sl_mult': 1.2,              # Daha geniÅŸ SL
        'confirmation_mult': 0.5,    # Daha kÄ±sa bekleme (hÄ±zlÄ± hareket)
    },
    'QUIET': {
        'min_score_offset': -5,      # Daha agresif
        'trail_distance_mult': 0.8,  # Daha sÄ±kÄ± trail
        'tp_mult': 0.8,
        'sl_mult': 0.9,
        'confirmation_mult': 1.5,    # Daha uzun bekleme
    },
    'TRENDING': {
        'min_score_offset': -10,     # Trend'e gÃ¼ven
        'trail_distance_mult': 1.0,
        'tp_mult': 1.5,              # Trend'de TP uzak
        'sl_mult': 0.8,              # Trend'de SL sÄ±kÄ±
        'confirmation_mult': 0.7,    # Trend'de hÄ±zlÄ± entry
    }
}

class MarketRegimeManager:
    """
    Phase 224D: BTC volatilite ve trend'den rejim tespit et.
    Rejime gÃ¶re parametreleri ayarla.
    """
    
    def __init__(self):
        self.current_regime = 'QUIET'
        self.regime_history = deque(maxlen=100)
        self._last_update = 0
        logger.info("ðŸŽ­ MarketRegimeManager initialized")
    
    def detect_regime(self) -> str:
        """BTC volatilite ve trend'den rejim tespit et."""
        try:
            btc_atr_pct = 2.0
            btc_trend = 'neutral'
            
            # Read from btc_filter (BTCCorrelationFilter global instance)
            if 'btc_filter' in globals() and btc_filter:
                btc_trend_raw = getattr(btc_filter, 'btc_trend', 'NEUTRAL')
                # Map BTCCorrelationFilter trend strings to regime format
                if btc_trend_raw in ('BULLISH', 'STRONG_BULLISH'):
                    btc_trend = 'bullish'
                elif btc_trend_raw in ('BEARISH', 'STRONG_BEARISH'):
                    btc_trend = 'bearish'
                else:
                    btc_trend = 'neutral'
                # ATR estimate from 30m + 1h momentum
                btc_1h_change = abs(getattr(btc_filter, 'btc_change_1h', 0))
                btc_4h_change = abs(getattr(btc_filter, 'btc_change_4h', 0))
                btc_atr_pct = max(btc_1h_change, btc_4h_change / 2, 1.0)
            
            if btc_atr_pct > 4.0:
                regime = 'VOLATILE'
            elif btc_trend in ('bullish', 'bearish') and btc_atr_pct < 3.0:
                regime = 'TRENDING'
            else:
                regime = 'QUIET'
            
            if regime != self.current_regime:
                logger.info(f"ðŸŽ­ REGIME_CHANGE: {self.current_regime} â†’ {regime} (BTC ATR={btc_atr_pct:.1f}%, trend={btc_trend})")
                self.current_regime = regime
            
            self.regime_history.append({
                'regime': regime,
                'time': datetime.now().isoformat(),
                'btc_atr_pct': btc_atr_pct,
                'btc_trend': btc_trend,
            })
            
            return regime
        except Exception as e:
            logger.debug(f"Regime detection error: {e}")
            return self.current_regime
    
    def get_profile(self) -> dict:
        """Mevcut rejime ait parametre profili."""
        return REGIME_PROFILES.get(self.current_regime, REGIME_PROFILES['QUIET'])
    
    def get_adjusted_min_score(self, base_score: int) -> int:
        """Rejime gÃ¶re ayarlanmÄ±ÅŸ minimum skor."""
        profile = self.get_profile()
        return base_score + profile.get('min_score_offset', 0)

# Global instance
market_regime_manager = MarketRegimeManager()


# ============================================================================
# PHASE 224D3: CANARY MODE - A/B Test Infrastructure
# Test new parameters on ~10% of positions
# ============================================================================

class CanaryMode:
    """
    Yeni parametre setini rastgele %10 pozisyonda dene.
    Deterministik: pozisyon ID hash'ine gÃ¶re.
    """
    
    def __init__(self, canary_pct: float = 0.10):
        self.canary_pct = canary_pct
        self.canary_params = {}      # Deneysel parametreler {key: value}
        self.canary_results = []     # Canary pozisyon PnL'leri
        self.control_results = []    # Normal pozisyon PnL'leri
        self.enabled = False         # BaÅŸlangÄ±Ã§ta kapalÄ±
        logger.info(f"ðŸ¤ CanaryMode initialized (pct={canary_pct*100:.0f}%)")
    
    def should_use_canary(self, pos_id: str) -> bool:
        """Deterministik: pos_id hash'inin son 2 hanesi < canary_pct * 100."""
        if not self.enabled or not self.canary_params:
            return False
        import hashlib
        h = int(hashlib.md5(pos_id.encode()).hexdigest(), 16)
        return (h % 100) < int(self.canary_pct * 100)
    
    def get_params(self, pos_id: str, base_params: dict) -> dict:
        """Base params + canary overrides."""
        if not self.should_use_canary(pos_id):
            return base_params
        merged = {**base_params, **self.canary_params}
        return merged
    
    def record_result(self, pos_id: str, pnl: float, is_canary: bool = None):
        """Trade kapanÄ±nca sonucu kaydet. Use stored is_canary flag if available."""
        if is_canary is None:
            is_canary = self.should_use_canary(pos_id)
        if is_canary:
            self.canary_results.append(pnl)
        else:
            self.control_results.append(pnl)
    
    def get_report(self) -> dict:
        """A/B test sonuÃ§larÄ±."""
        canary_n = len(self.canary_results)
        control_n = len(self.control_results)
        
        canary_wr = sum(1 for r in self.canary_results if r > 0) / max(1, canary_n)
        control_wr = sum(1 for r in self.control_results if r > 0) / max(1, control_n)
        
        canary_avg = sum(self.canary_results) / max(1, canary_n)
        control_avg = sum(self.control_results) / max(1, control_n)
        
        return {
            'canary': {'n': canary_n, 'win_rate': round(canary_wr * 100, 1), 'avg_pnl': round(canary_avg, 4)},
            'control': {'n': control_n, 'win_rate': round(control_wr * 100, 1), 'avg_pnl': round(control_avg, 4)},
            'canary_params': self.canary_params,
            'is_better': canary_avg > control_avg if canary_n >= 10 and control_n >= 10 else None,
        }

# Global instance
canary_mode = CanaryMode()

# ============================================================================
# PHASE 225: PRICE SHOCK MANAGER
# ============================================================================

class PriceShockManager:
    """
    Bidirectional price shock detection + automatic response.
    
    Detects sudden BTC/coin price moves using ATR-dynamic thresholds and
    4-filter validation (price, volume, sustained, liquidation/funding).
    
    Response: block opposing signals, cancel opposing pending orders,
    tighten SL on exposed positions (idempotent, entry-distance based).
    
    Guardrails:
    1. SL tightening = entry-SL distance Ã— 0.7 (not price Ã— 0.7), idempotent
    2. Shock deactivation restores original SL from snapshot
    3. Market shock > coin shock priority
    4. Funding = supporting evidence only (not sole trigger)
    5. Full event logging (filters passed, actions taken, duration)
    """
    
    def __init__(self):
        self.shock_mode = 'NORMAL'  # NORMAL | BEAR_SHOCK | BULL_SHOCK
        self.shock_start_time = None
        self.shock_cooldown_until = 0  # timestamp
        self.min_shock_duration = 600  # 10 minutes minimum
        self.shock_ttl = 900  # 15 minutes TTL
        self.cooldown_duration = 900  # 15 minutes cooldown after shock ends
        self.sl_tighten_factor = 0.7  # SL distance Ã— 0.7
        self.recovery_cancel_pct = 0.60  # %60 recovery â†’ fake alarm
        self.recovery_check_delay = 180  # 3 minutes
        
        # Snapshots for restore
        self.sl_snapshots = {}  # {pos_id: {'sl': original_sl, 'trailing': original_trailing}}
        self.shock_trigger_price = 0.0  # BTC price at shock trigger
        
        # History for logging
        self.shock_history = []  # [{type, timestamp, filters, actions, duration}]
        self.current_shock_event = None
        
        # BTC price tracking for 5m change
        self.btc_price_history = []  # [(timestamp, price)] â€” last 10 minutes
        
        logger.info("âš¡ PriceShockManager initialized (Phase 225)")
    
    def _update_price_history(self, btc_price: float):
        """Track BTC price for 5-minute change calculation."""
        now = datetime.now().timestamp()
        self.btc_price_history.append((now, btc_price))
        # Keep last 10 minutes
        cutoff = now - 600
        self.btc_price_history = [(t, p) for t, p in self.btc_price_history if t > cutoff]
    
    def _get_btc_5m_change(self) -> float:
        """Calculate BTC % change over last 5 minutes."""
        now = datetime.now().timestamp()
        current_prices = [(t, p) for t, p in self.btc_price_history if t > now - 30]
        old_prices = [(t, p) for t, p in self.btc_price_history if now - 330 < t < now - 270]
        
        if not current_prices or not old_prices:
            return 0.0
        
        current = current_prices[-1][1]
        old = sum(p for _, p in old_prices) / len(old_prices)
        
        if old <= 0:
            return 0.0
        return ((current - old) / old) * 100
    
    def _get_dynamic_threshold(self, btc_filter) -> float:
        """ATR-based dynamic threshold. Higher in volatile markets, lower in quiet."""
        btc_1h = abs(getattr(btc_filter, 'btc_change_1h', 0))
        btc_4h = abs(getattr(btc_filter, 'btc_change_4h', 0))
        
        # Estimate 5m ATR from 1h and 4h changes
        estimated_5m_atr = max(btc_1h / 4, btc_4h / 12, 0.3)
        
        # Threshold = 1.5 Ã— estimated ATR, clamped to [0.5%, 2.0%]
        threshold = max(0.5, min(2.0, 1.5 * estimated_5m_atr))
        return threshold
    
    def check_for_shock(self, btc_filter, liquidation_tracker, funding_oi_tracker):
        """Main shock detection â€” called every scanner cycle."""
        now = datetime.now().timestamp()
        btc_price = getattr(btc_filter, 'btc_price', 0)
        
        if btc_price <= 0:
            return
        
        self._update_price_history(btc_price)
        
        # Check TTL expiry for active shock
        if self.shock_mode != 'NORMAL':
            elapsed = now - (self.shock_start_time or now)
            
            # Fake alarm check: recovery within 3 minutes
            if elapsed > self.recovery_check_delay and self.shock_trigger_price > 0:
                if self.shock_mode == 'BEAR_SHOCK':
                    # Calculate actual % recovery from trigger price
                    drop_pct = abs(((self.shock_trigger_price - btc_price) / self.shock_trigger_price) * 100) if self.shock_trigger_price > 0 else 0
                    # Price has recovered above trigger = fake alarm
                    if btc_price > self.shock_trigger_price:
                        logger.warning(f"âš¡ SHOCK_FAKE_ALARM: BTC recovered above trigger ${self.shock_trigger_price:.0f} â†’ ${btc_price:.0f} â€” cancelling BEAR_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                    # Original drop was X%, now only Y% â†’ if recovered >60% of drop
                    original_5m_drop = abs(self.current_shock_event.get('btc_change_5m', 0)) if self.current_shock_event else 1
                    if original_5m_drop > 0 and drop_pct < original_5m_drop * (1 - self.recovery_cancel_pct):
                        logger.warning(f"âš¡ SHOCK_FAKE_ALARM: Drop shrunk {original_5m_drop:.2f}%â†’{drop_pct:.2f}% (>60% recovered) â€” cancelling BEAR_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                elif self.shock_mode == 'BULL_SHOCK':
                    pump_pct = abs(((btc_price - self.shock_trigger_price) / self.shock_trigger_price) * 100) if self.shock_trigger_price > 0 else 0
                    if btc_price < self.shock_trigger_price:
                        logger.warning(f"âš¡ SHOCK_FAKE_ALARM: BTC reversed below trigger ${self.shock_trigger_price:.0f} â†’ ${btc_price:.0f} â€” cancelling BULL_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
                    original_5m_pump = abs(self.current_shock_event.get('btc_change_5m', 0)) if self.current_shock_event else 1
                    if original_5m_pump > 0 and pump_pct < original_5m_pump * (1 - self.recovery_cancel_pct):
                        logger.warning(f"âš¡ SHOCK_FAKE_ALARM: Pump shrunk {original_5m_pump:.2f}%â†’{pump_pct:.2f}% (>60% recovered) â€” cancelling BULL_SHOCK")
                        self._deactivate_shock('FAKE_RECOVERY')
                        return
            
            # TTL expiry (after minimum duration)
            if elapsed > max(self.min_shock_duration, self.shock_ttl):
                logger.info(f"âš¡ SHOCK_TTL: {self.shock_mode} expired after {elapsed/60:.1f}min")
                self._deactivate_shock('TTL_EXPIRED')
                return
            
            # If shock still active, check if it should extend
            btc_5m = self._get_btc_5m_change()
            threshold = self._get_dynamic_threshold(btc_filter)
            if abs(btc_5m) > threshold:
                # Extend TTL
                self.shock_start_time = now - self.min_shock_duration  # Keep min duration passed
                logger.debug(f"âš¡ SHOCK_EXTEND: {self.shock_mode} TTL extended (BTC 5m={btc_5m:+.2f}%)")
            return
        
        # Cooldown check
        if now < self.shock_cooldown_until:
            return
        
        # === DETECTION ===
        btc_5m = self._get_btc_5m_change()
        threshold = self._get_dynamic_threshold(btc_filter)
        
        if abs(btc_5m) < threshold:
            return  # No shock candidate
        
        # 4-filter validation (need 3/4)
        filters_passed = []
        
        # Filter 1: Price shock (already confirmed above)
        filters_passed.append('price')
        
        # Filter 2: Volume spike â€” use 30m momentum as proxy
        btc_30m = abs(getattr(btc_filter, 'btc_change_30m', 0))
        if btc_30m > threshold * 0.8:
            filters_passed.append('volume_momentum')
        
        # Filter 3: No quick recovery â€” check if move is sustained
        # Use ratio of 30m vs 5m changes (if both same direction, sustained)
        if btc_5m * getattr(btc_filter, 'btc_change_30m', 0) > 0:  # Same sign
            filters_passed.append('sustained')
        
        # Filter 4: Liquidation spike OR funding extreme
        try:
            # Check BTCUSDT liquidations
            btc_liqs = liquidation_tracker.recent_liquidations.get('BTCUSDT', [])
            recent_liq_usd = sum(
                l.get('usd', 0) for l in btc_liqs 
                if l.get('timestamp', 0) > now - 60
            )
            if recent_liq_usd > 200000:  # $200K+ BTC liquidations in 60s
                filters_passed.append('liquidation')
        except:
            pass
        
        if 'liquidation' not in filters_passed:
            try:
                btc_funding = funding_oi_tracker.funding_rates.get('BTCUSDT', 0)
                if abs(btc_funding) > 0.001:  # 0.1%+ extreme funding
                    filters_passed.append('funding_extreme')
            except:
                pass
        
        # Need 3/4 filters
        if len(filters_passed) < 3:
            logger.debug(f"âš¡ SHOCK_INSUFFICIENT: BTC 5m={btc_5m:+.2f}% but only {len(filters_passed)}/4 filters: {filters_passed}")
            return
        
        # === ACTIVATE SHOCK ===
        shock_type = 'BEAR_SHOCK' if btc_5m < 0 else 'BULL_SHOCK'
        self.shock_mode = shock_type
        self.shock_start_time = now
        self.shock_trigger_price = btc_price
        
        self.current_shock_event = {
            'type': shock_type,
            'timestamp': now,
            'btc_change_5m': round(btc_5m, 2),
            'threshold': round(threshold, 2),
            'filters_passed': filters_passed,
            'btc_price': btc_price,
            'actions': [],
            'positions_affected': [],
        }
        
        logger.warning(f"âš¡ PRICE_SHOCK: {shock_type} activated | BTC 5m={btc_5m:+.2f}% (threshold={threshold:.2f}%) | Filters: {filters_passed}")
    
    def should_block_signal(self, signal_action: str, symbol: str = '') -> tuple:
        """Check if signal should be blocked due to active shock."""
        if self.shock_mode == 'NORMAL':
            return False, ''
        
        if self.shock_mode == 'BEAR_SHOCK' and signal_action == 'LONG':
            return True, f'BEAR_SHOCK: LONG blocked (BTC crash detected)'
        
        if self.shock_mode == 'BULL_SHOCK' and signal_action == 'SHORT':
            return True, f'BULL_SHOCK: SHORT blocked (BTC pump detected)'
        
        return False, ''
    
    def cancel_opposing_pending(self, pending_orders: list) -> list:
        """Cancel pending orders opposing the shock direction. Returns cancelled list."""
        if self.shock_mode == 'NORMAL':
            return []
        
        cancelled = []
        cancel_side = 'LONG' if self.shock_mode == 'BEAR_SHOCK' else 'SHORT'
        
        for order in list(pending_orders):
            if order.get('side') == cancel_side:
                cancelled.append(order)
                pending_orders.remove(order)
        
        if cancelled and self.current_shock_event:
            self.current_shock_event['actions'].append(f'cancel_pending_{cancel_side}_{len(cancelled)}')
        
        return cancelled
    
    def tighten_exposed_positions(self, positions: list):
        """
        Tighten SL for positions exposed to shock direction.
        Guardrail 1: Uses entry-SL DISTANCE Ã— 0.7, not price Ã— 0.7.
        Idempotent: snapshots prevent double-tightening.
        """
        if self.shock_mode == 'NORMAL':
            return
        
        exposed_side = 'LONG' if self.shock_mode == 'BEAR_SHOCK' else 'SHORT'
        
        for pos in positions:
            if pos.get('side') != exposed_side:
                continue
            
            pos_id = pos.get('id', '')
            
            # Idempotent: skip if already tightened
            if pos_id in self.sl_snapshots:
                continue
            
            entry = pos.get('entryPrice', 0)
            current_sl = pos.get('stopLoss', 0)
            current_trailing = pos.get('trailingStop', 0)
            
            if entry <= 0:
                continue
            
            # Snapshot original values for restore
            self.sl_snapshots[pos_id] = {
                'sl': current_sl,
                'trailing': current_trailing,
            }
            
            # Tighten: entry-SL distance Ã— 0.7
            # If trailingStop is 0 (not set), fall back to SL value
            effective_trailing = current_trailing if current_trailing > 0 else current_sl
            
            if exposed_side == 'LONG':
                sl_distance = entry - current_sl  # positive for valid SL below entry
                trail_distance = entry - effective_trailing
                # Guard: skip if SL already above entry (profitable position with moved stops)
                if sl_distance <= 0:
                    del self.sl_snapshots[pos_id]  # Remove snapshot since we're skipping
                    logger.debug(f"âš¡ SHOCK_SKIP: {pos.get('symbol')} LONG â€” SL already above entry (profitable), no tightening needed")
                    continue
                new_sl = entry - (sl_distance * self.sl_tighten_factor)
                new_trailing = entry - (trail_distance * self.sl_tighten_factor) if trail_distance > 0 else new_sl
            else:
                sl_distance = current_sl - entry  # positive for valid SL above entry
                trail_distance = effective_trailing - entry
                # Guard: skip if SL already below entry (profitable position with moved stops)
                if sl_distance <= 0:
                    del self.sl_snapshots[pos_id]
                    logger.debug(f"âš¡ SHOCK_SKIP: {pos.get('symbol')} SHORT â€” SL already below entry (profitable), no tightening needed")
                    continue
                new_sl = entry + (sl_distance * self.sl_tighten_factor)
                new_trailing = entry + (trail_distance * self.sl_tighten_factor) if trail_distance > 0 else new_sl
            
            pos['stopLoss'] = new_sl
            pos['trailingStop'] = new_trailing
            
            if self.current_shock_event:
                self.current_shock_event['positions_affected'].append(pos_id)
                self.current_shock_event['actions'].append(f'tighten_sl_{pos_id[-8:]}')
            
            logger.warning(f"ðŸ“‰ SHOCK_TIGHTEN: {pos.get('symbol')} {exposed_side} | SL {current_sl:.4f}â†’{new_sl:.4f} (distanceÃ—{self.sl_tighten_factor})")
    
    def _deactivate_shock(self, reason: str = 'TTL_EXPIRED'):
        """Deactivate shock and restore original SL values."""
        now = datetime.now().timestamp()
        duration = now - (self.shock_start_time or now)
        
        # Restore SL snapshots (Guardrail 2 â€” smart restore: don't overwrite improved trailing)
        restored_count = 0
        for pos_id, snapshot in self.sl_snapshots.items():
            try:
                for pos in global_paper_trader.positions:
                    if pos.get('id') == pos_id:
                        current_sl = pos.get('stopLoss', 0)
                        current_trailing = pos.get('trailingStop', 0)
                        side = pos.get('side', 'LONG')
                        
                        # Smart restore: only restore if snapshot SL is more protective than current
                        # For LONG: higher SL = more protective
                        # For SHORT: lower SL = more protective
                        if side == 'LONG':
                            restore_sl = max(snapshot['sl'], current_sl)  # Keep the higher (more protective)
                            restore_trail = max(snapshot['trailing'], current_trailing)
                        else:
                            restore_sl = min(snapshot['sl'], current_sl)  # Keep the lower (more protective)
                            restore_trail = min(snapshot['trailing'], current_trailing)
                        
                        pos['stopLoss'] = restore_sl
                        pos['trailingStop'] = restore_trail
                        restored_count += 1
                        logger.info(f"âœ… SHOCK_RESTORE: {pos.get('symbol')} SLâ†’{restore_sl:.4f} trailâ†’{restore_trail:.4f} (smart restore)")
                        break
            except:
                pass
        
        # Log event
        if self.current_shock_event:
            self.current_shock_event['duration_seconds'] = round(duration)
            self.current_shock_event['deactivation_reason'] = reason
            self.current_shock_event['restored_count'] = restored_count
            self.shock_history.append(self.current_shock_event)
            # Keep last 50 events
            self.shock_history = self.shock_history[-50:]
        
        old_mode = self.shock_mode
        self.shock_mode = 'NORMAL'
        self.shock_start_time = None
        self.shock_trigger_price = 0.0
        self.sl_snapshots.clear()
        self.current_shock_event = None
        
        # Set cooldown (Guardrail: hysteresis)
        self.shock_cooldown_until = now + self.cooldown_duration
        
        logger.warning(f"âš¡ SHOCK_DEACTIVATED: {old_mode} â†’ NORMAL | reason={reason} | duration={duration/60:.1f}min | restored={restored_count} positions | cooldown={self.cooldown_duration/60:.0f}min")
    
    def get_shock_status(self) -> dict:
        """Get current shock status for API/dashboard."""
        now = datetime.now().timestamp()
        return {
            'mode': self.shock_mode,
            'active': self.shock_mode != 'NORMAL',
            'start_time': self.shock_start_time,
            'elapsed_seconds': round(now - self.shock_start_time) if self.shock_start_time else 0,
            'trigger_price': self.shock_trigger_price,
            'cooldown_remaining': max(0, round(self.shock_cooldown_until - now)),
            'sl_snapshots_count': len(self.sl_snapshots),
            'history_count': len(self.shock_history),
            'last_event': self.shock_history[-1] if self.shock_history else None,
        }

# Global instance
price_shock_manager = PriceShockManager()

# ============================================================================
# PHASE 155: AI OPTIMIZER - PnL-CORRELATED PERFORMANCE ANALYZER
# ============================================================================

class PerformanceAnalyzer:
    """
    Phase 155: PnL-korelasyon bazlÄ± analiz.
    Her parametre iÃ§in kÃ¢rlÄ± vs zararlÄ± trade'lerin ortalama deÄŸerlerini karÅŸÄ±laÅŸtÄ±rÄ±r.
    Target = kÃ¢rlÄ± trade'lerin PnL-aÄŸÄ±rlÄ±klÄ± ortalamasÄ±.
    """
    
    # AI Optimizer'Ä±n kontrol ettiÄŸi parametreler
    OPTIMIZABLE_PARAMS = ['entry_tightness', 'z_score_threshold', 'min_score_low', 'min_score_high', 'max_positions']
    
    def __init__(self):
        self.last_analysis = None
        self.last_correlations = None
        self.analysis_interval_minutes = 60
        logger.info("ðŸ“ˆ PerformanceAnalyzer initialized (Phase 155: PnL-Correlation)")
    
    def analyze(self, trades: list, post_trade_stats: dict = None) -> dict:
        """Son trade'leri analiz et â€” genel istatistikler + parametre korelasyonu."""
        if not trades:
            return {}
        
        recent_trades = trades[-100:]
        
        # === GENEL Ä°STATÄ°STÄ°KLER ===
        winners = [t for t in recent_trades if t.get('pnl', 0) > 0]
        losers = [t for t in recent_trades if t.get('pnl', 0) < 0]
        
        win_rate = len(winners) / len(recent_trades) * 100 if recent_trades else 0
        avg_winner = sum(t.get('pnl', 0) for t in winners) / len(winners) if winners else 0
        avg_loser = sum(t.get('pnl', 0) for t in losers) / len(losers) if losers else 0
        profit_factor = abs(avg_winner * len(winners)) / abs(avg_loser * len(losers)) if losers and avg_loser != 0 else 999
        total_pnl = sum(t.get('pnl', 0) for t in recent_trades)
        
        # Coin bazlÄ± performans
        coin_performance = {}
        for t in recent_trades:
            symbol = t.get('symbol', '').replace('USDT', '')
            if symbol not in coin_performance:
                coin_performance[symbol] = {'wins': 0, 'losses': 0, 'pnl': 0}
            if t.get('pnl', 0) > 0:
                coin_performance[symbol]['wins'] += 1
            else:
                coin_performance[symbol]['losses'] += 1
            coin_performance[symbol]['pnl'] += t.get('pnl', 0)
        
        sorted_coins = sorted(coin_performance.items(), key=lambda x: x[1]['pnl'], reverse=True)
        top_coins = [c[0] for c in sorted_coins[:5] if c[1]['pnl'] > 0]
        worst_coins = [c[0] for c in sorted_coins[-5:] if c[1]['pnl'] < 0]
        
        # Reason bazlÄ± analiz
        reason_performance = {}
        for t in recent_trades:
            reason = t.get('reason', t.get('closeReason', 'UNKNOWN'))
            if reason not in reason_performance:
                reason_performance[reason] = {'count': 0, 'pnl': 0, 'wins': 0}
            reason_performance[reason]['count'] += 1
            reason_performance[reason]['pnl'] += t.get('pnl', 0)
            if t.get('pnl', 0) > 0:
                reason_performance[reason]['wins'] += 1
        
        kill_switch_trades = [t for t in recent_trades if 'KILL_SWITCH' in str(t.get('reason', '')) or 'KILL_SWITCH' in str(t.get('closeReason', ''))]
        kill_switch_rate = len(kill_switch_trades) / len(recent_trades) * 100 if recent_trades else 0
        
        # === PHASE 155: PARAMETRE KORELASYON ANALÄ°ZÄ° ===
        correlations = self._analyze_settings_correlation(recent_trades)
        self.last_correlations = correlations
        
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_time = datetime.now(turkey_tz)
        
        analysis = {
            'timestamp': turkey_time.strftime('%d.%m.%Y %H:%M:%S'),
            'trade_count': len(recent_trades),
            'total_pnl': round(total_pnl, 2),
            'win_rate': round(win_rate, 1),
            'avg_winner': round(avg_winner, 2),
            'avg_loser': round(avg_loser, 2),
            'profit_factor': round(min(profit_factor, 99), 2),
            'top_coins': top_coins,
            'worst_coins': worst_coins,
            'reason_performance': reason_performance,
            'early_exit_rate': post_trade_stats.get('early_exit_rate', 0) if post_trade_stats else 0,
            'kill_switch_rate': round(kill_switch_rate, 1),
            # Phase 155: Korelasyon verileri
            'correlations': correlations,
            'trades_with_snapshot': len([t for t in recent_trades if t.get('settingsSnapshot')]),
        }
        
        self.last_analysis = analysis
        
        corr_summary = ""
        if correlations:
            corr_parts = [f"{p}: {d.get('direction', '?')}" for p, d in correlations.items()]
            corr_summary = f" | Corr: {', '.join(corr_parts[:3])}"
        
        logger.info(f"ðŸ“ˆ ANALYSIS: PnL ${total_pnl:.0f} | WR {win_rate:.1f}% | PF {profit_factor:.2f} | Snapshots: {analysis['trades_with_snapshot']}{corr_summary}")
        
        return analysis
    
    def _analyze_settings_correlation(self, trades: list) -> dict:
        """
        Phase 155: Her parametre iÃ§in kÃ¢rlÄ± trade'lerdeki ortalama vs zararlÄ± trade'lerdeki ortalama.
        PnL-aÄŸÄ±rlÄ±klÄ± ortalama kullanÄ±r â€” bÃ¼yÃ¼k kÃ¢rlar daha fazla etki eder.
        """
        # Sadece settings snapshot'Ä± olan trade'leri kullan
        trades_with_snapshot = [t for t in trades if t.get('settingsSnapshot') and isinstance(t.get('settingsSnapshot'), dict) and len(t.get('settingsSnapshot', {})) > 0]
        
        if len(trades_with_snapshot) < 10:
            logger.debug(f"ðŸ“ˆ Correlation: Not enough trades with snapshot ({len(trades_with_snapshot)}/10 min)")
            return {}
        
        winners = [t for t in trades_with_snapshot if t.get('pnl', 0) > 0]
        losers = [t for t in trades_with_snapshot if t.get('pnl', 0) < 0]
        
        if len(winners) < 3 or len(losers) < 3:
            logger.debug(f"ðŸ“ˆ Correlation: Not enough winners({len(winners)}) or losers({len(losers)})")
            return {}
        
        correlations = {}
        
        for param in self.OPTIMIZABLE_PARAMS:
            # Winner deÄŸerleri (PnL-aÄŸÄ±rlÄ±klÄ± ortalama)
            winner_data = [(t['settingsSnapshot'].get(param), t.get('pnl', 0)) 
                          for t in winners if t['settingsSnapshot'].get(param) is not None]
            # Loser deÄŸerleri (basit ortalama â€” zarar miktarÄ± eÅŸit aÄŸÄ±rlÄ±klÄ±)
            loser_data = [(t['settingsSnapshot'].get(param), t.get('pnl', 0)) 
                         for t in losers if t['settingsSnapshot'].get(param) is not None]
            
            if len(winner_data) < 3 or len(loser_data) < 3:
                continue
            
            # PnL-aÄŸÄ±rlÄ±klÄ± winner ortalamasÄ± (bÃ¼yÃ¼k kÃ¢rlar daha fazla Ã§eker)
            total_winner_pnl = sum(pnl for _, pnl in winner_data)
            if total_winner_pnl > 0:
                winner_avg = sum(val * pnl for val, pnl in winner_data) / total_winner_pnl
            else:
                winner_avg = sum(val for val, _ in winner_data) / len(winner_data)
            
            # Basit loser ortalamasÄ±
            loser_avg = sum(val for val, _ in loser_data) / len(loser_data)
            
            # TÃ¼m trade'lerin ortalamasÄ± (referans)
            all_avg = sum(val for val, _ in winner_data + loser_data) / len(winner_data + loser_data)
            
            # Target: kÃ¢rlÄ± trade'lerin ortalamasÄ±na doÄŸru git
            target = winner_avg
            direction = 'UP' if winner_avg > loser_avg else 'DOWN'
            
            correlations[param] = {
                'winner_avg': round(winner_avg, 3),
                'loser_avg': round(loser_avg, 3),
                'all_avg': round(all_avg, 3),
                'target': round(target, 3),
                'direction': direction,
                'winner_count': len(winner_data),
                'loser_count': len(loser_data),
                'confidence': min(len(winner_data), len(loser_data)),  # How many data points
            }
        
        if correlations:
            logger.info(f"ðŸ“ˆ CORRELATIONS: {len(correlations)} params analyzed from {len(trades_with_snapshot)} trades")
        
        return correlations


# ============================================================================
# PHASE 155: AI OPTIMIZER - GRADIENT-BASED PARAMETER OPTIMIZER
# ============================================================================

class ParameterOptimizer:
    """
    Phase 155: Korelasyon bazlÄ± gradient optimizer.
    
    MantÄ±k:
    1. PerformanceAnalyzer her parametre iÃ§in kÃ¢rlÄ±/zararlÄ± trade ortalamalarÄ±nÄ± hesaplar
    2. Target = kÃ¢rlÄ± trade'lerin PnL-aÄŸÄ±rlÄ±klÄ± ortalamasÄ±
    3. Her dÃ¶ngÃ¼de mevcut deÄŸeri target'a doÄŸru kÃ¼Ã§Ã¼k adÄ±mlarla kaydÄ±r
    4. GÃ¼venlik limitleri ve max step ile kontrol et
    
    Sadece settings modal'dan aktif edildiÄŸinde Ã§alÄ±ÅŸÄ±r (self.enabled = False default).
    """
    
    def __init__(self):
        self.last_optimization = None
        self.optimization_history = []
        self.enabled = False  # VarsayÄ±lan KAPALI â€” sadece settings modal'dan aÃ§Ä±lÄ±r
        
        # GÃ¼venlik sÄ±nÄ±rlarÄ± â€” sadece gerÃ§ekten optimize edilen parametreler
        self.limits = {
            'entry_tightness': (0.5, 4.0),
            'z_score_threshold': (0.8, 2.5),
            'min_score_low': (30, 60),
            'min_score_high': (60, 95),
            'max_positions': (2, 15),
        }
        
        # Max step â€” bir dÃ¶ngÃ¼de maksimum deÄŸiÅŸim (ani sÄ±Ã§rama Ã¶nleme)
        self.max_steps = {
            'entry_tightness': 0.2,
            'z_score_threshold': 0.1,
            'min_score_low': 3,
            'min_score_high': 3,
            'max_positions': 1,
        }
        
        # Step ratio â€” target'a her dÃ¶ngÃ¼de mesafenin kaÃ§ta kaÃ§Ä± kadar yaklaÅŸ
        self.step_ratio = 0.20  # %20 â€” yavaÅŸ ve gÃ¼venli
        
        logger.info("ðŸ¤– ParameterOptimizer initialized (Phase 155: Gradient-based, disabled by default)")
    
    def optimize(self, analysis: dict, current_settings: dict) -> dict:
        """
        Korelasyon verilerine gÃ¶re parametreleri target'a doÄŸru kaydÄ±r.
        
        Args:
            analysis: PerformanceAnalyzer'dan gelen analiz (correlations dahil)
            current_settings: Mevcut paper_trader ayarlarÄ±
        
        Returns:
            dict: timestamp, recommendations, changes, applied bilgileri
        """
        if not analysis:
            return {}
        
        recommendations = {}
        changes = []
        
        correlations = analysis.get('correlations', {})
        total_pnl = analysis.get('total_pnl', 0)
        trades_with_snapshot = analysis.get('trades_with_snapshot', 0)
        
        # Yeterli veri yoksa sadece log yaz, Ã¶neri Ã¼retme
        if not correlations:
            logger.info(f"ðŸ¤– OPTIMIZER: No correlations yet (snapshots: {trades_with_snapshot}) â€” collecting data")
        else:
            # === GRADIENT-BAZLI OPTÄ°MÄ°ZASYON ===
            for param, corr_data in correlations.items():
                current_val = current_settings.get(param)
                target_val = corr_data.get('target')
                confidence = corr_data.get('confidence', 0)
                
                if current_val is None or target_val is None:
                    continue
                
                # Minimum confidence: en az 5 veri noktasÄ±
                if confidence < 5:
                    continue
                
                # Mesafe hesapla
                distance = target_val - current_val
                
                # KÃ¼Ã§Ã¼k adÄ±mla yaklaÅŸ (mesafenin %20'si, max step ile sÄ±nÄ±rlÄ±)
                max_step = self.max_steps.get(param, 0.2)
                step = distance * self.step_ratio
                step = max(-max_step, min(max_step, step))
                
                new_val = current_val + step
                
                # GÃ¼venlik limitleri uygula
                limits = self.limits.get(param)
                if limits:
                    new_val = max(limits[0], min(limits[1], new_val))
                
                # Integer parametreler (max_positions, min_score)
                if param in ('max_positions', 'min_score_low', 'min_score_high'):
                    new_val = int(round(new_val))
                else:
                    new_val = round(new_val, 2)
                
                # DeÄŸiÅŸim anlamlÄ± mÄ±? (minimum threshold)
                min_change = {
                    'entry_tightness': 0.05,
                    'z_score_threshold': 0.05,
                    'min_score_low': 1,
                    'min_score_high': 1,
                    'max_positions': 1,
                }.get(param, 0.01)
                
                if abs(new_val - current_val) >= min_change:
                    recommendations[param] = new_val
                    direction = corr_data.get('direction', '?')
                    changes.append(f"{param}: {current_val}â†’{new_val} (win_avg={corr_data.get('winner_avg', '?')}, {direction})")
        
        # === SONUÃ‡ ===
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_time = datetime.now(turkey_tz)
        
        result = {
            'timestamp': turkey_time.strftime('%d.%m.%Y %H:%M:%S'),
            'total_pnl': total_pnl,
            'recommendations': recommendations,
            'changes': changes,
            'applied': False,
            'correlations_count': len(correlations),
            'trades_with_snapshot': trades_with_snapshot,
        }
        
        self.last_optimization = result
        self.optimization_history.append(result)
        if len(self.optimization_history) > 50:
            self.optimization_history = self.optimization_history[-50:]
        
        if changes:
            logger.info(f"ðŸ¤– OPTIMIZER: {len(changes)} gradient changes â€” {', '.join(changes[:3])}")
        
        return result
    
    def apply_recommendations(self, paper_trader, recommendations: dict) -> dict:
        """
        Optimizasyon Ã¶nerilerini uygula (sadece enabled ise).
        
        Returns:
            dict: Uygulanan ayarlar {param_name: new_value} veya boÅŸ dict
        """
        if not self.enabled:
            logger.info("ðŸ¤– OPTIMIZER: Disabled â€” skipping apply")
            return {}
        
        if not recommendations:
            return {}
        
        applied = {}
        
        # Phase 155: Sadece optimize edilen parametreler
        param_map = {
            'entry_tightness': 'entry_tightness',
            'z_score_threshold': 'z_score_threshold',
            'min_score_low': 'min_score_low',
            'min_score_high': 'min_score_high',
            'max_positions': 'max_positions',
        }
        
        for param, attr_name in param_map.items():
            if param in recommendations:
                old_val = getattr(paper_trader, attr_name, None)
                new_val = recommendations[param]
                setattr(paper_trader, attr_name, new_val)
                applied[param] = {'old': old_val, 'new': new_val}
        
        if applied:
            applied_summary = ", ".join(f"{p}: {d['old']}â†’{d['new']}" for p, d in applied.items())
            logger.info(f"ðŸ¤– OPTIMIZER APPLIED: {applied_summary}")
            paper_trader.add_log(f"ðŸ¤– AI gÃ¼ncelledi: {applied_summary}")
            paper_trader.save_state()
            
            # Mark as applied
            if self.last_optimization:
                self.last_optimization['applied'] = True
                from zoneinfo import ZoneInfo
                turkey_tz = ZoneInfo('Europe/Istanbul')
                self.last_optimization['applied_at'] = datetime.now(turkey_tz).strftime('%d.%m.%Y %H:%M:%S')
                self.last_optimization['applied_settings'] = list(applied.keys())
        
        return applied
    
    def get_status(self) -> dict:
        return {
            'enabled': self.enabled,
            'last_optimization': self.last_optimization,
            'history_count': len(self.optimization_history),
            'correlations': performance_analyzer.last_correlations if performance_analyzer else None,
        }


# Global Adaptive Trading instances
post_trade_tracker = PostTradeTracker()
performance_analyzer = PerformanceAnalyzer()
parameter_optimizer = ParameterOptimizer()


# ============================================================================
# PHASE 53: MARKET REGIME DETECTOR
# ============================================================================

class MarketRegimeDetector:
    """
    Piyasa durumunu algÄ±lar ve AI optimizasyonuna veri saÄŸlar.
    BTC price action, volatilite ve trend analizi yapar.
    
    Phase 60: TRENDING_DOWN/TRENDING_UP ayrÄ±mÄ± eklendi.
    DÃ¼ÅŸÃ¼ÅŸ trendinde LONG sinyallere aÄŸÄ±r penalize uygulanÄ±r.
    """
    
    TRENDING_UP = "TRENDING_UP"      # GÃ¼Ã§lÃ¼ yÃ¼kselis trendi, LONG'lara bonus
    TRENDING_DOWN = "TRENDING_DOWN"  # GÃ¼Ã§lÃ¼ dÃ¼ÅŸÃ¼ÅŸ trendi, LONG'lara veto
    TRENDING = "TRENDING"            # Eski uyumluluk iÃ§in (yÃ¶n belirsiz)
    RANGING = "RANGING"              # Yatay piyasa, SL sÄ±kÄ±laÅŸtÄ±r, TP yakÄ±nlaÅŸtÄ±r
    VOLATILE = "VOLATILE"            # YÃ¼ksek volatilite, yÃ¼ksek min score, seÃ§ici ol
    QUIET = "QUIET"                  # DÃ¼ÅŸÃ¼k volatilite, dÃ¼ÅŸÃ¼k min score, agresif ol
    
    def __init__(self):
        self.current_regime = self.RANGING
        self.trend_direction = "NEUTRAL"  # UP, DOWN, NEUTRAL
        self.btc_prices = []  # Son 24 saatlik BTC fiyatlarÄ±
        self.last_update = None
        self.regime_history = []
        self.max_history = 100
        logger.info("ðŸ“Š MarketRegimeDetector initialized with Direction Awareness")
    
    def update_btc_price(self, price: float):
        """BTC fiyatÄ±nÄ± kaydet."""
        self.btc_prices.append({
            'price': price,
            'time': datetime.now()
        })
        # Son 24 saat tut (1440 dakika, her 5dk'da 1 kayÄ±t = 288 kayÄ±t)
        if len(self.btc_prices) > 300:
            self.btc_prices = self.btc_prices[-300:]
    
    def detect_regime(self) -> str:
        """Piyasa durumunu algÄ±la."""
        if len(self.btc_prices) < 10:
            return self.RANGING  # Yeterli veri yok
        
        prices = [p['price'] for p in self.btc_prices[-50:]]  # Son ~4 saat
        
        if len(prices) < 10:
            return self.RANGING
        
        # Volatilite hesapla (standart sapma / ortalama)
        avg_price = sum(prices) / len(prices)
        variance = sum((p - avg_price) ** 2 for p in prices) / len(prices)
        std_dev = variance ** 0.5
        volatility = (std_dev / avg_price) * 100  # YÃ¼zde olarak
        
        # Trend hesapla (ilk vs son fiyat)
        first_half = sum(prices[:len(prices)//2]) / (len(prices)//2)
        second_half = sum(prices[len(prices)//2:]) / (len(prices) - len(prices)//2)
        trend_strength = abs((second_half - first_half) / first_half) * 100  # YÃ¼zde
        
        # Phase 60: Trend yÃ¶nÃ¼nÃ¼ belirle
        trend_direction_raw = (second_half - first_half) / first_half * 100
        if trend_direction_raw > 1.0:
            self.trend_direction = "UP"
        elif trend_direction_raw < -1.0:
            self.trend_direction = "DOWN"
        else:
            self.trend_direction = "NEUTRAL"
        
        # Price range hesapla
        price_range = (max(prices) - min(prices)) / avg_price * 100  # YÃ¼zde
        
        # Regime belirleme (Phase 60: YÃ¶n farkÄ±ndalÄ±ÄŸÄ± eklendi)
        if volatility > 2.0 or price_range > 5.0:
            regime = self.VOLATILE
        elif trend_strength > 1.5 and price_range > 2.0:
            # Phase 60: Trend yÃ¶nÃ¼ne gÃ¶re TRENDING_UP veya TRENDING_DOWN
            if self.trend_direction == "DOWN":
                regime = self.TRENDING_DOWN
            elif self.trend_direction == "UP":
                regime = self.TRENDING_UP
            else:
                regime = self.TRENDING  # Eski uyumluluk
        elif volatility < 0.5 and price_range < 1.0:
            regime = self.QUIET
        else:
            regime = self.RANGING
        
        # DeÄŸiÅŸiklik varsa logla
        if regime != self.current_regime:
            logger.info(f"ðŸ“Š MARKET REGIME CHANGE: {self.current_regime} â†’ {regime} (vol:{volatility:.2f}%, trend:{trend_strength:.2f}%, dir:{self.trend_direction}, range:{price_range:.2f}%)")
            self.regime_history.append({
                'from': self.current_regime,
                'to': regime,
                'time': datetime.now().isoformat(),
                'volatility': volatility,
                'trend_strength': trend_strength,
                'trend_direction': self.trend_direction
            })
            if len(self.regime_history) > self.max_history:
                self.regime_history = self.regime_history[-self.max_history:]
        
        self.current_regime = regime
        self.last_update = datetime.now()
        
        return regime
    
    def get_regime_params(self) -> dict:
        """
        Mevcut regime iÃ§in Ã¶nerilen parametreleri dÃ¶ndÃ¼r.
        Bu deÄŸerler ParameterOptimizer tarafÄ±ndan kullanÄ±lÄ±r.
        """
        params = {
            # Phase 60: TRENDING_UP - YÃ¼kseliÅŸ trendinde LONG'lara bonus
            self.TRENDING_UP: {
                'min_score_adjustment': -5,    # Daha agresif LONG
                'trail_distance_mult': 1.3,    # Trail'i gevÅŸet, trend devam etsin
                'sl_atr_mult': 1.2,            # SL biraz gevÅŸet
                'tp_atr_mult': 1.5,            # TP'yi uzat
                'long_bonus': 0.15,            # LONG sinyallere bonus
                'short_penalty': 0.2,          # SHORT sinyallere penalty
                'description': 'ðŸ“ˆ YÃ¼kseliÅŸ trendi - LONG bonus, SHORT riskli'
            },
            # Phase 60: TRENDING_DOWN - DÃ¼ÅŸÃ¼ÅŸ trendinde LONG'lara veto
            self.TRENDING_DOWN: {
                'min_score_adjustment': +15,   # Ã‡ok seÃ§ici (LONG iÃ§in)
                'trail_distance_mult': 0.7,    # Trail'i sÄ±kÄ±laÅŸtÄ±r, hÄ±zlÄ± Ã§Ä±k
                'sl_atr_mult': 0.8,            # SL sÄ±kÄ± tut
                'tp_atr_mult': 0.7,            # TP yakÄ±n, hÄ±zlÄ± kÃ¢r al
                'long_penalty': 0.5,           # LONG sinyallere aÄŸÄ±r penalty
                'short_bonus': 0.2,            # SHORT sinyallere bonus
                'description': 'ðŸ“‰ DÃ¼ÅŸÃ¼ÅŸ trendi - LONG riskli, SHORT bonus'
            },
            self.TRENDING: {
                'min_score_adjustment': -5,    # Daha agresif
                'trail_distance_mult': 1.3,    # Trail'i gevÅŸet, trend devam etsin
                'sl_atr_mult': 1.2,            # SL biraz gevÅŸet
                'tp_atr_mult': 1.5,            # TP'yi uzat
                'description': 'Trend takibi modu - TP uzun, trail gevÅŸek'
            },
            self.RANGING: {
                'min_score_adjustment': 0,     # Normal
                'trail_distance_mult': 1.0,
                'sl_atr_mult': 1.0,
                'tp_atr_mult': 1.0,
                'description': 'Yatay piyasa - standart ayarlar'
            },
            self.VOLATILE: {
                'min_score_adjustment': +10,   # Ã‡ok seÃ§ici
                'trail_distance_mult': 0.8,    # Trail'i sÄ±kÄ±laÅŸtÄ±r
                'sl_atr_mult': 1.3,            # SL gevÅŸet (whipsaw korumasÄ±)
                'tp_atr_mult': 0.8,            # TP yakÄ±nlaÅŸtÄ±r
                'description': 'Volatil piyasa - yÃ¼ksek seÃ§icilik, hÄ±zlÄ± Ã§Ä±kÄ±ÅŸ'
            },
            self.QUIET: {
                'min_score_adjustment': -10,   # Agresif
                'trail_distance_mult': 0.9,    # Trail orta
                'sl_atr_mult': 0.9,            # SL sÄ±kÄ±
                'tp_atr_mult': 0.9,            # TP yakÄ±n
                'description': 'Sakin piyasa - agresif giriÅŸ, sÄ±kÄ± Ã§Ä±kÄ±ÅŸ'
            }
        }
        return params.get(self.current_regime, params[self.RANGING])
    
    def get_status(self) -> dict:
        """API iÃ§in durum Ã¶zeti."""
        return {
            'currentRegime': self.current_regime,
            'trendDirection': self.trend_direction,
            'lastUpdate': self.last_update.isoformat() if self.last_update else None,
            'priceCount': len(self.btc_prices),
            'params': self.get_regime_params(),
            'recentChanges': self.regime_history[-5:] if self.regime_history else []
        }


# Global Market Regime instance
market_regime_detector = MarketRegimeDetector()


# ============================================================================
# PHASE 54: SCORE COMPONENT ANALYZER
# ============================================================================

class ScoreComponentAnalyzer:
    """
    Hangi skor bileÅŸeninin en Ã§ok kÃ¢r getirdiÄŸini analiz eder.
    Korelasyon analizi yaparak aÄŸÄ±rlÄ±k Ã¶nerileri Ã¼retir.
    """
    
    def __init__(self):
        self.trade_components = []  # Trade'lerin skor bileÅŸenleri
        self.max_records = 500
        self.last_analysis = None
        self.weight_recommendations = {}
        logger.info("ðŸ“Š ScoreComponentAnalyzer initialized")
    
    def record_trade(self, trade: dict, components: dict):
        """
        Trade kapandÄ±ÄŸÄ±nda skor bileÅŸenlerini kaydet.
        components: {zscore, hurst, volume_spike, imbalance, mtf_score, spread_level}
        """
        record = {
            'trade_id': trade.get('id', ''),
            'pnl': trade.get('pnl', 0),
            'is_win': trade.get('pnl', 0) > 0,
            'pnl_percent': trade.get('pnlPercent', 0),
            'components': {
                'zscore': abs(components.get('zScore', 0)),
                'hurst': components.get('hurst', 0.5),
                'volume_spike': 1 if components.get('volumeSpike', False) else 0,
                'imbalance': abs(components.get('imbalance', 0)),
                'mtf_score': components.get('mtfScore', 0),
                'spread_level': self._spread_to_numeric(components.get('spreadLevel', 'medium')),
                'signal_score': components.get('signalScore', 0),
            },
            'timestamp': datetime.now().isoformat()
        }
        
        self.trade_components.append(record)
        
        if len(self.trade_components) > self.max_records:
            self.trade_components = self.trade_components[-self.max_records:]
        
        logger.debug(f"ðŸ“Š SCORE RECORD: {trade.get('symbol')} PnL:{trade.get('pnl', 0):.2f} ZS:{components.get('zScore', 0):.2f}")
    
    def _spread_to_numeric(self, spread_level: str) -> float:
        """Spread seviyesini sayÄ±ya Ã§evir. Phase 223d: Title Case uyumlu."""
        mapping = {
            'Very Low': 0.9,
            'Low': 0.7,
            'Normal': 0.5,
            'High': 0.3,
            'Very High': 0.1,
            'Extreme': 0.05,
            'Ultra': 0.02
        }
        return mapping.get(spread_level, 0.5)
    
    def analyze(self) -> dict:
        """Korelasyon analizi yap ve aÄŸÄ±rlÄ±k Ã¶nerileri Ã¼ret."""
        if len(self.trade_components) < 20:
            return {'error': 'Yeterli veri yok (min 20 trade)'}
        
        recent = self.trade_components[-100:]  # Son 100 trade
        
        # Her bileÅŸen iÃ§in kazanan/kaybeden ortalamalarÄ±nÄ± hesapla
        component_stats = {}
        component_names = ['zscore', 'hurst', 'volume_spike', 'imbalance', 'mtf_score', 'spread_level', 'signal_score']
        
        for comp in component_names:
            winners = [r['components'][comp] for r in recent if r['is_win']]
            losers = [r['components'][comp] for r in recent if not r['is_win']]
            
            avg_winner = sum(winners) / len(winners) if winners else 0
            avg_loser = sum(losers) / len(losers) if losers else 0
            
            # Kazanan/kaybeden farkÄ± (pozitif = kazananlarda daha yÃ¼ksek)
            diff = avg_winner - avg_loser
            
            # Korelasyon hesapla (basit yaklaÅŸÄ±m)
            all_values = [r['components'][comp] for r in recent]
            all_pnls = [r['pnl'] for r in recent]
            
            correlation = self._calculate_correlation(all_values, all_pnls)
            
            component_stats[comp] = {
                'avg_winner': round(avg_winner, 3),
                'avg_loser': round(avg_loser, 3),
                'diff': round(diff, 3),
                'correlation': round(correlation, 3),
                'importance': abs(correlation)  # Mutlak korelasyon
            }
        
        # Importance'a gÃ¶re sÄ±rala
        sorted_components = sorted(component_stats.items(), key=lambda x: x[1]['importance'], reverse=True)
        
        # AÄŸÄ±rlÄ±k Ã¶nerileri Ã¼ret
        recommendations = {}
        for comp, stats in sorted_components[:3]:  # Top 3 Ã¶nemli
            if stats['correlation'] > 0.15:
                recommendations[comp] = 'INCREASE'
            elif stats['correlation'] < -0.15:
                recommendations[comp] = 'DECREASE'
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'trade_count': len(recent),
            'component_stats': component_stats,
            'ranked_components': [{'name': k, **v} for k, v in sorted_components],
            'weight_recommendations': recommendations,
            'top_component': sorted_components[0][0] if sorted_components else None,
            'worst_component': sorted_components[-1][0] if sorted_components else None,
        }
        
        self.last_analysis = result
        self.weight_recommendations = recommendations
        
        top_comp = sorted_components[0] if sorted_components else ('N/A', {})
        logger.info(f"ðŸ“Š SCORE ANALYSIS: Top={top_comp[0]} (corr:{top_comp[1].get('correlation', 0):.2f}) | {len(recommendations)} Ã¶neri")
        
        return result
    
    def _calculate_correlation(self, x: list, y: list) -> float:
        """Basit Pearson korelasyonu hesapla."""
        if len(x) < 2 or len(x) != len(y):
            return 0.0
        
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(xi ** 2 for xi in x)
        sum_y2 = sum(yi ** 2 for yi in y)
        
        numerator = n * sum_xy - sum_x * sum_y
        denominator = ((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2)) ** 0.5
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def get_status(self) -> dict:
        """API iÃ§in durum Ã¶zeti."""
        return {
            'recordCount': len(self.trade_components),
            'lastAnalysis': self.last_analysis,
            'recommendations': self.weight_recommendations
        }


# Global Score Component Analyzer instance
score_component_analyzer = ScoreComponentAnalyzer()


# ============================================================================
# PHASE 48: KILL SWITCH FAULT TRACKER (Enhanced)
# ============================================================================



class KillSwitchFaultTracker:
    """
    Tracks coins that have triggered kill switch and applies penalty to future signals.
    
    Phase 60 - REDUCED DURATIONS:
    - Each kill switch adds -15 points to the coin's fault score (was -25)
    - Fault score decays by 10 points per 24 hours (was 5)
    - Coins with kill switch in last 2h are BLOCKED from new positions (was 4h)
    - Full recovery in ~1.5 days instead of 5 days
    """
    
    def __init__(self, penalty_per_fault: int = -5, decay_per_day: int = 10):
        self.faults: Dict[str, list] = {}  # symbol -> list of fault timestamps
        self.penalty_per_fault = penalty_per_fault  # -5 points per kill switch (Phase 121: was -15)
        self.decay_per_day = decay_per_day  # 10 points decay per 24h
        self.max_penalty = -30  # Maximum penalty cap (Phase 121: was -50)
        self.block_hours = 4  # Block new positions for 4 hours after KS (Phase 121)
        logger.info(f"ðŸ“‹ KillSwitchFaultTracker: {penalty_per_fault} pts/fault, {decay_per_day} decay/day, {self.block_hours}h block")
    
    def load_from_trade_history(self, trades: list):
        """Load fault history from existing trades on startup."""
        ks_count = 0
        for trade in trades:
            reason = trade.get('reason', '')
            if 'KILL_SWITCH' in reason:
                symbol = trade.get('symbol', '')
                close_time = trade.get('closeTime', 0)
                if symbol and close_time:
                    if symbol not in self.faults:
                        self.faults[symbol] = []
                    self.faults[symbol].append({
                        'timestamp': close_time / 1000,  # Convert from ms to seconds
                        'reason': reason
                    })
                    ks_count += 1
        
        # Clean up old faults
        self._cleanup_old_faults()
        
        active_faults = sum(len(f) for f in self.faults.values())
        logger.info(f"ðŸ“‹ Loaded {ks_count} kill switch faults from trade history, {active_faults} still active")
    
    def _cleanup_old_faults(self):
        """Remove faults older than 7 days."""
        cutoff = datetime.now().timestamp() - (7 * 24 * 60 * 60)
        for symbol in list(self.faults.keys()):
            self.faults[symbol] = [f for f in self.faults[symbol] if f['timestamp'] > cutoff]
            if not self.faults[symbol]:
                del self.faults[symbol]
    
    def record_fault(self, symbol: str, reason: str = "KILL_SWITCH"):
        """Record a kill switch fault for a symbol."""
        if symbol not in self.faults:
            self.faults[symbol] = []
        
        self.faults[symbol].append({
            'timestamp': datetime.now().timestamp(),
            'reason': reason
        })
        
        self._cleanup_old_faults()
        
        penalty = self.get_penalty(symbol)
        is_blocked = self.is_blocked(symbol)
        block_status = f"ðŸš« BLOCKED {self.block_hours}h" if is_blocked else ""
        logger.warning(f"ðŸ“‹ FAULT RECORDED: {symbol} ({reason}) - Penalty: {penalty}p {block_status}")
    
    def is_blocked(self, symbol: str) -> bool:
        """Check if a coin is blocked from new positions (KS within last 24h)."""
        if symbol not in self.faults or not self.faults[symbol]:
            return False
        
        now = datetime.now().timestamp()
        block_cutoff = now - (self.block_hours * 60 * 60)
        
        for fault in self.faults[symbol]:
            if fault['timestamp'] > block_cutoff:
                return True
        
        return False
    
    def get_penalty(self, symbol: str) -> int:
        """
        Calculate penalty for a symbol based on fault history.
        Newer faults have full penalty, older faults decay.
        """
        if symbol not in self.faults or not self.faults[symbol]:
            return 0
        
        now = datetime.now().timestamp()
        total_penalty = 0
        
        for fault in self.faults[symbol]:
            age_hours = (now - fault['timestamp']) / 3600
            age_days = age_hours / 24
            
            # Calculate decayed penalty
            decayed_penalty = self.penalty_per_fault + (self.decay_per_day * age_days)
            if decayed_penalty < 0:  # Only apply if still negative
                total_penalty += int(decayed_penalty)
        
        # Cap at max penalty
        return max(total_penalty, self.max_penalty)
    
    def get_all_faults(self) -> Dict[str, dict]:
        """Get summary of all faults for UI display."""
        result = {}
        for symbol, faults in self.faults.items():
            if faults:
                penalty = self.get_penalty(symbol)
                is_blocked = self.is_blocked(symbol)
                if penalty < 0 or is_blocked:
                    result[symbol] = {
                        'fault_count': len(faults),
                        'penalty': penalty,
                        'is_blocked': is_blocked,
                        'last_fault': max(f['timestamp'] for f in faults)
                    }
        return result


# Global KillSwitchFaultTracker instance
kill_switch_fault_tracker = KillSwitchFaultTracker()


# ============================================================================
# PHASE 59: COIN PERFORMANCE TRACKER (Coin-Based Learning)
# ============================================================================

class CoinPerformanceTracker:
    """
    Coin bazlÄ± performans takibi ve Ã¶ÄŸrenme sistemi.
    Her coin iÃ§in win rate, ortalama PnL ve kill switch sayÄ±sÄ±nÄ± takip eder.
    AI optimizer'a veri saÄŸlar ve dÃ¼ÅŸÃ¼k performanslÄ± coinleri otomatik bloklar.
    """
    
    def __init__(self, min_trades_for_stats: int = 5, block_threshold_wr: float = 20.0):
        self.coin_stats: Dict[str, dict] = {}  # {symbol: stats}
        self.min_trades_for_stats = min_trades_for_stats
        self.block_threshold_wr = block_threshold_wr  # Block if WR < 20%
        self.max_history_per_coin = 50  # Son 50 trade tut
        logger.info("ðŸ“Š CoinPerformanceTracker initialized (Phase 59)")
    
    def load_from_trade_history(self, trades: list):
        """Mevcut trade history'den coin istatistiklerini yÃ¼kle."""
        for trade in trades:
            symbol = trade.get('symbol', '')
            if not symbol:
                continue
            
            pnl = trade.get('pnl', 0)
            reason = trade.get('reason', trade.get('closeReason', ''))
            close_time = trade.get('closeTime', 0)
            size_usd = trade.get('size_usd', trade.get('sizeUsd', 100))  # KaldÄ±raÃ§lÄ± pozisyon
            leverage = trade.get('leverage', 10)  # KaldÄ±raÃ§
            
            self._record_trade_internal(symbol, pnl, reason, close_time, size_usd, leverage)
        
        logger.info(f"ðŸ“Š CoinPerformanceTracker: Loaded stats for {len(self.coin_stats)} coins")
    
    def _record_trade_internal(self, symbol: str, pnl: float, reason: str, close_time: int = 0, size_usd: float = 100.0, leverage: int = 10):
        """Dahili trade kayÄ±t fonksiyonu."""
        if symbol not in self.coin_stats:
            self.coin_stats[symbol] = {
                'trades': [],
                'total_trades': 0,
                'wins': 0,
                'losses': 0,
                'total_pnl': 0.0,
                'total_invested': 0.0,  # Toplam yatÄ±rÄ±lan miktar
                'kill_switch_count': 0,
                'last_trade_time': 0
            }
        
        stats = self.coin_stats[symbol]
        
        # Trade kaydet
        stats['trades'].append({
            'pnl': pnl,
            'size_usd': size_usd,  # KaldÄ±raÃ§lÄ± pozisyon boyutu
            'leverage': leverage,  # KaldÄ±raÃ§
            'margin': size_usd / leverage if leverage > 0 else size_usd,  # GerÃ§ek yatÄ±rÄ±lan
            'reason': reason,
            'time': close_time or int(datetime.now().timestamp() * 1000)
        })
        
        # Son N trade tut
        if len(stats['trades']) > self.max_history_per_coin:
            stats['trades'] = stats['trades'][-self.max_history_per_coin:]
        
        # Ä°statistikleri gÃ¼ncelle
        stats['total_trades'] += 1
        stats['total_pnl'] += pnl
        stats['total_invested'] = stats.get('total_invested', 0) + size_usd
        stats['last_trade_time'] = close_time or int(datetime.now().timestamp() * 1000)
        
        if pnl > 0:
            stats['wins'] += 1
        else:
            stats['losses'] += 1
        
        if 'KILL_SWITCH' in reason:
            stats['kill_switch_count'] += 1
    
    def record_trade(self, symbol: str, pnl: float, reason: str):
        """Yeni trade kaydet."""
        self._record_trade_internal(symbol, pnl, reason)
        
        # Coin performance logla
        stats = self.coin_stats.get(symbol, {})
        wr = self.get_win_rate(symbol)
        logger.debug(f"ðŸ“Š Coin {symbol}: WR={wr:.1f}% | PnL=${pnl:+.2f} | Total=${stats.get('total_pnl', 0):.2f}")
    
    def get_win_rate(self, symbol: str) -> float:
        """Coin'in win rate'ini dÃ¶ndÃ¼r."""
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        if total < self.min_trades_for_stats:
            return 50.0  # Yeterli veri yok, nÃ¶tr
        wins = stats.get('wins', 0)
        return (wins / total) * 100
    
    def get_coin_penalty(self, symbol: str) -> int:
        """
        Coin performansÄ±na gÃ¶re sinyal puanÄ± cezasÄ± dÃ¶ndÃ¼r.
        DÃ¼ÅŸÃ¼k performanslÄ± coinler iÃ§in 0-30 puan dÃ¼ÅŸÃ¼rÃ¼lÃ¼r.
        """
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        
        if total < self.min_trades_for_stats:
            return 0  # Yeterli veri yok
        
        win_rate = self.get_win_rate(symbol)
        avg_pnl = stats.get('total_pnl', 0) / total
        ks_rate = (stats.get('kill_switch_count', 0) / total) * 100
        
        penalty = 0
        
        # Win rate bazlÄ± ceza
        if win_rate < 25:
            penalty += 20
        elif win_rate < 35:
            penalty += 10
        elif win_rate < 45:
            penalty += 5
        
        # Avg PnL bazlÄ± ceza
        if avg_pnl < -10:
            penalty += 15
        elif avg_pnl < -5:
            penalty += 10
        elif avg_pnl < 0:
            penalty += 5
        
        # Kill switch rate bazlÄ± ceza
        if ks_rate > 40:
            penalty += 15
        elif ks_rate > 25:
            penalty += 10
        elif ks_rate > 15:
            penalty += 5
        
        return min(penalty, 50)  # Max 50 puan ceza
    
    def is_coin_blocked(self, symbol: str) -> bool:
        """Coin'in bloklanÄ±p bloklanmadÄ±ÄŸÄ±nÄ± kontrol et."""
        stats = self.coin_stats.get(symbol, {})
        total = stats.get('total_trades', 0)
        
        if total < self.min_trades_for_stats:
            return False
        
        win_rate = self.get_win_rate(symbol)
        ks_count = stats.get('kill_switch_count', 0)
        total_pnl = stats.get('total_pnl', 0)
        
        total_invested = stats.get('total_invested', 0)
        trades = stats.get('trades', [])
        
        # Kriter 1: Herhangi bir pozisyonda yatÄ±rÄ±lan MARGIN'Ä± kaybettiyse blokla
        # Margin = size_usd / leverage (gerÃ§ek yatÄ±rÄ±lan para)
        # Ã–rn: $100 margin, -$100 veya daha fazla zarar â†’ blokla
        for trade in trades:
            trade_size = trade.get('size_usd', 100)
            trade_leverage = trade.get('leverage', 10)
            trade_margin = trade_size / trade_leverage if trade_leverage > 0 else trade_size
            trade_pnl = trade.get('pnl', 0)
            # Margin kaybÄ± >= margin boyutu (100%+ kayÄ±p)
            if trade_pnl < 0 and abs(trade_pnl) >= trade_margin:
                return True
        
        # Kriter 2: Win rate Ã§ok dÃ¼ÅŸÃ¼k
        if win_rate < self.block_threshold_wr:
            return True
        
        # Kriter 3: Ã‡ok fazla kill switch
        if ks_count >= 5 and (ks_count / total) > 0.4:  # %40+ KS rate
            return True
        
        return False
    
    def get_worst_performers(self, limit: int = 10) -> list:
        """En kÃ¶tÃ¼ performanslÄ± coinleri dÃ¶ndÃ¼r."""
        performers = []
        for symbol, stats in self.coin_stats.items():
            total = stats.get('total_trades', 0)
            if total < self.min_trades_for_stats:
                continue
            
            win_rate = self.get_win_rate(symbol)
            avg_pnl = stats.get('total_pnl', 0) / total
            
            performers.append({
                'symbol': symbol,
                'win_rate': round(win_rate, 1),
                'avg_pnl': round(avg_pnl, 2),
                'total_pnl': round(stats.get('total_pnl', 0), 2),
                'trades': total,
                'ks_count': stats.get('kill_switch_count', 0),
                'penalty': self.get_coin_penalty(symbol)
            })
        
        # Total PnL'e gÃ¶re sÄ±rala (en kÃ¶tÃ¼den en iyiye)
        performers.sort(key=lambda x: x['total_pnl'])
        return performers[:limit]
    
    def get_best_performers(self, limit: int = 10) -> list:
        """En iyi performanslÄ± coinleri dÃ¶ndÃ¼r."""
        performers = []
        for symbol, stats in self.coin_stats.items():
            total = stats.get('total_trades', 0)
            if total < self.min_trades_for_stats:
                continue
            
            win_rate = self.get_win_rate(symbol)
            avg_pnl = stats.get('total_pnl', 0) / total
            
            performers.append({
                'symbol': symbol,
                'win_rate': round(win_rate, 1),
                'avg_pnl': round(avg_pnl, 2),
                'total_pnl': round(stats.get('total_pnl', 0), 2),
                'trades': total,
                'ks_count': stats.get('kill_switch_count', 0)
            })
        
        # Total PnL'e gÃ¶re sÄ±rala (en iyiden en kÃ¶tÃ¼ye)
        performers.sort(key=lambda x: x['total_pnl'], reverse=True)
        return performers[:limit]
    
    def get_stats_for_optimizer(self) -> dict:
        """AI optimizer iÃ§in coin istatistiklerini dÃ¶ndÃ¼r."""
        worst = self.get_worst_performers(5)
        best = self.get_best_performers(5)
        
        blocked_coins = [s for s in self.coin_stats.keys() if self.is_coin_blocked(s)]
        
        return {
            'worst_performers': worst,
            'best_performers': best,
            'blocked_coins': blocked_coins,
            'total_coins_tracked': len(self.coin_stats)
        }
    
    def get_all_stats(self) -> dict:
        """TÃ¼m coin istatistiklerini dÃ¶ndÃ¼r."""
        return {
            'coins': len(self.coin_stats),
            'worst_performers': self.get_worst_performers(10),
            'best_performers': self.get_best_performers(10),
            'blocked_coins': [s for s in self.coin_stats.keys() if self.is_coin_blocked(s)]
        }


# Global CoinPerformanceTracker instance
coin_performance_tracker = CoinPerformanceTracker()

# ============================================================================
# PHASE 36: ORDER BOOK IMBALANCE DETECTOR
# ============================================================================

class OrderBookImbalanceDetector:
    """
    Detects order book imbalance (OBI) to identify buying/selling pressure.
    
    Formula: OBI = (Bid_Qty - Ask_Qty) / (Bid_Qty + Ask_Qty)
    - OBI > 0.3: Strong buying pressure â†’ LONG boost
    - OBI < -0.3: Strong selling pressure â†’ SHORT boost
    """
    
    def __init__(self, threshold: float = 0.3, depth_levels: int = 5):
        self.threshold = threshold  # OBI threshold for signals
        self.depth_levels = depth_levels  # How many levels to analyze
        self.obi_cache = {}  # symbol -> {obi, timestamp}
        self.cache_ttl = 5  # Cache for 5 seconds
        logger.info(f"ðŸ“Š OrderBookImbalanceDetector initialized: threshold={threshold}, depth={depth_levels}")
    
    async def fetch_depth(self, symbol: str) -> dict:
        """Fetch L2 depth data from Binance."""
        try:
            import aiohttp
            # Convert symbol format (BTCUSDT -> BTCUSDT)
            formatted = symbol.replace('/', '')
            url = f"https://fapi.binance.com/fapi/v1/depth?symbol={formatted}&limit=20"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=2) as resp:
                    if resp.status == 200:
                        return await resp.json()
            return {}
        except Exception as e:
            logger.debug(f"Depth fetch error for {symbol}: {e}")
            return {}
    
    def calculate_obi(self, bids: list, asks: list) -> float:
        """
        Calculate Order Book Imbalance.
        
        Args:
            bids: List of [price, quantity] for bids
            asks: List of [price, quantity] for asks
            
        Returns:
            OBI value between -1 and 1
        """
        try:
            # Sum top N levels
            bid_qty = sum(float(b[1]) for b in bids[:self.depth_levels]) if bids else 0
            ask_qty = sum(float(a[1]) for a in asks[:self.depth_levels]) if asks else 0
            
            total = bid_qty + ask_qty
            if total == 0:
                return 0.0
            
            obi = (bid_qty - ask_qty) / total
            return round(obi, 4)
            
        except Exception as e:
            logger.debug(f"OBI calculation error: {e}")
            return 0.0
    
    async def get_obi(self, symbol: str) -> float:
        """Get OBI for symbol (with caching)."""
        now = datetime.now().timestamp()
        
        # Check cache
        if symbol in self.obi_cache:
            cached = self.obi_cache[symbol]
            if now - cached['timestamp'] < self.cache_ttl:
                return cached['obi']
        
        # Fetch fresh data
        depth = await self.fetch_depth(symbol)
        if not depth:
            return self.obi_cache.get(symbol, {}).get('obi', 0.0)
        
        bids = depth.get('bids', [])
        asks = depth.get('asks', [])
        obi = self.calculate_obi(bids, asks)
        
        # Update cache
        self.obi_cache[symbol] = {
            'obi': obi,
            'timestamp': now,
            'bid_qty': sum(float(b[1]) for b in bids[:self.depth_levels]) if bids else 0,
            'ask_qty': sum(float(a[1]) for a in asks[:self.depth_levels]) if asks else 0,
            # Phase 212: USD depth for Thin Book Guard
            'total_bid_usd': sum(float(b[0]) * float(b[1]) for b in bids[:self.depth_levels]) if bids else 0,
            'total_ask_usd': sum(float(a[0]) * float(a[1]) for a in asks[:self.depth_levels]) if asks else 0,
        }
        
        return obi
    
    def get_signal_boost(self, symbol: str, action: str) -> tuple:
        """
        Get score boost based on OBI alignment with signal direction.
        
        Returns:
            (boost_points: int, reason: str)
        """
        cached = self.obi_cache.get(symbol, {})
        obi = cached.get('obi', 0)
        
        if abs(obi) < self.threshold:
            return (0, "OBI neutral")
        
        # Strong buying pressure
        if obi > self.threshold:
            if action == "LONG":
                return (15, f"OBI aligned +{obi:.2f}")
            elif action == "SHORT":
                return (-10, f"OBI opposing +{obi:.2f}")
        
        # Strong selling pressure
        elif obi < -self.threshold:
            if action == "SHORT":
                return (15, f"OBI aligned {obi:.2f}")
            elif action == "LONG":
                return (-10, f"OBI opposing {obi:.2f}")
        
        return (0, "OBI neutral")
    
    def get_status(self) -> dict:
        """Get OBI detector status for debugging."""
        return {
            "cached_symbols": len(self.obi_cache),
            "threshold": self.threshold,
            "depth_levels": self.depth_levels,
            "top_imbalances": sorted(
                [(s, d['obi']) for s, d in self.obi_cache.items()],
                key=lambda x: abs(x[1]),
                reverse=True
            )[:10]
        }


# Global OBI Detector instance
obi_detector = OrderBookImbalanceDetector()


# Legacy function for backwards compatibility
def calculate_imbalance(bids: list, asks: list) -> float:
    """
    Calculate order book imbalance (legacy wrapper).
    Positive = Bullish, Negative = Bearish
    """
    return obi_detector.calculate_obi(bids, asks) * 100  # Return as percentage


# ============================================================================
# MARKET REGIME DETERMINATION
# ============================================================================

def get_market_regime(hurst: float) -> str:
    """Determine market regime based on Hurst Exponent."""
    if hurst > 0.55:
        return "TREND TAKÄ°BÄ°"
    elif hurst < 0.45:
        return "ORTALAMAYA DÃ–NÃœÅž"
    else:
        return "RASTGELE YÃœRÃœYÃœÅž"



# ============================================================================
# VWAP CALCULATION
# ============================================================================

def calculate_vwap(closes: list, volumes: list, prices: list) -> float:
    """
    Calculate Volume Weighted Average Price (VWAP).
    VWAP = Sum(Price * Volume) / Sum(Volume)
    """
    if not volumes or not prices:
        return closes[-1] if closes else 0.0
    
    try:
        # Use typical price for VWAP (High + Low + Close) / 3 if available, else Close
        # Here we use passed prices (closes or typical)
        # FORCE SLICING MATCH
        min_len = min(len(prices), len(volumes))
        if min_len == 0: return 0.0
        
        prices_arr = np.array(prices[-min_len:])
        volumes_arr = np.array(volumes[-min_len:])
        
        # Calculate for the window
        vwap = np.sum(prices_arr * volumes_arr) / np.sum(volumes_arr)
        return float(vwap)
    except Exception as e:
        logger.warning(f"VWAP calc error: {e}")
        return float(closes[-1])

# ============================================================================
# ADAPTIVE THRESHOLD (ATR-BASED)
# ============================================================================

def calculate_adaptive_threshold(base_threshold: float, atr: float, price: float, hurst: float = 0.5) -> float:
    """
    Adjust Z-Score threshold based on volatility (ATR) AND Hurst exponent.
    
    Hurst-based adjustment (Phase 128):
    - Hurst < 0.4 (Mean Reverting) -> Lower threshold (easier to enter, MR strategy)
    - Hurst = 0.5 (Random Walk) -> No change
    - Hurst > 0.6 (Trending) -> Higher threshold (harder to enter, need stronger signal)
    
    ATR-based adjustment:
    - High ATR -> Higher threshold (need bigger move in volatile markets)
    - Low ATR -> Lower threshold (smaller moves are significant)
    """
    if price == 0: return base_threshold
    
    threshold = base_threshold
    
    # 1. Hurst Factor (Phase 184) - NARROWED RANGE for more signals
    # Linear interpolation: H=0.2 â†’ 0.8x factor, H=0.5 â†’ 1.0x, H=0.8 â†’ 1.2x
    # Narrower range (was 0.6x-1.4x) so hurst doesn't over-inflate threshold
    hurst_factor = 1.0 + (hurst - 0.5) * 0.67
    
    # Clamp factor to narrower bounds (0.8x to 1.2x)
    hurst_factor = max(0.8, min(1.2, hurst_factor))
    
    threshold *= hurst_factor
    
    # 2. ATR Factor (existing logic)
    atr_pct = (atr / price) * 100
    
    # Phase 184: Reduced ATR inflation (was 1.2x â†’ 1.1x)
    if atr_pct > 2.0:  # High volatility
        threshold *= 1.1  # 10% harder (was 20%)
    elif atr_pct < 0.5:  # Low volatility
        threshold *= 0.85  # 15% easier
    
    return threshold

# ============================================================================
# SIGNAL GENERATOR (4-Layer Logic)
# ============================================================================

class SignalGenerator:
    """
    4-Layer signal generation based on DEVELOPER_HANDBOOK.
    
    Layer 1: Hurst Regime Filter
    Layer 2: Z-Score Threshold
    Layer 3: Liquidation Cascade
    Layer 4: Order Book Confirmation
    """
    
    def __init__(self):
        self.last_signal_time: float = 0
        self.min_signal_interval: float = 15.0  # RELAXED: 30s -> 15s for more signals
        self.liquidation_threshold: float = 100000  # $100k for cascade detection
        self.recent_liquidations: deque = deque(maxlen=50)
        self.leverage: int = 10 # Default Leverage
        logger.info(f"SignalGenerator Initialized (RELAXED). Leverage: {self.leverage}")
        
    def check_liquidation_cascade(self) -> tuple[bool, float]:
        """
        Check if there's a liquidation cascade.
        Returns (is_cascade, total_volume)
        """
        now = datetime.now().timestamp()
        # Look at liquidations in the last 30 seconds
        recent = [liq for liq in self.recent_liquidations 
                  if now - liq['timestamp'] < 30]
        
        if not recent:
            return False, 0
            
        total_volume = sum(liq['amount'] for liq in recent)
        is_cascade = total_volume > self.liquidation_threshold
        
        return is_cascade, total_volume
    
    def add_liquidation(self, side: str, amount: float, price: float):
        """Add a liquidation event."""
        self.recent_liquidations.append({
            'side': side,
            'amount': amount,
            'price': price,
            'timestamp': datetime.now().timestamp()
        })
    
    def generate_signal(
        self,
        hurst: float,
        zscore: float,
        imbalance: float,
        price: float,
        atr: float,
        vwap_zscore: float = 0.0,
        htf_trend: str = "NEUTRAL",
        leverage: int = 10,
        basis_pct: float = 0.0,
        whale_zscore: float = 0.0,
        smc_data: Optional[Dict] = None,
        breakout: Optional[str] = None,
        spread_pct: float = 0.05, # Phase 13
        volatility_ratio: float = 1.0, # Phase 13
        coin_profile: Optional[Dict] = None,  # Phase 28: Dynamic coin profile
        symbol: str = "BTCUSDT",  # Symbol for liquidation cascade lookup
        rsi: float = 50.0,  # RSI value (0-100)
        volume_ratio: float = 1.0,  # Current volume / avg volume
        sweep_result: Optional[Dict] = None,  # Liquidity sweep detection result
        coin_stats: Optional[Dict] = None,  # Coin-specific stats for dynamic thresholds
        coin_daily_trend: str = "NEUTRAL",  # Coin's own daily trend
        volume_24h: float = 0.0,  # Phase 123: 24h Volume for liquidity check
        adx: float = 25.0,  # ADX value for trend strength
        adx_trend: str = "NEUTRAL",  # Trend direction: BULLISH/BEARISH/NEUTRAL
        is_volume_spike: bool = False,  # Volume breakout detection
        market_regime: str = "RANGING",  # Phase 156: Market regime from MarketRegimeDetector
        ob_imbalance_trend: float = 0.0,  # Phase 156: Short-term order book imbalance trend
        funding_rate: float = 0.0,  # Phase 157: Funding rate for contrarian scoring
        coin_wr_penalty: int = 0,  # Phase 157: Coin WR penalty from trade pattern analysis
        side_wr_penalty: int = 0,  # Phase 157: Side WR penalty from trade pattern analysis
        enhanced_indicators: Optional[Dict] = None,  # Phase 193: MACD, BB, StochRSI, EMA cross
        fib_context: Optional[Dict] = None,  # Phase FIB: Fibonacci retracement context
    ) -> Optional[Dict[str, Any]]:
        """
        Generate signal based on 13 Layers of confluence (SMC + Breakouts + RSI + Volume + Sweep).
        Uses coin_profile for dynamic threshold and minimum score.
        """
        now = datetime.now().timestamp()
        
        # PHASE 102: Debug signal generation attempts (log every 100th)
        if not hasattr(self, '_attempt_count'):
            self._attempt_count = 0
        self._attempt_count += 1
        
        # Check minimum interval
        if now - self.last_signal_time < self.min_signal_interval:
            return None
        
        # ===================================================================
        # SAAT BAZLI FÄ°LTRE KALDIRILDI (Phase 101)
        # KullanÄ±cÄ± talebiyle 7/24 sinyal Ã¼retimi aktif
        # Risk: DÃ¼ÅŸÃ¼k likidite saatlerinde spread yÃ¼ksek olabilir
        # ===================================================================

        

        # Phase 28: Dynamic threshold from coin profile
        # Phase 152 FIX: User's min_confidence_score is always the floor
        user_min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 65
        # Phase 224D: Apply regime offset to min_score
        try:
            user_min_score = market_regime_manager.get_adjusted_min_score(user_min_score)
            user_min_score = max(40, min(95, user_min_score))  # Clamp to sane range
        except Exception:
            pass
        
        if coin_profile:
            base_threshold = coin_profile.get('optimal_threshold', 1.6)
            # Phase 152: coin_profile min_score cannot go below user's setting
            coin_min = coin_profile.get('min_score', 55)
            min_score_required = max(coin_min, user_min_score)
            is_backtest = coin_profile.get('is_backtest', False)
            logger.debug(f"Using coin profile: threshold={base_threshold}, min_score={min_score_required} (coin={coin_min}, user={user_min_score})")
        else:
            base_threshold = 1.5
            min_score_required = user_min_score
            is_backtest = False
        
        # Leverage Scaling:
        # 10x = 1.0x factor (No change)
        # 20x = 1.1x factor
        # 50x = 1.4x factor (+40% stricter)
        leverage_factor = 1.0 + max(0, (leverage - 10) / 100)
        
        # In backtest mode, skip adaptive threshold to allow more signals
        if is_backtest:
            effective_threshold = base_threshold
        else:
            # Phase 128: Pass hurst to calculate_adaptive_threshold for per-coin dynamic threshold
            adaptive_threshold = calculate_adaptive_threshold(base_threshold, atr, price, hurst)
            effective_threshold = adaptive_threshold * leverage_factor

        # =====================================================================
        # SMART_V2: Auto strategy routing + strategy-specific tuning
        # =====================================================================
        strategy_mode = (
            getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY)
            if 'global_paper_trader' in globals() and global_paper_trader
            else STRATEGY_MODE_LEGACY
        )
        pre_signal_side = "SHORT" if zscore > 0 else "LONG"
        # Phase 235: Pass macro trend direction for regime-aware directional tuning
        _s2_trend_dir = "NEUTRAL"
        try:
            _s2_trend_dir = market_regime_detector.trend_direction
        except Exception:
            pass
        smart_v2_profile = get_smart_v2_strategy_profile(
            mode=strategy_mode,
            signal_side=pre_signal_side,
            hurst=hurst,
            adx=adx,
            spread_pct=spread_pct,
            volume_ratio=volume_ratio,
            volatility_ratio=volatility_ratio,
            market_regime=market_regime,
            is_volume_spike=is_volume_spike,
            imbalance=imbalance,
            ob_imbalance_trend=ob_imbalance_trend,
            macro_trend_dir=_s2_trend_dir,
        )
        strategy_mode = smart_v2_profile.get('strategy_mode', STRATEGY_MODE_LEGACY)
        active_strategy = smart_v2_profile.get('active_strategy', 'legacy')
        strategy_label = smart_v2_profile.get('strategy_label', 'Legacy')
        strategy_threshold_mult = float(smart_v2_profile.get('threshold_mult', 1.0))
        strategy_entry_mult = float(smart_v2_profile.get('entry_mult', 1.0))
        strategy_exit_mult = float(smart_v2_profile.get('exit_mult', 1.0))
        strategy_leverage_mult = float(smart_v2_profile.get('leverage_mult', 1.0))
        strategy_score_bonus = int(smart_v2_profile.get('score_bonus', 0))
        strategy_min_offset = int(smart_v2_profile.get('min_score_offset', 0))
        strategy_notes = list(smart_v2_profile.get('notes', []))

        if strategy_mode == STRATEGY_MODE_SMART_V2:
            effective_threshold *= strategy_threshold_mult
            min_score_required = int(_clamp(min_score_required + strategy_min_offset, 40, 95))
        
        # Phase 120: Log AFTER effective_threshold is calculated
        if self._attempt_count % 100 == 1:
            exceeds = "âœ… PASS" if abs(zscore) > effective_threshold else "âŒ FAIL"
            logger.info(
                f"ðŸ”¬ SIGNAL_CHECK #{self._attempt_count}: {symbol} H={hurst:.2f} Z={zscore:.2f} "
                f"eff_thresh={effective_threshold:.2f} {exceeds} | mode={strategy_mode} strat={active_strategy}"
            )
        
        # PHASE 207: JESSE-INSPIRED STRATEGY ROUTING
        # Coin'in karakterine ve piyasa rejimine gore rota cikar
        router_profile = {}
        if coin_profile:
            # Check for global strategy_router inside generate_signal scope
            if 'strategy_router' in globals():
                router_profile = strategy_router.route_strategy(
                    coin_profile=coin_profile,
                    zscore=zscore,
                    hurst=hurst,
                    adx=adx,
                    market_regime=market_regime
                )
        
        # 2. CONFIDENCE SCORING SYSTEM (0-100)
        score = 0
        reasons = []
        
        # =====================================================================
        # PHASE 108: SIMPLIFIED MEAN REVERSION SIGNAL DIRECTION
        # Z-Score is designed for mean reversion - always use contrarian logic:
        # - zscore > +threshold (overbought) â†’ SHORT (price will revert down)
        # - zscore < -threshold (oversold) â†’ LONG (price will revert up)
        # Hurst is used for SCORING only, not direction determination.
        # =====================================================================
        
        signal_side = None
        
        # Simple mean reversion logic (contrarian)
        if abs(zscore) > effective_threshold:
            # Phase 207: Strategy Router VETO check for Mean Reversion
            if router_profile.get('veto_mr', False):
                logger.debug(f"ðŸ›‘ VETO: Router engelledi ({symbol}, MR_VETO) - {router_profile.get('reason')}")
                return None
                
            if zscore > effective_threshold:
                signal_side = "SHORT"
                reasons.append(f"Z(+{zscore:.1f})")
            else:  # zscore < -effective_threshold
                signal_side = "LONG"
                reasons.append(f"Z({zscore:.1f})")
            
            # Phase 152: Base score 50
            # Phase 207: Router AÄŸÄ±rlÄ±ÄŸÄ± ile Ã‡arp
            mr_weight = router_profile.get('mean_reversion_weight', 1.0)
            base_score = int(50 * mr_weight)
            score += base_score
            if mr_weight != 1.0:
                reasons.append(f"ROUTE_MR(x{mr_weight})")
            
            # Phase 152: Hurst etkisi artÄ±k SADECE threshold'da (calculate_adaptive_threshold)
            # Scoring'deki Ã§ifte etki kaldÄ±rÄ±ldÄ± â€” tutarlÄ±lÄ±k iÃ§in
            if hurst < 0.45:
                reasons.append(f"H_MR({hurst:.2f})")  # Log only, no score change
        else:
            return None  # Z-Score not extreme enough
        
        if signal_side is None:
            return None

        # Strategy score tuning (post-side, pre-confluence).
        if strategy_mode == STRATEGY_MODE_SMART_V2:
            if strategy_score_bonus != 0:
                score += strategy_score_bonus
                reasons.append(f"S2B({strategy_score_bonus:+d})")
            reasons.append(f"S2({strategy_label})")
        
        # =====================================================================
        # Phase 212: STRONG_TREND_FILTER kaldÄ±rÄ±ldÄ± (ADX>40)
        # REGIME_VETO (ADX>30 + Hurst>0.55) aynÄ± iÅŸi daha hassas yapÄ±yor.
        # ADX>40 filtresi hiÃ§ tetiklenmiyordu Ã§Ã¼nkÃ¼ REGIME_VETO daha Ã¶nce yakalÄ±yordu.
        # ADX trend alignment bonusu korundu.
        # =====================================================================
        if adx > 30 and adx_trend != "NEUTRAL":
            # ADX trend alignment bonus (sadece yÃ¶n uyumlu sinyallere)
            if (adx_trend == "BULLISH" and signal_side == "LONG") or \
               (adx_trend == "BEARISH" and signal_side == "SHORT"):
                
                # Phase 207: Trend Following AÄŸÄ±rlÄ±ÄŸÄ± Uygula
                if not router_profile.get('veto_tf', False):
                    tf_weight = router_profile.get('trend_weight', 1.0)
                    bonus = int(5 * tf_weight)
                    score += bonus
                    reasons.append(f"ADX_ALIGN({adx:.0f})+{bonus}")
        
        # Volume spike warning (for breakout detection)
        if is_volume_spike:
            # Volume spike during strong trend = breakout confirmation
            if adx > 25:
                score += 5  # Trend + volume spike = strong continuation
                reasons.append(f"VOL_SPIKE(trend)")
            else:
                # Volume spike without clear trend - could be reversal or manipulation
                logger.info(f"ðŸ“Š VOLUME_SPIKE: {symbol} vol_ratio={volume_ratio:.1f}x without strong trend")
        
        # Phase 128: TRACE LOG - every signal that passes Z-Score threshold
        logger.info(f"ðŸŽ¯ Z_PASS: {symbol} {signal_side} Z={zscore:.2f} H={hurst:.2f} score={score}")
        
        # =====================================================================
        # Phase 212: SPIKE PROTECTION (Pump-Dump Guard)
        # Fiyat ATR'nin 10x'i kadar hareket ettiyse pump-dump riski yÃ¼ksek.
        # Z-Score geÃ§miÅŸe baktÄ±ÄŸÄ± iÃ§in spike sonrasÄ± "ucuz" gÃ¶rebilir.
        # ATR normalden 10x+ fark = aÅŸÄ±rÄ± hareket, sinyal verme.
        # =====================================================================
        if atr > 0:
            # Z-Score excess + ATR combination: if zscore is extreme AND volatility spike
            spike_ratio = abs(zscore) * (price * 0.01 / atr) if atr > 0 else 0
            # If the price move is so extreme that ATR-normalized Z is >15, it's a pump-dump
            if abs(zscore) > 4.0 and volume_ratio > 3.0:
                logger.info(f"ðŸš¨ SPIKE_GUARD: {symbol} {signal_side} BLOCKED | Z={zscore:.2f} Vol={volume_ratio:.1f}x | Pump-dump risk")
                return None
        
        # Bonus based on Z-Score strength (0-10 pts extra)
        zscore_excess = abs(zscore) - effective_threshold
        zscore_bonus = min(10, int(zscore_excess * 5))  # Each 0.2 above threshold = +1 pt
        score += zscore_bonus
        
        # Log signal direction determination
        logger.debug(f"Phase 108: {symbol} H={hurst:.2f} Z={zscore:.2f} â†’ {signal_side}")
            
        # Layer 2: Order Book Imbalance (Confirmation) - Max 20 pts
        # Graduated scoring based on imbalance strength
        ob_aligned = False
        ob_score = 0
        if signal_side == "LONG" and imbalance > 0:
            if imbalance >= 10:
                ob_score = 20  # Strong buying pressure
            elif imbalance >= 5:
                ob_score = 15  # Good buying pressure
            elif imbalance >= 2:
                ob_score = 10  # Moderate buying pressure
            if ob_score > 0:
                score += ob_score
                ob_aligned = True
                reasons.append(f"OB(+{imbalance:.1f}%={ob_score}p)")
        elif signal_side == "SHORT" and imbalance < 0:
            if imbalance <= -10:
                ob_score = 20  # Strong selling pressure
            elif imbalance <= -5:
                ob_score = 15  # Good selling pressure
            elif imbalance <= -2:
                ob_score = 10  # Moderate selling pressure
            if ob_score > 0:
                score += ob_score
                ob_aligned = True
                reasons.append(f"OB({imbalance:.1f}%={ob_score}p)")
            
        # Layer 3: VWAP Z-Score (Mean Reversion Check) - Max 20 pts
        # RELAXED: 1.0 -> 0.7 threshold for easier confirmation
        vwap_aligned = False
        if signal_side == "LONG" and vwap_zscore < -0.7:
            score += 20
            vwap_aligned = True
            reasons.append(f"VWAP({vwap_zscore:.1f})")
        elif signal_side == "SHORT" and vwap_zscore > 0.7:
            score += 20
            vwap_aligned = True
            reasons.append(f"VWAP({vwap_zscore:.1f})")
            
        # Layer 4: Coin Daily Trend (Max 15 pts)
        # Phase 152: COIN-ONLY â€” BTC kontrolÃ¼ should_allow_signal'da yapÄ±lÄ±yor (Ã§ifte filtre fixlendi)
        # Sadece coin'in kendi daily trend'ine gÃ¶re skor
        mtf_score = 0
        if signal_side == "LONG":
            if coin_daily_trend == "STRONG_BULLISH":
                mtf_score = 15
            elif coin_daily_trend == "BULLISH":
                mtf_score = 10
            elif coin_daily_trend == "NEUTRAL":
                mtf_score = 0
            elif coin_daily_trend == "BEARISH":
                mtf_score = -10
            elif coin_daily_trend == "STRONG_BEARISH":
                mtf_score = -20  # GÃ¼Ã§lÃ¼ penalty ama VETO deÄŸil
        else: # SHORT
            if coin_daily_trend == "STRONG_BEARISH":
                mtf_score = 15
            elif coin_daily_trend == "BEARISH":
                mtf_score = 10
            elif coin_daily_trend == "NEUTRAL":
                mtf_score = 0
            elif coin_daily_trend == "BULLISH":
                mtf_score = -10
            elif coin_daily_trend == "STRONG_BULLISH":
                mtf_score = -20  # GÃ¼Ã§lÃ¼ penalty ama VETO deÄŸil
            
        score += mtf_score
        reasons.append(f"COIN_TREND({coin_daily_trend}={mtf_score})")
        
        # Layer 5: Liquidation Cascade (Bonus) - Max 15 pts
        # Uses real-time liquidation stream from Binance
        liq_score, liq_reason = liquidation_tracker.get_cascade_score(symbol if symbol else 'BTCUSDT', signal_side)
        if liq_score > 0:
            score += liq_score
            reasons.append(liq_reason)

        # Layer 6: Spot-Futures Basis (Sentiment) - Max 10 pts
        # Contango (Basis > 0) favors Longs, Backwardation favors Shorts
        # Threshold: 0.02% (2 bps)
        if signal_side == "LONG" and basis_pct > 0.02:
            score += 10
            reasons.append(f"Basis(+{basis_pct:.2f}%)")
        elif signal_side == "SHORT" and basis_pct < -0.02:
            score += 10
            reasons.append(f"Basis({basis_pct:.2f}%)")

        # Layer 7: Whale Sentiment (Real-Time AggTrades) - Max 15 pts
        if signal_side == "LONG" and whale_zscore > 2.0:
            score += 15
            reasons.append(f"WhaleBuy(Z:{whale_zscore:.1f})")
        elif signal_side == "SHORT" and whale_zscore < -2.0:
            score += 15
            reasons.append(f"WhaleSell(Z:{whale_zscore:.1f})")

        # Layer 8: SMC Fair Value Gaps (Magnets/Filters) - Max +/- 20 pts
        # Layer 8: SMC Fair Value Gaps and Order Blocks (Phase 208) - Max +/- 30 pts
        if smc_data:
            ob_bull = smc_data.get('ob_bullish')
            ob_bear = smc_data.get('ob_bearish')
            fvg_bull = smc_data.get('fvg_bullish')
            fvg_bear = smc_data.get('fvg_bearish')
            
            in_bull_ob = ob_bull and ob_bull['bottom'] <= price <= ob_bull['top']
            in_bear_ob = ob_bear and ob_bear['bottom'] <= price <= ob_bear['top']
            
            if signal_side == "LONG":
                if in_bull_ob:
                    score += 20
                    reasons.append("SMC(In Bull OB)")
                elif in_bear_ob:
                    score -= 20
                    reasons.append("SMC(In Bear OB!)")
                elif fvg_bull and fvg_bull['bottom'] <= price <= fvg_bull['top']:
                    score += 10
                    reasons.append("SMC(In Bull FVG)")
            elif signal_side == "SHORT":
                if in_bear_ob:
                    score += 20
                    reasons.append("SMC(In Bear OB)")
                elif in_bull_ob:
                    score -= 20
                    reasons.append("SMC(In Bull OB!)")
                elif fvg_bear and fvg_bear['bottom'] <= price <= fvg_bear['top']:
                    score += 10
                    reasons.append("SMC(In Bear FVG)")
                    
        # Layer 9: Dynamic S/R Breakout (Trend Following) - Phase 11
        # If Breakout Signal exists AND Hurst > 0.5 (Trend Regime)
        if breakout:
             if hurst > 0.5:
                 if breakout == "BREAKOUT_LONG" and signal_side == "LONG":
                     score += 25
                     reasons.append("BREAKOUT(Trend)")
                 elif breakout == "BREAKOUT_SHORT" and signal_side == "SHORT":
                     score += 25
                     reasons.append("BREAKDOWN(Trend)")
             elif hurst < 0.4:
                 # Mean Reversion Regime: Breakouts are often Fakeouts!
                 # Or actually, if Z-Score says LONG (Oversold) but we have breakdown...
                 # It's mixed signals.
                 score -= 10
                 reasons.append("FakeoutRisk")

        # =====================================================================
        # PHASE 136: BONUS-ONLY SCORING LAYERS
        # SADECE BONUS verir, asla penalty vermez - sinyal akÄ±ÅŸÄ±nÄ± bozmaz
        # =====================================================================
        
        # Layer 10: RSI Momentum Bonus (+5/+8)
        # LONG + oversold = bonus, SHORT + overbought = bonus
        if signal_side == "LONG" and rsi < 35:
            rsi_bonus = 8 if rsi < 25 else 5
            score += rsi_bonus
            reasons.append(f"RSI_OS({rsi:.0f})+{rsi_bonus}")
        elif signal_side == "SHORT" and rsi > 65:
            rsi_bonus = 8 if rsi > 75 else 5
            score += rsi_bonus
            reasons.append(f"RSI_OB({rsi:.0f})+{rsi_bonus}")
        
        # Layer 11: Volume Spike Bonus (+5/+8)
        # volume_ratio is passed as parameter (default=1.0)
        if volume_ratio >= 1.5:
            vol_bonus = 8 if volume_ratio >= 2.0 else 5
            score += vol_bonus
            reasons.append(f"VOL({volume_ratio:.1f}x)+{vol_bonus}")
        
        # Layer 12: SMT Divergence Bonus (+10)
        # Uses existing smt_divergence_detector.last_divergence (no new API call)
        try:
            smt_div_bonus = smt_divergence_detector.last_divergence
            if smt_div_bonus and smt_div_bonus.get('divergence_type'):
                smt_type = smt_div_bonus['divergence_type']
                smt_age = datetime.now().timestamp() - smt_divergence_detector.divergence_time
                if smt_age < 300:  # Son 5 dakika
                    if smt_type == "BULLISH" and signal_side == "LONG":
                        score += 10
                        reasons.append("SMT_BULL+10")
                    elif smt_type == "BEARISH" and signal_side == "SHORT":
                        score += 10
                        reasons.append("SMT_BEAR+10")
        except Exception:
            pass  # SMT detector not ready
        
        # Layer 13: VWAP Sweet Zone Bonus (+5)
        # vwap_zscore is passed as parameter (default=0.0)
        if vwap_zscore != 0:
            vwap_dev = abs(vwap_zscore)
            # Sweet spot: 0.5-2.0 sigma away from VWAP (ideal mean reversion)
            if 0.5 <= vwap_dev <= 2.0:
                score += 5
                reasons.append(f"VWAP_ZONE({vwap_dev:.1f}Ïƒ)+5")
        
        # =====================================================================
        # PHASE 156: LAYER 16 â€” ORDER BOOK IMBALANCE TREND (Short-term Flow)
        # Son 5 dakika bid/ask imbalance trend'i â€” alÄ±cÄ±/satÄ±cÄ± baskÄ±sÄ±nÄ± Ã¶lÃ§er
        # =====================================================================
        if abs(ob_imbalance_trend) > 2.0:
            if signal_side == "LONG" and ob_imbalance_trend > 2.0:
                ib_bonus = 8 if ob_imbalance_trend > 5.0 else 5
                score += ib_bonus
                reasons.append(f"IB_TREND(+{ob_imbalance_trend:.1f})+{ib_bonus}")
            elif signal_side == "SHORT" and ob_imbalance_trend < -2.0:
                ib_bonus = 8 if ob_imbalance_trend < -5.0 else 5
                score += ib_bonus
                reasons.append(f"IB_TREND({ob_imbalance_trend:.1f})+{ib_bonus}")
            elif signal_side == "LONG" and ob_imbalance_trend < -5.0:
                score -= 5
                reasons.append(f"IB_CONTRA({ob_imbalance_trend:.1f})-5")
            elif signal_side == "SHORT" and ob_imbalance_trend > 5.0:
                score -= 5
                reasons.append(f"IB_CONTRA({ob_imbalance_trend:.1f})-5")
        
        # =====================================================================
        # PHASE 157: LAYER 17 â€” FUNDING RATE CONTRARIAN SCORING
        # Funding rate'e gÃ¶re contrarian bonus/penalty/veto
        # =====================================================================
        if funding_rate != 0:
            fr_adj, fr_reason, fr_veto = funding_oi_tracker.get_funding_signal(symbol, signal_side)
            if fr_veto:
                logger.info(f"ðŸš« FUNDING_VETO: {symbol} {signal_side} â€” {fr_reason}")
                return None
            if fr_adj != 0:
                score += fr_adj
                reasons.append(f"{fr_reason}{'+' if fr_adj > 0 else ''}{fr_adj}")
        
        # =====================================================================
        # PHASE 157: LAYER 18 â€” TRADE PATTERN PENALTY/BONUS
        # KapanmÄ±ÅŸ trade analizi â€” dÃ¼ÅŸÃ¼k WR coin/side'a penalty
        # =====================================================================
        if coin_wr_penalty != 0:
            score += coin_wr_penalty
            reasons.append(f"COIN_WR({coin_wr_penalty:+d})")
        # Side penalty â€” calculated here where signal_side is known
        actual_side_penalty = trade_pattern_analyzer.get_side_penalty(signal_side)
        if actual_side_penalty != 0:
            score += actual_side_penalty
            reasons.append(f"SIDE_WR({actual_side_penalty:+d})")
        
        # Layer 14: POC Proximity Bonus (+5/+8)
        # coin_profile is passed as parameter (default=None)
        if coin_profile and coin_profile.get('poc', 0) > 0:
            poc = coin_profile['poc']
            poc_dist_pct = abs(price - poc) / poc * 100
            if poc_dist_pct < 2.0:
                score += 8
                reasons.append(f"POC_NEAR({poc_dist_pct:.1f}%)+8")
            elif poc_dist_pct < 5.0:
                score += 5
                reasons.append(f"POC_zone({poc_dist_pct:.1f}%)+5")
        
        # =====================================================================
        # PHASE 193: ENHANCED INDICATOR SCORING LAYERS (pandas-ta powered)
        # BONUS-ONLY â€” Sadece destekleyici skor, asla VETO veya penalty deÄŸil
        # =====================================================================
        if enhanced_indicators:
            ei = enhanced_indicators
            
            # Phase 207: Strategy Router Multipliers
            tf_weight = router_profile.get('trend_weight', 1.0) if not router_profile.get('veto_tf', False) else 0.0
            mr_weight = router_profile.get('mean_reversion_weight', 1.0) if not router_profile.get('veto_mr', False) else 0.0
            
            # Layer 19: MACD Momentum Confirmation (+5/+8)
            # MACD histogram sinyal yÃ¶nÃ¼nÃ¼ onaylÄ±yorsa bonus
            macd_hist = ei.get('macd_histogram', 0)
            macd_cross = ei.get('macd_signal_cross', 'NEUTRAL')
            if tf_weight > 0:
                if signal_side == "LONG":
                    if macd_cross == 'BULLISH':
                        bonus = int(8 * tf_weight)
                        score += bonus
                        reasons.append(f"MACD_CROSS_BULL+{bonus}")
                    elif macd_hist > 0:
                        bonus = int(5 * tf_weight)
                        score += bonus
                        reasons.append(f"MACD_POS+{bonus}")
                elif signal_side == "SHORT":
                    if macd_cross == 'BEARISH':
                        bonus = int(8 * tf_weight)
                        score += bonus
                        reasons.append(f"MACD_CROSS_BEAR+{bonus}")
                    elif macd_hist < 0:
                        bonus = int(5 * tf_weight)
                        score += bonus
                        reasons.append(f"MACD_NEG+{bonus}")
            
            # Layer 20: Bollinger Bands Position Confirmation (+5/+8)
            # LONG + fiyat alt BB'de = dÃ¼ÅŸÃ¼k fiyat desteÄŸi, SHORT + fiyat Ã¼st BB'de
            bb_pos = ei.get('bb_position', 0)
            if signal_side == "LONG" and bb_pos < -0.5:
                bb_bonus = 8 if bb_pos < -0.8 else 5
                score += bb_bonus
                reasons.append(f"BB_LOW({bb_pos:.2f})+{bb_bonus}")
            elif signal_side == "SHORT" and bb_pos > 0.5:
                bb_bonus = 8 if bb_pos > 0.8 else 5
                score += bb_bonus
                reasons.append(f"BB_HIGH({bb_pos:.2f})+{bb_bonus}")
            
            # Layer 21: Stochastic RSI Confirmation (+5/+8)
            # StochRSI crossover + extreme zone = gÃ¼Ã§lÃ¼ momentum sinyali
            stoch_k = ei.get('stoch_rsi_k', 50)
            stoch_cross = ei.get('stoch_rsi_cross', 'NEUTRAL')
            if mr_weight > 0:
                if signal_side == "LONG":
                    if stoch_cross == 'BULLISH':
                        bonus = int(8 * mr_weight)
                        score += bonus
                        reasons.append(f"SRSI_BULL({stoch_k:.0f})+{bonus}")
                    elif stoch_k < 20:
                        bonus = int(5 * mr_weight)
                        score += bonus
                        reasons.append(f"SRSI_OS({stoch_k:.0f})+{bonus}")
                elif signal_side == "SHORT":
                    if stoch_cross == 'BEARISH':
                        bonus = int(8 * mr_weight)
                        score += bonus
                        reasons.append(f"SRSI_BEAR({stoch_k:.0f})+{bonus}")
                    elif stoch_k > 80:
                        bonus = int(5 * mr_weight)
                        score += bonus
                        reasons.append(f"SRSI_OB({stoch_k:.0f})+{bonus}")
            
            # Layer 22: EMA Crossover Trend Confirmation (+5)
            # EMA(8) x EMA(21) â€” kÄ±sa vadeli trend yÃ¶nÃ¼
            ema_cross = ei.get('ema_cross', 'NEUTRAL')
            if tf_weight > 0:
                if signal_side == "LONG" and ema_cross == 'BULLISH':
                    bonus = int(5 * tf_weight)
                    score += bonus
                    reasons.append(f"EMA_BULL+{bonus}")
                elif signal_side == "SHORT" and ema_cross == 'BEARISH':
                    bonus = int(5 * tf_weight)
                    score += bonus
                    reasons.append(f"EMA_BEAR+{bonus}")

            # Layer 23: TTM Squeeze Momentum Confirmation (+5/-10)
            # Squeeze ON = consolide (patlamadÄ±), Squeeze OFF + Histogram = Patlama!
            sqz_on = ei.get('squeeze_on', False)
            sqz_hist = ei.get('squeeze_hist', 0.0)
            if sqz_on:
                # Hala sÄ±kÄ±ÅŸma alanÄ±nda, net bir kopuÅŸ (breakout) yok
                score -= 10
                reasons.append("SQZ_ON-10")
            elif signal_side == "LONG" and sqz_hist > 0:
                score += 5
                reasons.append("SQZ_BULL+5")
            elif signal_side == "SHORT" and sqz_hist < 0:
                score += 5
                reasons.append("SQZ_BEAR+5")

            # Layer 24: Choppiness Index (CHOP) Penalty/Bonus (-20/+5)
            # CHOP > 61.8 = AÅŸÄ±rÄ± yatay, yÃ¶nsÃ¼zlÃ¼k (Breakout iÃ§in KÃ–TÃœ)
            # CHOP < 38.2 = GÃ¼Ã§lÃ¼ trend (Breakout iÃ§in Ä°YÄ°)
            chop = ei.get('chop_value', 50.0)
            if chop > 61.8:
                score -= 20
                reasons.append(f"CHOP_RNG({chop:.1f})-20")
            elif chop < 38.2:
                score += 5
                reasons.append(f"CHOP_TRD({chop:.1f})+5")
        
        # =====================================================================
        # PHASE FIB: FIBONACCI ZONE CONFLUENCE (Layer 23, max +12)
        # Price in Fibonacci retracement zone â†’ score bonus
        # =====================================================================
        if FIB_ENABLED and FIB_SCORE_ENABLED and fib_context:
            fib_bonus = fib_context.get('fib_score_bonus', 0)
            if fib_bonus > 0:
                score += fib_bonus
                fib_level = fib_context.get('fib_level', '?')
                fib_conf = fib_context.get('confluence', [])
                conf_str = '+' + '+'.join(fib_conf) if fib_conf else ''
                reasons.append(f"Fib({fib_level},+{fib_bonus}{conf_str})")
            elif fib_context.get('skip_reason'):
                reasons.append(f"FibSkip({fib_context['skip_reason']})")
        
        # =====================================================================
        # PHASE 137: ADX + HURST REGIME DETECTION
        # SADECE BONUS - VETO YOK (Phase 133/134/135'teki hatayÄ± Ã¶nlemek iÃ§in)
        # =====================================================================
        
        # Layer 15: ADX + Hurst Regime Bonus
        # Phase 152: ADX artÄ±k fonksiyon parametresi olarak alÄ±nÄ±yor (L10455)
        # Override kaldÄ±rÄ±ldÄ± â€” gerÃ§ek ADX deÄŸeri kullanÄ±lÄ±r
        volatile_soft_risk_cap = False
        
        if adx < 20 and hurst < 0.45:
            # Strong range regime - ideal for mean reversion
            score += 10
            reasons.append(f"RANGE({adx:.0f},{hurst:.2f})+10")
        elif adx > 25 and hurst > 0.55:
            # Trend regime - only warning, NO VETO
            reasons.append(f"TREND_WARN({adx:.0f},{hurst:.2f})")
        
        # =====================================================================
        # PHASE 236: BLENDED REGIME BIAS
        # Coin macro (65%) + BTC macro (35%) â†’ weighted directional bias
        # Confidence-based magnitude: highâ†’Â±20/25, midâ†’Â±12/15, lowâ†’0
        # SMART_V2: full bias, LEGACY: half bias
        # =====================================================================
        regime_bias = 0
        regime_bias_reasons = []
        _blended_dir = "NEUTRAL"  # used by VOLATILE_VETO below
        try:
            # -- BTC macro bias --
            macro_regime = market_regime_detector.current_regime
            macro_trend_dir = market_regime_detector.trend_direction
            btc_regime = market_regime_manager.current_regime
            btc_bias = compute_btc_macro_bias(macro_regime, macro_trend_dir, btc_regime)

            # -- Coin macro bias --
            coin_bias = compute_coin_macro_bias(
                coin_daily_trend=coin_daily_trend,
                adx=adx,
                hurst=hurst,
                adx_trend=adx_trend,
            )

            # -- Blend --
            # -- Blend (btc_corr from coin_profile if available) --
            _btc_corr = None
            try:
                if coin_profile and isinstance(coin_profile, dict):
                    _btc_corr = coin_profile.get('btc_correlation', coin_profile.get('btcCorrelation', None))
            except Exception:
                pass
            blended = blend_macro_bias(coin_bias, btc_bias, btc_corr=_btc_corr)
            _blended_dir = blended["dir"]
            blended_conf = blended["confidence"]

            # Observability: birleÅŸim detayÄ±
            regime_bias_reasons.append(
                f"REGIME_BLEND("
                f"COIN:{coin_bias['dir']}@{coin_bias['confidence']:.2f},"
                f"BTC:{btc_bias['dir']}@{btc_bias['confidence']:.2f},"
                f"W:{blended['w_coin']}/{blended['w_btc']},"
                f"DIR:{_blended_dir},CONF:{blended_conf:.2f})"
            )

            # Pro-trend / counter-trend
            is_pro_trend = (
                (_blended_dir == "DOWN" and signal_side == "SHORT") or
                (_blended_dir == "UP" and signal_side == "LONG")
            )
            is_counter_trend = (
                (_blended_dir == "DOWN" and signal_side == "LONG") or
                (_blended_dir == "UP" and signal_side == "SHORT")
            )

            # Confidence-based bias magnitude
            if blended_conf >= 0.70:
                pro_bias, counter_bias = 20, -25
            elif blended_conf >= 0.45:
                pro_bias, counter_bias = 12, -15
            else:
                pro_bias, counter_bias = 0, 0  # conf dÃ¼ÅŸÃ¼k â†’ bias yok

            # SMART_V2 vs LEGACY scaling
            _strat = str(strategy_mode or "").upper()
            if _strat != STRATEGY_MODE_SMART_V2:
                # LEGACY: bias'Ä± yarÄ±ya yakÄ±n
                pro_bias = int(pro_bias * 0.55)
                counter_bias = int(counter_bias * 0.55)

            if is_pro_trend and pro_bias > 0:
                regime_bias = pro_bias
                regime_bias_reasons.append(f"REGIME_BIAS(+{pro_bias})")
            elif is_counter_trend and counter_bias < 0:
                regime_bias = counter_bias
                regime_bias_reasons.append(f"REGIME_BIAS({counter_bias})")

            if regime_bias != 0:
                score += regime_bias
                reasons.extend(regime_bias_reasons)
                logger.info(
                    f"ðŸŽ­ REGIME_BIAS: {symbol} {signal_side} "
                    f"coin={coin_bias['dir']}@{coin_bias['confidence']:.2f}({coin_bias.get('source','')}) "
                    f"btc={btc_bias['dir']}@{btc_bias['confidence']:.2f} "
                    f"â†’ blend={_blended_dir}@{blended_conf:.2f} "
                    f"bias={regime_bias:+d} strat={_strat} â†’ score={score}"
                )
            elif regime_bias_reasons:
                # bias=0 ama blend logla (gÃ¶zlemlenebilirlik)
                reasons.extend(regime_bias_reasons)
        except Exception as regime_bias_err:
            logger.debug(f"Regime bias error: {regime_bias_err}")
        
        # =====================================================================
        # PHASE 156: REGIME-SIGNAL VETO FILTER
        # Trend rejiminde karÅŸÄ± yÃ¶nlÃ¼ mean-reversion sinyallerini veto et
        # VOLATILE rejimde min_score'u artÄ±r
        # =====================================================================
        
        # Veto 1: Coin-level trend regime (ADX + Hurst)
        # ADX > 30 VE Hurst > 0.55 â†’ gÃ¼Ã§lÃ¼ trend, MR sinyali riskli
        is_coin_trending = adx > 30 and hurst > 0.55
        
        if is_coin_trending:
            # Trend yÃ¶nÃ¼ne karÅŸÄ± sinyal = VETO
            if adx_trend == "BULLISH" and signal_side == "SHORT":
                logger.info(f"ðŸš« REGIME_VETO: {symbol} SHORT rejected â€” coin in BULLISH trend (ADX={adx:.0f}, H={hurst:.2f})")
                return None
            elif adx_trend == "BEARISH" and signal_side == "LONG":
                logger.info(f"ðŸš« REGIME_VETO: {symbol} LONG rejected â€” coin in BEARISH trend (ADX={adx:.0f}, H={hurst:.2f})")
                return None
        
        # Veto 2: Macro VOLATILE rejimde daha yÃ¼ksek conviction iste
        # Phase 236: blended_dir ile yÃ¶n-farkÄ±nda pro-trend belirleme
        if market_regime == "VOLATILE":
            try:
                _is_pro_trend = (
                    (_blended_dir == "DOWN" and signal_side == "SHORT") or
                    (_blended_dir == "UP" and signal_side == "LONG")
                )
            except Exception:
                _is_pro_trend = False
            if _is_pro_trend:
                volatile_boost = int(min_score_required * 0.05)  # %5 artÄ±ÅŸ (trendle uyumlu)
            else:
                volatile_boost = int(min_score_required * 0.15)  # %15 artÄ±ÅŸ (trende karÅŸÄ±, strict)
            min_score_required += volatile_boost
            reasons.append(f"VOL_STRICT(+{volatile_boost})")
            if score < min_score_required:
                gap = int(min_score_required - score)
                soft_pass_ok = (
                    VOLATILE_VETO_SOFTPASS_ENABLED
                    and gap <= VOLATILE_VETO_SOFTPASS_MAX_GAP
                    and (is_volume_spike or volume_ratio >= 0.9)
                    and spread_pct <= max(0.30, EQ_MAX_SPREAD + 0.05)
                )
                if soft_pass_ok:
                    penalty = min(8, VOLATILE_VETO_SOFTPASS_PENALTY_BASE + max(0, gap))
                    old_score = score
                    score = max(40, score - penalty)
                    volatile_soft_risk_cap = True
                    reasons.append(f"VOL_SOFT(gap={gap},-{penalty})")
                    logger.info(
                        f"ðŸŸ¨ VOLATILE_SOFT_PASS: {symbol} {signal_side} "
                        f"score {old_score}->{score} (strict_min={min_score_required}, gap={gap})"
                    )
                else:
                    logger.info(f"ðŸš« VOLATILE_VETO: {symbol} {signal_side} score={score} < volatile_min={min_score_required}")
                    return None
        
        # =====================================================================
        # Phase 212: BTC TREND GUARD kaldÄ±rÄ±ldÄ±
        # BTC kontrolÃ¼ sadece process_signal_for_paper_trading() iÃ§inde
        # btc_filter.should_allow_signal() Ã¼zerinden yapÄ±lÄ±yor.
        # Ã‡ift penalty sorununu giderir.
        # =====================================================================
        
        # =====================================================================
        # PHASE 193: STOPLOSS FREQUENCY GUARD CHECK
        # =====================================================================
        if stoploss_frequency_guard.is_locked(symbol):
            lock_reason = stoploss_frequency_guard.get_lock_reason(symbol)
            logger.info(f"ðŸ›‘ SL_GUARD: {symbol} {signal_side} rejected â€” {lock_reason}")
            return None
        
        # =====================================================================
        # PHASE 48: KILL SWITCH FAULT PENALTY + BLOCK
        # =====================================================================
        # Check if coin is BLOCKED (kill switch within last 24h)
        if kill_switch_fault_tracker.is_blocked(symbol):
            logger.info(f"ðŸš« BLOCKED: {symbol} had kill switch within {kill_switch_fault_tracker.block_hours}h - signal rejected")
            return None
        
        # Apply penalty for coins that have previously triggered kill switch
        ks_penalty = kill_switch_fault_tracker.get_penalty(symbol)
        if ks_penalty < 0:
            score += ks_penalty  # ks_penalty is already negative
            reasons.append(f"KS_FAULT({ks_penalty}p)")
            logger.info(f"ðŸ“‹ Kill Switch Penalty applied to {symbol}: {ks_penalty} points (new score: {score})")
        
        # =====================================================================
        # AÅžAMA 1: MÄ°NÄ°MUM SKOR KONTROLÃœ
        # =====================================================================
        # Sadece Z-Score, OB, VWAP, MTF (veto iÃ§in), Liq Cascade, Basis, Whale, FVG, Breakout skorlarÄ± kullanÄ±ldÄ±
        
        # Phase 137 DEBUG: Trace log to confirm signals reach this point
        logger.info(f"ðŸ“ PRE_SCORE: {symbol} {signal_side} score={score} min={min_score_required} | reasons: {','.join(reasons[:4])}")
        
        if score < min_score_required:
            # Debug log for signal rejection (every 50th to avoid spam)
            if hasattr(self, '_reject_count'):
                self._reject_count += 1
            else:
                self._reject_count = 1
            # Phase 137 FIX: Log every 10th rejection instead of 50th for better visibility
            if self._reject_count % 10 == 1:
                logger.info(f"ðŸ“Š SCORE_LOW: {symbol} {signal_side} score={score} < min={min_score_required} | Z={zscore:.2f} H={hurst:.2f} | reasons: {', '.join(reasons[:5])}")
            return None
        
        # Phase 128: TRACE LOG - score check passed
        logger.info(f"âœ… SCORE_PASS: {symbol} {signal_side} score={score} >= min={min_score_required}")
        
        # =====================================================================
        # PHASE EQG: ENTRY QUALITY GATE
        # 3 koÅŸuldan en az 2'si geÃ§meli, yoksa low-quality entry
        # A: Volume (volume_ratio >= 1.25 VEYA is_volume_spike)
        # B: OB Direction (imbalance/ob_trend sinyalle uyumlu)
        # C: Liquidity (24h vol >= $1.5M VE spread <= 0.20%)
        # =====================================================================
        eq_pass_count = 0
        eq_reasons = []
        entry_quality_pass = True  # Default: pass
        
        if ENTRY_QUALITY_GATE_ENABLED:
            strategy_mode_upper = str(strategy_mode).upper()
            adaptive_mode = strategy_mode_upper in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)

            eq_min_volume_ratio = EQ_MIN_VOLUME_RATIO
            eq_min_imbalance = EQ_MIN_IMBALANCE
            eq_min_ob_trend = EQ_MIN_OB_TREND
            eq_min_volume_24h = EQ_MIN_VOLUME_24H
            eq_max_spread = EQ_MAX_SPREAD

            if adaptive_mode:
                # LEGACY + SMART_V2: kontrollÃ¼ gevÅŸeme (mikrocap gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ tamamen aÃ§madan)
                eq_min_volume_ratio = max(0.35, EQ_MIN_VOLUME_RATIO * 0.35)
                eq_min_imbalance = max(12.0, EQ_MIN_IMBALANCE * 0.5)
                eq_min_ob_trend = max(0.15, EQ_MIN_OB_TREND * 0.5)
                eq_min_volume_24h = max(350_000.0, EQ_MIN_VOLUME_24H * 0.3)
                eq_max_spread = max(0.35, EQ_MAX_SPREAD)

            # KoÅŸul A: Volume baÅŸlangÄ±cÄ±
            cond_a = volume_ratio >= eq_min_volume_ratio or is_volume_spike
            if cond_a:
                eq_pass_count += 1
                eq_reasons.append(f"A:Vol({volume_ratio:.1f}x)")

            # KoÅŸul B: OB yÃ¶n baskÄ±sÄ±
            cond_b = False
            if signal_side == "LONG":
                cond_b = imbalance >= eq_min_imbalance or ob_imbalance_trend >= eq_min_ob_trend
            elif signal_side == "SHORT":
                cond_b = imbalance <= -eq_min_imbalance or ob_imbalance_trend <= -eq_min_ob_trend
            if cond_b:
                eq_pass_count += 1
                eq_reasons.append(f"B:OB(imb={imbalance:.0f},tr={ob_imbalance_trend:.1f})")

            # KoÅŸul C: Likidite yeterli
            cond_c = volume_24h >= eq_min_volume_24h and spread_pct <= eq_max_spread
            if cond_c:
                eq_pass_count += 1
                eq_reasons.append(f"C:Liq(${volume_24h/1e6:.1f}M,sp={spread_pct:.2f}%)")

            # Gate kararÄ±:
            # - Adaptive modes (LEGACY + SMART_V2): 1/3 ile soft-pass, 0/3 ise yÃ¼ksek skorda kontrollÃ¼ geÃ§iÅŸ
            # - Other modes: 2/3 ÅŸartÄ±nÄ± korur
            eq_required = 2 if not adaptive_mode else 1
            eq_hard_mode = (ENTRY_QUALITY_MODE == 'hard') and not adaptive_mode
            eq_penalty = 15 if not adaptive_mode else 8

            if eq_pass_count < eq_required:
                entry_quality_pass = False
                fail_detail = f"EQ_GATE_FAIL({eq_pass_count}/3: {','.join(eq_reasons) or 'none'})"
                adaptive_hard_reject = adaptive_mode and eq_pass_count == 0 and score < 95
                if eq_hard_mode or adaptive_hard_reject:
                    logger.info(f"ðŸš« {fail_detail}: {symbol} {signal_side} score={score} | vol={volume_ratio:.2f}x imb={imbalance:.0f} ob_tr={ob_imbalance_trend:.1f} vol24h=${volume_24h/1e6:.1f}M sp={spread_pct:.2f}%")
                    return None
                else:  # soft mode
                    score -= eq_penalty
                    reasons.append(f"{fail_detail}-P{eq_penalty}")
                    logger.info(f"âš ï¸ {fail_detail}: {symbol} {signal_side} score-={eq_penalty} â†’ {score}")
            else:
                reasons.append(f"EQ_PASS({eq_pass_count}/3)")
                if eq_pass_count == 3:
                    reasons.append("EQ_STRONG")

        # =====================================================================
        # PHASE HYBRID: EXECUTION QUALITY SCORE (microstructure + confluence)
        # =====================================================================
        atr_pct_for_exec = (atr / price * 100) if price > 0 else 2.0
        fib_active_for_exec = bool(fib_context.get('fib_active', False)) if fib_context else False
        fib_bonus_for_exec = float(fib_context.get('fib_score_bonus', 0)) if fib_context else 0.0
        exec_quality = compute_execution_quality_score(
            signal_side=signal_side,
            confidence_score=score,
            volume_ratio=volume_ratio,
            spread_pct=spread_pct,
            atr_pct=atr_pct_for_exec,
            imbalance=imbalance,
            ob_imbalance_trend=ob_imbalance_trend,
            eq_count=eq_pass_count,
            fib_active=fib_active_for_exec,
            fib_bonus=fib_bonus_for_exec,
            is_volume_spike=is_volume_spike,
            zscore=zscore,
            adx=adx,
            hurst=hurst,
        )
        exec_quality_score = float(exec_quality.get("score", score))
        exec_quality_passed = bool(exec_quality.get("passed", True))
        exec_quality_notes = list(exec_quality.get("notes", []))
        if exec_quality.get("strict_passed"):
            score += 4
            reasons.append(f"EXEC_STRONG({exec_quality_score:.0f})")
        elif exec_quality_passed:
            score += 1
            reasons.append(f"EXEC_OK({exec_quality_score:.0f})")
        else:
            score -= 10
            reasons.append(f"EXEC_WEAK({exec_quality_score:.0f})")
            # Very weak execution quality is now a hard reject.
            if exec_quality_score < (EXEC_QUALITY_MIN_SCORE - 10):
                logger.info(
                    f"ðŸš« EXEC_QUALITY_VETO: {symbol} {signal_side} exec={exec_quality_score:.1f} "
                    f"< {EXEC_QUALITY_MIN_SCORE - 10:.1f} | vol={volume_ratio:.1f}x sp={spread_pct:.3f}% "
                    f"imb={imbalance:.1f} tr={ob_imbalance_trend:.1f}"
                )
                return None

        # =====================================================================
        # AÅžAMA 2: KONFÄ°RMASYON FÄ°LTRELERÄ° (Skor Vermez, Sadece Kontrol Eder)
        # Coin istatistiklerine gÃ¶re dinamik eÅŸikler kullanÄ±lÄ±r
        # =====================================================================
        confirmation_passed = True
        confirmation_fails = []
        
        # ===================================================================
        # Phase 110: COIN_TREND sadece pozisyon boyutunu etkiler
        # Sinyal Ã¼retiminde hiÃ§ etkisi yok - coin_daily_trend sinyale eklenir
        # Position sizing aÅŸamasÄ±nda kullanÄ±lÄ±r
        # ===================================================================
        # coin_daily_trend sinyale ekleniyor (aÅŸaÄŸÄ±da), burada iÅŸlem yok
        
        # Dinamik eÅŸikler hesapla (coin_stats varsa kullan, yoksa varsayÄ±lan)
        if coin_stats and coin_stats.get('sample_count', 0) >= 10:
            # Volume dinamik eÅŸik: ortalama - 1 * std (minimum kabul edilen)
            vol_threshold = max(0.3, coin_stats['volume_avg'] - coin_stats['volume_std'])
            reasons.append(f"DynTH(V:{vol_threshold:.1f}x)")
        else:
            # VarsayÄ±lan eÅŸikler (yeterli veri yok)
            vol_threshold = 0.5
        
        # ===================================================================
        # Phase 111: RSI KONTROLÃœ KALDIRILDI
        # Mean reversion sisteminde RSI extreme'leri beklenen durum.
        # Z-Score zaten fiyat sapmasÄ±nÄ± Ã¶lÃ§Ã¼yor - RSI gereksiz.
        # ===================================================================
        
        # Konfirmasyon 2: Volume/Liquidity KontrolÃ¼ (Phase 123 + Phase EQG)
        # Phase EQG: 24h volume threshold artÄ±k EQ_MIN_VOLUME_24H ile kontrol ediliyor
        # Ama ek gÃ¼venlik olarak Ã§ok dÃ¼ÅŸÃ¼k hacim kontrolÃ¼ kalÄ±yor
        adaptive_mode = str(strategy_mode).upper() in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2)
        min_volume = 500_000  # $500K min 24h volume (hard floor)
        if adaptive_mode:
            # Adaptive modes (LEGACY + SMART_V2): allow more mid-cap coverage while keeping microcaps filtered.
            min_volume = 300_000
            vol_threshold = max(0.18, vol_threshold * 0.60)
        
        if volume_24h < min_volume:
            confirmation_passed = False
            confirmation_fails.append(f"LOW_LIQ(24h_Vol=${volume_24h/1_000_000:.1f}M < $0.5M)")
        
        # Phase EQG: Volume ratio kontrolÃ¼ tekrar aktif
        if (volume_ratio + 1e-9) < vol_threshold:
            confirmation_passed = False
            confirmation_fails.append(f"LOW_VOL({volume_ratio:.2f}x<{vol_threshold:.2f})")
        
        # Konfirmasyon 3: Hurst Regime KontrolÃ¼ (SADECE UYARI - VETO DEÄžÄ°L)
        if hurst > 0.65:
            reasons.append(f"HURST_WARN({hurst:.2f}>0.65)")
        
        # Konfirmasyon 4: Liquidity Sweep KontrolÃ¼
        # Ters yÃ¶nde sweep varsa pozisyon aÃ§ma
        if sweep_result and sweep_result.get('sweep_type'):
            sweep_type = sweep_result['sweep_type']
            if sweep_type == 'BULLISH' and signal_side == 'SHORT':
                confirmation_passed = False
                confirmation_fails.append("SWEEP_CONTRA(BULL)")
            elif sweep_type == 'BEARISH' and signal_side == 'LONG':
                confirmation_passed = False
                confirmation_fails.append("SWEEP_CONTRA(BEAR)")
            else:
                # AynÄ± yÃ¶nde sweep = bonus log (sinyal gÃ¼Ã§lendi)
                reasons.append(f"Sweep({sweep_type})")
        
        # Konfirmasyon 5: SMT Divergence KontrolÃ¼
        # Ters yÃ¶nde divergence varsa dikkatli ol (uyarÄ±, veto deÄŸil)
        smt_div = smt_divergence_detector.last_divergence
        if smt_div and smt_div.get('divergence_type'):
            div_type = smt_div['divergence_type']
            age = datetime.now().timestamp() - smt_divergence_detector.divergence_time
            if age < 300:  # Son 5 dakika
                if div_type == 'BULLISH' and signal_side == 'SHORT':
                    # UyarÄ± - veto deÄŸil ama log
                    reasons.append("SMT_WARN(BULL)")
                elif div_type == 'BEARISH' and signal_side == 'LONG':
                    reasons.append("SMT_WARN(BEAR)")
                else:
                    # AynÄ± yÃ¶nde = teyit
                    reasons.append(f"SMT({div_type})")
        
        # Konfirmasyon baÅŸarÄ±sÄ±z mÄ±?
        if not confirmation_passed:
            only_liq_vol_fails = all(
                f.startswith("LOW_LIQ(") or f.startswith("LOW_VOL(")
                for f in confirmation_fails
            )
            legacy_soft_pass = (
                adaptive_mode
                and only_liq_vol_fails
                and score >= 88
                and eq_pass_count >= 1
            )
            if legacy_soft_pass:
                penalty = 8 if len(confirmation_fails) >= 2 else 5
                score = max(40, score - penalty)
                reasons.append(f"CONF_SOFT({len(confirmation_fails)})")
                logger.info(
                    f"ðŸŸ¨ CONF_SOFT_PASS: {symbol} {signal_side} score-={penalty} â†’ {score} "
                    f"| fails={';'.join(confirmation_fails)}"
                )
                confirmation_passed = True
            else:
                logger.info(f"ðŸš« CONF_FAIL: {symbol} {signal_side} score={score} failed: {', '.join(confirmation_fails)}")
                return None
        
        # TÃ¼m konfirmasyonlar geÃ§ti - devam et
        
        # =====================================================================
        # PHASE 99: UNIFIED DYNAMIC LEVERAGE (All Factors Combined)
        # Combines: Spread + Price + Volatility + Balance Protection
        # This is the SINGLE source of truth for leverage (UI + Binance)
        # =====================================================================
        
        import math
        
        # Get spread-adjusted parameters (includes leverage, SL/TP multipliers, pullback)
        # Get volatility-adjusted parameters (includes leverage, SL/TP multipliers, pullback)
        # Calculate actual volatility_pct from ATR and price
        if price > 0 and atr > 0:
            volatility_pct = (atr / price) * 100
        else:
            volatility_pct = 15.0  # Default to mid-range if unknown
        spread_params = get_volatility_adjusted_params(volatility_pct, atr, price, spread_pct)
        
        # Base leverage from Spread level (low spread = high leverage)
        # Phase 152: price_factor get_volatility_adjusted_params'da hesaplanÄ±yor (Ã§ifte hesaplama fixlendi)
        base_leverage = spread_params['leverage']
        
        # 1. VOLATILITY FACTOR: High ATR = lower leverage
        # ATR as % of price: <10% = 1.0, 10-20% = 0.8, 20-30% = 0.6, 30-50% = 0.4, 50%+ = 0.3
        volatility_pct = (atr / price * 100) if price > 0 and atr > 0 else 10.0
        if volatility_pct <= 10.0:
            volatility_factor = 1.0   # Low volatility - no reduction
        elif volatility_pct <= 20.0:
            volatility_factor = 0.8   # Normal volatility
        elif volatility_pct <= 30.0:
            volatility_factor = 0.6   # High volatility
        elif volatility_pct <= 50.0:
            volatility_factor = 0.4   # Very high volatility
        else:
            volatility_factor = 0.3   # Extreme volatility
        
        # 2. BALANCE PROTECTION FACTOR
        leverage_mult = balance_protector.calculate_leverage_multiplier(
            balance_protector.peak_balance
        )
        
        # COMBINED LEVERAGE: base Ã— volatility Ã— balance_protection Ã— user_multiplier Ã— strategy_multiplier
        # Phase 152: price_factor kaldÄ±rÄ±ldÄ± â€” get_volatility_adjusted_params zaten uyguluyor
        # Phase 216: User-controlled leverage multiplier from settings
        user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        final_leverage = int(round(base_leverage * volatility_factor * leverage_mult * user_lev_mult * strategy_leverage_mult))

        # Ensure leverage bounds (3-75x)
        final_leverage = max(3, min(75, final_leverage))
        if volatile_soft_risk_cap:
            old_leverage = final_leverage
            final_leverage = min(final_leverage, VOLATILE_VETO_SOFTPASS_LEVERAGE_CAP)
            if final_leverage < old_leverage:
                reasons.append(f"VOL_CAP({old_leverage}->{final_leverage}x)")

        # Log if any factor reduced leverage significantly
        if volatility_factor < 0.9 or leverage_mult < 0.9 or user_lev_mult != 1.0 or strategy_leverage_mult != 1.0:
            logger.info(
                f"ðŸ“Š Unified Leverage: base={base_leverage}x Ã— vol={volatility_factor:.2f} Ã— bal={leverage_mult:.2f} "
                f"Ã— user={user_lev_mult:.1f} Ã— strat={strategy_leverage_mult:.2f} â†’ {final_leverage}x | "
                f"{symbol} @ ${price:.6f} (ATR:{volatility_pct:.1f}%)"
            )

        # Use spread-based SL/TP multipliers (override regime-based)
        atr_sl = spread_params['sl_multiplier']
        atr_tp = spread_params['tp_multiplier']
        trail_mult = spread_params['trail_multiplier']
        effective_exit_tightness = _clamp(
            (
                getattr(global_paper_trader, 'exit_tightness', 1.0)
                if 'global_paper_trader' in globals() and global_paper_trader
                else 1.0
            ) * strategy_exit_mult,
            0.3,
            15.0
        )
        
        # Adjust based on Hurst regime (fine-tuning)
        if hurst < 0.45:  # Strong Mean Reversion
            atr_tp *= 1.2  # Wider TP for mean reversion
            trail_act = atr * 1.0
        elif hurst > 0.55:  # Trending
            atr_tp *= 1.3  # Even wider TP for trends
            trail_act = atr * 1.5
        else:
            trail_act = atr * 1.2
        
        # Phase 13: Volatility Adjustments (keep existing logic)
        if volatility_ratio > 1.5:
            atr_sl *= 1.2
            atr_tp *= 1.5
            reasons.append(f"VolExp({volatility_ratio:.1f}x)")
        elif volatility_ratio < 0.8:
            atr_tp *= 0.8
            reasons.append("LowVol")
        
        # Spread Protection Buffer
        spread_buffer = 0.0
        if spread_pct > 0.1:
            spread_buffer = price * (spread_pct / 100)
            reasons.append(f"SpreadProt({spread_pct:.2f}%)")
        
        # =====================================================================
        # PHASE HYBRID ENTRY: ATR + spread + volume + quality + settings multiplier
        # =====================================================================
        entry_tightness = (
            getattr(global_paper_trader, 'entry_tightness', 1.0)
            if 'global_paper_trader' in globals() and global_paper_trader
            else 1.0
        )
        effective_entry_tightness = _clamp(entry_tightness * strategy_entry_mult, 0.5, 15.0)
        atr_pct_percent = (atr / price * 100) if price > 0 else 2.0
        hybrid_entry = get_hybrid_entry_profile(
            atr_pct=atr_pct_percent,
            spread_pct=spread_pct,
            volume_ratio=volume_ratio,
            leverage=final_leverage,
            entry_tightness=effective_entry_tightness,
            confidence_score=score,
            eq_count=eq_pass_count,
            fib_active=fib_active_for_exec,
            adx=adx,
            hurst=hurst,
            is_volume_spike=is_volume_spike,
        )
        pullback_pct = float(hybrid_entry.get('pullback_pct', 0.8)) / 100.0  # percent -> fraction
        atr_pct = atr_pct_percent / 100.0
        
        # =====================================================================
        # Phase 239V2: Dynamic minimum pullback floor (regime-aware)
        # =====================================================================
        dyn_result = compute_dynamic_min_pullback_pct(
            atr_pct=atr_pct_percent,
            spread_pct=spread_pct,
            volume_ratio=volume_ratio,
            ob_imbalance=imbalance,
            ob_imbalance_trend=ob_imbalance_trend,
            side=signal_side,
            signal_score=score,
            adx=adx,
            hurst=hurst,
            coin_daily_trend=coin_daily_trend,
            entry_algo_multiplier=effective_entry_tightness,
        )
        dyn_min_pb_pct = dyn_result['final_pct']
        dyn_regime_band = dyn_result['regime_band']
        dyn_min_pb_frac = dyn_min_pb_pct / 100.0  # percent -> fraction
        
        # Apply floor: pullback must be at least dynamic minimum
        if pullback_pct < dyn_min_pb_frac:
            original_pb = pullback_pct
            pullback_pct = dyn_min_pb_frac
            reasons.append(f"DYN_FLOOR({original_pb*100:.2f}%â†’{pullback_pct*100:.2f}%)")
        
        # Upper clamp uses regime band max (converted to fraction)
        dyn_clamp_max_frac = dyn_result['clamp_max'] / 100.0
        pullback_pct = _clamp(pullback_pct, dyn_min_pb_frac, max(0.12, dyn_clamp_max_frac))
        
        # (PULLBACK_V2_FINAL log is emitted below, after momentum/EQ relax)
        
        # =====================================================================
        # PHASE 152: MOMENTUM ENTRY â€” GÃ¼Ã§lÃ¼ trend'de kontrollÃ¼ gevÅŸeme
        # ADX > 30 (gÃ¼Ã§lÃ¼ trend) + Hurst > 0.55 (trending rejim) + 
        # Coin daily trend aligned â†’ Pullback'i %45'e dÃ¼ÅŸÃ¼r (tam bypass deÄŸil)
        # =====================================================================
        strong_momentum = (
            adx > 30 and
            hurst > 0.55 and
            (
                (signal_side == "LONG" and coin_daily_trend in ["BULLISH", "STRONG_BULLISH"]) or
                (signal_side == "SHORT" and coin_daily_trend in ["BEARISH", "STRONG_BEARISH"])
            )
        )
        
        if strong_momentum:
            original_pullback = pullback_pct
            # Phase 239: Controlled relaxation instead of full bypass
            pullback_pct = max(0.0035, pullback_pct * 0.45)  # min 0.35%, reduce to 45% of locked
            reasons.append(f"âš¡ MOMENTUM_RELAX(ADX={adx:.0f},H={hurst:.2f},pb {original_pullback*100:.2f}%â†’{pullback_pct*100:.2f}%)")
            logger.info(f"âš¡ MOMENTUM RELAXATION: {symbol} {signal_side} â€” pullback {original_pullback*100:.2f}%â†’{pullback_pct*100:.2f}% | ADX={adx:.1f} H={hurst:.2f} trend={coin_daily_trend}")
        elif ENTRY_QUALITY_GATE_ENABLED and eq_pass_count == 3:
            # PHASE EQG: STRONG QUALITY PULLBACK REDUCTION
            # 3/3 kalite koÅŸulu geÃ§tiyse â†’ daha erken giriÅŸ (trend baÅŸlangÄ±cÄ±nÄ± yakala)
            original_pb = pullback_pct
            pullback_pct *= 0.82
            reasons.append(f"EQ_EARLY(pb {original_pb*100:.1f}%â†’{pullback_pct*100:.1f}%)")
        
        # =====================================================================
        # Phase 239V2: FINAL FLOOR GUARD â€” absolute invariant
        # No relax (momentum, EQ, fib) may break the dynamic floor.
        # =====================================================================
        pre_final_pb = pullback_pct
        if pullback_pct < dyn_min_pb_frac:
            pullback_pct = dyn_min_pb_frac
            reasons.append(f"FLOOR_GUARD({pre_final_pb*100:.2f}%â†’{pullback_pct*100:.2f}%)")
        
        logger.info(
            f"PULLBACK_V2_FINAL: {symbol} {signal_side} hybrid={hybrid_entry.get('pullback_pct', 0.8):.2f}% "
            f"dyn_floor={dyn_min_pb_pct:.3f}% pre_final={pre_final_pb*100:.3f}% "
            f"final={pullback_pct*100:.3f}% tight={dyn_result.get('tight_mult', 1):.3f} "
            f"regime={dyn_regime_band}"
        )
        
        if signal_side == "LONG":
            atr_entry = price * (1 - pullback_pct)
        else:
            atr_entry = price * (1 + pullback_pct)
        
        # =====================================================================
        # PHASE FIB: FIBONACCI ENTRY BLEND
        # Blend ATR-based entry with Fibonacci entry (alpha=0.35)
        # strong_momentum â†’ bypass (market entry), fib kapalÄ±
        # deviation > max_dev â†’ fallback to ATR entry
        # Phase EQG: EQ_STRONG durumunda Fib deviation limiti geniÅŸletilir (1.0% â†’ 1.5%)
        # =====================================================================
        ideal_entry = atr_entry  # Default: ATR-based entry
        fib_blend_applied = False
        max_dev = 1.5 if (ENTRY_QUALITY_GATE_ENABLED and eq_pass_count == 3) else FIB_MAX_ENTRY_DEV_PCT
        
        if not strong_momentum and FIB_ENABLED and FIB_ENTRY_ENABLED and fib_context:
            fib_entry = fib_context.get('fib_entry', 0)
            if fib_entry > 0 and fib_context.get('fib_active'):
                dev_pct = abs(fib_entry - atr_entry) / price * 100 if price > 0 else 999
                if dev_pct <= max_dev:
                    alpha = FIB_BLEND_ALPHA
                    ideal_entry = atr_entry * (1 - alpha) + fib_entry * alpha
                    fib_blend_applied = True
                    reasons.append(f"FibBlend(a={alpha})")
                    logger.info(f"ðŸ“ FIB ENTRY: {symbol} {signal_side} atr_entry={atr_entry:.6f} fib_entry={fib_entry:.6f} â†’ blend={ideal_entry:.6f} (dev={dev_pct:.2f}% max={max_dev:.1f}%)")
                else:
                    reasons.append(f"FibSkip(too_far,{dev_pct:.1f}%)")
        
        if signal_side == "LONG":
            sl = ideal_entry - (atr * atr_sl * effective_exit_tightness) - spread_buffer
            tp = ideal_entry + (atr * atr_tp * effective_exit_tightness)
            trail_activation = ideal_entry + (trail_act * effective_exit_tightness)
            trail_dist = atr * trail_mult * effective_exit_tightness
        else:
            sl = ideal_entry + (atr * atr_sl * effective_exit_tightness) + spread_buffer
            tp = ideal_entry - (atr * atr_tp * effective_exit_tightness)
            trail_activation = ideal_entry - (trail_act * effective_exit_tightness)
            trail_dist = atr * trail_mult * effective_exit_tightness
        
        # =====================================================================
        # PHASE 29: BALANCE-PROTECTED SIZE MULTIPLIER
        # =====================================================================
        
        # Base size from score
        size_mult = 1.0
        if score >= 90: size_mult = 1.5
        elif score < 80: size_mult = 0.8
        
        # Apply BalanceProtector adjustment
        balance_size_mult = balance_protector.calculate_position_size_multiplier(
            balance_protector.peak_balance
        )
        size_mult *= balance_size_mult
        
        # =====================================================================
        # PHASE 110: TREND-BASED POSITION SIZE REDUCTION
        # Trend karÅŸÄ±tÄ± trade'lerde pozisyon boyutunu azalt
        # =====================================================================
        trend_size_reduction = 1.0  # Default no reduction
        if coin_daily_trend == "STRONG_BEARISH" and signal_side == "LONG":
            trend_size_reduction = 0.7  # 30% smaller position
            reasons.append("ðŸ“‰ TrendConflict(-30%)")
        elif coin_daily_trend == "STRONG_BULLISH" and signal_side == "SHORT":
            trend_size_reduction = 0.7  # 30% smaller position
            reasons.append("ðŸ“ˆ TrendConflict(-30%)")
        elif coin_daily_trend == "BEARISH" and signal_side == "LONG":
            trend_size_reduction = 0.85  # 15% smaller position
            reasons.append("ðŸ“‰ trend_conflict(-15%)")
        elif coin_daily_trend == "BULLISH" and signal_side == "SHORT":
            trend_size_reduction = 0.85  # 15% smaller position
            reasons.append("ðŸ“ˆ trend_conflict(-15%)")
        
        size_mult *= trend_size_reduction
        if volatile_soft_risk_cap:
            size_mult *= VOLATILE_VETO_SOFTPASS_SIZE_MULT
            reasons.append(f"VOL_SIZE({VOLATILE_VETO_SOFTPASS_SIZE_MULT:.2f}x)")
        
        self.last_signal_time = now
        
        # Log spread level and leverage with ATR% for debugging
        reasons.append(f"Spread({spread_params['level']})")
        reasons.append(f"Lev({final_leverage}x)")
        
        # Debug: Log the actual ATR% value and what level it maps to
        logger.info(
            f"ðŸ“Š Signal {signal_side}: Spread%={spread_pct:.2f}% PB%={pullback_pct*100:.2f}% "
            f"(ATR:{atr_pct*100:.1f}%+Spread:{spread_pct:.2f}%) â†’ Level={spread_params['level']} â†’ "
            f"Lev={base_leverage}x (after BalProt: {final_leverage}x) | mode={strategy_mode}/{active_strategy}"
        )  # Phase 223: label was ATR% but value was spread_pct
        
        # Phase 127: Log successful signal generation for tracing
        logger.info(f"âœ… SIGNAL_GEN: {symbol} {signal_side} score={score} lev={final_leverage}x entry=${ideal_entry:.4f} PB={pullback_pct*100:.2f}%")
        
        return {
            'action': signal_side,
            'price': price,        # Signal price
            'entryPrice': ideal_entry, # Pending Order Price
            'sl': sl,
            'tp': tp,
            'trailActivation': trail_activation,
            'trailDistance': trail_dist,
            'reason': ", ".join(reasons),
            'timestamp': now,
            'confidenceScore': score,
            'sizeMultiplier': size_mult,
            'leverage': final_leverage,  # Phase 29: Dynamic leverage
            'strategyMode': strategy_mode,
            'activeStrategy': active_strategy,
            'strategyLabel': strategy_label,
            'strategyNotes': strategy_notes,
            'smartThresholdMult': strategy_threshold_mult,
            'smartEntryMult': strategy_entry_mult,
            'smartExitMult': strategy_exit_mult,
            'smartLeverageMult': strategy_leverage_mult,
            'spreadLevel': spread_params['level'],
            'pullbackPct': round(pullback_pct * 100, 2),  # Phase 160: ATR+Spread based
            'pullbackMinDyn': round(dyn_min_pb_pct, 4),  # Phase 239V2: Dynamic floor (percent)
            'pullbackModelVersion': 'v2',  # Phase 239V2
            'pullbackDynBase': dyn_result.get('base', 0),
            'pullbackDynAdj': dyn_result.get('adj_total', 0),
            'pullbackDynFinal': round(pullback_pct * 100, 4),  # locked final (percent)
            'pullbackDynFloor': round(dyn_min_pb_pct, 4),       # dynamic floor (percent)
            'pullbackDynRegimeBand': dyn_regime_band,
            'atrPct': round(atr_pct * 100, 2),  # Phase 160: Raw ATR% for bounce calc
            'coinDailyTrend': coin_daily_trend,  # Phase 110: For position sizing
            'trendSizeReduction': trend_size_reduction,  # Phase 110: Applied reduction
            # Phase 153: ADX and Hurst for dynamic bounce confirmation
            'adx': adx,
            'hurst': hurst,
            'spreadPct': spread_pct,  # Phase 228: Real bid-ask spread for dynamic trail
            'volatility_pct': atr_pct * 100,  # Phase 228: Volatility for dynamic trail
            # Phase FIB: Fibonacci telemetry
            'fibActive': fib_context.get('fib_active', False) if fib_context else False,
            'fibLevel': fib_context.get('fib_level') if fib_context else None,
            'fibBonus': fib_context.get('fib_score_bonus', 0) if fib_context else 0,
            'fibEntry': fib_context.get('fib_entry', 0) if fib_context else 0,
            'atrEntry': atr_entry,
            'fibBlendAlpha': FIB_BLEND_ALPHA if fib_blend_applied else 0,
            'effectiveEntryTightness': effective_entry_tightness,
            'effectiveExitTightness': effective_exit_tightness,
            # Phase EQG: Entry Quality telemetry
            'volumeRatio': round(volume_ratio, 2),
            'isVolumeSpike': is_volume_spike,
            'imbalancePct': round(imbalance, 1),
            'obImbalanceTrend': round(ob_imbalance_trend, 1),
                'entryQualityPass': entry_quality_pass,
                'entryQualityReasons': eq_reasons,
                # Hybrid entry observability
                'trailEntryMinMovePct': hybrid_entry.get('trail_entry_min_move_pct', 0.8),
                'trailEntryMinRoiPct': hybrid_entry.get('trail_entry_min_roi_pct', 8.0),
                'entryThresholdMult': hybrid_entry.get('entry_threshold_mult', 1.0),
                'entryTightnessMult': hybrid_entry.get('entry_tightness_mult', 1.0),
                'entryExecScore': exec_quality_score,
                'entryExecPassed': exec_quality_passed,
                'entryExecNotes': exec_quality_notes,
            }


# ============================================================================
# BINANCE DATA STREAMER
# ============================================================================


# WhaleDetector removed â€” WhaleTracker (L4412) is the active implementation
# See project_analysis.md #5 for details

class PaperTradingEngine:
    """
    Simulates trading execution on the backend (Server-Side).
    Persists state to JSON to survive restarts.
    """
    def __init__(self, state_file: str = None):
        # Use persistent volume path on Fly.io, fallback to local for development
        if state_file is None:
            if os.path.exists("/data"):
                state_file = "/data/paper_trading_state.json"
                logger.info("ðŸ“ Using persistent volume: /data/paper_trading_state.json")
            else:
                state_file = "paper_trading_state.json"
                logger.info("ðŸ“ Using local storage: paper_trading_state.json")
        self.state_file = state_file
        self.balance = 10000.0
        self.initial_balance = 10000.0
        self.positions = []
        self.trades = []
        self.equity_curve = [{"time": int(datetime.now().timestamp() * 1000), "balance": 10000.0, "drawdown": 0.0}]
        self.stats = {
            "totalTrades": 0, "winningTrades": 0, "losingTrades": 0, "winRate": 0.0,
            "totalPnl": 0.0, "maxDrawdown": 0.0, "profitFactor": 0.0
        }
        self.enabled = True  # Phase 16: Auto-trade toggle
        # Phase 17: Cloud Trading Settings
        self.symbol = "SOLUSDT"
        self.leverage = 10
        self.risk_per_trade = 0.02  # 2%
        # Phase 18: Full Trading Parameters
        self.sl_atr = 15  # 1.5x ATR â€” tighter SL for better R:R
        self.tp_atr = 30  # 3.0x ATR â€” wider TP for better R:R
        self.trail_activation_atr = 1.5
        self.trail_distance_atr = 1.5  # Phase 222: 1.0â†’1.5 (trail %80 loss rate fix)
        self.sl_multiplier = 2.0  # ATR multiplier for SL (used in sync loop)
        self.tp_multiplier = 3.0  # ATR multiplier for TP (used in sync loop)
        # Phase 22: Multi-position config
        self.max_positions = 50  # Allow up to 50 positions
        self.allow_hedging = True  # Allow LONG + SHORT simultaneously
        # Algorithm sensitivity settings (can be adjusted via API)
        self.z_score_threshold = 1.6  # Min Z-Score for signal
        # Phase 50: Dynamic Min Score Range
        self.min_score_low = 60   # Minimum possible score (aggressive mode)
        self.min_score_high = 90  # Maximum possible score (defensive mode)
        self.min_confidence_score = 68  # Current effective min score (dynamically calculated)
        # Phase 36: Entry/Exit tightness settings
        self.entry_tightness = 1.8  # 0.5-15.0: Pullback multiplier (GevÅŸek/Loose mode)
        self.exit_tightness = 1.2   # 0.5-15.0: SL/TP multiplier
        # Strategy engine mode
        self.strategy_mode = STRATEGY_MODE_LEGACY  # LEGACY | SMART_V2
        # Phase 200: Counter-signal adaptive exit tightness cache TTL
        self.counter_signal_ttl = 900  # 15 minutes
        # Phase 19: Server-side persistent logs
        self.logs = []
        # Phase 20: Advanced Risk Management Config
        self.max_position_age_hours = 24
        self.daily_drawdown_limit = 5.0  # %5 gÃ¼nlÃ¼k kayÄ±p limiti
        self.trailing_drawdown_limit = 5.0  # Phase 206: Zirveden %5 dÃ¼ÅŸÃ¼ÅŸ limiti (Profit Lock)
        self.daily_peak_equity = 10000.0
        self.daily_peak_date = ""
        self.emergency_sl_pct = 3.5   # Phase 212: %5â†’%3.5 (10x lev = %35 margin max kayÄ±p)
        self.current_spread_pct = 0.05  # Will be updated from WebSocket
        self.daily_start_balance = 10000.0
        # Phase 217: Portfolio-level drawdown protection
        self.portfolio_max_unrealized_loss_pct = 15.0  # Toplam aÃ§Ä±k pozisyon max kayÄ±p %
        # Phase 217: Save state throttle
        self._last_save_time = 0
        self.leverage_multiplier = 1.0  # Phase 217: User-adjustable leverage multiplier (0.3-3.0)
        # Phase 34: Pending Orders System
        self.pending_orders = []  # List of pending limit orders waiting for pullback
        self.pending_order_timeout_seconds = 1800  # 30 minutes to fill or cancel
        # Pipeline metrics for fill rate observability
        self.pipeline_metrics = {
            'pending_created': 0, 'signal_confirmed': 0, 'pending_expired': 0,
            'stale_dropped': 0, 'trail_entry_start': 0, 'trail_entry_ok': 0,
            'trail_entry_fail': 0, 'trail_entry_timeout': 0, 'market_fallback': 0,
            'signal_missed': 0, 'spread_rejected': 0, 'drift_rejected': 0, 'filled': 0,
            'fallback_on_fail': 0, 'fallback_on_expire': 0,
            'thin_book_rejected': 0, 'mtf_rejected': 0, 'mtf_soft_override': 0,
            'pending_reinforced': 0, 'pending_flipped': 0, 'memory_soft_pass': 0,
            'thin_book_soft_override': 0, 'thin_book_super_override': 0,
            'order_attempted': 0, 'order_success': 0, 'order_failed': 0,
            'market_fallback_failed': 0,
            # Phase 237: Signal quality counters
            'soft_pass_count': 0, 'hard_reject_count': 0,
            'tradeability_reject_count': 0, 'false_negative_count': 0,
            'risk_gate_soft_pass': 0,
        }
        # Settings log spam guard
        self._last_settings_log_ts = 0
        self._last_settings_log_signature = ""
        # Symbol-level execution feedback for UI (latest rejection reason).
        self.execution_feedback = {}  # {symbol: {"reason": str, "ts": int}}
        
        # =========================================================================
        # COIN BLACKLIST SYSTEM
        # Automatically blocks coins that consistently cause losses
        # =========================================================================
        self.coin_blacklist = {}  # symbol -> {until: timestamp, reason: str, losses: int}
        self.coin_stats = {}  # symbol -> {wins: int, losses: int, consecutive_losses: int, last_trade_time: float}
        self.blacklist_threshold = 2  # Consecutive losses to trigger blacklist
        self.blacklist_duration_hours = 2  # Hours to keep coin blacklisted
        
        # Phase 224A: MAE/MFE Diagnostics + Signal EV
        self.score_band_stats = {}  # {"60-70": {wins, losses, total_win, total_loss, avg_win, avg_loss}}
        self.last_signal_per_coin = {}  # {symbol: {side, time}} for flip detection
        self.signal_memory = {}  # {symbol: {side, streak, last_seen, score, ...}}
        
        # Phase 60: AI Optimizer Toggle - kapalÄ±yken dinamik hesaplamalar yapÄ±lmaz
        self.ai_optimizer_enabled = False  # Default: OFF - manuel ayarlar geÃ§erli
        
        self.load_state()
        self.add_log("ðŸš€ Paper Trading Engine baÅŸlatÄ±ldÄ±")
    
    def get_today_pnl(self) -> dict:
        """
        Calculate today's PnL based on Turkey timezone (UTC+3).
        Returns dict with todayPnl (dollar) and todayPnlPercent.
        """
        # pytz imported globally
        
        # Turkey timezone (UTC+3)
        turkey_tz = pytz.timezone('Europe/Istanbul')
        now_turkey = datetime.now(turkey_tz)
        
        # Start of today in Turkey time
        today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_ms = int(today_start.timestamp() * 1000)
        
        # Sum PnL of trades closed today
        today_pnl = 0.0
        today_trades_count = 0
        
        for trade in self.trades:
            close_time = trade.get('closeTime', 0)
            if close_time >= today_start_ms:
                today_pnl += trade.get('pnl', 0)
                today_trades_count += 1
        
        # Calculate percent based on start of day balance
        # We store dayStartBalance or use initial if not set
        day_start_balance = getattr(self, 'day_start_balance', 10000.0)
        if day_start_balance <= 0:
            day_start_balance = 10000.0
        
        today_pnl_percent = (today_pnl / day_start_balance) * 100 if day_start_balance > 0 else 0
        
        return {
            'todayPnl': round(today_pnl, 2),
            'todayPnlPercent': round(today_pnl_percent, 2),
            'todayTradesCount': today_trades_count
        }
    
    def calculate_dynamic_min_score(self) -> int:
        """
        Phase 50: Dinamik Minimum Skor Hesaplama
        Son 10 trade'in win rate'ine gÃ¶re min_score_low ve min_score_high arasÄ±nda skor belirler.
        
        Phase 60: AI Optimizer kapalÄ±yken bu hesaplama ATLANIR.
        KullanÄ±cÄ±nÄ±n Settings Modal'dan ayarladÄ±ÄŸÄ± deÄŸerler geÃ§erli olur.
        
        Win Rate < 40% â†’ min_score_high (defansif mod)
        Win Rate > 60% â†’ min_score_low (agresif mod)
        Win Rate 40-60% â†’ orta deÄŸer (normal mod)
        """
        # Phase 60: AI Optimizer kapalÄ±ysa dinamik hesaplama yapma
        if not self.ai_optimizer_enabled:
            return self.min_confidence_score  # Manuel ayarÄ± koru
        
        # Son 10 trade'i al
        recent_trades = self.trades[-10:] if len(self.trades) >= 10 else self.trades
        
        if len(recent_trades) < 5:
            # Yeterli veri yok, orta deÄŸer kullan
            mid_score = (self.min_score_low + self.min_score_high) // 2
            self.min_confidence_score = mid_score
            return mid_score
        
        # Win rate hesapla
        wins = sum(1 for t in recent_trades if t.get('pnl', 0) > 0)
        win_rate = wins / len(recent_trades)
        
        # Dinamik skor hesapla
        # Win Rate 0% â†’ max score (70)
        # Win Rate 50% â†’ mid score (60) 
        # Win Rate 100% â†’ min score (50)
        score_range = self.min_score_high - self.min_score_low  # 70 - 50 = 20
        
        # win_rate arttÄ±kÃ§a skor DÃœÅžER (daha agresif)
        dynamic_score = self.min_score_high - int(win_rate * score_range)
        
        # AralÄ±k iÃ§inde kal
        dynamic_score = max(self.min_score_low, min(self.min_score_high, dynamic_score))
        
        # GÃ¼ncelle ve logla
        old_score = self.min_confidence_score
        self.min_confidence_score = dynamic_score
        
        if old_score != dynamic_score:
            mode = "ðŸ›¡ï¸ Defansif" if dynamic_score >= 65 else ("âš”ï¸ Agresif" if dynamic_score <= 55 else "âš–ï¸ Normal")
            logger.info(f"ðŸ“Š Dynamic Min Score: {old_score} â†’ {dynamic_score} | WR: {win_rate*100:.0f}% | Mode: {mode}")
            self.add_log(f"ðŸ“Š Min Skor: {dynamic_score} ({mode}, WR:{win_rate*100:.0f}%)")
        
        return dynamic_score

    # =========================================================================
    # Signal Memory: same-coin reinforcement / flip context
    # =========================================================================
    def _prune_signal_memory(self, now_ms: int = None):
        if not SIGNAL_MEMORY_ENABLED:
            return
        if now_ms is None:
            now_ms = int(datetime.now().timestamp() * 1000)
        ttl_ms = SIGNAL_MEMORY_TTL_SECONDS * 1000
        for sym, mem in list(self.signal_memory.items()):
            if now_ms - int(mem.get('last_seen', 0)) > ttl_ms:
                self.signal_memory.pop(sym, None)

    def register_signal_memory(
        self,
        symbol: str,
        side: str,
        score: float,
        volume_ratio: float = 1.0,
        spread_pct: float = 0.05
    ) -> dict:
        """
        Track repeated signals per coin and produce reinforcement hints.
        Returns tuning context used by execution filters/pending logic.
        """
        if not SIGNAL_MEMORY_ENABLED:
            return {
                "reinforce_count": 0,
                "score_bonus": 0,
                "thinbook_scale": 1.0,
                "pending_extend_sec": 0,
                "flip_recent": False,
                "memory_side": side,
            }

        now_ms = int(datetime.now().timestamp() * 1000)
        self._prune_signal_memory(now_ms)

        safe_symbol = str(symbol or "").upper()
        safe_side = "LONG" if str(side).upper() in ("LONG", "BUY") else "SHORT"
        mem = self.signal_memory.get(safe_symbol)
        flip_recent = False

        if not mem:
            mem = {
                "side": safe_side,
                "streak": 1,
                "opposite_hits": 0,
                "first_seen": now_ms,
                "last_seen": now_ms,
                "score": float(score or 0),
                "volume_ratio": float(volume_ratio or 1.0),
                "spread_pct": float(spread_pct or 0.05),
            }
        else:
            prev_side = str(mem.get("side", safe_side)).upper()
            last_seen = int(mem.get("last_seen", now_ms))
            quick_window_ms = 4 * 60 * 1000

            if prev_side == safe_side:
                mem["streak"] = min(6, int(mem.get("streak", 1)) + 1)
                mem["opposite_hits"] = max(0, int(mem.get("opposite_hits", 0)) - 1)
            else:
                mem["streak"] = 1
                mem["opposite_hits"] = min(4, int(mem.get("opposite_hits", 0)) + 1)
                flip_recent = (now_ms - last_seen) <= quick_window_ms

            mem["side"] = safe_side
            mem["last_seen"] = now_ms
            mem["score"] = float(score or 0)
            mem["volume_ratio"] = (float(mem.get("volume_ratio", 1.0)) * 0.65) + (float(volume_ratio or 1.0) * 0.35)
            mem["spread_pct"] = (float(mem.get("spread_pct", 0.05)) * 0.65) + (float(spread_pct or 0.05) * 0.35)

        self.signal_memory[safe_symbol] = mem

        reinforce_count = max(0, int(mem.get("streak", 1)) - 1)
        score_bonus = min(SIGNAL_MEMORY_MAX_BONUS, reinforce_count * SIGNAL_MEMORY_BONUS_STEP)
        thinbook_relax = min(0.35, reinforce_count * SIGNAL_MEMORY_THINBOOK_RELAX_STEP)
        thinbook_scale = max(SIGNAL_MEMORY_THINBOOK_MIN_SCALE, 1.0 - thinbook_relax)
        pending_extend_sec = min(
            SIGNAL_MEMORY_PENDING_EXTEND_MAX_SECONDS,
            reinforce_count * SIGNAL_MEMORY_PENDING_EXTEND_STEP_SECONDS
        )

        return {
            "reinforce_count": reinforce_count,
            "score_bonus": score_bonus,
            "thinbook_scale": thinbook_scale,
            "pending_extend_sec": pending_extend_sec,
            "flip_recent": flip_recent,
            "memory_side": safe_side,
            "opposite_hits": int(mem.get("opposite_hits", 0)),
        }
    
    # =========================================================================
    # Phase 224B: EV-Based Signal Filter
    # =========================================================================
    def calculate_signal_ev(self, signal: dict) -> float:
        """
        Phase 224B: Expected Value hesaplama.
        EV = p(win) * avg_win - (1-p) * |avg_loss|
        Skor bandÄ±na gÃ¶re historik win rate kullanÄ±r.
        Returns: EV value (positive = profitable, negative = avoid)
        """
        score = signal.get('confidenceScore', 0)
        
        # Skor bandÄ±: 50-60, 60-70, 70-80, 80-90, 90-100
        band = min(90, max(50, (score // 10) * 10))
        band_key = f"{band}-{band + 10}"
        
        hist = self.score_band_stats.get(band_key, {})
        total = hist.get('wins', 0) + hist.get('losses', 0)
        
        if total < 5:
            # Yetersiz veri â†’ EV tahmini: score'u PnL Ã¶lÃ§eÄŸine dÃ¶nÃ¼ÅŸtÃ¼r
            # avg_win/avg_loss tipik ~0.01-0.05 USDT/margin aralÄ±ÄŸÄ±nda
            return (score - 60) * 0.005  # 60 skor = 0 EV, 80 skor = 0.1 EV
        
        p_win = hist['wins'] / total
        avg_win = hist.get('avg_win', 0)
        avg_loss = abs(hist.get('avg_loss', 0))
        
        ev = p_win * avg_win - (1 - p_win) * avg_loss
        return ev
    
    def update_score_band_stats(self, signal_score: int, pnl: float):
        """Phase 224B: Trade kapanÄ±nca skor bandÄ± istatistiÄŸini gÃ¼ncelle."""
        band = min(90, max(50, (signal_score // 10) * 10))
        band_key = f"{band}-{band + 10}"
        
        if band_key not in self.score_band_stats:
            self.score_band_stats[band_key] = {
                'wins': 0, 'losses': 0,
                'total_win': 0.0, 'total_loss': 0.0,
                'avg_win': 0.0, 'avg_loss': 0.0
            }
        
        stats = self.score_band_stats[band_key]
        if pnl > 0:
            stats['wins'] += 1
            stats['total_win'] += pnl
        else:
            stats['losses'] += 1
            stats['total_loss'] += pnl
        
        stats['avg_win'] = stats['total_win'] / max(1, stats['wins'])
        stats['avg_loss'] = stats['total_loss'] / max(1, stats['losses'])
    
    def get_dynamic_risk_per_trade(self) -> float:
        """
        Son 5 trade'in performansÄ±na gÃ¶re risk yÃ¼zdesini dinamik ayarla.
        4+ win: %4 (agresif), 2-3 win: %3 (standart), 0-1 win: %2 (koruyucu)
        """
        if len(self.trades) < 5:
            return self.risk_per_trade  # Yeterli veri yok, varsayÄ±lan kullan
        
        # Son 5 trade'i al
        last_5 = self.trades[-5:]
        wins = sum(1 for t in last_5 if t.get('pnl', 0) > 0)
        
        if wins >= 4:
            # Kazanma serisi: agresif
            return 0.04  # %4
        elif wins >= 2:
            # Normal: standart
            return 0.03  # %3
        else:
            # Kaybetme serisi: koruyucu
            return 0.02  # %2
    
    def add_log(self, message: str):
        """Add a timestamped log entry (persisted to state and SQLite)."""
        # Use Turkey timezone
        from zoneinfo import ZoneInfo
        turkey_tz = ZoneInfo('Europe/Istanbul')
        turkey_now = datetime.now(turkey_tz)
        timestamp = turkey_now.strftime("%H:%M:%S")
        ts = int(turkey_now.timestamp() * 1000)
        entry = {"time": timestamp, "message": message, "ts": ts}
        self.logs.append(entry)
        self.logs = self.logs[-100:]  # Keep last 100 logs in memory
        logger.info(f"[PaperTrading] {message}")
        
        # Save to SQLite (async, non-blocking)
        try:
            safe_create_task(sqlite_manager.add_log(timestamp, message, ts))
        except Exception:
            pass  # Ignore if event loop not running

    def set_execution_feedback(self, symbol: str, reason: str):
        """Store latest execution-stage rejection reason for a symbol."""
        if not symbol:
            return
        now_ms = int(datetime.now().timestamp() * 1000)
        self.execution_feedback[symbol] = {
            "reason": str(reason),
            "ts": now_ms,
        }

    def clear_execution_feedback(self, symbol: str):
        """Clear execution feedback once symbol progresses to pending/filled."""
        if symbol in self.execution_feedback:
            self.execution_feedback.pop(symbol, None)

    def get_execution_feedback(self, symbol: str, ttl_sec: int = 1800) -> Optional[dict]:
        """Get recent execution feedback; auto-expire stale entries."""
        if not symbol:
            return None
        item = self.execution_feedback.get(symbol)
        if not item:
            return None
        ts = int(item.get("ts", 0) or 0)
        if ts <= 0:
            return None
        age_ms = int(datetime.now().timestamp() * 1000) - ts
        if age_ms > ttl_sec * 1000:
            self.execution_feedback.pop(symbol, None)
            return None
        return item
    
    # =========================================================================
    # COIN BLACKLIST SYSTEM METHODS
    # =========================================================================
    
    def is_coin_blacklisted(self, symbol: str) -> bool:
        """Check if a coin is currently blacklisted."""
        if symbol not in self.coin_blacklist:
            return False
        
        blacklist_entry = self.coin_blacklist[symbol]
        until_time = blacklist_entry.get('until', 0)
        
        if datetime.now().timestamp() > until_time:
            # Blacklist expired, remove it
            del self.coin_blacklist[symbol]
            self.add_log(f"âœ… {symbol} blacklist'ten Ã§Ä±karÄ±ldÄ± (sÃ¼re doldu)")
            return False
        
        return True
    
    def add_to_blacklist(self, symbol: str, reason: str, losses: int):
        """Add a coin to the blacklist."""
        until_time = datetime.now().timestamp() + (self.blacklist_duration_hours * 3600)
        self.coin_blacklist[symbol] = {
            'until': until_time,
            'reason': reason,
            'losses': losses,
            'added_at': datetime.now().isoformat()
        }
        self.add_log(f"ðŸš« {symbol} BLACKLIST'e eklendi: {reason} ({self.blacklist_duration_hours}h)")
        logger.warning(f"Coin blacklisted: {symbol} - {reason}")
    
    def update_coin_stats(self, symbol: str, is_win: bool, pnl: float):
        """Update coin statistics after a trade closes."""
        if symbol not in self.coin_stats:
            self.coin_stats[symbol] = {
                'wins': 0,
                'losses': 0,
                'consecutive_losses': 0,
                'consecutive_wins': 0,
                'total_pnl': 0.0,
                'last_trade_time': 0
            }
        
        stats = self.coin_stats[symbol]
        stats['last_trade_time'] = datetime.now().timestamp()
        stats['total_pnl'] += pnl
        
        if is_win:
            stats['wins'] += 1
            stats['consecutive_wins'] += 1
            stats['consecutive_losses'] = 0  # Reset loss streak
        else:
            stats['losses'] += 1
            stats['consecutive_losses'] += 1
            stats['consecutive_wins'] = 0  # Reset win streak
            
            # Check if should blacklist
            if stats['consecutive_losses'] >= self.blacklist_threshold:
                reason = f"{stats['consecutive_losses']} ardÄ±ÅŸÄ±k zarar"
                self.add_to_blacklist(symbol, reason, stats['consecutive_losses'])
                # Reset consecutive after blacklist
                stats['consecutive_losses'] = 0
    
    def clean_expired_blacklist(self):
        """Remove expired entries from blacklist."""
        now = datetime.now().timestamp()
        expired = [s for s, data in self.coin_blacklist.items() if now > data.get('until', 0)]
        for symbol in expired:
            del self.coin_blacklist[symbol]
            self.add_log(f"âœ… {symbol} blacklist sÃ¼resi doldu")
    
    def get_blacklist_info(self) -> dict:
        """Get current blacklist status for API/UI."""
        self.clean_expired_blacklist()
        return {
            'blacklisted_coins': list(self.coin_blacklist.keys()),
            'count': len(self.coin_blacklist),
            'details': self.coin_blacklist
        }

    # =========================================================================
    # PHASE 200: ADAPTIVE EXIT TIGHTNESS (Counter-Signal)
    # Per-position exit_tightness based on opposing signals
    # =========================================================================
    
    def get_effective_exit_tightness(self, pos: dict) -> float:
        """Get per-position exit_tightness with counter-signal modifier and BTC Macro Regime control.
        
        Phase 204: Adaptive Exits using BTC Macro + Coin Regime
        If BTC is strongly trending opposite to our position, tighten exits to take profit early.
        If BTC is trending in our direction, widen exits to ride the trend.
        """
        modifier = pos.get('counter_signal_modifier', 1.0)
        cs_time = pos.get('counter_signal_time', 0)
        side = pos.get('side', 'NONE')
        
        # Expire modifier after TTL (15 minutes)
        if modifier < 1.0 and cs_time > 0:
            now_ts = datetime.now().timestamp()
            if now_ts - cs_time > self.counter_signal_ttl:
                # Expired â€” reset to global
                pos['counter_signal_modifier'] = 1.0
                modifier = 1.0
        
        base_et = float(pos.get('effectiveExitTightnessBase', self.exit_tightness) or self.exit_tightness)
        effective_et = base_et * modifier
        
        # Phase 204: BTC Macro Regime checks
        try:
            # Check BTC trend (mtf_confirmation global)
            btc_trends = mtf_confirmation.coin_trends.get('BTCUSDT', {})
            btc_1d_trend = btc_trends.get('trend_1d', 'NEUTRAL')
            btc_4h_trend = btc_trends.get('trend_4h', 'NEUTRAL')
            
            # Phase 244: Only use 1D trend (4H too short-term, causes premature exits)
            is_btc_bullish = btc_1d_trend in ['BULLISH', 'STRONG_BULLISH']
            is_btc_bearish = btc_1d_trend in ['BEARISH', 'STRONG_BEARISH']
            
            # Counter-trend to BTC Macro: Tighten (softened from 0.7 to 0.85)
            if side == 'LONG' and is_btc_bearish:
                effective_et = min(effective_et, base_et * 0.85)  # Phase 244: 0.7â†’0.85
            elif side == 'SHORT' and is_btc_bullish:
                effective_et = min(effective_et, base_et * 0.85)  # Phase 244: 0.7â†’0.85
                
            # Pro-trend with BTC Macro: Loosen slightly (softened from 1.25 to 1.15)
            elif side == 'LONG' and is_btc_bullish:
                effective_et = max(effective_et, base_et * 1.15) # Phase 244: 1.25â†’1.15
            elif side == 'SHORT' and is_btc_bearish:
                effective_et = max(effective_et, base_et * 1.15) # Phase 244: 1.25â†’1.15
                
        except Exception as e:
            pass # Failsafe
            
        return max(0.3, min(15.0, effective_et)) # Clamp to bounds
    
    # =========================================================================
    # DYNAMIC ATR MULTIPLIER
    # Adjusts SL/TP based on current volatility conditions
    # =========================================================================
    
    def calculate_dynamic_atr_multiplier(self, atr: float, price: float, lookback_atr: float = None) -> float:
        """
        Calculate a dynamic multiplier for ATR-based SL/TP.
        
        Logic:
        - Normal volatility (ATR ~1% of price): multiplier = 1.0
        - High volatility (ATR >2% of price): multiplier = 1.3-1.5 (wider SL/TP)
        - Low volatility (ATR <0.5% of price): multiplier = 0.7-0.8 (tighter SL/TP)
        
        Returns: float between 0.7 and 1.5
        """
        if price <= 0 or atr <= 0:
            return 1.0
        
        # Calculate ATR as percentage of price
        atr_pct = (atr / price) * 100
        
        # Define volatility bands
        LOW_VOL_THRESHOLD = 0.5   # <0.5% = low volatility
        NORMAL_VOL = 1.0          # ~1% = normal
        HIGH_VOL_THRESHOLD = 2.0  # >2% = high volatility
        
        if atr_pct < LOW_VOL_THRESHOLD:
            # Low volatility: tighten SL/TP (0.7-0.9)
            multiplier = 0.7 + (atr_pct / LOW_VOL_THRESHOLD) * 0.2
        elif atr_pct > HIGH_VOL_THRESHOLD:
            # High volatility: widen SL/TP (1.2-1.5)
            excess_vol = min(atr_pct - HIGH_VOL_THRESHOLD, 3.0)  # Cap at 5%
            multiplier = 1.2 + (excess_vol / 3.0) * 0.3
        else:
            # Normal volatility: scale linearly (0.9-1.2)
            normalized = (atr_pct - LOW_VOL_THRESHOLD) / (HIGH_VOL_THRESHOLD - LOW_VOL_THRESHOLD)
            multiplier = 0.9 + normalized * 0.3
        
        return round(min(1.5, max(0.7, multiplier)), 2)

    # =========================================================================
    # PHASE 30: KELLY CRITERION POSITION SIZING
    # =========================================================================
    
    def calculate_kelly_fraction(self) -> float:
        """
        Kelly Criterion ile optimal pozisyon boyutu hesapla.
        Kelly% = W - [(1-W) / R]
        W = Win rate (son 20 trade)
        R = Average Win / Average Loss
        
        Half-Kelly kullanÄ±lÄ±r (gÃ¼venlik iÃ§in).
        Returns: %1-%5 arasÄ± risk oranÄ±
        """
        # Minimum trade sayÄ±sÄ±na ulaÅŸmadÄ±ysa default kullan
        if len(self.trades) < 10:
            return self.risk_per_trade  # Default %2
        
        # Son 20 trade'i al
        recent_trades = self.trades[-20:]
        
        wins = [t for t in recent_trades if t.get('pnl', 0) > 0]
        losses = [t for t in recent_trades if t.get('pnl', 0) < 0]
        
        if not wins or not losses:
            return self.risk_per_trade
        
        # Win rate hesapla
        win_rate = len(wins) / len(recent_trades)
        
        # Ortalama kazanÃ§ ve kayÄ±p
        avg_win = np.mean([t['pnl'] for t in wins])
        avg_loss = abs(np.mean([t['pnl'] for t in losses]))
        
        if avg_loss <= 0:
            return self.risk_per_trade
        
        # Win/Loss ratio
        R = avg_win / avg_loss
        
        # Kelly formÃ¼lÃ¼
        kelly = win_rate - ((1 - win_rate) / R)
        
        # Half-Kelly (daha gÃ¼venli)
        half_kelly = kelly * 0.5
        
        # SÄ±nÄ±rla: %1 - %5 arasÄ±
        final_risk = max(0.01, min(0.05, half_kelly))
        
        logger.debug(f"Kelly Calculation: WR={win_rate:.2f}, R={R:.2f}, Kelly={kelly:.3f}, Final={final_risk:.3f}")
        
        return final_risk
    
    def get_kelly_stats(self) -> dict:
        """Kelly hesaplama istatistikleri."""
        if len(self.trades) < 10:
            return {"status": "insufficient_data", "trades_needed": 10 - len(self.trades)}
        
        recent = self.trades[-20:]
        wins = [t for t in recent if t.get('pnl', 0) > 0]
        losses = [t for t in recent if t.get('pnl', 0) < 0]
        
        win_rate = len(wins) / len(recent) if recent else 0
        avg_win = np.mean([t['pnl'] for t in wins]) if wins else 0
        avg_loss = abs(np.mean([t['pnl'] for t in losses])) if losses else 1
        
        return {
            "status": "active",
            "sample_size": len(recent),
            "win_rate": round(win_rate * 100, 1),
            "avg_win": round(avg_win, 2),
            "avg_loss": round(avg_loss, 2),
            "win_loss_ratio": round(avg_win / avg_loss if avg_loss > 0 else 0, 2),
            "kelly_fraction": round(self.calculate_kelly_fraction() * 100, 2)
        }
    
    # =========================================================================
    # ASYNC OPEN_POSITION FOR AUTO-TRADING
    # =========================================================================
    
    async def open_position(self, side: str, price: float, atr: float, signal: dict, symbol: str = None):
        """
        Open a new position for auto-trading from background scanner.
        
        Args:
            side: 'LONG' or 'SHORT'
            price: Current price
            atr: Average True Range value
            signal: Signal dict with optional parameters
            symbol: Symbol to trade (defaults to self.symbol)
        """
        if not self.enabled:
            self.add_log(f"â¸ï¸ Auto-trade kapalÄ±, iÅŸlem yapÄ±lmadÄ±")
            return None
        
        # Phase 191: Paper pozisyon aÃ§mayÄ± engelle â€” sadece live
        if not live_binance_trader.enabled:
            logger.debug(f"ðŸ“„ Paper trade skipped: {side} {symbol if symbol else self.symbol} (live only mode)")
            return None
        
        # Use provided symbol or default
        trade_symbol = symbol if symbol else self.symbol
        
        # BLACKLIST CHECK: Skip coins that consistently cause losses
        if self.is_coin_blacklisted(trade_symbol):
            self.set_execution_feedback(trade_symbol, "BLACKLISTED")
            logger.debug(f"Skipping {trade_symbol} - blacklisted")
            return None
        
        # Check position + pending order limits
        total_exposure = len(self.positions) + len(self.pending_orders)
        if total_exposure >= self.max_positions:
            self.set_execution_feedback(trade_symbol, "MAX_EXPOSURE")
            logger.info(f"ðŸš« OPEN_POS SKIP: Max exposure reached ({total_exposure}/{self.max_positions})")
            return None  # Silently skip to avoid log spam
        
        # Phase 217: Direction exposure limit â€” max %70 aynÄ± yÃ¶nde (count-based)
        long_count = sum(1 for p in self.positions if p.get('side') == 'LONG')
        short_count = sum(1 for p in self.positions if p.get('side') == 'SHORT')
        max_same_direction = max(3, self.max_positions * 70 // 100)
        if side == 'LONG' and long_count >= max_same_direction:
            self.set_execution_feedback(trade_symbol, "DIRECTION_LIMIT_LONG")
            logger.info(f"ðŸš« DIRECTION LIMIT: {long_count} LONG aÃ§Ä±k (max {max_same_direction})")
            return None
        if side == 'SHORT' and short_count >= max_same_direction:
            self.set_execution_feedback(trade_symbol, "DIRECTION_LIMIT_SHORT")
            logger.info(f"ðŸš« DIRECTION LIMIT: {short_count} SHORT aÃ§Ä±k (max {max_same_direction})")
            return None
        
        # Phase 219: USDT-based directional exposure limit â€” max %40 of balance per direction
        # Prevents overexposure to one direction. Uses margin (sizeUsd/leverage) as actual capital at risk.
        MAX_DIRECTION_EXPOSURE_PCT = 0.40  # 40% of wallet balance per direction
        same_dir_margin = sum(
            p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
            for p in self.positions if p.get('side') == side
        )
        # Also count pending orders for same direction
        same_dir_margin += sum(
            p.get('sizeUsd', 0) / max(1, p.get('leverage', 10))
            for p in self.pending_orders if p.get('side') == side
        )
        max_dir_exposure = self.balance * MAX_DIRECTION_EXPOSURE_PCT
        if same_dir_margin >= max_dir_exposure:
            self.set_execution_feedback(trade_symbol, "DIRECTION_EXPOSURE")
            logger.info(f"ðŸš« DIRECTION EXPOSURE: {side} margin ${same_dir_margin:.2f} >= ${max_dir_exposure:.2f} ({MAX_DIRECTION_EXPOSURE_PCT*100:.0f}% of ${self.balance:.2f})")
            return None
        
        # =========================================================================
        # PHASE 33: POSITION SCALING LOGIC
        # =========================================================================
        # Count entries for this specific coin and direction (positions + pending)
        same_coin_same_dir_pos = [p for p in self.positions if p.get('symbol') == trade_symbol and p.get('side') == side]
        same_coin_same_dir_pend = [p for p in self.pending_orders if p.get('symbol') == trade_symbol and p.get('side') == side]
        
        if len(same_coin_same_dir_pos) + len(same_coin_same_dir_pend) >= 3:
            self.set_execution_feedback(trade_symbol, "SCALE_LIMIT")
            logger.info(f"ðŸš« OPEN_POS SKIP: Scale-in limit reached for {trade_symbol} {side}")
            return None  # Silently skip scale-in limit
        
        # Check for existing pending order for same symbol
        existing_pending = next((p for p in self.pending_orders if p.get('symbol') == trade_symbol), None)
        if existing_pending:
            now_ms = int(datetime.now().timestamp() * 1000)
            existing_side = existing_pending.get('side')
            new_score = int(signal.get('confidenceScore', 0) if signal else 0)
            old_score = int(existing_pending.get('signalScore', 0) or 0)
            score_gap = new_score - old_score

            if existing_side == side:
                # Same direction: reinforce pending instead of dropping new signal.
                reinforce_count = int(existing_pending.get('reinforcedCount', 0) or 0) + 1
                existing_pending['reinforcedCount'] = reinforce_count
                existing_pending['signalScore'] = max(old_score, new_score)
                existing_pending['lastReinforceAt'] = now_ms
                existing_pending['volatility_pct'] = (atr / price * 100) if price > 0 else existing_pending.get('volatility_pct', 2.0)
                existing_pending['spreadPct'] = signal.get('spreadPct', existing_pending.get('spreadPct', 0.05)) if signal else existing_pending.get('spreadPct', 0.05)
                existing_pending['volumeRatio'] = signal.get('volumeRatio', existing_pending.get('volumeRatio', 1.0)) if signal else existing_pending.get('volumeRatio', 1.0)

                # Blend entry with latest signal entry (small shift to avoid hard jumps).
                # Phase 239 fix: guard with pullbackLocked so entry never drifts past locked boundary.
                try:
                    new_entry = float(signal.get('entryPrice', existing_pending.get('entryPrice', price))) if signal else float(existing_pending.get('entryPrice', price))
                    old_entry = float(existing_pending.get('entryPrice', new_entry))
                    blend_alpha = 0.35 if score_gap >= 0 else 0.20
                    blended = old_entry * (1 - blend_alpha) + new_entry * blend_alpha
                    
                    # Clamp: blended entry must not exceed locked pullback entry
                    locked_entry_frac = float(existing_pending.get('pullbackLocked', 0))
                    # Defensive: real fraction is clamped â‰¤0.12; anything above is legacy percent
                    if locked_entry_frac > 0.12:
                        locked_entry_frac = locked_entry_frac / 100.0
                    if locked_entry_frac > 0:
                        signal_price = float(existing_pending.get('signalPrice', price))
                        if side == 'LONG':
                            # LONG: locked entry = signalPrice * (1 - fraction)
                            locked_limit = signal_price * (1 - locked_entry_frac)
                            blended = min(blended, locked_limit)
                        else:
                            # SHORT: locked entry = signalPrice * (1 + fraction)
                            locked_limit = signal_price * (1 + locked_entry_frac)
                            blended = max(blended, locked_limit)
                    
                    existing_pending['entryPrice'] = blended
                except Exception:
                    pass

                # Extend lifetime + speed up confirmation when reinforcement is strong.
                extend_sec = max(
                    180,
                    int(signal.get('memoryExtensionSec', 0) if signal else 0)
                )
                existing_pending['expiresAt'] = max(
                    int(existing_pending.get('expiresAt', now_ms)),
                    now_ms + (extend_sec * 1000)
                )
                confirm_after = int(existing_pending.get('confirmAfter', now_ms))
                if confirm_after > now_ms:
                    remaining = confirm_after - now_ms
                    speedup = 0.80 if reinforce_count <= 1 else 0.65
                    existing_pending['confirmAfter'] = now_ms + int(remaining * speedup)

                self.pipeline_metrics['pending_reinforced'] += 1
                self.set_execution_feedback(trade_symbol, f"PENDING_REINFORCED({reinforce_count})")
                logger.info(
                    f"ðŸ” PENDING REINFORCE: {trade_symbol} {side} score {old_score}->{existing_pending['signalScore']} "
                    f"reinforce={reinforce_count} entry={existing_pending.get('entryPrice', 0):.6f}"
                )
                return existing_pending

            # Opposite direction: allow flip only if new signal is meaningfully stronger.
            allow_flip = (
                score_gap >= SIGNAL_MEMORY_OPPOSITE_FLIP_MIN_SCORE_GAP
                or bool(signal.get('memoryFlipRecent', False) if signal else False)
            )
            if allow_flip:
                self.pending_orders.remove(existing_pending)
                self.pipeline_metrics['pending_flipped'] += 1
                logger.info(
                    f"ðŸ”€ PENDING FLIP: {trade_symbol} {existing_side}->{side} "
                    f"(score {old_score}->{new_score}, gap={score_gap})"
                )
            else:
                self.set_execution_feedback(trade_symbol, "PENDING_OPPOSITE_WEAK")
                logger.info(
                    f"ðŸš« OPEN_POS SKIP: Opposite pending exists for {trade_symbol} "
                    f"({existing_side}->{side}, score gap={score_gap})"
                )
                return None
        
        # Check if we already have opposite position in same coin (hedging check)
        same_coin_opposite = [p for p in self.positions if p.get('symbol') == trade_symbol and p.get('side') != side]
        if same_coin_opposite and not self.allow_hedging:
            self.set_execution_feedback(trade_symbol, "HEDGING_DISABLED")
            logger.info(f"ðŸš« OPEN_POS SKIP: Hedging disabled, opposite pos exists for {trade_symbol}")
            return None
        
        # ATR fallback
        if atr <= 0:
            atr = price * 0.01
        
        # =========================================================================
        # PHASE 34: PENDING ORDER SYSTEM (PULLBACK ENTRY)
        # =========================================================================
        # Create a pending order that waits for price to reach pullback level
        
        # Entry is already dynamically calculated in SignalGenerator (includes entry_tightness).
        # Avoid double-scaling entry_tightness here.
        if signal and 'entryPrice' in signal and signal.get('entryPrice', 0) > 0:
            entry_price = float(signal.get('entryPrice'))
            pullback_pct = float(signal.get('pullbackPct', 0))
        else:
            # No pullback, use current price
            entry_price = price
            pullback_pct = 0
        
        # Get spread-adjusted parameters from signal
        spread_level = signal.get('spreadLevel', 'normal') if signal else 'normal'
        
        # Use leverage from signal (spread-adjusted) or calculate
        raw_leverage = 0  # Phase 238B
        if signal and 'leverage' in signal:
            adjusted_leverage = signal['leverage']
            raw_leverage = signal.get('signalLeverageRaw', adjusted_leverage)
        else:
            session_adjusted_leverage = session_manager.adjust_leverage(self.leverage)
            leverage_mult = balance_protector.calculate_leverage_multiplier(self.balance)
            user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
            adjusted_leverage = int(session_adjusted_leverage * leverage_mult * user_lev_mult)
            adjusted_leverage = max(3, min(75, adjusted_leverage))
            raw_leverage = adjusted_leverage
        
        # Phase 238B: Capture raw before caps
        if not raw_leverage:
            raw_leverage = adjusted_leverage
        
        # Phase 230B: Override leverage cap (BTC counter-trend protection)
        if signal and signal.get('overrideLeverageCap'):
            cap = signal['overrideLeverageCap']
            if adjusted_leverage > cap:
                logger.info(f"ðŸ’ª OVERRIDE LEV CAP: {self.symbol} {adjusted_leverage}x â†’ {cap}x")
                adjusted_leverage = cap
        
        # Phase 238B: LEV_PIPE log
        _lev_cap_reason = signal.get('leverageCapReason', 'none') if signal else 'none'
        if raw_leverage != adjusted_leverage:
            logger.info(f"LEV_PIPE: {trade_symbol} raw={raw_leverage} â†’ effective={adjusted_leverage} cap={_lev_cap_reason}")
        if signal:
            signal['signalLeverageRaw'] = raw_leverage
            signal['signalLeverageEffective'] = adjusted_leverage
        
        # DYNAMIC POSITION SIZING: Son 5 trade performansÄ±na gÃ¶re risk ayarla
        dynamic_risk = self.get_dynamic_risk_per_trade()
        session_risk = session_manager.adjust_risk(dynamic_risk)
        size_mult = signal.get('sizeMultiplier', 1.0) if signal else 1.0
        
        # Phase 143: Apply Strong Trend size reduction
        strong_trend_size_mult = signal.get('strong_trend_size_mult', 1.0) if signal else 1.0
        size_mult = size_mult * strong_trend_size_mult
        if strong_trend_size_mult < 1.0:
            logger.info(f"ðŸ“‰ STRONG_TREND SIZE: {strong_trend_size_mult:.0%} multiplier applied â†’ size_mult={size_mult:.2f}")
        elif strong_trend_size_mult > 1.0:
            logger.info(f"ðŸš€ TREND_MODE SIZE: {strong_trend_size_mult:.0%} multiplier applied â†’ size_mult={size_mult:.2f}")
        
        # Calculate SL/TP based on pullback entry price
        # Apply exit_tightness: lower = quicker exit (smaller SL/TP), higher = hold longer (bigger SL/TP)
        # DYNAMIC ATR MULTIPLIER: Adjust based on current volatility
        dynamic_atr_mult = self.calculate_dynamic_atr_multiplier(atr, price)
        
        # Phase 202: Trend Mode â€” wider params for strong trend pro-trend signals
        is_trend_mode = signal.get('trend_mode', False) if signal else False
        if is_trend_mode:
            # Trend Mode: let winners run with wider params
            tm_sl_mult = 1.33    # SL 33% wider (1.5x â†’ 2.0x ATR effective)
            tm_tp_mult = 1.67    # TP 67% wider (3.0x â†’ 5.0x ATR effective)
            tm_trail_act_mult = 1.67  # Trail activation 67% wider (1.5x â†’ 2.5x effective)
            tm_trail_dist_mult = 1.50  # Trail distance 50% wider (1.0x â†’ 1.5x effective)
            logger.warning(f"ðŸš€ TREND_MODE PARAMS: {side} {trade_symbol} | TPÃ—{tm_tp_mult:.2f} TrailÃ—{tm_trail_act_mult:.2f} SLÃ—{tm_sl_mult:.2f}")
        else:
            tm_sl_mult = 1.0
            tm_tp_mult = 1.0
            tm_trail_act_mult = 1.0
            tm_trail_dist_mult = 1.0

        effective_exit_tightness = _clamp(
            float(signal.get('effectiveExitTightness', self.exit_tightness)) if signal else self.exit_tightness,
            0.3,
            15.0
        )

        adjusted_sl_atr = (self.sl_atr / 10) * effective_exit_tightness * dynamic_atr_mult * tm_sl_mult
        adjusted_tp_atr = (self.tp_atr / 10) * effective_exit_tightness * dynamic_atr_mult * tm_tp_mult
        
        # Use dynamic trail params from signal if available (Cloud Scanner + WebSocket parity)
        if signal and 'dynamic_trail_activation' in signal:
            # Use per-coin dynamic trail params
            base_trail_activation_atr = signal['dynamic_trail_activation']
            base_trail_distance_atr = signal['dynamic_trail_distance']
        else:
            # Fallback to global defaults
            base_trail_activation_atr = self.trail_activation_atr
            base_trail_distance_atr = self.trail_distance_atr
        
        adjusted_trail_activation_atr = base_trail_activation_atr * effective_exit_tightness * dynamic_atr_mult * tm_trail_act_mult
        adjusted_trail_distance_atr = base_trail_distance_atr * effective_exit_tightness * dynamic_atr_mult * tm_trail_dist_mult
        
        # Phase 224D G5: Apply regime profile multipliers
        try:
            regime_profile = market_regime_manager.get_profile()
            tuning_recs = getattr(self, '_tuning_recs', {})
            
            # Regime multipliers
            r_tp_mult = regime_profile.get('tp_mult', 1.0)
            r_sl_mult = regime_profile.get('sl_mult', 1.0)
            r_trail_mult = regime_profile.get('trail_distance_mult', 1.0)
            
            # PostTradeTracker tuning overrides (if available)
            if tuning_recs.get('tp_mult'):
                r_tp_mult *= tuning_recs['tp_mult']
            if tuning_recs.get('trail_distance_mult'):
                r_trail_mult *= tuning_recs['trail_distance_mult']
            
            adjusted_sl_atr *= r_sl_mult
            adjusted_tp_atr *= r_tp_mult
            adjusted_trail_activation_atr *= r_trail_mult
            adjusted_trail_distance_atr *= r_trail_mult
            
            if r_tp_mult != 1.0 or r_sl_mult != 1.0 or r_trail_mult != 1.0:
                logger.info(f"ðŸŽ­ REGIME_PARAMS: {trade_symbol} | TPÃ—{r_tp_mult:.2f} SLÃ—{r_sl_mult:.2f} TrailÃ—{r_trail_mult:.2f} regime={market_regime_manager.current_regime}")
        except Exception as rp_err:
            logger.debug(f"Regime profile params error: {rp_err}")
        
        if side == 'LONG':
            sl = max(entry_price * 0.01, entry_price - (atr * adjusted_sl_atr))
            tp = entry_price + (atr * adjusted_tp_atr)
            trail_activation = entry_price + (atr * adjusted_trail_activation_atr)
        else:
            sl = entry_price + (atr * adjusted_sl_atr)
            tp = max(entry_price * 0.01, entry_price - (atr * adjusted_tp_atr))
            trail_activation = max(entry_price * 0.01, entry_price - (atr * adjusted_trail_activation_atr))
        
        trail_distance = atr * adjusted_trail_distance_atr
        
        # Position sizing
        risk_amount = self.balance * session_risk * size_mult
        position_size_usd = risk_amount * adjusted_leverage
        
        # Apply MTF size modifier (bonus: 1.1 = +10%, penalty: 0.8 = -20%)
        mtf_size_modifier = signal.get('mtf_size_modifier', 1.0) if signal else 1.0
        position_size_usd = position_size_usd * mtf_size_modifier
        
        position_size = position_size_usd / entry_price
        
        # Create pending order
        # Signal Confirmation: Phase 224B adaptive delay â€” ATR/spread/skora gÃ¶re 1-8dk
        atr_pct_confirm = (atr / price * 100) if price > 0 else 2.0
        conf_score = signal.get('confidenceScore', 0) if signal else 0
        
        # Base wait: ATR-based
        if atr_pct_confirm > 5.0:
            base_wait_min = 2       # YÃ¼ksek volatilite â†’ kÄ±sa bekle
        elif atr_pct_confirm > 2.0:
            base_wait_min = 4       # Normal
        else:
            base_wait_min = 6       # DÃ¼ÅŸÃ¼k volatilite â†’ uzun bekle
        
        # Score adjustment: yÃ¼ksek skor â†’ daha az bekleme
        if conf_score >= 85:
            base_wait_min = max(1, base_wait_min - 2)
        elif conf_score >= 70:
            base_wait_min = max(2, base_wait_min - 1)
        
        # Spread adjustment: yÃ¼ksek spread â†’ daha uzun bekle
        if spread_level in ('High', 'Very High'):
            base_wait_min += 2
        elif spread_level in ('Extreme', 'Ultra'):
            base_wait_min += 4
        
        signal_confirmation_delay_seconds = base_wait_min * 60
        
        # Phase 224D: Regime-based confirmation multiplier
        try:
            regime_profile = market_regime_manager.get_profile()
            confirm_mult = regime_profile.get('confirmation_mult', 1.0)
            signal_confirmation_delay_seconds = int(signal_confirmation_delay_seconds * confirm_mult)
            signal_confirmation_delay_seconds = max(60, min(600, signal_confirmation_delay_seconds))  # 1-10dk cap
        except Exception:
            pass

        reinforce_count = int(signal.get('signalReinforceCount', 0) if signal else 0)
        if reinforce_count >= 2:
            signal_confirmation_delay_seconds = max(30, int(signal_confirmation_delay_seconds * 0.75))

        memory_extend_sec = int(signal.get('memoryExtensionSec', 0) if signal else 0)
        memory_extend_sec = max(0, min(SIGNAL_MEMORY_PENDING_EXTEND_MAX_SECONDS, memory_extend_sec))
        pending_timeout_seconds = self.pending_order_timeout_seconds + memory_extend_sec
        
        # Phase 155: AI Optimizer â€” snapshot settings at trade open time
        settings_snapshot = {
            'entry_tightness': self.entry_tightness,
            'z_score_threshold': self.z_score_threshold,
            'min_score_low': self.min_score_low,
            'min_score_high': self.min_score_high,
            'max_positions': self.max_positions,
            'strategy_mode': self.strategy_mode,
            'market_regime': market_regime_detector.current_regime if 'market_regime_detector' in dir() or True else 'UNKNOWN',
        }
        try:
            settings_snapshot['market_regime'] = market_regime_detector.current_regime
        except:
            settings_snapshot['market_regime'] = 'UNKNOWN'
        # Phase 211: OBI depth settings
        settings_snapshot['obi_threshold_veto'] = 0.6
        settings_snapshot['obi_threshold_penalty'] = 0.3
        settings_snapshot['obi_penalty_points'] = 15
        try:
            obi_cached = obi_detector.obi_cache.get(trade_symbol, {})
            settings_snapshot['obi_value_at_entry'] = round(obi_cached.get('obi', 0), 4)
        except:
            settings_snapshot['obi_value_at_entry'] = 0
            
        # Phase 211: Merge the full signal telemetry into the settings snapshot
        if signal and 'telemetry' in signal:
            try:
                tel = signal['telemetry']
                settings_snapshot.update(tel if isinstance(tel, dict) else json.loads(tel))
            except Exception as tel_err:
                logger.debug(f"Telemetry update error: {tel_err}")
                
        # Phase 239V2: Extract dynamic pullback telemetry from signal dict
        # (dyn_result / dyn_min_pb_pct / dyn_regime_band are NOT in open_position scope)
        def _safe_float(val, default: float) -> float:
            try:
                v = float(val)
                if v != v or v == float('inf') or v == float('-inf'):  # NaN/inf guard
                    return default
                return v
            except (TypeError, ValueError):
                return default

        _sig = signal if isinstance(signal, dict) else {}
        _dyn_floor = _safe_float(_sig.get('pullbackDynFloor', _sig.get('pullbackMinDyn', pullback_pct)), pullback_pct)
        _dyn_base = _safe_float(_sig.get('pullbackDynBase', 0), 0.0)
        _dyn_adj = _safe_float(_sig.get('pullbackDynAdj', 0), 0.0)
        _dyn_final = _safe_float(_sig.get('pullbackDynFinal', pullback_pct), pullback_pct)
        _dyn_band = str(_sig.get('pullbackDynRegimeBand', 'neutral') or 'neutral').lower()
        # Clamp consistency
        if _dyn_floor <= 0:
            _dyn_floor = pullback_pct
        if _dyn_final <= 0:
            _dyn_final = pullback_pct
        if _dyn_final < _dyn_floor:
            _dyn_final = _dyn_floor
        if _dyn_floor != pullback_pct or _dyn_final != pullback_pct:
            logger.debug(
                f"DYN_TELEM: {trade_symbol} floor={_dyn_floor:.4f} final={_dyn_final:.4f} "
                f"base={_dyn_base:.4f} band={_dyn_band}"
            )

        pending_order = {
            "id": f"PO_{int(datetime.now().timestamp())}_{side}_{trade_symbol}",
            "symbol": trade_symbol,
            "side": side,
            "signalPrice": price,
            "entryPrice": entry_price,
            "pullbackPct": pullback_pct,
            # Phase 239V2: Dynamic pullback lock + telemetry (from signal dict)
            "pullbackMinDyn": round(_dyn_floor, 4),
            "pullbackLocked": round(pullback_pct / 100.0, 6),  # FRACTION
            "pullbackModelVersion": "v2",
            "pullbackDynBase": round(_dyn_base, 4),
            "pullbackDynAdj": round(_dyn_adj, 4),
            "pullbackDynFinal": round(_dyn_final, 4),
            "pullbackDynFloor": round(_dyn_floor, 4),
            "pullbackDynRegimeBand": _dyn_band,
            "size": position_size,
            "sizeUsd": position_size_usd,
            "stopLoss": sl,
            "takeProfit": tp,
            "trailActivation": trail_activation,
            "trailDistance": trail_distance,
            "leverage": adjusted_leverage,
            "spreadLevel": spread_level,
            "signalScore": signal.get('confidenceScore', 0) if signal else 0,
            "mtfScore": signal.get('mtf_score', 0) if signal else 0,
            "zScore": signal.get('zscore', 0) if signal else 0,
            "createdAt": int(datetime.now().timestamp() * 1000),
            "confirmAfter": int((datetime.now().timestamp() + signal_confirmation_delay_seconds) * 1000),
            "expiresAt": int((datetime.now().timestamp() + pending_timeout_seconds) * 1000),
            "atr": atr,
            "confirmed": False,
            "adx": signal.get('adx', 0) if signal else 0,
            "hurst": signal.get('hurst', 0.5) if signal else 0.5,
            "dynamic_trail_activation": signal.get('dynamic_trail_activation', self.trail_activation_atr) if signal else self.trail_activation_atr,
            "dynamic_trail_distance": signal.get('dynamic_trail_distance', self.trail_distance_atr) if signal else self.trail_distance_atr,
            "volatility_pct": (atr / price * 100) if price > 0 else 2.0,
            "spreadPct": signal.get('spreadPct', 0.05) if signal else 0.05,
            "volumeRatio": signal.get('volumeRatio', 1.0) if signal else 1.0,
            "trailEntryMinMovePct": signal.get('trailEntryMinMovePct', 0.0) if signal else 0.0,
            "trailEntryMinRoiPct": signal.get('trailEntryMinRoiPct', 0.0) if signal else 0.0,
            "entryThresholdMult": signal.get('entryThresholdMult', 1.0) if signal else 1.0,
            "entryExecScore": signal.get('entryExecScore', 0.0) if signal else 0.0,
            "entryExecPassed": signal.get('entryExecPassed', True) if signal else True,
            "strategyMode": signal.get('strategyMode', STRATEGY_MODE_LEGACY) if signal else STRATEGY_MODE_LEGACY,
            "activeStrategy": signal.get('activeStrategy', 'legacy') if signal else 'legacy',
            "strategyLabel": signal.get('strategyLabel', 'Legacy') if signal else 'Legacy',
            "reinforcedCount": reinforce_count,
            "memoryExtensionSec": memory_extend_sec,
            "effectiveExitTightness": effective_exit_tightness,
            "trend_mode": is_trend_mode,
            "settingsSnapshot": settings_snapshot,
            "is_canary": canary_mode.should_use_canary(f"PO_{int(datetime.now().timestamp())}_{side}_{trade_symbol}"),
            # Phase 237C: State machine fields
            "state": "CREATED" if PENDING_SM_V2_ENABLED else "LEGACY",
            "stateChangedAt": int(datetime.now().timestamp() * 1000),
            "transitionCount": 0,
            "lastTransitionReason": "initial",
            # Phase 238B: Leverage pipeline fields
            "signalLeverageRaw": signal.get('signalLeverageRaw', adjusted_leverage) if signal else adjusted_leverage,
            "signalLeverageEffective": adjusted_leverage,
            "leverageCapApplied": signal.get('leverageCapApplied', False) if signal else False,
            "leverageCapReason": signal.get('leverageCapReason', '') if signal else '',
        }
        
        self.pending_orders.append(pending_order)
        self.pipeline_metrics['pending_created'] += 1
        self.clear_execution_feedback(trade_symbol)
        self.add_log(f"ðŸ“‹ PENDING: {side} {trade_symbol} | ${price:.4f} â†’ ${entry_price:.4f} ({pullback_pct}% pullback) | Spread: {spread_level}")
        logger.info(f"ðŸ“‹ PENDING ORDER: {side} {trade_symbol} @ {entry_price} (pullback {pullback_pct}% from {price}, spread={spread_level})")
        
        return pending_order
    
    async def check_pending_orders(self, opportunities: list):
        """Check all pending orders against current prices and execute or expire them."""
        current_time = int(datetime.now().timestamp() * 1000)
        # High-score signals get market fallback on hard exits to improve fill rate.
        MARKET_FALLBACK_MIN_SCORE = 80
        # Stale logic tuned softer to avoid dropping still-valid candidates too early.
        STALE_THRESHOLD_UNCONFIRMED_MIN = 15
        STALE_THRESHOLD_CONFIRMED_MIN = 30
        STALE_GRACE_MIN = 5
        STALE_PENALTY_PER_MIN = 1
        STALE_MIN_SCORE_BUFFER = 5
        
        for order in list(self.pending_orders):
            symbol = order.get('symbol', '')
            side = order.get('side', '')
            entry_price = order.get('entryPrice', 0)
            expires_at = order.get('expiresAt', 0)
            
            # Find current price for this symbol (also used by expiry fallback)
            current_price = None
            for opp in opportunities:
                if opp.get('symbol') == symbol:
                    current_price = opp.get('price', 0)
                    break
            
            # Check expiration first (with high-score market fallback for confirmed signals)
            if current_time > expires_at:
                signal_score = order.get('signalScore', 0)
                is_confirmed = order.get('confirmed', False)
                if is_confirmed and signal_score >= MARKET_FALLBACK_MIN_SCORE and current_price and current_price > 0:
                    self.pipeline_metrics['market_fallback'] += 1
                    self.pipeline_metrics['fallback_on_expire'] += 1
                    self.add_log(f"ðŸ”¥ MARKET FALLBACK: {side} {symbol} score={signal_score} â†’ pending expired, filling at market")
                    logger.info(f"ðŸ”¥ MARKET FALLBACK(EXPIRE): {side} {symbol} score={signal_score} age_expired â†’ market fill")
                    await self._gate_and_execute(order, current_price, opportunities, current_time, force_market=True)
                    continue
                if order in self.pending_orders:
                    self.pending_orders.remove(order)
                self.pipeline_metrics['pending_expired'] += 1
                self.set_execution_feedback(symbol, "PENDING_EXPIRED")
                self.add_log(f"â° PENDING EXPIRED: {side} {symbol} @ ${entry_price:.4f} (30dk timeout)")
                logger.info(f"Pending order expired: {order['id']}")
                if PENDING_SM_V2_ENABLED:
                    transition_pending_state(order, 'EXPIRED', 'timeout', current_time)
                continue
            
            # Phase 224B: Stale Signal Penalty â€” skor zamanla dÃ¼ÅŸer
            created_at = order.get('createdAt', current_time)
            pending_age_min = (current_time - created_at) / 60000
            is_confirmed = order.get('confirmed', False)
            reinforced_count = int(order.get('reinforcedCount', 0) or 0)
            stale_threshold_min = STALE_THRESHOLD_CONFIRMED_MIN if is_confirmed else STALE_THRESHOLD_UNCONFIRMED_MIN
            stale_threshold_min += min(20, reinforced_count * 4)
            stale_grace_min = STALE_GRACE_MIN + min(10, reinforced_count * 2)
            if pending_age_min > stale_threshold_min:
                stale_penalty = min(20, int((pending_age_min - stale_threshold_min) * STALE_PENALTY_PER_MIN))
                original_score = order.get('signalScore', 70)
                stale_floor = max(40, self.min_confidence_score - STALE_MIN_SCORE_BUFFER - min(8, reinforced_count * 2))
                adjusted_score = max(stale_floor, original_score - stale_penalty)
                if pending_age_min > (stale_threshold_min + stale_grace_min) and adjusted_score < self.min_confidence_score:
                    self.pending_orders.remove(order)
                    self.pipeline_metrics['stale_dropped'] += 1
                    self.set_execution_feedback(symbol, "STALE_SIGNAL")
                    self.add_log(f"â³ STALE_SIGNAL: {side} {symbol} removed (score {original_score}â†’{adjusted_score} < min {self.min_confidence_score}, age={pending_age_min:.0f}min)")
                    logger.info(
                        f"â³ STALE_SIGNAL: {order['id']} removed (age={pending_age_min:.0f}min, "
                        f"stale_thresh={stale_threshold_min}min+{stale_grace_min}min, reinforce={reinforced_count}, "
                        f"score {original_score}â†’{adjusted_score})"
                    )
                    continue
            
            if not current_price or current_price <= 0:
                continue
            
            # ===================================================================
            # SIGNAL CONFIRMATION: 5 dakika bekleme
            # Sinyal geldiÄŸinde hemen execute etme, trend doÄŸrulanmasÄ±nÄ± bekle
            # ===================================================================
            confirm_after = order.get('confirmAfter', 0)
            is_confirmed = order.get('confirmed', False)
            
            if not is_confirmed:
                if current_time < confirm_after:
                    # HenÃ¼z konfirmasyon sÃ¼resi dolmadÄ± - fiyat hala doÄŸru yÃ¶nde mi kontrol et
                    signal_price = order.get('signalPrice', entry_price)
                    
                    # FIX #3: Signal Invalidation Logic Corrected
                    # LONG sinyal: EÄŸer fiyat Ã‡OK FAZLA DÃœÅžTÃœYSE (entry'i geÃ§ip gitti), sinyal geÃ§ersiz
                    # SHORT sinyal: EÄŸer fiyat Ã‡OK FAZLA YÃœKSELDÄ°YSE (entry'i geÃ§ip gitti), sinyal geÃ§ersiz
                    # Threshold: Entry fiyatÄ±nÄ±n %3 Ã¶tesine geÃ§erse iptal
                    
                    if side == 'LONG':
                        # LONG iÃ§in: Fiyat entry'den %3 daha aÅŸaÄŸÄ± dÃ¼ÅŸtÃ¼yse â†’ sinyal kaÃ§Ä±rÄ±ldÄ±
                        price_drop_pct = (signal_price - current_price) / signal_price * 100
                        if price_drop_pct > 3.0:  # Fiyat %3'den fazla dÃ¼ÅŸtÃ¼ - entry kaÃ§Ä±rÄ±ldÄ±
                            self.pending_orders.remove(order)
                            self.pipeline_metrics['signal_missed'] += 1
                            self.set_execution_feedback(symbol, "SIGNAL_MISSED")
                            self.add_log(f"âŒ SIGNAL MISSED: {side} {symbol} - fiyat entry'den Ã§ok uzaklaÅŸtÄ± (-{price_drop_pct:.1f}%)")
                            logger.info(f"Signal missed: {order['id']} - price dropped too far below entry")
                            continue
                    else:  # SHORT
                        # SHORT iÃ§in: Fiyat entry'den %3 daha yukarÄ± Ã§Ä±ktÄ±ysa â†’ sinyal kaÃ§Ä±rÄ±ldÄ±
                        price_rise_pct = (current_price - signal_price) / signal_price * 100
                        if price_rise_pct > 3.0:  # Fiyat %3'den fazla yÃ¼kseldi - entry kaÃ§Ä±rÄ±ldÄ±
                            self.pending_orders.remove(order)
                            self.pipeline_metrics['signal_missed'] += 1
                            self.set_execution_feedback(symbol, "SIGNAL_MISSED")
                            self.add_log(f"âŒ SIGNAL MISSED: {side} {symbol} - fiyat entry'den Ã§ok uzaklaÅŸtÄ± (+{price_rise_pct:.1f}%)")
                            logger.info(f"Signal missed: {order['id']} - price rose too far above entry")
                            continue
                    
                    # Beklemeye devam et
                    remaining_secs = (confirm_after - current_time) / 1000
                    if remaining_secs > 0 and remaining_secs % 60 < 5:  # Her dakika log
                        logger.debug(f"Waiting for confirmation: {symbol} {side} - {remaining_secs:.0f}s remaining")
                    continue
                else:
                    # Konfirmasyon sÃ¼resi doldu - sinyali onayla
                    order['confirmed'] = True
                    self.pipeline_metrics['signal_confirmed'] += 1
                    self.clear_execution_feedback(symbol)
                    self.add_log(f"âœ… SIGNAL CONFIRMED: {side} {symbol} @ ${current_price:.4f} (5dk bekleme tamamlandÄ±)")
                    logger.info(f"Signal confirmed after 5min wait: {order['id']}")
                    if PENDING_SM_V2_ENABLED:
                        transition_pending_state(order, 'WAIT_CONFIRM', 'signal_confirmed', current_time)            
            # =================================================================
            # Phase 175: TRAILING ENTRY (mirrors Trailing Take Profit logic)
            # Instead of bounce+volume+trending, simply track bottom/peak
            # and trigger when price reverses by trail_entry_distance.
            # Same concept as trail TP but inverted for entries.
            # =================================================================
            trailing_entry_active = order.get('trailingEntryActive', False)
            atr = order.get('atr', entry_price * 0.01)

            if not trailing_entry_active:
                # Step 1: Check if price reached pullback entry level
                reached_entry = False
                if side == 'LONG' and current_price <= entry_price:
                    reached_entry = True
                elif side == 'SHORT' and current_price >= entry_price:
                    reached_entry = True

                if reached_entry:
                    # Start trailing entry â€” track the extreme price
                    order['trailingEntryActive'] = True
                    self.pipeline_metrics['trail_entry_start'] += 1
                    order['trailEntryStartTime'] = current_time
                    if PENDING_SM_V2_ENABLED:
                        transition_pending_state(order, 'TRAIL_ACTIVE', 'reached_entry', current_time)
                    # Initialize extreme price (bottom for LONG, peak for SHORT)
                    order['extremePrice'] = current_price

                    order_hurst = order.get('hurst', 0.5)
                    order_adx = order.get('adx', 20.0)
                    order_spread = order.get('spreadPct', 0.05)
                    order_vol_ratio = order.get('volumeRatio', 1.0)
                    order_atr_pct = order.get('volatility_pct', 0) or order.get('volatilityPct', 0)
                    if not order_atr_pct and entry_price > 0:
                        order_atr_pct = (atr / entry_price) * 100
                    order_atr_pct = order_atr_pct or 2.0
                    dynamic_trail_dist = order.get('dynamic_trail_distance', None)

                    if dynamic_trail_dist is not None and dynamic_trail_dist > 0:
                        # Entry trail starts from per-coin trail distance, then widened dynamically.
                        hurst_s = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                        entry_trail_ratio = 0.65 - hurst_s * 0.25  # 0.40 (trend) - 0.65 (range)
                        base_trail_entry_dist = atr * dynamic_trail_dist * entry_trail_ratio
                    else:
                        adx_s = min(1.0, max(0.0, (order_adx - 15) / 45))
                        hurst_s = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                        trend_s = adx_s * 0.6 + hurst_s * 0.4
                        trail_factor = 0.70 - trend_s * 0.25
                        base_trail_entry_dist = atr * trail_factor

                    trail_entry_dist = get_hybrid_runtime_trail_distance(
                        base_trail_distance=base_trail_entry_dist,
                        atr_pct=order_atr_pct,
                        spread_pct=order_spread,
                        volume_ratio=order_vol_ratio,
                        roi_pct=0.0,
                        exit_tightness=self.entry_tightness,
                        hurst=order_hurst,
                        adx=order_adx,
                    )

                    order['trailEntryDistance'] = trail_entry_dist
                    min_entry_move = float(order.get('trailEntryMinMovePct', 0.0) or 0.0)
                    min_reversal_pct = max(0.08, min_entry_move * 0.45) if min_entry_move > 0 else 0.08
                    order['trailEntryMinReversalPct'] = min_reversal_pct

                    trail_pct = (trail_entry_dist / entry_price * 100) if entry_price > 0 else 0
                    self.add_log(
                        f"ðŸ“ TRAIL ENTRY: {side} {symbol} @ ${current_price:.6f} | "
                        f"Mesafeâ‰¥{trail_pct:.2f}% | Reversalâ‰¥{min_reversal_pct:.2f}%"
                    )
                    logger.info(
                        f"ðŸ“ TRAIL ENTRY START: {side} {symbol} entry=${entry_price:.6f} extreme=${current_price:.6f} "
                        f"trail_dist={trail_pct:.2f}% rev_min={min_reversal_pct:.2f}% et={self.entry_tightness}"
                    )
            else:
                # Step 2: Trailing entry active â€” track extreme and check reversal
                # This mirrors Trail TP: track peakPrice, trigger when price drops by trail_distance
                # Here: track bottomPrice (LONG) or peakPrice (SHORT), trigger on reversal
                trail_entry_distance = order.get('trailEntryDistance', atr * 0.08)
                extreme_price = order.get('extremePrice', current_price)
                trail_start = order.get('trailEntryStartTime', current_time)
                trail_timeout_ms = 15 * 60 * 1000  # 15 minute timeout

                # Cancel distance: how far from entry before giving up
                order_adx = order.get('adx', 0)
                order_hurst = order.get('hurst', 0.5)
                order_spread = order.get('spreadPct', 0.05)
                order_vol_ratio = order.get('volumeRatio', 1.0)
                adx_strength = min(1.0, max(0.0, (order_adx - 15) / 45))
                hurst_strength = min(1.0, max(0.0, (order_hurst - 0.35) / 0.4))
                trend_strength = adx_strength * 0.6 + hurst_strength * 0.4
                base_cancel = 0.7 + trend_strength * 0.8
                cancel_distance = atr * base_cancel
                cancel_distance *= math.sqrt(_clamp(self.entry_tightness, 0.5, 15.0))
                cancel_distance *= 1.0 + max(0.0, order_spread - 0.08) * 1.8
                if order_vol_ratio < 1.0:
                    cancel_distance *= 1.12
                elif order_vol_ratio > 2.0:
                    cancel_distance *= 0.95
                cancel_distance = _clamp(cancel_distance, atr * 0.4, atr * 4.0)

                elapsed_ms = current_time - trail_start
                elapsed_secs = elapsed_ms / 1000
                min_reversal_pct = float(order.get('trailEntryMinReversalPct', 0.08) or 0.08)

                if side == 'LONG':
                    # Track bottom price (like trail TP tracks peak)
                    if current_price < extreme_price:
                        order['extremePrice'] = current_price
                        extreme_price = current_price

                    # Reversal confirmed: price rose from bottom by trail_entry_distance
                    if current_price >= extreme_price + trail_entry_distance:
                        reversal_pct = ((current_price - extreme_price) / extreme_price * 100) if extreme_price > 0 else 0
                        if reversal_pct >= min_reversal_pct:
                            self.add_log(
                                f"âœ… TRAIL ENTRY OK: {side} {symbol} @ ${current_price:.6f} | "
                                f"Bottom=${extreme_price:.6f} +{reversal_pct:.2f}% ({elapsed_secs:.0f}s)"
                            )
                            logger.info(
                                f"âœ… TRAIL ENTRY CONFIRMED: {side} {symbol} price=${current_price:.6f} "
                                f"bottom=${extreme_price:.6f} reversal={reversal_pct:.2f}% (min={min_reversal_pct:.2f}%)"
                            )
                            self.pipeline_metrics['trail_entry_ok'] += 1
                            if await self._gate_and_execute(order, current_price, opportunities, current_time):
                                continue
                            continue  # wait also skips to next order

                    # Cancel: dropped too far below entry
                    if current_price < entry_price - cancel_distance:
                        signal_score = order.get('signalScore', 0)
                        if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                            self.pipeline_metrics['market_fallback'] += 1
                            self.pipeline_metrics['fallback_on_fail'] += 1
                            self.add_log(f"ðŸ”¥ MARKET FALLBACK: {side} {symbol} score={signal_score} â†’ trail fail, filling at market")
                            logger.info(f"ðŸ”¥ MARKET FALLBACK(FAIL): {side} {symbol} score={signal_score} dropped too far â†’ market fill")
                            await self._gate_and_execute(order, current_price, opportunities, current_time, force_market=True)
                            continue
                        if order in self.pending_orders:
                            self.pending_orders.remove(order)
                        self.pipeline_metrics['trail_entry_fail'] += 1
                        self.set_execution_feedback(symbol, "TRAIL_ENTRY_FAIL")
                        self.add_log(f"âŒ TRAIL ENTRY FAIL: {side} {symbol} dÃ¼ÅŸÃ¼ÅŸ devam (${current_price:.6f})")
                        logger.info(f"âŒ TRAIL ENTRY CANCEL: {side} {symbol} dropped {((entry_price-current_price)/atr):.1f}Ã—ATR below entry")
                        continue
                else:  # SHORT
                    # Track peak price (like trail TP tracks peak for short)
                    if current_price > extreme_price:
                        order['extremePrice'] = current_price
                        extreme_price = current_price

                    # Reversal confirmed: price dropped from peak by trail_entry_distance
                    if current_price <= extreme_price - trail_entry_distance:
                        reversal_pct = ((extreme_price - current_price) / extreme_price * 100) if extreme_price > 0 else 0
                        if reversal_pct >= min_reversal_pct:
                            self.add_log(
                                f"âœ… TRAIL ENTRY OK: {side} {symbol} @ ${current_price:.6f} | "
                                f"Peak=${extreme_price:.6f} -{reversal_pct:.2f}% ({elapsed_secs:.0f}s)"
                            )
                            logger.info(
                                f"âœ… TRAIL ENTRY CONFIRMED: {side} {symbol} price=${current_price:.6f} "
                                f"peak=${extreme_price:.6f} reversal={reversal_pct:.2f}% (min={min_reversal_pct:.2f}%)"
                            )
                            self.pipeline_metrics['trail_entry_ok'] += 1
                            if await self._gate_and_execute(order, current_price, opportunities, current_time):
                                continue
                            continue

                    # Cancel: rose too far above entry
                    if current_price > entry_price + cancel_distance:
                        signal_score = order.get('signalScore', 0)
                        if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                            self.pipeline_metrics['market_fallback'] += 1
                            self.pipeline_metrics['fallback_on_fail'] += 1
                            self.add_log(f"ðŸ”¥ MARKET FALLBACK: {side} {symbol} score={signal_score} â†’ trail fail, filling at market")
                            logger.info(f"ðŸ”¥ MARKET FALLBACK(FAIL): {side} {symbol} score={signal_score} rose too far â†’ market fill")
                            await self._gate_and_execute(order, current_price, opportunities, current_time, force_market=True)
                            continue
                        if order in self.pending_orders:
                            self.pending_orders.remove(order)
                        self.pipeline_metrics['trail_entry_fail'] += 1
                        self.set_execution_feedback(symbol, "TRAIL_ENTRY_FAIL")
                        self.add_log(f"âŒ TRAIL ENTRY FAIL: {side} {symbol} yÃ¼kseliÅŸ devam (${current_price:.6f})")
                        logger.info(f"âŒ TRAIL ENTRY CANCEL: {side} {symbol} rose {((current_price-entry_price)/atr):.1f}Ã—ATR above entry")
                        continue

                # Timeout check
                if elapsed_ms > trail_timeout_ms:
                    # Fix 2: Strong signals get market fallback instead of timeout
                    signal_score = order.get('signalScore', 0)
                    if signal_score >= MARKET_FALLBACK_MIN_SCORE:
                        self.pipeline_metrics['market_fallback'] += 1
                        self.add_log(f"ðŸ”¥ MARKET FALLBACK: {side} {symbol} score={signal_score} â†’ trail timeout, filling at market")
                        logger.info(f"ðŸ”¥ MARKET FALLBACK: {side} {symbol} score={signal_score} trail_timeout={elapsed_secs:.0f}s â†’ market fill")
                        await self._gate_and_execute(order, current_price, opportunities, current_time, force_market=True)
                        continue
                    # Normal timeout
                    if order in self.pending_orders:
                        self.pending_orders.remove(order)
                    self.pipeline_metrics['trail_entry_timeout'] += 1
                    self.set_execution_feedback(symbol, "TRAIL_ENTRY_TIMEOUT")
                    self.add_log(f"â° TRAIL ENTRY TIMEOUT: {side} {symbol} (15dk reversal olmadÄ±, score={signal_score})")
                    logger.info(f"â° TRAIL ENTRY TIMEOUT: {side} {symbol} after {elapsed_secs:.0f}s score={signal_score}")
                    continue

                # Periodic log (every ~30s)
                trail_pct = (trail_entry_distance / entry_price * 100) if entry_price > 0 else 0
                if elapsed_secs > 0 and int(elapsed_secs) % 30 < 4:
                    logger.debug(f"ðŸ“ TRAIL ENTRY WAIT: {side} {symbol} {elapsed_secs:.0f}s | price=${current_price:.6f} extreme=${extreme_price:.6f} dist={trail_pct:.2f}%")
    
    async def _gate_and_execute(self, order: dict, fill_price: float,
                                 opportunities: list, current_time: int,
                                 force_market: bool = False) -> bool:
        """Revalidation gate wrapper around execute_pending_order.
        Returns True if order was executed or removed, False if wait (order stays).
        Uses unified decision: PASS / WARN_WAIT / FAIL_DROP.
        """
        symbol = order.get('symbol', '')
        side = order.get('side', '')
        _opp = next((o for o in opportunities if o.get('symbol') == symbol), None)
        rv = revalidate_pending_entry(order, _opp, current_time)

        decision = rv['decision']
        order['recheckScore'] = rv['recheck_score']
        order['recheckReasons'] = rv['reasons']
        order['recheckDecision'] = decision
        order['recheckLastAt'] = current_time

        if decision == 'FAIL_DROP':
            if order in self.pending_orders:
                self.pending_orders.remove(order)
            self.pipeline_metrics.setdefault('recheck_fail', 0)
            self.pipeline_metrics['recheck_fail'] += 1
            self.set_execution_feedback(symbol, "ENTRY_RECHECK_FAIL")
            self.add_log(
                f"ðŸš« ENTRY_RECHECK_FAIL: {side} {symbol} score={rv['recheck_score']:.0f} "
                f"| {rv['reason_summary']}"
            )
            return True  # order removed

        if decision == 'WARN_WAIT' and not force_market:
            self.pipeline_metrics.setdefault('recheck_warn', 0)
            self.pipeline_metrics['recheck_warn'] += 1
            order['confirmAfter'] = max(
                int(order.get('confirmAfter', current_time)),
                current_time + 30_000
            )
            logger.info(
                f"âš ï¸ ENTRY_RECHECK_WAIT: {symbol} {side} score={rv['recheck_score']:.0f} "
                f"â†’ waiting 30s | {rv['reason_summary']}"
            )
            return False  # order stays, not executed

        # PASS â€” execute
        self.pipeline_metrics.setdefault('recheck_pass', 0)
        self.pipeline_metrics['recheck_pass'] += 1
        # force_market is passed through as-is; recheck does NOT downgrade it.
        await self.execute_pending_order(order, fill_price, force_market=force_market)
        return True

    async def execute_pending_order(self, order: dict, fill_price: float, force_market: bool = False):
        """Execute a pending order at the fill price.
        Args:
            force_market: If True, bypass spread/drift guards (used by market fallback).
        """
        # Remove from pending
        if order in self.pending_orders:
            self.pending_orders.remove(order)
        
        # Phase 55: Check if already have position in this coin
        symbol = order.get('symbol', '')
        is_live_mode = live_binance_trader.enabled and live_binance_trader.trading_mode == 'live'
        existing_position = next((p for p in self.positions if p['symbol'] == symbol), None)
        if existing_position:
            self.add_log(f"âš ï¸ {symbol}'de zaten pozisyon var, yeni order iptal edildi")
            logger.info(f"âš ï¸ SKIP ORDER: {symbol} already has open position")
            return  # Don't create duplicate position
        
        
        # Recalculate SL/TP based on actual fill price
        # Apply exit_tightness for faster/slower exits
        atr = order.get('atr', fill_price * 0.01)
        side = order['side']
        
        # FIX #2: Dynamic ATR Multiplier (parity with open_position)
        dynamic_atr_mult = self.calculate_dynamic_atr_multiplier(atr, fill_price)
        
        # Phase 202: Trend Mode wider params
        is_trend_mode = order.get('trend_mode', False)
        if is_trend_mode:
            tm_sl_mult = 1.33
            tm_tp_mult = 1.67
            tm_trail_act_mult = 1.67
            tm_trail_dist_mult = 1.50
            logger.warning(f"ðŸš€ TREND_MODE EXEC: {side} {symbol} | wider TP/Trail/SL")
        else:
            tm_sl_mult = 1.0
            tm_tp_mult = 1.0
            tm_trail_act_mult = 1.0
            tm_trail_dist_mult = 1.0

        effective_exit_tightness = _clamp(
            float(order.get('effectiveExitTightness', self.exit_tightness)),
            0.3,
            15.0
        )

        adjusted_sl_atr = (self.sl_atr / 10) * effective_exit_tightness * dynamic_atr_mult * tm_sl_mult
        adjusted_tp_atr = (self.tp_atr / 10) * effective_exit_tightness * dynamic_atr_mult * tm_tp_mult
        
        # Use dynamic trail params from order if available (Cloud Scanner + WebSocket parity)
        if 'dynamic_trail_activation' in order:
            base_trail_activation_atr = order['dynamic_trail_activation']
            base_trail_distance_atr = order['dynamic_trail_distance']
        else:
            base_trail_activation_atr = self.trail_activation_atr
            base_trail_distance_atr = self.trail_distance_atr
        
        adjusted_trail_activation_atr = base_trail_activation_atr * effective_exit_tightness * dynamic_atr_mult * tm_trail_act_mult
        adjusted_trail_distance_atr = base_trail_distance_atr * effective_exit_tightness * dynamic_atr_mult * tm_trail_dist_mult
        
        if side == 'LONG':
            sl = max(fill_price * 0.01, fill_price - (atr * adjusted_sl_atr))
            tp = fill_price + (atr * adjusted_tp_atr)
            trail_activation = fill_price + (atr * adjusted_trail_activation_atr)
        else:
            sl = fill_price + (atr * adjusted_sl_atr)
            tp = max(fill_price * 0.01, fill_price - (atr * adjusted_tp_atr))
            trail_activation = max(fill_price * 0.01, fill_price - (atr * adjusted_trail_activation_atr))
        
        trail_distance = atr * adjusted_trail_distance_atr
        
        # Phase 224D3: Apply CanaryMode parameter overrides for canary positions
        try:
            if order.get('is_canary', False) and canary_mode.enabled:
                base_params = {'sl': sl, 'tp': tp, 'trail_activation': trail_activation, 'trail_distance': trail_distance}
                canary_result = canary_mode.get_params(order.get('id', ''), base_params)
                # Apply canary multipliers if present
                if 'tp_mult' in canary_mode.canary_params:
                    tp_m = canary_mode.canary_params['tp_mult']
                    if side == 'LONG':
                        tp = fill_price + (tp - fill_price) * tp_m
                    else:
                        tp = fill_price - (fill_price - tp) * tp_m
                if 'sl_mult' in canary_mode.canary_params:
                    sl_m = canary_mode.canary_params['sl_mult']
                    if side == 'LONG':
                        sl = fill_price - (fill_price - sl) * sl_m
                    else:
                        sl = fill_price + (sl - fill_price) * sl_m
                if 'trail_mult' in canary_mode.canary_params:
                    tr_m = canary_mode.canary_params['trail_mult']
                    trail_distance *= tr_m
                logger.info(f"ðŸ¤ CANARY: {symbol} {side} | overrides applied: {canary_mode.canary_params}")
        except Exception as canary_err:
            logger.debug(f"CanaryMode params error: {canary_err}")
        
        # Create actual position
        new_position = {
            "id": order['id'].replace('PO_', 'POS_'),
            "symbol": order['symbol'],
            "side": order['side'],
            "entryPrice": fill_price,
            "size": order['size'],
            "sizeUsd": order['sizeUsd'],
            "contracts": order['size'],  # Phase 223b: needed for partial TP
            "stopLoss": sl,
            "takeProfit": tp,
            "trailingStop": sl,
            "trailActivation": trail_activation,
            "trailDistance": trail_distance,
            "isTrailingActive": False,
            "unrealizedPnl": 0.0,
            "unrealizedPnlPercent": 0.0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": order['leverage'],
            "spreadLevel": order['spreadLevel'],
            "pullbackPct": order.get('pullbackPct', 1.0),  # Adverse exit kontrolÃ¼ iÃ§in
            # Phase 239V2: Dynamic pullback telemetry (propagated from pending order)
            "pullbackMinDyn": order.get('pullbackMinDyn', 0.60),
            "pullbackLocked": order.get('pullbackLocked', 0),
            "pullbackModelVersion": order.get('pullbackModelVersion', 'v2'),
            "pullbackDynBase": order.get('pullbackDynBase', 0),
            "pullbackDynAdj": order.get('pullbackDynAdj', 0),
            "pullbackDynFinal": order.get('pullbackDynFinal', 0),
            "pullbackDynFloor": order.get('pullbackDynFloor', 0),
            "pullbackDynRegimeBand": order.get('pullbackDynRegimeBand', 'neutral'),
            "recheckScore": order.get('recheckScore', 0),
            "recheckDecision": order.get('recheckDecision', 'PASS'),
            "recheckReasons": order.get('recheckReasons', []),
            # Phase 49: Carry forward analysis data from pending order
            "signalScore": order.get('signalScore', 0),
            "mtfScore": order.get('mtfScore', 0),
            "zScore": order.get('zScore', 0),
            "strategyMode": order.get('strategyMode', STRATEGY_MODE_LEGACY),
            "activeStrategy": order.get('activeStrategy', 'legacy'),
            "strategyLabel": order.get('strategyLabel', 'Legacy'),
            # Phase 202: Trend Mode flag for stepped SL
            "trend_mode": is_trend_mode,
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": 0.0,
            "mfe_pct": 0.0,
            "mae_price": fill_price,
            "mfe_price": fill_price,
            "decision_trace": [],
            # Phase 224D3: CanaryMode flag propagated from pending order
            "is_canary": order.get('is_canary', False),
            # Dynamic trail activation threshold data (propagated from pending order)
            "volatility_pct": order.get('volatility_pct', (order.get('atr', fill_price * 0.02) / fill_price * 100) if fill_price > 0 else 2.0),
            "spreadPct": order.get('spreadPct', 0.05),
            "volumeRatio": order.get('volumeRatio', 1.0),
            "effectiveExitTightnessBase": effective_exit_tightness,
            # Runtime trail telemetry (updated every tick)
            "effectiveExitTightness": effective_exit_tightness,
            "runtimeTrailDistance": trail_distance,
            "runtimeTrailDistancePct": round((trail_distance / fill_price * 100), 4) if fill_price > 0 else 0.0,
            "runtimeTrailActivationMovePct": 0.0,
            "runtimeTrailActivationRoiPct": 0.0,
            "runtimeTrailThresholdMult": 1.0,
            "runtimeTrailLastUpdateTs": int(datetime.now().timestamp() * 1000),
            # Phase 238B: Leverage pipeline fields
            "signalLeverageRaw": order.get('signalLeverageRaw', order['leverage']),
            "signalLeverageEffective": order['leverage'],
            "leverageCapApplied": order.get('leverageCapApplied', False),
            "leverageCapReason": order.get('leverageCapReason', ''),
        }
        
        # =====================================================================
        # LIVE TRADING: Send order to Binance before creating local position
        # Phase 186: Limit entry + pre-trade spread filter
        # =====================================================================
        if is_live_mode and not force_market:
            try:
                # Phase 186 Feature C: Pre-trade spread filter
                ccxt_sym = f"{symbol[:-4]}/USDT:USDT"
                try:
                    pre_ticker = await live_binance_trader.exchange.fetch_ticker(ccxt_sym)
                    pre_bid = pre_ticker.get('bid', 0)
                    pre_ask = pre_ticker.get('ask', 0)
                    pre_mid = (pre_bid + pre_ask) / 2 if pre_bid and pre_ask else 0
                    pre_spread = ((pre_ask - pre_bid) / pre_mid * 100) if pre_mid > 0 else 0
                    
                    ENTRY_SPREAD_LIMIT = 0.3  # Max 0.3% spread for entry
                    if pre_spread > ENTRY_SPREAD_LIMIT:
                        logger.warning(f"ðŸš« SPREAD_FILTER: Rejecting {side} {symbol} entry â€” spread={pre_spread:.3f}% > {ENTRY_SPREAD_LIMIT}% (bid=${pre_bid:.6f} ask=${pre_ask:.6f})")
                        self.add_log(f"ðŸš« SPREAD FILTER: {symbol} entry skipped (spread {pre_spread:.2f}% too wide)")
                        self.pipeline_metrics['spread_rejected'] += 1
                        self.set_execution_feedback(symbol, f"SPREAD_FILTER:{pre_spread:.2f}%")
                        # Return order to pending for retry
                        if order not in self.pending_orders:
                            self.pending_orders.append(order)
                        return
                except Exception as sf_err:
                    logger.debug(f"Spread filter check error: {sf_err}")
                    # Continue with entry if spread check fails
                
                # ===== Phase 201: Pre-Entry Price Drift Check =====
                # Compare signal price vs current price â€” reject if drifted too much
                try:
                    signal_price = order.get('signalPrice', 0)
                    # Use pre_ticker from spread filter if available, otherwise fetch fresh
                    try:
                        current_price = pre_ticker.get('last', fill_price)
                    except NameError:
                        current_price = fill_price
                    if signal_price > 0 and current_price > 0:
                        MAX_PRICE_DRIFT_PCT = 1.5  # Max 1.5% drift since signal
                        price_drift_pct = abs(current_price - signal_price) / signal_price * 100
                        if price_drift_pct > MAX_PRICE_DRIFT_PCT:
                            logger.warning(f"ðŸš« SLIPPAGE_GUARD: {side} {symbol} REJECTED â€” price drifted {price_drift_pct:.2f}% since signal (signal=${signal_price:.6f} â†’ now=${current_price:.6f})")
                            self.add_log(f"ðŸš« SLIPPAGE GUARD: {symbol} price drifted {price_drift_pct:.1f}% since signal")
                            self.pipeline_metrics['drift_rejected'] += 1
                            self.set_execution_feedback(symbol, f"SLIPPAGE_GUARD:{price_drift_pct:.2f}%")
                            # Don't retry â€” signal is stale
                            return
                        else:
                            logger.debug(f"âœ… DRIFT_CHECK: {symbol} drift={price_drift_pct:.2f}% OK (max {MAX_PRICE_DRIFT_PCT}%)")
                except Exception as drift_err:
                    logger.debug(f"Price drift check error: {drift_err}")
                
                logger.info(f"ðŸ”´ LIVE ORDER: Sending {side} {symbol} to Binance (LIMIT entry)...")
                self.pipeline_metrics['order_attempted'] += 1
                
                # Phase 186 Feature B: Use limit entry with market fallback
                result = await live_binance_trader.place_limit_entry_order(
                    symbol=symbol,
                    side=side,
                    size_usd=order['sizeUsd'],
                    leverage=order['leverage']
                )
                
                if result:
                    self.pipeline_metrics['order_success'] += 1
                    # ===== Phase 201: Post-Fill Max Slippage Rejection =====
                    fill_slippage = abs(result.get('slippage_pct', 0))
                    MAX_FILL_SLIPPAGE_PCT = 0.5  # Max 0.5% fill slippage
                    if fill_slippage > MAX_FILL_SLIPPAGE_PCT:
                        logger.warning(f"ðŸš« SLIPPAGE_GUARD: {side} {symbol} fill slippage {fill_slippage:.3f}% > max {MAX_FILL_SLIPPAGE_PCT}% â€” CLOSING immediately")
                        self.add_log(f"ðŸš« SLIPPAGE REJECT: {symbol} closed (fill slip {fill_slippage:.2f}%)")
                        self.set_execution_feedback(symbol, f"SLIPPAGE_REJECT:{fill_slippage:.2f}%")
                        try:
                            await live_binance_trader.close_position(
                                symbol=symbol,
                                side=side,
                                amount=result.get('amount', order['size'])
                            )
                        except Exception as close_err:
                            logger.error(f"âŒ Slippage rejection close failed: {close_err}")
                        return  # Don't create local position
                    
                    new_position['binance_order_id'] = result.get('id')
                    actual_fill = result.get('price', fill_price)
                    new_position['binance_fill_price'] = actual_fill
                    new_position['isLive'] = True
                    new_position['entry_method'] = result.get('entry_method', 'MARKET')
                    new_position['entry_slippage'] = result.get('slippage_pct', 0)
                    new_position['entry_spread'] = result.get('spread_pct', 0)
                    logger.info(f"âœ… BINANCE ORDER SUCCESS: {result.get('id')} | method={result.get('entry_method', 'MARKET')} | slippage={fill_slippage:.3f}%")
                    
                    # Phase 186: Update entryPrice + SL/TP if actual fill differs
                    if abs(actual_fill - fill_price) / fill_price > 0.001:
                        new_position['entryPrice'] = actual_fill
                        # Recalculate SL/TP with actual fill
                        if side == 'LONG':
                            new_position['stopLoss'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_sl_atr))
                            new_position['takeProfit'] = actual_fill + (atr * adjusted_tp_atr)
                            new_position['trailActivation'] = actual_fill + (atr * adjusted_trail_activation_atr)
                            new_position['trailingStop'] = new_position['stopLoss']
                        else:
                            new_position['stopLoss'] = actual_fill + (atr * adjusted_sl_atr)
                            new_position['takeProfit'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_tp_atr))
                            new_position['trailActivation'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_trail_activation_atr))
                            new_position['trailingStop'] = new_position['stopLoss']
                        logger.info(f"ðŸ“ SL/TP RECALC: {symbol} fill=${actual_fill:.6f} vs expected=${fill_price:.6f} â†’ SL=${new_position['stopLoss']:.6f} TP=${new_position['takeProfit']:.6f}")
                else:
                    self.pipeline_metrics['order_failed'] += 1
                    order_error = (live_binance_trader.last_order_error or "unknown_order_error")[:120]
                    logger.error(f"âŒ BINANCE ORDER FAILED - skipping position creation")
                    self.add_log(f"âŒ BINANCE HATASI: {side} {symbol} - Emir gÃ¶nderilemedi ({order_error})")
                    self.set_execution_feedback(symbol, f"BINANCE_ORDER_FAILED:{order_error}")
                    return  # Don't create position if Binance order failed
                    
            except Exception as e:
                self.pipeline_metrics['order_failed'] += 1
                error_msg = str(e)[:80]  # Truncate long error messages
                order_error = live_binance_trader.last_order_error
                if order_error:
                    error_msg = f"{error_msg} | {order_error[:80]}"
                logger.error(f"âŒ LIVE ORDER ERROR: {e}")
                self.add_log(f"âŒ BINANCE HATASI: {side} {symbol} - {error_msg}")
                self.set_execution_feedback(symbol, "BINANCE_ORDER_ERROR")
                return  # Don't create position if there was an error
        elif force_market and is_live_mode:
            # Force market: bypass spread/drift guards, send direct market order
            try:
                logger.info(f"ðŸ”¥ FORCE MARKET ORDER: Sending {side} {symbol} to Binance (MARKET, no spread/drift check)...")
                self.pipeline_metrics['order_attempted'] += 1
                result = await live_binance_trader.place_market_order(
                    symbol=symbol,
                    side=side,
                    size_usd=order['sizeUsd'],
                    leverage=order['leverage']
                )
                if result:
                    self.pipeline_metrics['order_success'] += 1
                    new_position['binance_order_id'] = result.get('id')
                    actual_fill = result.get('price', fill_price)
                    new_position['binance_fill_price'] = actual_fill
                    new_position['isLive'] = True
                    new_position['entry_method'] = 'MARKET_FALLBACK'
                    new_position['entry_slippage'] = result.get('slippage_pct', 0)
                    new_position['entry_spread'] = result.get('spread_pct', 0)
                    logger.info(f"âœ… FORCE MARKET SUCCESS: {result.get('id')} | slippage={abs(result.get('slippage_pct', 0)):.3f}%")
                    # Recalculate SL/TP with actual fill
                    if abs(actual_fill - fill_price) / fill_price > 0.001:
                        new_position['entryPrice'] = actual_fill
                        if side == 'LONG':
                            new_position['stopLoss'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_sl_atr))
                            new_position['takeProfit'] = actual_fill + (atr * adjusted_tp_atr)
                            new_position['trailActivation'] = actual_fill + (atr * adjusted_trail_activation_atr)
                            new_position['trailingStop'] = new_position['stopLoss']
                        else:
                            new_position['stopLoss'] = actual_fill + (atr * adjusted_sl_atr)
                            new_position['takeProfit'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_tp_atr))
                            new_position['trailActivation'] = max(actual_fill * 0.01, actual_fill - (atr * adjusted_trail_activation_atr))
                            new_position['trailingStop'] = new_position['stopLoss']
                else:
                    self.pipeline_metrics['order_failed'] += 1
                    self.pipeline_metrics['market_fallback_failed'] += 1
                    order_error = (live_binance_trader.last_order_error or "unknown_order_error")[:120]
                    logger.error(f"âŒ FORCE MARKET FAILED - skipping position creation")
                    self.add_log(f"âŒ MARKET FALLBACK HATASI: {side} {symbol} - Emir gÃ¶nderilemedi ({order_error})")
                    self.set_execution_feedback(symbol, f"MARKET_FALLBACK_FAILED:{order_error}")
                    return
            except Exception as e:
                self.pipeline_metrics['order_failed'] += 1
                self.pipeline_metrics['market_fallback_failed'] += 1
                order_error = live_binance_trader.last_order_error
                error_msg = str(e)[:80]
                if order_error:
                    error_msg = f"{error_msg} | {order_error[:80]}"
                logger.error(f"âŒ FORCE MARKET ERROR: {e}")
                self.add_log(f"âŒ MARKET FALLBACK HATASI: {side} {symbol} - {error_msg}")
                self.set_execution_feedback(symbol, "MARKET_FALLBACK_ERROR")
                return
        else:
            # Paper mode execution observability parity
            self.pipeline_metrics['order_attempted'] += 1
            self.pipeline_metrics['order_success'] += 1
        
        # Paper Trading: Initial Margin = Position Size / Leverage
        # KaldÄ±raÃ§lÄ± iÅŸlemde sadece teminat miktarÄ± bakiyeden dÃ¼ÅŸÃ¼lÃ¼r
        leverage = new_position.get('leverage', 10)
        initial_margin = new_position['sizeUsd'] / leverage
        new_position['initialMargin'] = initial_margin  # Store for close calculation
        
        # Live trading'de bakiyeyi dÃ¼ÅŸÃ¼rme - Binance zaten dÃ¼ÅŸÃ¼rdÃ¼
        if not live_binance_trader.enabled:
            self.balance -= initial_margin
        
        self.positions.append(new_position)
        self.pipeline_metrics['filled'] += 1
        self.clear_execution_feedback(symbol)
        
        # Save to SQLite for persistent openTime tracking
        try:
            await db_manager.save_open_position(new_position)
            logger.info(f"ðŸ“‚ Position saved to SQLite: {symbol} openTime={new_position.get('openTime')}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save position to SQLite: {e}")
        
        # Calculate how much better than signal price we got
        signal_price = order.get('signalPrice', fill_price)
        if side == 'LONG':
            improvement = ((signal_price - fill_price) / signal_price) * 100
        else:
            improvement = ((fill_price - signal_price) / signal_price) * 100
        
        live_tag = "ðŸ”´ LIVE" if live_binance_trader.enabled else "ðŸ“„ PAPER"
        self.add_log(f"âœ… {live_tag} FILLED: {side} {order['symbol']} @ ${fill_price:.4f} | Improvement: {improvement:.2f}% | Lev: {order['leverage']}x")
        self.save_state()
        logger.info(f"âœ… {live_tag} FILLED: {side} {order['symbol']} @ {fill_price} (improvement: {improvement:.2f}%)")
    
    # =========================================================================
    # PHASE 20: ADVANCED RISK MANAGEMENT METHODS
    # =========================================================================
    
    def get_dynamic_trail_distance(self, atr: float, roi_pct: float = 0) -> float:
        """
        Calculate trail distance based on current spread and ROI.
        Phase 59: ROI-based dynamic trail - more profit = wider trail
        """
        spread = self.current_spread_pct
        
        # Base trail distance from spread
        if spread < 0.05:
            base_trail = atr * 0.5  # Tight trailing for low spread
        elif spread < 0.15:
            base_trail = atr * 1.0  # Normal trailing
        else:
            base_trail = atr * (1.0 + spread)  # Wide trailing scales with spread
        
        # Phase 59: ROI-based multiplier - kÃ¢r arttÄ±kÃ§a trail geniÅŸler
        if roi_pct >= 50:
            roi_mult = 2.0  # Very profitable, give lots of room
        elif roi_pct >= 25:
            roi_mult = 1.5  # Good profit, moderate room
        elif roi_pct >= 10:
            roi_mult = 1.2  # Small profit, slightly more room
        else:
            roi_mult = 1.0  # Standard trail
        
        return base_trail * roi_mult
    
    def update_progressive_sl(self, pos: dict, current_price: float, atr: float):
        """Move SL progressively as position goes into profit.
        
        Thresholds are multiplied by exit_tightness:
        - Lower exit_tightness (0.3-0.5) = earlier SL moves
        - Higher exit_tightness (1.5-2.0) = later SL moves
        """
        entry = pos['entryPrice']
        
        # Apply exit_tightness to thresholds - lower = earlier activation
        t = self.get_effective_exit_tightness(pos)
        
        if pos['side'] == 'LONG':
            profit_atr = (current_price - entry) / atr if atr > 0 else 0
            
            # Thresholds scaled by exit_tightness
            if profit_atr >= 2.5 * t:
                new_sl = entry + (2.0 * atr)  # Lock in 2 ATR profit
            elif profit_atr >= 2.0 * t:
                new_sl = entry + (1.5 * atr)  # Lock in 1.5 ATR profit
            elif profit_atr >= 1.5 * t:
                new_sl = entry + (1.0 * atr)  # Lock in 1 ATR profit
            elif profit_atr >= 1.0 * t:
                new_sl = entry + (0.5 * atr)  # Lock in 0.5 ATR profit
            elif profit_atr >= 0.25 * t:
                new_sl = entry  # Breakeven (daha erken koruma)
            else:
                return False  # No change
                
            if new_sl > pos['stopLoss']:
                old_sl = pos['stopLoss']
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl  # Also update trailing stop
                self.add_log(f"ðŸ“ˆ PROGRESSIVE SL: ${old_sl:.6f} â†’ ${new_sl:.6f} (+{profit_atr:.1f} ATR)")
                return True
                
        elif pos['side'] == 'SHORT':
            profit_atr = (entry - current_price) / atr if atr > 0 else 0
            
            # Thresholds scaled by exit_tightness
            if profit_atr >= 2.5 * t:
                new_sl = entry - (2.0 * atr)
            elif profit_atr >= 2.0 * t:
                new_sl = entry - (1.5 * atr)
            elif profit_atr >= 1.5 * t:
                new_sl = entry - (1.0 * atr)
            elif profit_atr >= 1.0 * t:
                new_sl = entry - (0.5 * atr)
            elif profit_atr >= 0.25 * t:
                new_sl = entry  # Breakeven (daha erken koruma)
            else:
                return False
                
            if new_sl < pos['stopLoss']:
                old_sl = pos['stopLoss']
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl  # Also update trailing stop
                self.add_log(f"ðŸ“ˆ PROGRESSIVE SL: ${old_sl:.6f} â†’ ${new_sl:.6f} (+{profit_atr:.1f} ATR)")
                return True
        
        return False
    
    def check_loss_recovery(self, pos: dict, current_price: float, atr: float) -> bool:
        """If in loss and recovering, trail to minimize loss."""
        entry = pos['entryPrice']
        
        if pos['side'] == 'LONG':
            loss_pct = ((entry - current_price) / entry) * 100 if entry > 0 else 0
            
            # Only if in loss (>1%) and price is recovering
            if loss_pct > 1:
                if 'recovery_low' not in pos:
                    pos['recovery_low'] = current_price
                elif current_price < pos['recovery_low']:
                    pos['recovery_low'] = current_price
                    
                # If price bounced from low by 0.3 ATR
                if current_price > pos['recovery_low'] + (atr * 0.3):
                    if not pos.get('recovery_mode', False):
                        pos['recovery_mode'] = True
                        pos['recovery_sl'] = current_price - (atr * 0.3)
                        self.add_log(f"ðŸ”„ RECOVERY MODE: Zarar minimizasyonu aktif @ ${current_price:.6f}")
                    else:
                        new_recovery_sl = current_price - (atr * 0.3)
                        if new_recovery_sl > pos.get('recovery_sl', 0):
                            pos['recovery_sl'] = new_recovery_sl
                            
                    # Check recovery SL hit
                    if current_price <= pos['recovery_sl']:
                        self.close_position(pos, current_price, 'RECOVERY_EXIT')
                        return True
                        
        elif pos['side'] == 'SHORT':
            loss_pct = ((current_price - entry) / entry) * 100 if entry > 0 else 0
            
            if loss_pct > 1:  # %1 kayÄ±pta recovery mode (daha erken mÃ¼dahale)
                if 'recovery_high' not in pos:
                    pos['recovery_high'] = current_price
                elif current_price > pos['recovery_high']:
                    pos['recovery_high'] = current_price
                    
                if current_price < pos['recovery_high'] - (atr * 0.3):
                    if not pos.get('recovery_mode', False):
                        pos['recovery_mode'] = True
                        pos['recovery_sl'] = current_price + (atr * 0.3)
                        self.add_log(f"ðŸ”„ RECOVERY MODE: Zarar minimizasyonu aktif @ ${current_price:.6f}")
                    else:
                        new_recovery_sl = current_price + (atr * 0.3)
                        if new_recovery_sl < pos.get('recovery_sl', float('inf')):
                            pos['recovery_sl'] = new_recovery_sl
                            
                    if current_price >= pos['recovery_sl']:
                        self.close_position(pos, current_price, 'RECOVERY_EXIT')
                        return True
        
        return False
    
    def check_time_based_exit(self, pos: dict, current_price: float, atr: float = None) -> bool:
        """Gradually liquidate positions that are open too long - close on bounces."""
        open_time = pos.get('openTime', 0)
        age_ms = int(datetime.now().timestamp() * 1000) - open_time
        age_hours = age_ms / (1000 * 60 * 60)
        
        if atr is None:
            atr = current_price * 0.01
        
        # exit_tightness ile Ã¶lÃ§eklendir: yÃ¼ksek = daha uzun tutma sÃ¼resi
        et = self.get_effective_exit_tightness(pos)
        adjusted_max_age = self.max_position_age_hours * et
        adjusted_hard_limit = 48 * et
        bounce_mult = 0.3 * et  # Bounce threshold: yÃ¼ksek = daha geniÅŸ
        
        # After adjusted max age, start gradual liquidation
        if age_hours > adjusted_max_age:
            # Mark position for gradual exit if not already
            if not pos.get('gradual_exit_mode', False):
                pos['gradual_exit_mode'] = True
                pos['gradual_exit_start'] = current_price
                self.add_log(f"â° ZAMAN AÅžIMI: {age_hours:.1f}h > {adjusted_max_age:.1f}h (x{et:.1f}) - AÅŸamalÄ± tasfiye")
            
            # For LONG: Close on bounces (price goes up then comes back)
            if pos['side'] == 'LONG':
                if 'gradual_high' not in pos:
                    pos['gradual_high'] = current_price
                elif current_price > pos['gradual_high']:
                    pos['gradual_high'] = current_price
                
                # If price dropped from high by bounce_mult * ATR, close position
                if pos['gradual_high'] - current_price >= atr * bounce_mult:
                    self.add_log(f"ðŸ“‰ BOUNCED EXIT: AÅŸamalÄ± tasfiye tamamlandÄ±")
                    pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_GRADUAL', 'roi': round(((current_price - pos['entryPrice']) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                    self.close_position(pos, current_price, 'TIME_GRADUAL')
                    return True
                    
            # For SHORT: Close when price dips then comes back
            elif pos['side'] == 'SHORT':
                if 'gradual_low' not in pos:
                    pos['gradual_low'] = current_price
                elif current_price < pos['gradual_low']:
                    pos['gradual_low'] = current_price
                
                # If price rose from low by bounce_mult * ATR, close position
                if current_price - pos['gradual_low'] >= atr * bounce_mult:
                    self.add_log(f"ðŸ“ˆ BOUNCED EXIT: AÅŸamalÄ± tasfiye tamamlandÄ±")
                    pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_GRADUAL', 'roi': round(((pos['entryPrice'] - current_price) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                    self.close_position(pos, current_price, 'TIME_GRADUAL')
                    return True
            
            # Hard limit: force close regardless
            if age_hours > adjusted_hard_limit:
                self.add_log(f"ðŸ†˜ {adjusted_hard_limit:.0f}h+ SAAT: Zorunlu Ã§Ä±kÄ±ÅŸ (x{et:.1f})")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TIME_FORCE', 'roi': round(((current_price - pos['entryPrice']) / pos['entryPrice'] * 100) if pos.get('side') == 'LONG' and pos['entryPrice'] > 0 else ((pos['entryPrice'] - current_price) / pos['entryPrice'] * 100) if pos['entryPrice'] > 0 else 0, 1)})
                self.close_position(pos, current_price, 'TIME_FORCE')
                return True
                
        return False
    
    def check_emergency_sl(self, pos: dict, current_price: float) -> bool:
        """Hard limit for maximum loss per position.
        
        Dynamic threshold: max(base_emergency_pct, actual_sl_distance * 1.5) * exit_tightness
        This ensures Emergency SL never triggers BEFORE normal SL on high-vol coins.
        exit_tightness scales the threshold: higher = more patient, lower = quicker exit.
        """
        entry = pos['entryPrice']
        
        if pos['side'] == 'LONG':
            loss_pct = ((entry - current_price) / entry) * 100 if entry > 0 else 0
        else:
            loss_pct = ((current_price - entry) / entry) * 100 if entry > 0 else 0
        
        # Dynamic emergency threshold: never tighter than the position's own SL
        sl_price = pos.get('stopLoss', 0)
        if sl_price > 0 and entry > 0:
            actual_sl_distance_pct = abs(entry - sl_price) / entry * 100
            effective_emergency_pct = max(self.emergency_sl_pct, actual_sl_distance_pct * 1.5)
        else:
            effective_emergency_pct = self.emergency_sl_pct
        
        # Apply exit_tightness: higher = wider emergency threshold (more patient)
        et = self.get_effective_exit_tightness(pos)
        effective_emergency_pct = effective_emergency_pct * et
        
        # Cap at 10% * exit_tightness to prevent runaway losses
        effective_emergency_pct = min(effective_emergency_pct, 10.0 * et)
            
        if loss_pct >= effective_emergency_pct:
            self.add_log(f"ðŸ†˜ ACÄ°L Ã‡IKIÅž: %{loss_pct:.1f} kayÄ±p (eÅŸik: %{effective_emergency_pct:.1f}, x{et:.1f})")
            self.close_position(pos, current_price, 'EMERGENCY_SL')
            return True
        return False
    
    def check_portfolio_drawdown(self) -> bool:
        """Phase 217: TÃ¼m aÃ§Ä±k pozisyonlarÄ±n toplam unrealized kaybÄ±nÄ± kontrol et."""
        if not self.positions:
            return False
        
        total_unrealized = sum(p.get('unrealizedPnl', 0) for p in self.positions)
        
        if self.balance <= 0:
            return False
        
        loss_pct = (total_unrealized / self.balance) * 100
        
        if loss_pct < -self.portfolio_max_unrealized_loss_pct:
            # En kÃ¶tÃ¼ pozisyondan baÅŸlayarak kapat
            sorted_positions = sorted(
                self.positions,
                key=lambda p: p.get('unrealizedPnl', 0)
            )
            
            # En kÃ¶tÃ¼ %50'sini kapat
            close_count = max(1, len(sorted_positions) // 2)
            to_close = list(sorted_positions[:close_count])  # Phase 243: snapshot to prevent list mutation
            for pos in to_close:
                current_price = pos.get('currentPrice', pos.get('entryPrice', 0))
                self.close_position(pos, current_price, 'PORTFOLIO_DRAWDOWN')
            
            self.add_log(
                f"ðŸš¨ PORTFÃ–Y KORUMA: Toplam kayÄ±p %{abs(loss_pct):.1f} "
                f"(limit: %{self.portfolio_max_unrealized_loss_pct}), "
                f"{close_count} pozisyon kapatÄ±ldÄ±"
            )
            return True
        return False
    
    def check_adverse_position_exit(self, pos: dict, current_price: float, atr: float = None) -> bool:
        """
        4 saat boyunca terste kalan pozisyonlarÄ± kontrol et.
        
        Kapatma kriterleri:
        1. Pozisyon 4+ saat terste (giriÅŸ fiyatÄ±nÄ±n ters tarafÄ±nda)
        2. Fiyat, pullback seviyesinden daha fazla dÃ¼ÅŸmemiÅŸse kapat
        
        Bu sayede:
        - DÃ¶nmeyecek pozisyonlardan erken Ã§Ä±kÄ±lÄ±r
        - Daha fazla dÃ¼ÅŸmemiÅŸse zarar minimize edilir
        """
        open_time = pos.get('openTime', 0)
        age_ms = int(datetime.now().timestamp() * 1000) - open_time
        age_hours = age_ms / (1000 * 60 * 60)
        
        # exit_tightness ile Ã¶lÃ§eklendir: yÃ¼ksek = daha sabÄ±rlÄ± (4h * 2.7 = 10.8h)
        et = self.get_effective_exit_tightness(pos)
        adverse_hours = 4 * et
        if age_hours < adverse_hours:
            return False
        
        entry = pos['entryPrice']
        # exit_tightness ile pullback geniÅŸlet: yÃ¼ksek = daha geniÅŸ tolerans
        pullback_pct = pos.get('pullbackPct', 1.0) * et
        
        if pos['side'] == 'LONG':
            # Terste mi? (fiyat entry'nin altÄ±nda)
            if current_price >= entry:
                return False  # KÃ¢rda, kontrol etme
            
            # Pullback threshold: entry'den ne kadar aÅŸaÄŸÄ± dÃ¼ÅŸebilir
            pullback_threshold = entry * (1 - pullback_pct / 100)
            
            # Fiyat pullback threshold'unun Ã¼stÃ¼ndeyse (Ã§ok fazla dÃ¼ÅŸmediyse) kapat
            if current_price >= pullback_threshold:
                loss_pct = ((entry - current_price) / entry) * 100
                self.add_log(f"â° ADVERSE EXIT: {pos['symbol']} {age_hours:.1f}h terste | Zarar: %{loss_pct:.2f}")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'ADVERSE_TIME', 'roi': round(-loss_pct, 1)})
                self.close_position(pos, current_price, 'ADVERSE_TIME_EXIT')
                return True
                
        elif pos['side'] == 'SHORT':
            # Terste mi? (fiyat entry'nin Ã¼stÃ¼nde)
            if current_price <= entry:
                return False  # KÃ¢rda, kontrol etme
            
            # Pullback threshold: entry'den ne kadar yukarÄ± Ã§Ä±kabilir
            pullback_threshold = entry * (1 + pullback_pct / 100)
            
            # Fiyat pullback threshold'unun altÄ±ndaysa (Ã§ok fazla yÃ¼kselmemiÅŸse) kapat
            if current_price <= pullback_threshold:
                loss_pct = ((current_price - entry) / entry) * 100
                self.add_log(f"â° ADVERSE EXIT: {pos['symbol']} {age_hours:.1f}h terste | Zarar: %{loss_pct:.2f}")
                pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'ADVERSE_TIME', 'roi': round(-loss_pct, 1)})
                self.close_position(pos, current_price, 'ADVERSE_TIME_EXIT')
                return True
        
        return False

    
    def check_daily_drawdown(self) -> bool:
        """Pause trading if daily loss exceeds limit."""
        # Phase 60: Use Turkey timezone (UTC+3) for consistency with get_today_pnl
        # pytz imported globally
        turkey_tz = pytz.timezone('Europe/Istanbul')
        now_turkey = datetime.now(turkey_tz)
        today_start = now_turkey.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_ms = int(today_start.timestamp() * 1000)
        
        today_trades = [t for t in self.trades if t.get('closeTime', 0) >= today_start_ms]
        daily_pnl = sum(t.get('pnl', 0) for t in today_trades)
        daily_pnl_pct = (daily_pnl / self.balance) * 100 if self.balance > 0 else 0
        
        if daily_pnl_pct < -self.daily_drawdown_limit:
            if self.enabled:
                self.enabled = False
                self.add_log(f"ðŸš¨ GÃœNLÃœK LÄ°MÄ°T: %{abs(daily_pnl_pct):.1f} kayÄ±p, trading durduruldu")
                self.save_state()
            return True
        return False

    def check_trailing_drawdown(self) -> bool:
        """Phase 206: Freqtrade Trailing Max Drawdown Guard (Profit Lock)
        Sistemin gun icinde ulastigi tepe (peak) degerinden belirli bir yuzde 
        dusus yasanirsa mevcut tum pozisyonlari kapatir ve profit lock uygular.
        """
        if self.balance <= 0:
            return False

        turkey_tz = pytz.timezone('Europe/Istanbul')
        now_turkey = datetime.now(turkey_tz)
        today_date = now_turkey.strftime("%Y-%m-%d")
        
        # Reset peak at new day
        if getattr(self, 'daily_peak_date', '') != today_date:
            self.daily_peak_date = today_date
            self.daily_peak_equity = self.balance
            
        total_unrealized = sum(p.get('unrealizedPnl', 0) for p in self.positions)
        current_equity = self.balance + total_unrealized
        
        # Update daily peak
        if current_equity > getattr(self, 'daily_peak_equity', 0):
            self.daily_peak_equity = current_equity
            
        if getattr(self, 'daily_peak_equity', 0) <= 0:
            return False
            
        peak_drawdown_pct = ((self.daily_peak_equity - current_equity) / self.daily_peak_equity) * 100
        limit = getattr(self, 'trailing_drawdown_limit', 5.0)
        
        # KÃ¢r kilidi: Zirve ile cari arasi fark treshold'u asarsa
        if peak_drawdown_pct >= limit:
            if not getattr(self, '_trailing_dd_locked_today', False):
                self._trailing_dd_locked_today = True  # Prevent spamming
                if self.positions:
                    for pos in list(self.positions):
                        current_price = pos.get('currentPrice', pos.get('entryPrice', 0))
                        self.close_position(pos, current_price, 'TRAILING_DD_LOCK')
                        
                self.add_log(f"ðŸ”’ PROFIT LOCK: GÃ¼nlÃ¼k zirveden %{peak_drawdown_pct:.1f} dÃ¼ÅŸÃ¼ÅŸ. Pozisyonlar kapatÄ±ldÄ±.")
                logger.warning(f"ðŸ”’ TRAILING DD LOCK: Peak Equity ${self.daily_peak_equity:.2f}, Current ${current_equity:.2f} (-{peak_drawdown_pct:.1f}%)")
                
                # Trading'i durdur
                if self.enabled:
                    self.enabled = False
                    self.add_log(f"ðŸš¨ PROFIT LOCK: Auto-Buy gÃ¼n sonuna kadar (veya manuel aÃ§Ä±lana dek) durduruldu.")
                    self.save_state()
                return True
                
        # Reset prevention flag if we recovered
        elif peak_drawdown_pct < limit * 0.5:
            self._trailing_dd_locked_today = False
            
        return False
        
        
    def load_state(self):
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    data = json.load(f)
                    self.balance = data.get('balance', 10000.0)
                    self.positions = data.get('positions', [])
                    self.trades = data.get('trades', [])
                    self.equity_curve = data.get('equity_curve', [])
                    self.stats = data.get('stats', self.stats)
                    self.enabled = data.get('enabled', True)
                    # Phase 17: Load settings
                    self.symbol = data.get('symbol', 'SOLUSDT')
                    self.leverage = data.get('leverage', 10)
                    self.risk_per_trade = data.get('risk_per_trade', 0.02)
                    # Phase 18: Load full trading parameters
                    self.sl_atr = data.get('sl_atr', 15)  # Default: 15 (1.5x ATR)
                    self.tp_atr = data.get('tp_atr', 30)  # Default: 30 (3.0x ATR)
                    self.trail_activation_atr = data.get('trail_activation_atr', 1.5)
                    self.trail_distance_atr = data.get('trail_distance_atr', 1.0)
                    self.max_positions = data.get('max_positions', 50)  # Default: 50
                    # Phase 32: Load algorithm sensitivity settings
                    self.z_score_threshold = data.get('z_score_threshold', 1.6)  # Default: 1.6
                    self.min_confidence_score = data.get('min_confidence_score', 68)  # Default: 68
                    # Phase 50: Dynamic Min Score Range
                    self.min_score_low = data.get('min_score_low', 60)  # Default: 60
                    self.min_score_high = data.get('min_score_high', 90)  # Default: 90
                    # Phase 36: Load entry/exit tightness
                    self.entry_tightness = data.get('entry_tightness', 1.8)  # Default: GevÅŸek
                    self.exit_tightness = data.get('exit_tightness', 1.2)  # Default: 1.2x
                    self.strategy_mode = str(data.get('strategy_mode', STRATEGY_MODE_LEGACY)).upper()
                    if self.strategy_mode not in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2):
                        self.strategy_mode = STRATEGY_MODE_LEGACY
                    # Phase 57: Load Kill Switch settings
                    if 'kill_switch_first_reduction' in data:
                        daily_kill_switch.first_reduction_pct = data.get('kill_switch_first_reduction', -100)
                    if 'kill_switch_full_close' in data:
                        daily_kill_switch.full_close_pct = data.get('kill_switch_full_close', -150)
                    # Phase 60: Load AI Optimizer state
                    self.ai_optimizer_enabled = data.get('ai_optimizer_enabled', False)
                    # Phase 217: Load leverage multiplier + daily_start_balance
                    self.leverage_multiplier = data.get('leverage_multiplier', 1.0)
                    self.daily_start_balance = data.get('daily_start_balance', self.balance)
                    self.daily_peak_equity = data.get('daily_peak_equity', self.daily_start_balance)
                    self.daily_peak_date = data.get('daily_peak_date', "")
                    self.trailing_drawdown_limit = data.get('trailing_drawdown_limit', 5.0)
                    # Sync with parameter_optimizer
                    try:
                        parameter_optimizer.enabled = self.ai_optimizer_enabled
                    except:
                        pass
                    # Phase 19: Load logs
                    self.logs = data.get('logs', [])
                    logger.info(f"Loaded Paper Trading: ${self.balance:.2f} | {self.symbol} | {self.leverage}x | SL:{self.sl_atr} TP:{self.tp_atr} | KS:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}")
                    
                    # Phase 48: Load kill switch faults from trade history
                    kill_switch_fault_tracker.load_from_trade_history(self.trades)
                    # Phase 59: Load coin performance stats from trade history
                    coin_performance_tracker.load_from_trade_history(self.trades)
                    # Phase 224B: Load EV signal filter state
                    self.score_band_stats = data.get('score_band_stats', {})
                    self.last_signal_per_coin = data.get('last_signal_per_coin', {})
                    self.signal_memory = data.get('signal_memory', {})
                    # Pipeline metrics persistence
                    saved_metrics = data.get('pipeline_metrics', {})
                    if saved_metrics:
                        self.pipeline_metrics.update(saved_metrics)
            except Exception as e:
                logger.error(f"Failed to load state: {e}")
                
    def save_state(self, force: bool = False):
        # Phase 217: Save state throttle â€” max 1 save per 2 seconds (unless force=True)
        now = datetime.now().timestamp()
        if not force and now - self._last_save_time < 2.0:
            return
        self._last_save_time = now
        try:
            data = {
                "balance": self.balance,
                "positions": self.positions,
                "trades": self.trades,
                "equity_curve": self.equity_curve[-500:],
                "stats": self.stats,
                "enabled": self.enabled,
                # Phase 17: Save settings
                "symbol": self.symbol,
                "leverage": self.leverage,
                "risk_per_trade": self.risk_per_trade,
                # Phase 18: Save full trading parameters
                "sl_atr": self.sl_atr,
                "tp_atr": self.tp_atr,
                "trail_activation_atr": self.trail_activation_atr,
                "trail_distance_atr": self.trail_distance_atr,
                "max_positions": self.max_positions,
                # Phase 32: Save algorithm sensitivity settings
                "z_score_threshold": self.z_score_threshold,
                "min_confidence_score": self.min_confidence_score,
                # Phase 50: Dynamic Min Score Range
                "min_score_low": self.min_score_low,
                "min_score_high": self.min_score_high,
                # Phase 36: Save entry/exit tightness
                "entry_tightness": self.entry_tightness,
                "exit_tightness": self.exit_tightness,
                "strategy_mode": self.strategy_mode,
                # Phase 57: Kill Switch settings
                "kill_switch_first_reduction": daily_kill_switch.first_reduction_pct,
                "kill_switch_full_close": daily_kill_switch.full_close_pct,
                # Phase 60: AI Optimizer state
                "ai_optimizer_enabled": self.ai_optimizer_enabled,
                # Phase 217: Leverage multiplier + daily_start_balance
                "leverage_multiplier": getattr(self, 'leverage_multiplier', 1.0),
                "daily_start_balance": self.daily_start_balance,
                "daily_peak_equity": getattr(self, 'daily_peak_equity', self.daily_start_balance),
                "daily_peak_date": getattr(self, 'daily_peak_date', ""),
                "trailing_drawdown_limit": getattr(self, 'trailing_drawdown_limit', 5.0),
                # Phase 19: Save logs
                "logs": self.logs[-100:],
                # Phase 224B: EV signal filter state
                "score_band_stats": self.score_band_stats,
                "last_signal_per_coin": self.last_signal_per_coin,
                "signal_memory": self.signal_memory,
                "pipeline_metrics": self.pipeline_metrics,
            }
            with open(self.state_file, 'w') as f:
                json.dump(data, f)
        except Exception as e:
            logger.error(f"Failed to save state: {e}")

    def reset(self):
        """Reset paper trading to initial state.
        In live mode, preserves Binance balance instead of hardcoding 10000.
        """
        # Live modda Binance balance'Ä±nÄ± koru, paper modda 10000 kullan
        if live_binance_trader.enabled and hasattr(self, 'balance') and self.balance > 0:
            reset_balance = self.balance  # Keep current Binance balance
            logger.info(f"ðŸ”„ Reset: Keeping live balance ${reset_balance:.2f}")
        else:
            reset_balance = 10000.0
        
        self.balance = reset_balance
        self.initial_balance = reset_balance
        self.positions = []
        self.trades = []
        self.equity_curve = [{"time": int(datetime.now().timestamp() * 1000), "balance": reset_balance, "drawdown": 0.0}]
        self.stats = {
            "totalTrades": 0, "winningTrades": 0, "losingTrades": 0, "winRate": 0.0,
            "totalPnl": 0.0, "maxDrawdown": 0.0, "profitFactor": 0.0
        }
        # Phase 32: Clear old logs on reset
        self.logs = []
        # Clear pending orders
        self.pending_orders = []
        self.signal_memory = {}
        # Reset pipeline metrics
        for key in self.pipeline_metrics:
            self.pipeline_metrics[key] = 0
        self.save_state()
        logger.info("ðŸ”„ Paper Trading Reset to $10,000")

    def close_position_by_id(self, position_id: str, current_price: float) -> bool:
        """Close a specific position by ID."""
        pos = next((p for p in self.positions if p['id'] == position_id), None)
        if not pos:
            return False
        self.close_position(pos, current_price, 'MANUAL')
        return True

    def on_signal(self, signal: Dict, current_price: float):
        # Phase 19: Log signal received
        action = signal.get('action', 'UNKNOWN')
        self.add_log(f"ðŸ“¡ SÄ°NYAL ALINDI: {action} @ ${current_price:.6f}")
        
        # Phase 16: Check if auto-trade is enabled
        if not self.enabled:
            self.add_log(f"â¸ï¸ Auto-trade kapalÄ±, iÅŸlem yapÄ±lmadÄ±")
            return
        
        # Phase 22: Multi-position and hedging logic
        action = signal.get('action', 'UNKNOWN')
        
        # Check total position limit
        if len(self.positions) >= self.max_positions:
            self.add_log(f"âš ï¸ Max pozisyon limiti ({self.max_positions}), yeni iÅŸlem yapÄ±lmadÄ±")
            return
        
        # PHASE 33: Position scaling is handled in open_position method
        # This method is mainly for opposite signal exit logic
        
        # =====================================================================
        # PHASE 29: ENHANCED OPPOSITE SIGNAL EXIT - BALANCE PROTECTION FOCUS
        # =====================================================================
        
        opposite_positions = [p for p in self.positions if p.get('side') != action]
        
        # ATR for calculations (fallback to 1% of price)
        atr_estimate = current_price * 0.01
        
        for pos in opposite_positions:
            entry = pos.get('entryPrice', current_price)
            
            # Calculate PnL percentage
            if pos['side'] == 'LONG':
                pnl_pct = ((current_price - entry) / entry) * 100
            else:
                pnl_pct = ((entry - current_price) / entry) * 100
            
            # 1. PROFITABLE: Close immediately to lock profit
            if pnl_pct > 0.5:  # At least 0.5% profit
                self.add_log(f"ðŸ”„ SÄ°NYAL TERSÄ°NE DÃ–NDÃœ: {pos['side']} %{pnl_pct:.1f} karlÄ± kapatÄ±lÄ±yor!")
                self.close_position(pos, current_price, 'SIGNAL_REVERSAL_PROFIT')
                continue
            
            # 2. SMALL LOSS (-2% to 0.5%): Activate breakeven trailing
            elif pnl_pct > -2:
                if not pos.get('breakeven_mode', False):
                    pos['breakeven_mode'] = True
                    pos['isTrailingActive'] = True
                    # Set tight trailing to try to close at breakeven or minimal loss
                    if pos['side'] == 'LONG':
                        pos['trailingStop'] = current_price - (atr_estimate * 0.3)
                        pos['trailDistance'] = atr_estimate * 0.3
                    else:
                        pos['trailingStop'] = current_price + (atr_estimate * 0.3)
                        pos['trailDistance'] = atr_estimate * 0.3
                    self.add_log(f"ðŸ›¡ï¸ BREAKEVEN MODE: {pos['side']} %{pnl_pct:.1f} - SÄ±kÄ± trailing aktif")
            
            # 3. LARGER LOSS (< -2%): Recovery mode with emergency SL
            else:
                if not pos.get('recovery_mode', False):
                    pos['recovery_mode'] = True
                    pos['isTrailingActive'] = True
                    # Set emergency stop loss to prevent further losses
                    if pos['side'] == 'LONG':
                        # Set SL at current price minus small buffer (accept the loss)
                        emergency_sl = current_price - (atr_estimate * 0.5)
                        pos['stopLoss'] = max(pos.get('stopLoss', 0), emergency_sl)
                    else:
                        emergency_sl = current_price + (atr_estimate * 0.5)
                        pos['stopLoss'] = min(pos.get('stopLoss', float('inf')), emergency_sl)
                    self.add_log(f"ðŸ†˜ RECOVERY MODE: {pos['side']} %{pnl_pct:.1f} - Emergency SL aktif @ {pos['stopLoss']:.6f}")

        # If hedging is disabled, check for opposite direction (Check again as some might have closed above)
        if not self.allow_hedging:
            remaining_opposite = [p for p in self.positions if p.get('side') != action]
            if len(remaining_opposite) > 0:
                self.add_log(f"âš ï¸ Hedging kapalÄ±, zaten ters pozisyon var")
                return

        # =====================================================================
        # PHASE 29: BALANCE-PROTECTED POSITION SIZING
        # PHASE 30: KELLY CRITERION + SESSION MANAGER
        # =====================================================================
        
        # Update BalanceProtector with current balance
        balance_protector.update_peak(self.balance)
        
        # Get leverage from signal (spread-based dynamic leverage)
        leverage = signal.get('leverage', self.leverage)
        
        # Phase 30: Apply SessionManager leverage adjustment
        session_adjusted_leverage = session_manager.adjust_leverage(leverage)
        
        # Apply BalanceProtector leverage multiplier
        leverage_mult = balance_protector.calculate_leverage_multiplier(self.balance)
        # Phase 238 fix: WS path already bakes user_mult into signal['leverage']
        if signal.get('leverage_includes_user_mult'):
            user_lev_mult = 1.0  # already included â€” avoid double-scaling
        else:
            user_lev_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        adjusted_leverage = int(session_adjusted_leverage * leverage_mult * user_lev_mult)
        adjusted_leverage = max(3, min(75, adjusted_leverage))
        raw_leverage = signal.get('signalLeverageRaw', adjusted_leverage)  # Phase 238B
        
        # Phase 230B: Override leverage cap (BTC counter-trend protection)
        if signal.get('overrideLeverageCap'):
            cap = signal['overrideLeverageCap']
            if adjusted_leverage > cap:
                logger.info(f"ðŸ’ª OVERRIDE LEV CAP: {symbol} {adjusted_leverage}x â†’ {cap}x")
                adjusted_leverage = cap
        
        # Phase 238B: LEV_PIPE log
        _lev_cap_reason2 = signal.get('leverageCapReason', 'none')
        if raw_leverage != adjusted_leverage:
            logger.info(f"LEV_PIPE: {symbol} raw={raw_leverage} â†’ effective={adjusted_leverage} cap={_lev_cap_reason2}")
        signal['signalLeverageRaw'] = raw_leverage
        signal['signalLeverageEffective'] = adjusted_leverage
        
        # Get size multiplier from signal and BalanceProtector
        signal_size_mult = signal.get('sizeMultiplier', 1.0)
        balance_size_mult = balance_protector.calculate_position_size_multiplier(self.balance)
        final_size_mult = signal_size_mult * balance_size_mult
        
        # Check if we should reduce risk
        if balance_protector.should_reduce_risk(self.balance):
            final_size_mult *= 0.5  # Additional 50% reduction
            self.add_log(f"âš ï¸ DRAWDOWN KORUMASI: Pozisyon boyutu azaltÄ±ldÄ±")
        
        # Phase 30: Kelly Criterion position sizing
        kelly_risk = self.calculate_kelly_fraction()
        session_risk = session_manager.adjust_risk(kelly_risk)
        
        # Position Sizing with Kelly
        risk_amount = self.balance * session_risk * final_size_mult
        position_size_usd = risk_amount * adjusted_leverage
        position_size = position_size_usd / current_price
        
        # Log session info
        session_info = session_manager.get_session_info()
        self.add_log(f"ðŸ“ Session: {session_info['name_tr']} | Kelly: {kelly_risk*100:.1f}% | Lev: {adjusted_leverage}x")
        
        new_position = {
            "id": f"{int(datetime.now().timestamp())}_{signal['action']}",
            "symbol": self.symbol,
            "side": signal['action'],
            "entryPrice": current_price,
            "size": position_size,
            "sizeUsd": position_size_usd,
            "contracts": position_size,  # Phase 223b: needed for partial TP
            "stopLoss": signal['sl'],
            "takeProfit": signal['tp'],
            "trailingStop": signal['sl'],
            "trailActivation": signal['trailActivation'],
            "trailDistance": signal['trailDistance'],
            "isTrailingActive": False,
            "unrealizedPnl": 0.0,
            "unrealizedPnlPercent": 0.0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": adjusted_leverage,  # Phase 29: Store leverage
            "spreadLevel": signal.get('spreadLevel', 'normal'),  # Phase 29: Store spread level
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": 0.0,
            "mfe_pct": 0.0,
            "mae_price": current_price,
            "mfe_price": current_price,
            "decision_trace": [],
            # Runtime trail telemetry (updated every tick)
            "effectiveExitTightness": self.exit_tightness,
            "runtimeTrailDistance": signal.get('trailDistance', 0),
            "runtimeTrailDistancePct": round((signal.get('trailDistance', 0) / current_price * 100), 4) if current_price > 0 else 0.0,
            "runtimeTrailActivationMovePct": 0.0,
            "runtimeTrailActivationRoiPct": 0.0,
            "runtimeTrailThresholdMult": 1.0,
            "runtimeTrailLastUpdateTs": int(datetime.now().timestamp() * 1000),
            # Phase 238B: Leverage pipeline fields
            "signalLeverageRaw": signal.get('signalLeverageRaw', adjusted_leverage),
            "signalLeverageEffective": adjusted_leverage,
            "leverageCapApplied": signal.get('leverageCapApplied', False),
            "leverageCapReason": signal.get('leverageCapReason', ''),
        }
        
        # Paper Trading: Initial Margin = Position Size / Leverage
        # KaldÄ±raÃ§lÄ± iÅŸlemde sadece teminat miktarÄ± bakiyeden dÃ¼ÅŸÃ¼lÃ¼r
        initial_margin = new_position['sizeUsd'] / adjusted_leverage
        new_position['initialMargin'] = initial_margin  # Store for close calculation
        self.balance -= initial_margin
        
        self.positions.append(new_position)
        
        # Save to SQLite for persistent openTime tracking
        try:
            asyncio.create_task(db_manager.save_open_position(new_position))
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save position to SQLite: {e}")
        
        self.add_log(f"ðŸš€ POZÄ°SYON AÃ‡ILDI: {signal['action']} {self.symbol} @ ${current_price:.4f} | {adjusted_leverage}x | SL:${signal['sl']:.4f} TP:${signal['tp']:.4f}")
        self.save_state()
        logger.info(f"ðŸš€ OPEN POSITION: {signal['action']} {self.symbol} @ {current_price} | {adjusted_leverage}x | Size: ${position_size_usd:.2f}")

    def update(self, current_price: float, atr: float = None):
        """Update positions with Phase 20 Advanced Risk Management."""
        # Phase 20: Check daily drawdown first
        if self.check_daily_drawdown():
            return
        # Phase 206: Check trailing drawdown (Profit Lock)
        if self.check_trailing_drawdown():
            return
        # Phase 217: Check portfolio-level drawdown
        if self.check_portfolio_drawdown():
            return
        
        # Calculate ATR-like value from position if not provided
        if atr is None:
            atr = current_price * 0.01  # Fallback: 1% of price as ATR estimate
        
        for pos in list(self.positions):
            # Skip if already closed by another check
            if pos not in self.positions:
                continue
            
            # Phase 190: Use per-position price (from fast loop WebSocket / Binance sync updates)
            current_price = pos.get('currentPrice', pos.get('markPrice', current_price))
            atr = pos.get('atr', current_price * 0.01)
            
            # Phase 212: Entry-based Emergency SL DEVRE DIÅžI
            # Trail-based Emergency SL (pre-guard, %1) zaten flash crash koruyor.
            # Entry-based versiyon volatile coin'lerde erken kapanmaya neden oluyordu.
            # Kalan korumalar: Trail Emergency SL, Normal SL, Adverse Exit, Time Exit, Daily Drawdown
            # if self.check_emergency_sl(pos, current_price):
            #     continue
            
            # Phase 210: Flash Trade Guard â€” minimum 60s hold time
            MIN_HOLD_SECONDS_PT = 60
            open_time_ms_pt = pos.get('openTime', 0)
            if open_time_ms_pt > 0:
                hold_duration_pt = datetime.now().timestamp() - (open_time_ms_pt / 1000)
                if hold_duration_pt < MIN_HOLD_SECONDS_PT:
                    continue  # Skip remaining exit checks â€” too early
                
            # Calc PnL
            if pos['side'] == 'LONG':
                pnl = (current_price - pos['entryPrice']) * pos['size']
            else:
                pnl = (pos['entryPrice'] - current_price) * pos['size']
            
            pnl_percent = (pnl / pos['sizeUsd']) * 100 * pos.get('leverage', 10) if pos.get('sizeUsd', 0) > 0 else 0
            
            pos['unrealizedPnl'] = pnl
            pos['unrealizedPnlPercent'] = pnl_percent
            
            # Phase 224A: MAE/MFE update
            if pnl_percent < pos.get('mae_pct', 0):
                pos['mae_pct'] = pnl_percent
                pos['mae_price'] = current_price
            if pnl_percent > pos.get('mfe_pct', 0):
                pos['mfe_pct'] = pnl_percent
                pos['mfe_price'] = current_price
            
            # Phase 217: Estimate funding fee cost
            open_time_ms = pos.get('openTime', 0)
            if open_time_ms > 0:
                age_hours = (datetime.now().timestamp() * 1000 - open_time_ms) / (1000 * 60 * 60)
                funding_periods = int(age_hours / 8)  # Her 8 saatte bir funding
                if funding_periods > 0:
                    symbol = pos.get('symbol', '')
                    rate = funding_oi_tracker.funding_rates.get(symbol, 0.0001) if 'funding_oi_tracker' in globals() else 0.0001
                    size_usd = pos.get('sizeUsd', 0)
                    pos['estimatedFundingCost'] = round(size_usd * abs(rate) * funding_periods, 4)
            
            # ===== PHASE 20: RISK MANAGEMENT PRIORITY ===== 
            
            # 1.5. Adverse Position Exit (4h terste kalan pozisyonlar)
            if self.check_adverse_position_exit(pos, current_price, atr):
                continue
            
            # 2. Time-based exit (gradual liquidation)
            if self.check_time_based_exit(pos, current_price, atr):
                continue
            
            # 3. Progressive SL (move SL to lock profits)
            self.update_progressive_sl(pos, current_price, atr)
            
            # 4. Loss Recovery Mode
            # DISABLED: Paper-only check_loss_recovery had a too-aggressive -1% threshold
            # that bypassed normal SL. All positions (paper + live) now use 
            # LossRecoveryTrailManager with spread-based thresholds (-3% to -7%)
            
            # ===== ORIGINAL TRAILING LOGIC (spread-aware + ROI-aware) =====
            
            # Phase 59: Calculate ROI for dynamic trail
            roi_pct = pos.get('unrealizedPnlPercent', 0)
            if roi_pct == 0:
                # Calculate if not cached
                entry = pos.get('entryPrice', 0)
                if entry > 0:
                    if pos['side'] == 'LONG':
                        roi_pct = ((current_price - entry) / entry) * 100 * pos.get('leverage', 1)
                    else:
                        roi_pct = ((entry - current_price) / entry) * 100 * pos.get('leverage', 1)
            
            # Get dynamic trail distance based on spread AND ROI
            dynamic_trail = self.get_dynamic_trail_distance(atr, roi_pct)
            
            # ================================================================
            # Phase 144: ROI-Based Trail Activation (with leverage + exit_tightness)
            # ================================================================
            # Phase 151: Spread-based trail activation ROI
            # Low volatility coins â†’ earlier activation, high volatility â†’ later
            spread_activation_map = {
                'Very Low': 2.0,   # BTC/ETH â€” low vol, early trail
                'Low':      3.0,
                'Normal':   4.0,
                'High':     6.0,   # High spread = later trail
                'Very High': 8.0,  # Meme â€” very volatile, late trail
                'Extreme':  12.0,  # Hyper-volatile
                'Ultra':    16.0   # Extreme edge cases
            }
            base_activation_roi = spread_activation_map.get(pos.get('spreadLevel', pos.get('spread_level', 'Normal')), 4.0)  # Phase 223c
            # Phase 218: Trail threshold must account for leverage â€” otherwise tiny price moves
            # on high leverage (e.g. 0.42% on 20x = 8.5% ROI) falsely trigger trail
            pos_leverage = pos.get('leverage', 10)
            activation_threshold = base_activation_roi * self.get_effective_exit_tightness(pos) * pos_leverage
            
            if pos['side'] == 'LONG':
                # LONG: ROI must be >= threshold (positive ROI)
                if roi_pct >= activation_threshold:
                    if not pos['isTrailingActive']:
                        self.add_log(f"ðŸ”„ TRAIL AKTÄ°F: {pos['symbol']} LONG ROI={roi_pct:.1f}% >= {activation_threshold:.1f}%")
                    pos['isTrailingActive'] = True
                
                if pos['isTrailingActive']:
                    new_sl = current_price - dynamic_trail
                    if new_sl > pos['trailingStop']:
                        pos['trailingStop'] = new_sl
                        pos['stopLoss'] = new_sl
                
                # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                if 'slConfirmCount' not in pos:
                    pos['slConfirmCount'] = 0
                if 'slBreachStartTime' not in pos:
                    pos['slBreachStartTime'] = 0
                
                now_ts = datetime.now().timestamp()
                if current_price <= pos['stopLoss']:
                    if pos['slConfirmCount'] == 0:
                        pos['slBreachStartTime'] = now_ts
                    pos['slConfirmCount'] += 1
                    breach_duration = now_ts - pos['slBreachStartTime']
                    if pos['slConfirmCount'] >= 5 and breach_duration >= 15:
                        # ROI negatifse SL'den kapanmÄ±ÅŸ â€” trailing aktif olsa bile etiket SL_HIT
                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive') and roi_pct >= 0) else 'SL_HIT'
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': reason, 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, reason)
                else:
                    if pos['slConfirmCount'] > 0:
                        self.add_log(f"âš¡ Spike bypassed: {pos['symbol']} LONG | {pos['slConfirmCount']} ticks")
                    pos['slConfirmCount'] = 0
                    pos['slBreachStartTime'] = 0
                    if current_price >= pos['takeProfit']:
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TP_HIT', 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, 'TP_HIT')
                    
            elif pos['side'] == 'SHORT':
                # SHORT: ROI must be >= threshold (positive ROI means price went down)
                if roi_pct >= activation_threshold:
                    if not pos['isTrailingActive']:
                        self.add_log(f"ðŸ”„ TRAIL AKTÄ°F: {pos['symbol']} SHORT ROI={roi_pct:.1f}% >= {activation_threshold:.1f}%")
                    pos['isTrailingActive'] = True
                    
                if pos['isTrailingActive']:
                    new_sl = current_price + dynamic_trail
                    if new_sl < pos['trailingStop']:
                        pos['trailingStop'] = new_sl
                        pos['stopLoss'] = new_sl
                
                # SPIKE BYPASS v2: 5-Tick + 30-Second Confirmation for SL
                if 'slConfirmCount' not in pos:
                    pos['slConfirmCount'] = 0
                if 'slBreachStartTime' not in pos:
                    pos['slBreachStartTime'] = 0
                
                now_ts = datetime.now().timestamp()
                if current_price >= pos['stopLoss']:
                    if pos['slConfirmCount'] == 0:
                        pos['slBreachStartTime'] = now_ts
                    pos['slConfirmCount'] += 1
                    breach_duration = now_ts - pos['slBreachStartTime']
                    if pos['slConfirmCount'] >= 5 and breach_duration >= 15:
                        # ROI negatifse SL'den kapanmÄ±ÅŸ â€” trailing aktif olsa bile etiket SL_HIT
                        reason = 'TRAIL_EXIT' if (pos.get('isTrailingActive') and roi_pct >= 0) else 'SL_HIT'
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': reason, 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, reason)
                else:
                    if pos['slConfirmCount'] > 0:
                        self.add_log(f"âš¡ Spike bypassed: {pos['symbol']} SHORT | {pos['slConfirmCount']} ticks")
                    pos['slConfirmCount'] = 0
                    pos['slBreachStartTime'] = 0
                    if current_price <= pos['takeProfit']:
                        pos.setdefault('decision_trace', []).append({'t': int(datetime.now().timestamp()), 'mgr': 'TP_HIT', 'roi': round(roi_pct, 1)})
                        self.close_position(pos, current_price, 'TP_HIT')

    def _format_detailed_reason(self, reason: str, pos: Dict, exit_price: float, pnl_percent: float) -> str:
        """
        Phase 138: Format detailed close reason for trade history.
        
        Returns a human-readable reason with specific trigger details.
        """
        symbol = pos.get('symbol', 'UNKNOWN')
        entry_price = pos.get('entryPrice', 0)
        sl = pos.get('stopLoss', 0)
        tp = pos.get('takeProfit', 0)
        trailing_stop = pos.get('trailingStop', 0)
        peak_price = pos.get('peakPrice', pos.get('entryPrice', 0))
        
        # Calculate distance percentages
        if entry_price > 0:
            exit_vs_entry_pct = ((exit_price - entry_price) / entry_price) * 100
            if pos.get('side') == 'SHORT':
                exit_vs_entry_pct = -exit_vs_entry_pct
        else:
            exit_vs_entry_pct = 0
        
        reason_map = {
            # Stop Loss variants
            'SL': f"ðŸ”´ SL: Stop Loss FiyatÄ± AÅŸÄ±ldÄ± ({pnl_percent:+.1f}%)",
            'SL_HIT': f"ðŸ”´ SL: Stop Loss Tetiklendi @ ${exit_price:.4f} ({pnl_percent:+.1f}%)",
            'EMERGENCY_SL': f"ðŸš¨ EMERGENCY: Acil Stop Loss ({pnl_percent:+.1f}%)",
            
            # Take Profit variants
            'TP': f"ðŸŸ¢ TP: Take Profit Hedefi ({pnl_percent:+.1f}%)",
            'TP_HIT': f"ðŸŸ¢ TP: Take Profit Tetiklendi @ ${exit_price:.4f} ({pnl_percent:+.1f}%)",
            
            # Trailing Stop
            'TRAIL': f"ðŸ“ˆ TRAIL: Trailing Stop ({pnl_percent:+.1f}%, peak'ten Ã§ekilme)",
            'TRAIL_EXIT': f"ðŸ“ˆ TRAIL: Trailing Stop Ã‡Ä±kÄ±ÅŸÄ± ({pnl_percent:+.1f}%)",
            'TRAILING_STOP': f"ðŸ“ˆ TRAIL: Trailing Stop Tetiklendi ({pnl_percent:+.1f}%)",
            
            # Kill Switch
            'KILL_SWITCH_FULL': f"âš ï¸ KILL: Kill Switch Tam Kapatma ({pnl_percent:+.1f}%)",
            'KILL_SWITCH_PARTIAL': f"âš ï¸ KILL: Kill Switch KÄ±smi (%50, {pnl_percent:+.1f}%)",
            
            # Time-based
            'TIME_REDUCE_4H': f"â° TIME: 4 Saat KuralÄ± (-10%, {pnl_percent:+.1f}%)",
            'TIME_REDUCE_8H': f"â° TIME: 8 Saat KuralÄ± (-10%, {pnl_percent:+.1f}%)",
            'TIME_GRADUAL': f"â° TIME: Kademeli Zaman Ã‡Ä±kÄ±ÅŸÄ± ({pnl_percent:+.1f}%)",
            'TIME_FORCE': f"â° TIME: Zorunlu Zaman Ã‡Ä±kÄ±ÅŸÄ± ({pnl_percent:+.1f}%)",
            
            # Recovery & Adverse
            'RECOVERY_EXIT': f"ðŸ”„ RECOVERY: Toparlanma Ã‡Ä±kÄ±ÅŸÄ± ({pnl_percent:+.1f}%)",
            'ADVERSE_TIME_EXIT': f"âš¡ ADVERSE: Olumsuz Zaman Ã‡Ä±kÄ±ÅŸÄ± ({pnl_percent:+.1f}%)",
            
            # Manual
            'MANUAL': f"ðŸ‘¤ MANUAL: Manuel Kapatma ({pnl_percent:+.1f}%)",
            
            # Signal Reversal
            'SIGNAL_REVERSAL_PROFIT': f"ðŸ”„ REVERSAL: Sinyal DeÄŸiÅŸimi KarlÄ± Ã‡Ä±kÄ±ÅŸ ({pnl_percent:+.1f}%)",
            
            # Phase 214: Failed Continuation
            'FAILED_CONTINUATION': f"ðŸ”„ FAILED_CONT: KalÄ±cÄ±lÄ±k SaÄŸlanamadÄ± â€” {pos.get('fc_failed_count', 0)} baÅŸarÄ±sÄ±z deneme ({pnl_percent:+.1f}%)",
            
            # Phase 217: Portfolio Drawdown
            'PORTFOLIO_DRAWDOWN': f"ðŸš¨ PORTFÃ–Y: Toplam kayÄ±p limiti aÅŸÄ±ldÄ± ({pnl_percent:+.1f}%)",
        }
        
        return reason_map.get(reason, f"ðŸ“‹ {reason} ({pnl_percent:+.1f}%)")

    def close_position(self, pos: Dict, exit_price: float, reason: str):
        """
        Close a position and record it in trade history.
        For live trading, also schedules async Binance close.
        """
        # Phase 243: Atomic idempotent guard â€” check and set flag before any work
        if pos.get('_closing') or pos not in self.positions:
            logger.warning(f"âš ï¸ IDEMPOTENT_GUARD: {pos.get('symbol')} already closing/removed, skipping ({reason})")
            return None
        pos['_closing'] = True
        
        # Calculate PnL
        # Phase 244B: Use actual Binance fill price for entry if available (slippage correction)
        effective_entry = pos.get('entryPrice', 0)
        fill_entry = pos.get('binance_fill_price', 0)
        if fill_entry > 0 and pos.get('isLive', False):
            effective_entry = fill_entry  # Use real Binance fill instead of signal price
        
        if pos['side'] == 'LONG':
            pnl = (exit_price - effective_entry) * pos['size']
        else:
            pnl = (effective_entry - exit_price) * pos['size']
        
        # Phase 244: Deduct estimated round-trip trading fees for accurate PNL reporting
        # Binance Futures fee ~0.04% per side (0.036% with BNB), round-trip = ~0.08%
        notional = abs(exit_price * pos['size'])
        estimated_fee = notional * 0.0008  # 0.08% round-trip
        pnl -= estimated_fee
        
        # Phase 244B: Deduct accumulated funding fees (tracked per position in sync loop)
        accumulated_funding = pos.get('accumulated_funding', 0)
        if accumulated_funding != 0:
            pnl += accumulated_funding  # funding can be + or - (already signed)
            logger.info(f"ðŸ“Š PNL_FUNDING: {pos.get('symbol')} funding adjustment: ${accumulated_funding:+.4f}")
        
        # Paper Trading: Pozisyon kapandÄ±ÄŸÄ±nda Initial Margin + PnL bakiyeye eklenir
        initial_margin = pos.get('initialMargin', pos.get('sizeUsd', 0) / pos.get('leverage', 10))
        
        # Live trading'de bakiye Binance'den senkronize edilir
        if not live_binance_trader.enabled:
            self.balance += initial_margin + pnl
        
        # Remove from positions list
        if pos in self.positions:
            self.positions.remove(pos)
        
        # Update SQLite: mark position as CLOSED with close_time
        try:
            pos_id = pos.get('id', '')
            pos_symbol = pos.get('symbol', '')
            asyncio.create_task(db_manager.close_position_in_db(pos_id, pos_symbol))
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to close position in SQLite: {e}")
        
        # Record trade
        trade = {
            "id": pos.get('id', f"trade_{int(datetime.now().timestamp())}"),
            "symbol": pos.get('symbol', 'UNKNOWN'),
            "side": pos.get('side', 'LONG'),
            "entryPrice": pos.get('entryPrice', 0),
            "exitPrice": exit_price,
            "size": pos.get('size', 0),
            "sizeUsd": pos.get('sizeUsd', 0),
            "pnl": pnl,
            "pnlPercent": (pnl / initial_margin * 100) if initial_margin > 0 else 0,
            "margin": initial_margin,
            "roi": (pnl / initial_margin * 100) if initial_margin > 0 else 0,
            "openTime": pos.get('openTime', 0),
            "closeTime": int(datetime.now().timestamp() * 1000),
            "reason": reason,
            "leverage": pos.get('leverage', 10),
            "isLive": pos.get('isLive', False),
            "signalScore": pos.get('signalScore', 0),
            "mtfScore": pos.get('mtfScore', 0),
            "zScore": pos.get('zScore', 0),
            "spreadLevel": pos.get('spreadLevel', 'unknown'),
            "stopLoss": pos.get('stopLoss', 0),
            "takeProfit": pos.get('takeProfit', 0),
            "trailActivation": pos.get('trailActivation', 0),
            "trailingStop": pos.get('trailingStop', 0),
            "isTrailingActive": pos.get('isTrailingActive', False),
            "atr": pos.get('atr', 0),
            "slMultiplier": pos.get('slMultiplier', 0),
            "tpMultiplier": pos.get('tpMultiplier', 0),
            # Phase 155: AI Optimizer settings snapshot from open time
            "settingsSnapshot": pos.get('settingsSnapshot', {}),
            # Phase 186: Execution quality + complete position data
            "entry_method": pos.get('entry_method', 'MARKET'),
            "entry_slippage": pos.get('entry_slippage', 0),
            "entry_spread": pos.get('entry_spread', 0),
            "binance_fill_price": pos.get('binance_fill_price', 0),
            "binance_order_id": pos.get('binance_order_id', ''),
            "hurst": pos.get('hurst', 0.5),
            "adx": pos.get('adx', 0),
            "pullbackPct": pos.get('pullbackPct', 0),
            # Phase 224A: MAE/MFE + Decision Trace
            "mae_pct": round(pos.get('mae_pct', 0), 2),
            "mfe_pct": round(pos.get('mfe_pct', 0), 2),
            "decision_trace": pos.get('decision_trace', [])[-5:],
            # Phase 232: Canonical reason + legacy closeReason
            "closeReason": reason,
            # Phase 232: Close metrics snapshot
            "close_metrics_json": json.dumps({
                'entry': pos.get('entryPrice', 0),
                'exit': exit_price,
                'stopLoss': pos.get('stopLoss', 0),
                'takeProfit': pos.get('takeProfit', 0),
                'trailingStop': pos.get('trailingStop', 0),
                'atr': pos.get('atr', 0),
                'leverage': pos.get('leverage', 10),
                'price_move_pct': round(abs(exit_price - pos.get('entryPrice', 0)) / pos.get('entryPrice', 1) * 100, 4) if pos.get('entryPrice', 0) > 0 else 0,
                'roi_pct': round((pnl / initial_margin * 100), 2) if initial_margin > 0 else 0,
                'spreadLevel': pos.get('spreadLevel', 'unknown'),
                'isTrailingActive': pos.get('isTrailingActive', False),
            }),
        }
        
        # =====================================================================
        # PHASE 193: POST-CLOSE HOOKS (SL Guard, FreqAI, Hyperopt)
        # =====================================================================
        try:
            # 1. StoplossFrequencyGuard: Record SL exits
            if reason in ('SL_HIT', 'EMERGENCY_SL'):
                stoploss_frequency_guard.record_stoploss(
                    symbol=pos.get('symbol', 'UNKNOWN'),
                    reason=reason
                )
            
            # 2. FreqAI: Record trade features for ML training
            if freqai_model and freqai_model.enabled:
                ml_features = {
                    'zscore': pos.get('zScore', 0),
                    'hurst': pos.get('hurst', 0.5),
                    'rsi': pos.get('rsi', 50),
                    'adx': pos.get('adx', 25),
                    'volume_ratio': pos.get('volumeRatio', 1.0),
                    'bb_position': pos.get('bbPosition', 0),
                    'macd_histogram': pos.get('macdHistogram', 0),
                    'stoch_rsi_k': pos.get('stochRsiK', 50),
                    'ema_cross_bullish': 1.0 if pos.get('emaCross') == 'BULLISH' else 0.0,
                    'vwap_zscore': pos.get('vwapZscore', 0),
                    'spread_pct': pos.get('spreadPct', 0),
                    'funding_rate': pos.get('fundingRate', 0),
                    'imbalance': pos.get('imbalance', 0),
                    'signal_score': pos.get('signalScore', 0),
                    'leverage': pos.get('leverage', 10),
                    'atr_pct': (pos.get('atr', 0) / pos.get('entryPrice', 1)) * 100 if pos.get('entryPrice', 0) > 0 else 0,
                }
                freqai_model.record_trade(ml_features, pnl > 0)
            
            # 3. Hyperopt: Record trade data for parameter optimization
            if hhq_hyperoptimizer and hhq_hyperoptimizer.enabled:
                hhq_hyperoptimizer.record_trade(trade)
                if hhq_hyperoptimizer.should_auto_optimize():
                    asyncio.create_task(hhq_hyperoptimizer.optimize())
        except Exception as e:
            logger.warning(f"âš ï¸ Phase 193 post-close hook error: {e}")
        
        # Phase 138: LIVE positions - store reason for Binance sync, DON'T write trade yet
        # Binance sync will detect the close and write trade with this reason
        symbol = pos.get('symbol', 'UNKNOWN')
        is_live = pos.get('isLive', False)
        
        if is_live:
            # Store detailed reason for Binance sync to use
            leverage = pos.get('leverage', 10)
            size_usd = pos.get('sizeUsd', 0)
            margin = size_usd / leverage if leverage > 0 and size_usd > 0 else 0
            roi = (pnl / margin * 100) if margin > 0 else 0  # Leveraged ROI
            
            detailed_reason = self._format_detailed_reason(reason, pos, exit_price, roi)
            
            pending_close_reasons[symbol] = {
                "reason": detailed_reason,
                "original_reason": reason,
                "pnl": pnl,
                "exitPrice": exit_price,
                "timestamp": int(datetime.now().timestamp() * 1000),
                "trade_data": trade,  # Full trade data for Binance sync to use
                "entry_order_id": pos.get('binance_order_id', ''),  # Phase 229
            }
            logger.info(f"ðŸ“‹ PENDING REASON SET: {symbol} = {detailed_reason}")
            
            # Phase 187: Save to position_closes with ALL settings data
            try:
                close_data = {
                    'symbol': symbol,
                    'side': pos.get('side', 'LONG'),
                    'reason': detailed_reason,
                    'original_reason': reason,
                    'entryPrice': pos.get('entryPrice', 0),
                    'exitPrice': exit_price,
                    'pnl': pnl,
                    'leverage': leverage,
                    'sizeUsd': size_usd,
                    'margin': margin,
                    'roi': roi,
                    'timestamp': int(datetime.now().timestamp() * 1000),
                    # Phase 187: Complete settings + execution data
                    'stopLoss': pos.get('stopLoss', 0),
                    'takeProfit': pos.get('takeProfit', 0),
                    'atr': pos.get('atr', 0),
                    'trailingStop': pos.get('trailingStop', 0),
                    'trailActivation': pos.get('trailActivation', 0),
                    'settingsSnapshot': pos.get('settingsSnapshot', {}),
                    'entry_method': pos.get('entry_method', 'MARKET'),
                    'entry_slippage': pos.get('entry_slippage', 0),
                    'entry_spread': pos.get('entry_spread', 0),
                    'signalScore': pos.get('signalScore', 0),
                    'spreadLevel': pos.get('spreadLevel', 'unknown'),
                    'binance_fill_price': pos.get('binance_fill_price', 0),
                    'hurst': pos.get('hurst', 0.5),
                    'trade_id': trade.get('id', ''),
                    # Phase 224A
                    'mae_pct': round(pos.get('mae_pct', 0), 2),
                    'mfe_pct': round(pos.get('mfe_pct', 0), 2),
                    # Phase 224A: Decision trace
                    'decision_trace': json.dumps(pos.get('decision_trace', [])[-10:]),
                    # Phase 229: Order ID-based matching
                    'entry_order_id': pos.get('binance_order_id', ''),
                }
                safe_create_task(sqlite_manager.save_position_close(close_data))
            except Exception as e:
                logger.debug(f"SQLite position close save error: {e}")
            
            # Phase 187: ALSO save LIVE trades to trades table!
            # Previously only position_closes got the data, trades table was skipped
            try:
                safe_create_task(sqlite_manager.save_trade(trade))
                logger.info(f"ðŸ’¾ LIVE trade saved to trades table: {symbol} PnL={pnl:.4f}")
            except Exception as e:
                logger.debug(f"SQLite LIVE trade save error: {e}")
            
            # Still append to in-memory trades for frontend
            self.trades.append(trade)
        else:
            # PAPER positions: write trade history as normal
            self.trades.append(trade)
            
            # Save trade to SQLite (async, non-blocking)
            try:
                safe_create_task(sqlite_manager.save_trade(trade))
            except Exception as e:
                logger.debug(f"SQLite save error: {e}")
        
        # Update Stats (for both LIVE and PAPER)
        self.stats['totalTrades'] += 1
        self.stats['totalPnl'] += pnl
        if pnl > 0: 
            self.stats['winningTrades'] += 1
        else: 
            self.stats['losingTrades'] += 1
        
        # Update coin-specific stats for blacklist system
        symbol = pos.get('symbol', 'UNKNOWN')
        is_win = pnl > 0
        self.update_coin_stats(symbol, is_win, pnl)
        
        # Phase 224B: Update score band statistics for EV calculation
        signal_score = pos.get('signalScore', 0)
        if signal_score > 0:
            self.update_score_band_stats(signal_score, pnl)
        
        # Phase 224C: Record exit in ExitArbitrator
        try:
            roi_arb = (pnl / max(0.01, pos.get('initialMargin', 1))) * 100
            exit_arbitrator.record_exit(
                symbol=symbol,
                reason=reason,
                roi=roi_arb,
                pnl=pnl,
                decision_trace=pos.get('decision_trace', [])
            )
        except Exception as ea_err:
            logger.debug(f"ExitArbitrator error: {ea_err}")
        
        # Phase 224D3: Record result in CanaryMode (use stored flag)
        try:
            canary_mode.record_result(pos.get('id', ''), pnl, is_canary=pos.get('is_canary', False))
        except Exception as cm_err:
            logger.debug(f"CanaryMode error: {cm_err}")
        
        # Log position close
        live_tag = "ðŸ”´ LIVE" if pos.get('isLive', False) else "ðŸ“„ PAPER"
        emoji = "âœ…" if pnl > 0 else "âŒ"
        self.add_log(f"{emoji} {live_tag} KAPANDI [{reason}]: {pos.get('side', 'UNKNOWN')} @ ${exit_price:.4f} | PnL: ${pnl:.2f}")
        self.save_state(force=True)  # Critical: position close MUST be persisted
        logger.info(f"âœ… {live_tag} CLOSE: {reason} PnL: {pnl:.2f}")
        
        # =====================================================================
        # LIVE TRADING: Schedule close on Binance (fire-and-forget)
        # =====================================================================
        if live_binance_trader.enabled and pos.get('isLive', False):
            symbol = pos.get('symbol', '')
            side = pos.get('side', 'LONG')
            # Phase 141: Use contracts with size fallback for consistency with Binance API
            amount = pos.get('contracts', pos.get('size', 0))
            
            logger.info(f"ðŸ”´ LIVE CLOSE: Scheduling {side} {symbol} close on Binance...")
            
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.ensure_future(self._close_on_binance(symbol, side, amount))
                else:
                    loop.run_until_complete(self._close_on_binance(symbol, side, amount))
            except RuntimeError:
                asyncio.run(self._close_on_binance(symbol, side, amount))
            
            # Phase 157: Schedule Binance trade history fetch after close
            ui_state_cache.trigger_trade_fetch(delay_seconds=3)
        
        # Phase 52: Post-trade tracking for 24h analysis
        try:
            post_trade_tracker.start_tracking(trade)
        except Exception as e:
            logger.debug(f"Post-trade tracking error: {e}")
        
        # Phase 54: Record score components for analysis
        try:
            components = {
                'zScore': pos.get('zScore', 0),
                'signalScore': pos.get('signalScore', 0),
                'mtfScore': pos.get('mtfScore', 0),
                'spreadLevel': pos.get('spreadLevel', 'medium'),
                'hurst': pos.get('hurst', 0.5),
                'imbalance': pos.get('imbalance', 0),
            }
            score_component_analyzer.record_trade(trade, components)
        except Exception as e:
            logger.debug(f"Score component record error: {e}")
        
        # Phase 59: Record coin performance for learning
        try:
            coin_performance_tracker.record_trade(pos.get('symbol', ''), pnl, reason)
        except Exception as e:
            logger.debug(f"Coin performance record error: {e}")
    
    async def _close_on_binance(self, symbol: str, side: str, amount: float):
        """Helper to close position on Binance asynchronously.
        Phase 87: Now fetches actual Binance position size to prevent partial closes.
        """
        try:
            # Phase 87: Get ACTUAL position size from Binance (not paper trader)
            # This fixes the BULLA bug where paper size (57) != Binance size (60)
            binance_positions = await live_binance_trader.get_positions()
            actual_amount = amount  # fallback to paper amount
            
            for pos in binance_positions:
                if pos.get('symbol') == symbol:
                    actual_amount = pos.get('size', amount)
                    if abs(actual_amount - amount) > 0.001:
                        logger.warning(f"âš ï¸ Size mismatch: Paper={amount:.4f}, Binance={actual_amount:.4f} - using Binance size")
                    break
            
            result = await live_binance_trader.close_position(symbol, side, actual_amount)
            if result:
                close_order_id = str(result.get('id', ''))
                logger.info(f"âœ… BINANCE CLOSE SUCCESS: {symbol} | Size: {actual_amount:.4f} | OrderID: {close_order_id[:12]}")
                
                # Phase 229: Save close_order_id to pending_close_reasons + SQLite
                if close_order_id and symbol in pending_close_reasons:
                    pending_close_reasons[symbol]['close_order_id'] = close_order_id
                if close_order_id:
                    safe_create_task(sqlite_manager.update_close_order_id(symbol, close_order_id))
            else:
                logger.error(f"âŒ BINANCE CLOSE FAILED for {symbol}")
        except Exception as e:
            logger.error(f"âŒ LIVE CLOSE ERROR: {e}")



class SmartMoneyAnalyzer:
    """
    Analyzes Price Action for Smart Money Concepts (SMC).
    Focus: Fair Value Gaps (FVG) and Market Structure (BOS).
    """
    def __init__(self, window_size: int = 50):
        self.window_size = window_size
        self.fvgs = [] # List of {'top': float, 'bottom': float, 'type': 'BULL'|'BEAR', 'mitigated': bool, 'timestamp': int}
        self.structure = "NEUTRAL"
        
    def detect_fvg(self, highs: list, lows: list, closes: list, times: list):
        """
        Detects FVGs from the last 3 candles.
        Bullish FVG: Low[0] > High[2] (Gap Up)
        Bearish FVG: High[0] < Low[2] (Gap Down)
        """
        if len(highs) < 3: return
        
        # Bullish FVG
        # Previous 2 candles (idx -2) High vs Current candle (idx 0) Low
        # Wait, usually detection is confirmed after candle close. 
        # So we look at indices -1 (just closed), -2, -3.
        
        # Using [Current, Prev, PrevPrev] convention where -1 is latest closed
        # Indices: -1 (Latest), -2 (Middle), -3 (Oldest)
        
        # Bullish FVG: Low[-1] > High[-3]
        if lows[-1] > highs[-3]:
            gap_size = lows[-1] - highs[-3]
            # Filter tiny gaps (must be > 0.05% of price to be relevant)
            if gap_size > (closes[-1] * 0.0005):
                self.fvgs.append({
                    'top': lows[-1],
                    'bottom': highs[-3],
                    'type': 'BULLISH',
                    'mitigated': False,
                    'timestamp': times[-1]
                })

        # Bearish FVG: High[-1] < Low[-3]
        if highs[-1] < lows[-3]:
            gap_size = lows[-3] - highs[-1]
            if gap_size > (closes[-1] * 0.0005):
                self.fvgs.append({
                    'top': lows[-3],
                    'bottom': highs[-1],
                    'type': 'BEARISH',
                    'mitigated': False,
                    'timestamp': times[-1]
                })
                
        # Cleanup and Check Mitigation
        self.cleanup_mitigated(highs[-1], lows[-1])
        
    def cleanup_mitigated(self, current_high: float, current_low: float):
        # A FVG is mitigated if price trades completely through it.
        # Actually, often just touching it ("filling" it) counts.
        # Strict: If price closes beyond it? NO, usually if wick fills it.
        
        for fvg in self.fvgs:
            if fvg['mitigated']: continue
            
            if fvg['type'] == 'BULLISH':
                # Price drops below the bottom of the bullish gap
                if current_low < fvg['bottom']:
                    fvg['mitigated'] = True
            elif fvg['type'] == 'BEARISH':
                # Price rises above the top of the bearish gap
                if current_high > fvg['top']:
                    fvg['mitigated'] = True
        
        # Keep only last 10 unmitigated FVGs to avoid clutter
        unmitigated = [f for f in self.fvgs if not f['mitigated']]
        self.fvgs = unmitigated[-10:]
        
    def get_nearest_fvg(self, current_price: float) -> Optional[Dict]:
        """Finds nearest unmitigated FVG to current price (Magnet)."""
        if not self.fvgs: return None
        
        # Determine direction
        nearest = None
        min_dist = float('inf')
        
        for fvg in self.fvgs:
            # Distance from center of FVG
            center = (fvg['top'] + fvg['bottom']) / 2
            dist = abs(current_price - center)
            if dist < min_dist:
                min_dist = dist
                nearest = fvg
                
        return nearest

class PivotAnalyzer:
    """
    detects Dynamic Support & Resistance using Pivot Points.
    Port of LuxAlgo 'Support and Resistance Levels with Breaks'.
    """
    def __init__(self, left_bars: int = 15, right_bars: int = 15):
        self.left_bars = left_bars
        self.right_bars = right_bars
        self.resistances = deque(maxlen=5) # Store last 5 active resistance levels
        self.supports = deque(maxlen=5)    # Store last 5 active support levels
        self.last_clean_time = 0
        
    def update(self, highs: list, lows: list, times: list):
        """
        Check for NEW pivot points.
        A pivot is confirmed when we have 'right_bars' of data after it.
        So we specifically look at the candle at index -(right_bars + 1).
        """
        window = self.left_bars + self.right_bars + 1
        if len(highs) < window: return

        # Index of the potential pivot (start counting from end)
        # If we have 100 candles, right_bars=15.
        # We look at index -16.
        pivot_idx = -(self.right_bars + 1)
        
        # --- Check Pivot High ---
        # Get window of highs centered on pivot_idx
        # Slicing in Python is tricky with negative indices.
        # Simplest: Convert to full list indices if possible or use relative slices carefully.
        # Let's say pivot_idx is -16. Window starts at -31, ends at -1 (exclusive of current unmatched?) No.
        # range: [pivot_idx - left_bars : pivot_idx + right_bars + 1]
        
        # Safety check for slice bounds
        if abs(pivot_idx - self.left_bars) > len(highs): return
        
        candidate_high = highs[pivot_idx]
        
        # Check if it's the max in the window
        # Note: highs[pivot_idx] is single value.
        # We need to slice around it.
        start_i = pivot_idx - self.left_bars
        end_i = pivot_idx + self.right_bars + 1 # Slice end is exclusive
        
        # In negative indexing:
        # if pivot_idx = -16, right=15, left=15.
        # start = -31. end = 0? No, end = -16 + 15 + 1 = 0! which means up to the end.
        
        if end_i == 0:
            window_highs = highs[start_i:]
            window_lows = lows[start_i:]
        else:
            window_highs = highs[start_i:end_i]
            window_lows = lows[start_i:end_i]

        if len(window_highs) == window and candidate_high == max(window_highs):
            # FOUND RESISTANCE
            # Avoid duplicates: Check if we haven't added this one yet
            pivot_time = times[pivot_idx]
            if not any(r['timestamp'] == pivot_time for r in self.resistances):
                self.resistances.append({
                    'price': candidate_high,
                    'timestamp': pivot_time,
                    'broken': False
                })

        # --- Check Pivot Low ---
        candidate_low = lows[pivot_idx]
        if len(window_lows) == window and candidate_low == min(window_lows):
            # FOUND SUPPORT
            pivot_time = times[pivot_idx]
            if not any(s['timestamp'] == pivot_time for s in self.supports):
                self.supports.append({
                    'price': candidate_low,
                    'timestamp': pivot_time,
                    'broken': False
                })

    def check_breakout(self, close: float, open_price: float, volume_osc: float, vol_thresh: float = 20.0) -> Optional[str]:
        """
        Check if current PRICE breaks any active level with VOLUME.
        """
        # 1. Check Resistance Break (Bullish)
        # Condition: Close > Res AND Open < Res (Clean crossover) AND VolOsc > Thresh
        # Or simply Close > Res is enough?
        # Script says: crossover(close, highUsePivot) AND osc > volumeThresh
        
        for res in self.resistances:
            if not res['broken']:
                # Basic crossover check: Current Close > Res (and maybe prev close < Res?)
                # For simplicity, we just check if we are ABOVE it now.
                # But breakout implies 'just happened'.
                # We'll rely on the caller to provide 'just happened' context or just state "ABOVE RESISTANCE".
                # Actually, strictly for Signal Generation, we want the MOMENT.
                if close > res['price'] and open_price < res['price']: # Candle pierced it
                    if volume_osc > vol_thresh:
                        return "BREAKOUT_LONG"
        
        # 2. Check Support Break (Bearish)
        for sup in self.supports:
            if not sup['broken']:
                if close < sup['price'] and open_price > sup['price']:
                    if volume_osc > vol_thresh:
                        return "BREAKOUT_SHORT"
                        
        return None

def calculate_volume_osc(volumes: list, short_len: int = 5, long_len: int = 10) -> float:
    if len(volumes) < long_len: return 0.0
    
    # Simple EMA manual calc or use numpy convolve?
    # Or pandas ewm if we had pandas.
    # We can do simple smoothing.
    
    # Using np.mean for simplicity? No, EMA is crucial for speed.
    # Let's approximate EMA using latest values if we don't want full history.
    # But we have full history in 'volumes'.
    
    # Vectorized EMA with numpy?
    # Simple implementation:
    v = np.array(volumes)
    
    def ema(data, window):
        alpha = 2 / (window + 1)
        # Very standardized EMA implementation
        weights = (1 - alpha) ** np.arange(len(data))[::-1]
        weights /= weights.sum()
        return np.sum(data * weights) # This is Weighted Moving Average, close enough for short windows?
        # Actually EMA is recursive.
        
    # Better: Use simple SMA for now if EMA is too heavy?
    # User specifically asked for EMA logic.
    # Let's write a proper iterative EMA helper for the last value.
    
    def get_last_ema(data, N):
        alpha = 2 / (N + 1)
        ema = data[0]
        for val in data[1:]:
            ema = alpha * val + (1 - alpha) * ema
        return ema
        
    short_ema = get_last_ema(volumes, short_len)
    long_ema = get_last_ema(volumes, long_len)
    
    if long_ema == 0: return 0.0
    
    return 100 * (short_ema - long_ema) / long_ema

class BinanceStreamer:
    """
    Handles Binance data streaming and analysis.
    Uses WebSocket streams for real-time data (no rate limits).
    """
    
    def __init__(self, symbol: str = "BTC/USDT"):
        self.symbol = symbol
        self.raw_symbol = symbol.replace("/", "")  # BTCUSDT for WebSocket
        self.exchange: Optional[ccxt_async.binance] = None
        self.prices: deque = deque(maxlen=500)
        self.highs: deque = deque(maxlen=500)
        self.lows: deque = deque(maxlen=500)
        self.closes: deque = deque(maxlen=500)
        self.volumes: deque = deque(maxlen=500)
        self.spreads: deque = deque(maxlen=500)
        self.last_price: float = 0.0
        self.running: bool = False
        self.last_htf_trend: str = "NEUTRAL"
        self.signal_generator = SignalGenerator()
        self.pending_liquidation: Optional[Dict] = None
        
        # WebSocket stream state (real-time, no rate limits)
        self.ws_ticker: Dict = {}
        self.ws_spot_ticker: Dict = {} # SPOT Monitoring
        self.ws_order_book: Dict = {'bids': [], 'asks': []}
        
        # Phase 13: Volatility History
        self.atr_history: deque = deque(maxlen=200) # Store ATR values for VR calculation
        self.ws_connected: bool = False
        
        # Whale Hunter
        self.whale_detector = WhaleDetector(threshold_usd=100000.0) # $100k Threshold
        
        # SMC Analyzer (Phase 10)
        self.smc_analyzer = SmartMoneyAnalyzer()
        
        # Pivot Analyzer (Phase 11)
        self.pivot_analyzer = PivotAnalyzer(left_bars=15, right_bars=15)
        
        # Phase 15: Cloud Paper Trading Engine (Use global instance for REST API access)
        # Note: global_paper_trader is defined later, set in connect()
        self.paper_trader = None  # Will be set to global_paper_trader in connect()
        
        # Phase 28: Dynamic Coin Profile
        self.coin_profile = None  # Will be loaded in connect()
        
        logger.info(f"â˜ï¸ Cloud Paper Trading Active.")
    
    async def update_coin_profile(self):
        """Load or update coin profile for dynamic parameter optimization."""
        try:
            if self.exchange:
                self.coin_profile = await coin_profiler.get_or_update(self.symbol, self.exchange)
                logger.info(f"ðŸ“Š Coin profile loaded: {self.symbol} | Threshold: {self.coin_profile.get('optimal_threshold', 1.6)}")
            else:
                logger.warning("Exchange not connected, using default profile")
                self.coin_profile = coin_profiler._get_default_profile(self.symbol)
        except Exception as e:
            logger.error(f"Failed to load coin profile: {e}")
            self.coin_profile = coin_profiler._get_default_profile(self.symbol)

    async def connect(self):
        """Initialize CCXT exchange connection and WebSocket streams."""
        self.running = True
        self.exchange = ccxt_async.binance({
            'enableRateLimit': True,
            'options': {
                'defaultType': 'future',
            }
        })
        logger.info(f"Connected to Binance for {self.symbol}")
        
        # Start WebSocket streams in background
        asyncio.create_task(self.start_combined_stream())
        asyncio.create_task(self.start_liquidation_stream())
        asyncio.create_task(self.start_spot_stream()) # Phase 7: Spot
        asyncio.create_task(self.start_agg_trade_stream()) # Phase 9: Whale Hunter
        asyncio.create_task(self.monitor_htf_trend())
        
                
    async def start_agg_trade_stream(self):
        """Streams real-time Aggregated Trades for Whale Detection."""
        ws_url = f"wss://stream.binance.com:9443/ws/{self.symbol.lower().replace('/', '')}@aggTrade"
        while self.running:
            try:
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    while self.running:
                        msg = await ws.recv()
                        data = json.loads(msg)
                        # Process AggTrade
                        # e: event type, E: event time, p: price, q: quantity, m: is_buyer_maker
                        self.whale_detector.process_trade(
                            price=float(data['p']),
                            quantity=float(data['q']),
                            is_buyer_maker=data['m'],
                            timestamp=data['E']
                        )
            except Exception as e:
                logger.error(f"AggTrade Stream Error: {e}")
                await asyncio.sleep(5)

    async def monitor_htf_trend(self):
        """Periodically update 4H trend context."""
        while self.running:
            try:
                trend = await self.fetch_htf_trend()
                self.last_htf_trend = trend
                logger.info(f"HTF Trend Updated: {trend}")
                await asyncio.sleep(300) # Update every 5 minutes
            except Exception as e:
                logger.error(f"HTF Monitor error: {e}")
                await asyncio.sleep(60)

    async def start_spot_stream(self):
        """Connect to Binance SPOT WebSocket for Basis Monitoring."""
        symbol_lower = self.raw_symbol.lower()
        # Spot Stream URL
        ws_url = f"wss://stream.binance.com:9443/ws/{symbol_lower}@ticker"
        
        while self.running:
            try:
                # 20s Ping Interval (New Requirement Jan 2026)
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    logger.info(f"Connected to SPOT Stream: {symbol_lower}")
                    
                    while self.running:
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=30.0)
                            data = json.loads(msg)
                            
                            # Raw Stream Data for Ticker
                            if 'c' in data:
                                self.ws_spot_ticker = {
                                    'last': float(data.get('c', 0)),
                                    'volume': float(data.get('v', 0))
                                }
                        except asyncio.TimeoutError:
                            continue
                        except Exception as e:
                            logger.warning(f"Spot stream error: {e}")
                            break
            except Exception as e:
                logger.error(f"Spot Socket error: {e}")
                if self.running:
                    await asyncio.sleep(5)

    async def start_combined_stream(self):
        """Connect to Binance combined WebSocket for ticker + order book."""
        symbol_lower = self.raw_symbol.lower()
        # Combined stream: ticker + depth (20 levels, 100ms updates)
        ws_url = f"wss://fstream.binance.com/stream?streams={symbol_lower}@ticker/{symbol_lower}@depth20@100ms"
        
        while self.running:
            try:
                # 20s Ping Interval (Resilience Update)
                async with websockets.connect(ws_url, ping_interval=20) as ws:
                    logger.info(f"Connected to Binance WebSocket streams: {symbol_lower}")
                    self.ws_connected = True
                    
                    while self.running:
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=30.0)
                            data = json.loads(msg)
                            
                            if 'stream' in data and 'data' in data:
                                stream_name = data['stream']
                                stream_data = data['data']
                                
                                if '@ticker' in stream_name:
                                    # Update ticker data
                                    self.ws_ticker = {
                                        'last': float(stream_data.get('c', 0)),
                                        'open': float(stream_data.get('o', 0)), # Needed for breakout
                                        'high': float(stream_data.get('h', 0)),
                                        'low': float(stream_data.get('l', 0)),
                                        'volume': float(stream_data.get('v', 0)),
                                    }
                                elif '@depth' in stream_name:
                                    # Update order book data
                                    self.ws_order_book = {
                                        'bids': [[float(b[0]), float(b[1])] for b in stream_data.get('b', [])],
                                        'asks': [[float(a[0]), float(a[1])] for a in stream_data.get('a', [])],
                                    }
                        except asyncio.TimeoutError:
                            continue
                        except Exception as e:
                            logger.warning(f"Stream message error: {e}")
                            break
                            
            except Exception as e:
                logger.error(f"WebSocket stream error: {e}")
                self.ws_connected = False
                if self.running:
                    await asyncio.sleep(5)  # Reconnect delay
        
    async def disconnect(self):
        """Close exchange connection."""
        self.running = False
        if self.exchange:
            await self.exchange.close()
            logger.info("Disconnected from Binance")

    async def switch_symbol(self, new_symbol: str):
        """Switch the active symbol and restart streams."""
        if self.symbol == new_symbol:
            return

        logger.info(f"ðŸ”„ Switching symbol from {self.symbol} to {new_symbol}")

        # 1. Stop current streams
        await self.disconnect()

        # 2. Update symbol state
        self.symbol = new_symbol
        self.raw_symbol = new_symbol.replace("/", "")

        # 3. Clear data buffers
        self.prices.clear()
        self.highs.clear()
        self.lows.clear()
        self.closes.clear()
        self.volumes.clear()
        self.spreads.clear()
        self.ws_order_book = {'bids': [], 'asks': []}

        # 4. Restart connection
        # connect() will set running=True
        await self.connect()
            
    async def start_liquidation_stream(self):
        """Connect to Binance Futures liquidation WebSocket."""
        symbol_lower = self.raw_symbol.lower()
        ws_url = f"wss://fstream.binance.com/ws/{symbol_lower}@forceOrder"
        
        try:
            async with websockets.connect(ws_url) as ws:
                logger.info(f"Connected to Binance Liquidation Stream: {symbol_lower}")
                self.liquidation_ws = ws
                
                while self.running:
                    try:
                        msg = await asyncio.wait_for(ws.recv(), timeout=1.0)
                        data = json.loads(msg)
                        
                        if 'o' in data:
                            liq_data = data['o']
                            side = liq_data.get('S', 'UNKNOWN')
                            qty = float(liq_data.get('q', 0))
                            price = float(liq_data.get('p', 0))
                            amount_usd = qty * price
                            
                            # Add to signal generator
                            self.signal_generator.add_liquidation(side, amount_usd, price)
                            
                            # Store pending liquidation for next update
                            self.pending_liquidation = {
                                'side': 'SATIM' if side == 'SELL' else 'ALIM',
                                'amount': amount_usd,
                                'price': price,
                                'isCascade': amount_usd > 100000
                            }
                            
                            logger.info(f"ðŸ”¥ Liquidation: {side} ${amount_usd:,.0f} @ {price}")
                            
                    except asyncio.TimeoutError:
                        continue
                    except Exception as e:
                        logger.warning(f"Liquidation stream error: {e}")
                        await asyncio.sleep(1)
                        
        except Exception as e:
            logger.error(f"Failed to connect to liquidation stream: {e}")
            
    async def fetch_ticker(self) -> dict:
        """Fetch current ticker data."""
        try:
            ticker = await self.exchange.fetch_ticker(self.symbol)
            return ticker
        except Exception as e:
            logger.error(f"Ticker fetch error: {e}")
            return {}
            
    async def fetch_order_book(self, limit: int = 20) -> dict:
        """Fetch order book data."""
        try:
            order_book = await self.exchange.fetch_order_book(self.symbol, limit)
            return order_book
        except Exception as e:
            logger.error(f"Order book fetch error: {e}")
            return {'bids': [], 'asks': []}
    
    async def fetch_ohlcv(self) -> list:
        """Fetch recent OHLCV for ATR calculation."""
        try:
            ohlcv = await self.exchange.fetch_ohlcv(self.symbol, '1m', limit=100)
            return ohlcv
        except Exception as e:
            logger.error(f"OHLCV fetch error: {e}")
            return []
            
    def update_price(self, price: float, high: float = None, low: float = None, volume: float = 0):
        """Update price history."""
        self.prices.append(price)
        self.volumes.append(volume)
        
        if high:
            self.highs.append(high)
        else:
            self.highs.append(price)
            
        if low:
            self.lows.append(low)
        else:
            self.lows.append(price)
            
        self.closes.append(price)
        
        # Spread calculation
        if len(self.prices) >= 20:
            ma = np.mean(list(self.prices)[-20:])
            spread = price - ma
            self.spreads.append(spread)
            
        self.last_price = price
        
        # SMC Detection (FVG)
        if len(self.closes) >= 5:
            self.smc_analyzer.detect_fvg(
                list(self.highs), 
                list(self.lows), 
                list(self.closes), 
                [int(datetime.now().timestamp()) for _ in range(len(self.closes))] # Simplified mock times
            )
        
        # Pivot Detection (Phase 11)
        if len(self.closes) >= 35:
             self.pivot_analyzer.update(
                list(self.highs), 
                list(self.lows), 
                [int(datetime.now().timestamp()) for _ in range(len(self.closes))]
             )
        # For simplicity, we run detection on every price update but it only looks at closed candles

        # Phase 15: Update Paper Trading (Check SL/TP)
        if hasattr(self, 'paper_trader') and self.paper_trader:
            # Phase 20: Pass ATR for risk management
            atr_value = self.atr if hasattr(self, 'atr') and self.atr > 0 else price * 0.01
            self.paper_trader.update(price, atr_value)

    def get_metrics(self) -> dict:
        """Calculate all metrics from current data."""
        prices_list = list(self.prices)
        spreads_list = list(self.spreads)
        highs_list = list(self.highs)
        lows_list = list(self.lows)
        closes_list = list(self.closes)
        volumes_list = list(self.volumes)
        
        # Ensure consistent lengths for VWAP calculation
        min_len = min(len(prices_list), len(closes_list), len(volumes_list))
        if min_len > 0:
            prices_list = prices_list[-min_len:]
            closes_list = closes_list[-min_len:]
            volumes_list = volumes_list[-min_len:]
        
        hurst = calculate_hurst(prices_list)
        zscore = calculate_zscore(spreads_list)
        spread = spreads_list[-1] if spreads_list else 0.0
        regime = get_market_regime(hurst)
        atr = calculate_atr(highs_list, lows_list, closes_list)
        
        # VWAP Z-Score
        vwap = calculate_vwap(closes_list, volumes_list, prices_list)
        std_dev = np.std(prices_list[-20:]) if len(prices_list) >= 20 else 1.0
        vwap_zscore = (prices_list[-1] - vwap) / std_dev if std_dev > 0 else 0
        
        # Volume Oscillator (Phase 11)
        vol_osc = calculate_volume_osc(volumes_list)
        
        # Phase 13: Volatility History & Ratio
        self.atr_history.append(atr)
        avg_atr = np.mean(self.atr_history) if len(self.atr_history) > 10 else atr
        volatility_ratio = atr / avg_atr if avg_atr > 0 else 1.0
        
        # Phase 13: Real-Time Spread % (Bid-Ask)
        spread_pct = 0.05 # Default safest
        if self.ws_order_book['bids'] and self.ws_order_book['asks']:
            best_bid = float(self.ws_order_book['bids'][0][0])
            best_ask = float(self.ws_order_book['asks'][0][0])
            if best_bid > 0:
                spread_val = best_ask - best_bid
                spread_pct = (spread_val / best_bid) * 100
        
        return {
            "hurst": round(hurst, 4),
            "regime": regime,
            "zScore": round(zscore, 4),
            "spread": round(spread, 4), # This is Close - SMA(20)
            "spreadPct": round(spread_pct, 4), # This is Bid-Ask Spread
            "atr": round(atr, 2),
            "volatilityRatio": round(volatility_ratio, 2),
            "vwap_zscore": round(vwap_zscore, 2),
            "vol_osc": round(vol_osc, 2)
        }

    async def fetch_htf_trend(self) -> str:
        """Fetch 4H RSI and Trend via REST API."""
        try:
            # Fetch last 50 4H candles
            if hasattr(self, 'exchange'):
                ohlcv = await self.exchange.fetch_ohlcv(self.symbol, '4h', limit=50)
                if not ohlcv: return "NEUTRAL"
                
                closes = np.array([float(x[4]) for x in ohlcv])
                
                # Calculate RSI
                delta = np.diff(closes)
                gain = (delta > 0) * delta
                loss = (delta < 0) * -delta
                
                avg_gain = np.mean(gain[-14:])
                avg_loss = np.mean(loss[-14:])
                
                if avg_loss == 0: return "BULLISH"
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
                
                # Determine Trend
                ma20 = np.mean(closes[-20:])
                current = closes[-1]
                
                if current > ma20:
                    if rsi > 70: return "STRONG_BULLISH"
                    return "BULLISH"
                else:
                    if rsi < 30: return "STRONG_BEARISH"
                    return "BEARISH"
            return "NEUTRAL"
        except Exception as e:
            logger.warning(f"HTF Trend error: {e}")
            return "NEUTRAL"


# ============================================================================
# WEBSOCKET ENDPOINT
# ============================================================================

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return JSONResponse({"status": "healthy", "timestamp": datetime.now().isoformat()})

@app.get("/server-ip")
async def server_ip():
    """Get server's outbound IP for Binance whitelisting."""
    import aiohttp
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("https://api.ipify.org?format=json", timeout=aiohttp.ClientTimeout(total=10)) as response:
                data = await response.json()
                return JSONResponse({"outbound_ip": data.get("ip"), "region": os.environ.get("FLY_REGION", "unknown")})
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

# Phase 16: Global Paper Trader for REST API access
global_paper_trader = PaperTradingEngine()

# Phase 138: Global dictionary to track close reasons for Binance sync
# When engine triggers SL/TP/Trail, reason is stored here instead of writing to trade history
# Binance sync will use this to set proper reason when detecting closed position
pending_close_reasons = {}  # {symbol: {"reason": str, "details": dict, "timestamp": int}}

# Phase 205: Last closed candle's close price per symbol
# Updated by scanner candle builder (5m) â€” used for exit decisions instead of tick price
# This prevents false exits caused by intra-candle wicks/spikes
last_candle_close = {}  # {symbol: float}

@app.get("/paper-trading/status")
async def paper_trading_status():
    """Get current paper trading status - used for initial UI sync."""
    today_pnl_data = global_paper_trader.get_today_pnl()
    stats_with_today = {**global_paper_trader.stats, **today_pnl_data}
    
    # Phase 239: Data quality metrics
    try:
        data_quality = await sqlite_manager.get_trade_data_quality_24h()
    except Exception:
        data_quality = {}
    
    return JSONResponse({
        "balance": global_paper_trader.balance,
        "positions": global_paper_trader.positions,
        "trades": global_paper_trader.trades,  # ALL trades (no limit)
        "stats": stats_with_today,
        "enabled": global_paper_trader.enabled,
        "logs": global_paper_trader.logs[-100:],  # Last 100 logs
        "equityCurve": global_paper_trader.equity_curve[-200:],  # Last 200 points
        "tradingMode": live_binance_trader.trading_mode,  # paper or live
        "liveEnabled": live_binance_trader.enabled,
        "pipelineMetrics": global_paper_trader.pipeline_metrics,
        "pendingOrdersCount": len(global_paper_trader.pending_orders),
        "lastOrderError": live_binance_trader.last_order_error,
        # Phase 237D: Reject attribution summary
        "falseNegativeSummary": get_reject_attribution_summary() if REJECT_ATTRIBUTION_ENABLED else {},
        # Phase 239: Trade metadata quality
        "dataQuality": data_quality,
        # Phase 239V2: Revalidation gate stats
        "recheckStats": {
            "pass": global_paper_trader.pipeline_metrics.get('recheck_pass', 0),
            "fail": global_paper_trader.pipeline_metrics.get('recheck_fail', 0),
            "warn": global_paper_trader.pipeline_metrics.get('recheck_warn', 0),
        },
    })


# ============================================================================
# LIVE TRADING ENDPOINTS
# ============================================================================

@app.get("/live-trading/status")
async def live_trading_status():
    """Get live trading status - Binance connection and positions."""
    
    # Check environment variable directly (not cached value from import time)
    env_trading_mode = os.environ.get('TRADING_MODE', 'paper')
    init_error = None
    
    # Auto-initialize if TRADING_MODE is live and exchange not yet created
    # Use same logic as test-connection: check exchange object, not enabled flag
    if env_trading_mode == 'live' and not live_binance_trader.exchange:
        live_binance_trader.trading_mode = env_trading_mode
        try:
            success = await live_binance_trader.initialize()
            if not success:
                init_error = getattr(live_binance_trader, 'last_error', 'Initialize returned False')
        except Exception as e:
            init_error = str(e)
            logger.error(f"Live trading init error: {e}")
    
    if not live_binance_trader.enabled:
        return JSONResponse({
            "enabled": False,
            "trading_mode": env_trading_mode,
            "message": "Live trading not enabled. Set TRADING_MODE=live to activate.",
            "init_error": init_error or getattr(live_binance_trader, 'last_error', None),
            "lastOrderError": live_binance_trader.last_order_error
        })
    
    try:
        balance = await live_binance_trader.get_balance()
        positions = await live_binance_trader.get_positions()
        pnl_data = await live_binance_trader.get_pnl_from_binance()
        # Phase 187b: Trade history from SQLite (full data, no limit)
        # Previously: get_trade_history(limit=50, days_back=7) from Binance Income API
        # Now: all trades from SQLite with entry/exit prices, reasons, settings
        trades = await sqlite_manager.get_full_trade_history(limit=0)
        logger.info(f"Phase 187b: Got {len(trades)} trades from SQLite")
        
        return JSONResponse({
            "enabled": True,
            "trading_mode": "live",
            "balance": balance,
            "positions": positions,
            "position_count": len(positions),
            "last_sync": live_binance_trader.last_sync_time,
            "status": live_binance_trader.get_status(),
            "lastOrderError": live_binance_trader.last_order_error,
            # PnL data from Binance income history
            "todayPnl": pnl_data.get('todayPnl', 0),
            "todayPnlPercent": pnl_data.get('todayPnlPercent', 0),
            "totalPnl": pnl_data.get('totalPnl', 0),
            "totalPnlPercent": pnl_data.get('totalPnlPercent', 0),
            "todayTradesCount": pnl_data.get('todayTradesCount', 0),
            # Phase 187b: Full trade history from SQLite
            "trades": trades,
            "tradeCount": len(trades),
        })
    except Exception as e:
        return JSONResponse({
            "enabled": True,
            "trading_mode": "live",
            "error": str(e),
            "lastOrderError": live_binance_trader.last_order_error
        }, status_code=500)


@app.post("/live-trading/emergency-close")
async def live_trading_emergency_close():
    """Emergency close all positions on Binance."""
    if not live_binance_trader.enabled:
        return JSONResponse({
            "success": False,
            "message": "Live trading not enabled"
        }, status_code=400)
    
    try:
        closed = await live_binance_trader.close_all_positions()
        return JSONResponse({
            "success": True,
            "closed_positions": len(closed),
            "details": closed
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)


@app.post("/live-trading/test-connection")
async def live_trading_test_connection():
    """Test Binance API connection."""
    try:
        if not live_binance_trader.exchange:
            # Try to initialize
            success = await live_binance_trader.initialize()
            if not success:
                return JSONResponse({
                    "success": False,
                    "message": "Failed to initialize Binance connection"
                }, status_code=400)
        
        balance = await live_binance_trader.get_balance()
        return JSONResponse({
            "success": True,
            "message": "Binance connection successful!",
            "balance": balance
        })
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e)
        }, status_code=500)

@app.get("/live-trading/raw-positions")
async def live_trading_raw_positions():
    """Debug: Get raw positions from Binance API."""
    try:
        if not live_binance_trader.exchange:
            return JSONResponse({"error": "Exchange not initialized"}, status_code=400)
        
        # Get raw positions from Binance
        raw_positions = await live_binance_trader.exchange.fetch_positions()
        
        # Filter only positions with any activity
        active = []
        for p in raw_positions:
            contracts = float(p.get('contracts', 0))
            notional = float(p.get('notional', 0))
            if abs(contracts) > 0 or abs(notional) > 0:
                active.append({
                    'symbol': p.get('symbol'),
                    'contracts': contracts,
                    'notional': notional,
                    'entryPrice': p.get('entryPrice'),
                    'markPrice': p.get('markPrice'),
                    'side': p.get('side'),
                    'leverage': p.get('leverage'),
                    'unrealizedPnl': p.get('unrealizedPnl'),
                    'marginMode': p.get('marginMode'),
                    'raw_info': p.get('info', {})  # Include raw Binance response
                })
        
        return JSONResponse({
            "total_symbols": len(raw_positions),
            "active_positions": len(active),
            "positions": active
        })
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

@app.post("/paper-trading/reset")
async def paper_trading_reset():
    """Reset paper trading to initial state."""
    global_paper_trader.reset()
    return JSONResponse({"success": True, "message": "Paper trading reset to $10,000"})

@app.post("/paper-trading/toggle")
async def paper_trading_toggle():
    """Toggle auto-trading on/off."""
    global_paper_trader.enabled = not global_paper_trader.enabled
    global_paper_trader.save_state()
    status = "enabled" if global_paper_trader.enabled else "disabled"
    return JSONResponse({"success": True, "enabled": global_paper_trader.enabled, "message": f"Auto-trading {status}"})

# Phase 52: Optimizer endpoints
@app.post("/optimizer/toggle")
async def optimizer_toggle():
    """Toggle auto-optimizer on/off."""
    parameter_optimizer.enabled = not parameter_optimizer.enabled
    
    # Phase 60: Sync with paper_trader for dynamic calculations
    if global_paper_trader:
        global_paper_trader.ai_optimizer_enabled = parameter_optimizer.enabled
        global_paper_trader.save_state()
    
    status = "enabled" if parameter_optimizer.enabled else "disabled"
    logger.info(f"ðŸ¤– Auto-optimizer {status}")
    
    # Log mode change
    if global_paper_trader:
        if parameter_optimizer.enabled:
            global_paper_trader.add_log(f"ðŸ¤– AI Optimizer AKTÄ°F - Dinamik ayarlar etkin")
        else:
            global_paper_trader.add_log(f"ðŸ‘¤ AI Optimizer KAPALI - Manuel ayarlar geÃ§erli")
    
    return JSONResponse({
        "success": True, 
        "enabled": parameter_optimizer.enabled, 
        "message": f"Auto-optimizer {status}"
    })

@app.get("/trade-analysis")
async def trade_analysis():
    """Phase 157: Trade pattern analysis + funding status."""
    analysis = trade_pattern_analyzer.last_analysis or {"status": "not_run"}
    funding = funding_oi_tracker.get_status()
    return {
        "tradeAnalysis": analysis,
        "funding": funding,
        "coinWr": {k: {"wr": v["wr"], "total": v["total"], "pnl": v.get("total_pnl", 0)} 
                   for k, v in trade_pattern_analyzer.coin_wr.items() if v.get("total", 0) >= 3},
        "hourWr": {str(k): {"wr": v["wr"], "total": v["total"]} 
                   for k, v in trade_pattern_analyzer.hour_wr.items()},
    }

@app.get("/optimizer/status")
async def optimizer_status():
    """Get optimizer status and analysis."""
    # Convert tracking dict to list for UI
    tracking_list = []
    try:
        for trade_id, data in post_trade_tracker.tracking.items():
            exit_time = data.get('exit_time')
            exit_time_str = None
            if exit_time:
                try:
                    exit_time_str = exit_time.isoformat() if hasattr(exit_time, 'isoformat') else str(exit_time)
                except:
                    exit_time_str = str(exit_time)
            
            tracking_list.append({
                'id': trade_id,
                'symbol': data.get('symbol', ''),
                'side': data.get('side', ''),
                'exitPrice': data.get('exit_price', 0),
                'exitTime': exit_time_str,
                'pnl': data.get('pnl', 0),
                'reason': data.get('reason', ''),
                'maxPriceAfter': data.get('max_price_after', 0),
                'minPriceAfter': data.get('min_price_after', 0),
                'priceSamples': data.get('price_samples', 0),
            })
    except Exception as e:
        logger.error(f"Error building tracking list: {e}")
    
    return JSONResponse({
        "enabled": parameter_optimizer.enabled,
        "lastOptimization": parameter_optimizer.last_optimization,
        "lastAnalysis": performance_analyzer.last_analysis,
        "postTradeStats": post_trade_tracker.get_stats(),
        "trackingCount": len(post_trade_tracker.tracking),
        "trackingList": tracking_list,
        "recentAnalyses": post_trade_tracker.analysis_results[-10:],
        "marketRegime": market_regime_detector.get_status(),
        "scoreAnalysis": score_component_analyzer.get_status()
    })

@app.post("/optimizer/run")
async def optimizer_run_now():
    """Manually trigger optimization analysis."""
    try:
        pt_stats = post_trade_tracker.get_stats()
        analysis = performance_analyzer.analyze(global_paper_trader.trades, pt_stats)
        
        if analysis:
            current_settings = {
                'z_score_threshold': global_paper_trader.z_score_threshold,
                'min_score_low': global_paper_trader.min_score_low,
                'min_score_high': global_paper_trader.min_score_high,
                'entry_tightness': global_paper_trader.entry_tightness,
                'max_positions': global_paper_trader.max_positions,
            }
            optimization = parameter_optimizer.optimize(analysis, current_settings)
            
            return JSONResponse({
                "success": True,
                "analysis": analysis,
                "optimization": optimization
            })
        
        return JSONResponse({"success": False, "message": "No trades to analyze"})
    except Exception as e:
        logger.error(f"Optimizer run error: {e}")
        return JSONResponse({"success": False, "message": str(e)})


# ============================================================================
# PHASE 59: PERFORMANCE DASHBOARD ENDPOINTS
# ============================================================================

@app.get("/performance/coins")
async def get_coin_performance():
    """Get coin-based performance statistics â€” Binance verisi Ã¶ncelikli."""
    # Binance verisi varsa onu kullan
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=500)
        if binance_trades and len(binance_trades) >= 5:
            coin_stats = {}
            for t in binance_trades:
                sym = t.get('symbol', 'UNKNOWN').replace('USDT', '')
                if sym not in coin_stats:
                    coin_stats[sym] = {'wins': 0, 'losses': 0, 'total_pnl': 0, 'trades': 0}
                coin_stats[sym]['trades'] += 1
                pnl = t.get('pnl', 0)
                coin_stats[sym]['total_pnl'] += pnl
                if pnl > 0:
                    coin_stats[sym]['wins'] += 1
                else:
                    coin_stats[sym]['losses'] += 1
            
            # Calculate WR
            for sym, data in coin_stats.items():
                total = data['wins'] + data['losses']
                data['win_rate'] = round((data['wins'] / total * 100) if total > 0 else 0, 1)
                data['avg_pnl'] = round(data['total_pnl'] / data['trades'], 4) if data['trades'] > 0 else 0
                data['total_pnl'] = round(data['total_pnl'], 2)
            
            # Sort by total PnL
            best_coins = sorted(coin_stats.items(), key=lambda x: x[1]['total_pnl'], reverse=True)[:10]
            worst_coins = sorted(coin_stats.items(), key=lambda x: x[1]['total_pnl'])[:10]
            
            return JSONResponse({
                "success": True,
                "source": "binance",
                "bestCoins": [{"symbol": s, **d} for s, d in best_coins],
                "worstCoins": [{"symbol": s, **d} for s, d in worst_coins],
                "totalCoins": len(coin_stats),
                "totalTrades": len(binance_trades)
            })
    except Exception as e:
        logger.debug(f"Binance coin perf error: {e}")
    
    # Fallback to paper trader
    return JSONResponse({
        "success": True,
        "source": "paper",
        **coin_performance_tracker.get_all_stats()
    })

@app.get("/performance/daily")
async def get_daily_performance():
    """Get daily PnL data for charts â€” Binance verisi Ã¶ncelikli."""
    import pytz
    turkey_tz = pytz.timezone('Europe/Istanbul')
    
    # Try Binance trades first
    trades = []
    source = "paper"
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=1000)
        if binance_trades and len(binance_trades) >= 5:
            trades = binance_trades
            source = "binance"
    except Exception as e:
        logger.debug(f"Binance daily perf error: {e}")
    
    # Fallback to paper trades
    if not trades:
        trades = global_paper_trader.trades
        source = "paper"
    
    # Group trades by day (using Turkey timezone)
    daily_pnl = {}
    for trade in trades:
        close_time = trade.get('closeTime', trade.get('close_time', 0))
        pnl = trade.get('pnl', 0)
        if close_time and close_time > 0:
            try:
                utc_dt = datetime.utcfromtimestamp(close_time / 1000).replace(tzinfo=pytz.UTC)
                turkey_dt = utc_dt.astimezone(turkey_tz)
                day = turkey_dt.strftime('%Y-%m-%d')
                if day not in daily_pnl:
                    daily_pnl[day] = {'pnl': 0, 'trades': 0, 'wins': 0}
                daily_pnl[day]['pnl'] += pnl
                daily_pnl[day]['trades'] += 1
                if pnl > 0:
                    daily_pnl[day]['wins'] += 1
            except:
                pass
    
    # Convert to list sorted by date
    daily_list = []
    for day, data in sorted(daily_pnl.items()):
        wr = (data['wins'] / data['trades'] * 100) if data['trades'] > 0 else 0
        daily_list.append({
            'date': day,
            'pnl': round(data['pnl'], 2),
            'trades': data['trades'],
            'winRate': round(wr, 1)
        })
    
    # Calculate cumulative PnL
    cumulative = 0
    for item in daily_list:
        cumulative += item['pnl']
        item['cumulative'] = round(cumulative, 2)
    
    return JSONResponse({
        "success": True,
        "source": source,
        "dailyPnl": daily_list[-30:],  # Last 30 days
        "totalDays": len(daily_list)
    })

@app.get("/performance/optimizer-history")
async def get_optimizer_history():
    """Get AI optimizer change history."""
    history = parameter_optimizer.optimization_history[-20:]  # Last 20
    return JSONResponse({
        "success": True,
        "history": history
    })

@app.get("/performance/summary")
async def get_performance_summary():
    """Get comprehensive performance summary â€” Binance verisi Ã¶ncelikli."""
    
    # Try Binance trades first
    trades = []
    source = "paper"
    try:
        binance_trades = await sqlite_manager.get_binance_trades(limit=1000)
        if binance_trades and len(binance_trades) >= 5:
            trades = binance_trades
            source = "binance"
    except Exception as e:
        logger.debug(f"Binance summary error: {e}")
    
    # Fallback to paper trades
    if not trades:
        trades = global_paper_trader.trades
        source = "paper"
    
    total_trades = len(trades)
    total_pnl = sum(t.get('pnl', 0) for t in trades)
    winning_trades = len([t for t in trades if t.get('pnl', 0) > 0])
    win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
    
    # Recent performance (last 7 days)
    week_ago = datetime.now().timestamp() * 1000 - (7 * 24 * 60 * 60 * 1000)
    recent_trades = [t for t in trades if t.get('closeTime', t.get('close_time', 0)) > week_ago]
    recent_pnl = sum(t.get('pnl', 0) for t in recent_trades)
    recent_wins = len([t for t in recent_trades if t.get('pnl', 0) > 0])
    recent_wr = (recent_wins / len(recent_trades) * 100) if recent_trades else 0
    
    # Close reason breakdown
    reason_stats = {}
    for t in trades:
        reason = t.get('reason', t.get('closeReason', 'UNKNOWN'))
        # Normalize reason
        if 'SL' in str(reason).upper() or 'STOP' in str(reason).upper():
            reason = 'SL_HIT'
        elif 'TP' in str(reason).upper() or 'TAKE' in str(reason).upper():
            reason = 'TP_HIT'
        elif 'TRAIL' in str(reason).upper():
            reason = 'TRAILING'
        elif 'BREAKEVEN' in str(reason).upper():
            reason = 'BREAKEVEN'
        elif 'TIME' in str(reason).upper():
            reason = 'TIME_EXIT'
        
        if reason not in reason_stats:
            reason_stats[reason] = {'count': 0, 'pnl': 0}
        reason_stats[reason]['count'] += 1
        reason_stats[reason]['pnl'] += t.get('pnl', 0)
    
    # Round reason PnL
    for r in reason_stats:
        reason_stats[r]['pnl'] = round(reason_stats[r]['pnl'], 2)
    
    # Average trade metrics
    avg_win = 0
    avg_loss = 0
    wins = [t.get('pnl', 0) for t in trades if t.get('pnl', 0) > 0]
    losses = [t.get('pnl', 0) for t in trades if t.get('pnl', 0) < 0]
    if wins:
        avg_win = sum(wins) / len(wins)
    if losses:
        avg_loss = sum(losses) / len(losses)
    profit_factor = abs(sum(wins) / sum(losses)) if losses and sum(losses) != 0 else 0
    
    # Get today's PnL from Binance income API (includes FUNDING_FEE + COMMISSION)
    binance_today_pnl = 0
    binance_today_pnl_pct = 0
    binance_total_pnl_income = 0
    try:
        if live_binance_trader.enabled:
            # Use cached PnL if available (updated every scan cycle)
            cached = getattr(live_binance_trader, 'cached_pnl', None)
            if cached:
                binance_today_pnl = cached.get('todayPnl', 0)
                binance_today_pnl_pct = cached.get('todayPnlPercent', 0)
                binance_total_pnl_income = cached.get('totalPnl', 0)
            else:
                # Fetch fresh if no cache
                pnl_data = await live_binance_trader.get_pnl_from_binance()
                binance_today_pnl = pnl_data.get('todayPnl', 0)
                binance_today_pnl_pct = pnl_data.get('todayPnlPercent', 0)
                binance_total_pnl_income = pnl_data.get('totalPnl', 0)
    except Exception as e:
        logger.debug(f"Binance today PnL fetch error: {e}")
    
    return JSONResponse({
        "success": True,
        "source": source,
        "totalPnl": round(total_pnl, 2),
        "totalTrades": total_trades,
        "winRate": round(win_rate, 1),
        "winningTrades": winning_trades,
        "losingTrades": total_trades - winning_trades,
        "recentPnl": round(recent_pnl, 2),
        "recentTrades": len(recent_trades),
        "recentWinRate": round(recent_wr, 1),
        "avgWin": round(avg_win, 4),
        "avgLoss": round(avg_loss, 4),
        "profitFactor": round(profit_factor, 2),
        "closeReasons": reason_stats,
        "coinStats": coin_performance_tracker.get_stats_for_optimizer(),
        "optimizerEnabled": parameter_optimizer.enabled,
        "lastOptimization": parameter_optimizer.last_optimization,
        "binanceTodayPnl": round(binance_today_pnl, 2),
        "binanceTodayPnlPct": round(binance_today_pnl_pct, 2),
        "binanceTotalPnlIncome": round(binance_total_pnl_income, 2)
    })

@app.post("/scanner/start")
async def scanner_start():
    """Start the background scanner."""
    task_alive = _is_scanner_task_alive()
    cache_age = 0
    if ui_state_cache.last_update > 0:
        cache_age = int(max(0, datetime.now().timestamp() - ui_state_cache.last_update))

    if multi_coin_scanner.running and task_alive:
        if cache_age > SCANNER_STALE_CACHE_SEC:
            restarted = await restart_background_scanner(
                reason=f"api_start_stale_cache_{cache_age}s"
            )
            return JSONResponse({
                "success": True,
                "running": True,
                "message": "Scanner stale detected, restarted" if restarted else "Scanner running (restart cooldown)",
                "cacheAgeSec": cache_age,
                "staleRestarted": restarted
            })
        return JSONResponse({"success": True, "running": True, "message": "Scanner already running"})

    multi_coin_scanner.running = True
    if not task_alive:
        await restart_background_scanner(reason="api_start", force=True)

    logger.info("ðŸš€ Scanner started via API")
    return JSONResponse({"success": True, "running": True, "message": "Scanner started"})

@app.post("/scanner/stop")
async def scanner_stop():
    """Stop the background scanner."""
    global background_scanner_task
    multi_coin_scanner.running = False
    if _is_scanner_task_alive():
        background_scanner_task.cancel()
        try:
            await asyncio.wait_for(background_scanner_task, timeout=2.0)
        except asyncio.TimeoutError:
            logger.warning("âš ï¸ scanner_stop: cancel timeout")
        except asyncio.CancelledError:
            pass
        except Exception as stop_err:
            logger.warning(f"âš ï¸ scanner_stop cancel error: {stop_err}")
    background_scanner_task = None
    logger.info("ðŸ›‘ Scanner stopped via API")
    return JSONResponse({"success": True, "running": False, "message": "Scanner stopped"})

@app.get("/scanner/status")
async def scanner_status():
    """Get scanner running status."""
    task_alive = _is_scanner_task_alive()
    cache_age = 0
    if ui_state_cache.last_update > 0:
        cache_age = int(max(0, datetime.now().timestamp() - ui_state_cache.last_update))

    # Self-heal: if scanner marked running but task died, restart automatically.
    auto_restarted = False
    stale_restarted = False
    if multi_coin_scanner.running and not task_alive:
        auto_restarted = await restart_background_scanner(reason="status_dead_task")
        task_alive = _is_scanner_task_alive()
    elif multi_coin_scanner.running and task_alive and cache_age > SCANNER_STALE_CACHE_SEC:
        stale_restarted = await restart_background_scanner(
            reason=f"status_stale_cache_{cache_age}s"
        )
        task_alive = _is_scanner_task_alive()

    # Keep running flag consistent with actual task state (important for frontend WS bootstrap).
    if task_alive and not multi_coin_scanner.running:
        multi_coin_scanner.running = True
        logger.warning("ðŸ” Scanner running flag healed via /scanner/status (task alive, flag was false)")

    effective_running = multi_coin_scanner.running or task_alive

    return JSONResponse({
        "running": effective_running,
        "runningFlag": multi_coin_scanner.running,
        "totalCoins": len(multi_coin_scanner.coins),
        "analyzedCoins": len(multi_coin_scanner.analyzers),
        "taskAlive": task_alive,
        "cacheInitialized": ui_state_cache._initialized,
        "cacheAgeSec": cache_age,
        "autoRestarted": auto_restarted,
        "staleRestarted": stale_restarted,
        "staleThresholdSec": SCANNER_STALE_CACHE_SEC
    })

# Phase 17: Settings endpoints
@app.get("/paper-trading/settings")
async def paper_trading_get_settings():
    """Get current cloud trading settings."""
    return JSONResponse({
        "symbol": global_paper_trader.symbol,
        "leverage": global_paper_trader.leverage,
        "riskPerTrade": global_paper_trader.risk_per_trade,
        "enabled": global_paper_trader.enabled,
        "balance": global_paper_trader.balance,
        "positions": global_paper_trader.positions,
        "stats": {**global_paper_trader.stats, **global_paper_trader.get_today_pnl()},
        "trades": global_paper_trader.trades[-50:],
        "equityCurve": global_paper_trader.equity_curve[-100:],
        "slAtr": global_paper_trader.sl_atr,
        "tpAtr": global_paper_trader.tp_atr,
        "trailActivationAtr": global_paper_trader.trail_activation_atr,
        "trailDistanceAtr": global_paper_trader.trail_distance_atr,
        "maxPositions": global_paper_trader.max_positions,
        # Algorithm sensitivity settings
        "zScoreThreshold": global_paper_trader.z_score_threshold,
        "minConfidenceScore": global_paper_trader.min_confidence_score,
        # Phase 50: Dynamic Min Score Range
        "minScoreLow": global_paper_trader.min_score_low,
        "minScoreHigh": global_paper_trader.min_score_high,
        # Phase 36: Entry/Exit tightness
        "entryTightness": global_paper_trader.entry_tightness,
        "exitTightness": global_paper_trader.exit_tightness,
        "strategyMode": getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY),
        # Server-side logs
        "logs": global_paper_trader.logs[-50:],
        # Phase 52: Adaptive Trading System stats
        "optimizer": {
            "enabled": parameter_optimizer.enabled,
            "lastOptimization": parameter_optimizer.last_optimization,
            "postTradeStats": post_trade_tracker.get_stats(),
            "lastAnalysis": performance_analyzer.last_analysis,
        },
        # Phase 57: Kill Switch settings
        "killSwitchFirstReduction": daily_kill_switch.first_reduction_pct,
        "killSwitchFullClose": daily_kill_switch.full_close_pct,
        # Phase 216: Leverage multiplier
        "leverageMultiplier": getattr(global_paper_trader, 'leverage_multiplier', 1.0),
        # Execution diagnostics
        "lastOrderError": live_binance_trader.last_order_error,
        "pipelineMetrics": global_paper_trader.pipeline_metrics
    })

@app.post("/paper-trading/settings")
async def paper_trading_update_settings(
    symbol: str = None, 
    leverage: int = None, 
    riskPerTrade: float = None,
    slAtr: float = None,
    tpAtr: float = None,
    trailActivationAtr: float = None,
    trailDistanceAtr: float = None,
    maxPositions: int = None,
    zScoreThreshold: float = None,
    minConfidenceScore: int = None,
    minScoreLow: int = None,
    minScoreHigh: int = None,
    entryTightness: float = None,
    exitTightness: float = None,
    strategyMode: str = None,
    killSwitchFirstReduction: float = None,
    killSwitchFullClose: float = None,
    leverageMultiplier: float = None
):
    """Update cloud trading settings."""
    if symbol:
        global_paper_trader.symbol = symbol
        # Switch Binance Streamer to new symbol
        # Assuming binance_streamer is the global instance variable
        if 'binance_streamer' in globals():
            await binance_streamer.switch_symbol(symbol)
        else:
             logger.warning("âš ï¸ binance_streamer global not found, stream not switched.")

    if leverage:
        global_paper_trader.leverage = leverage
    if riskPerTrade:
        global_paper_trader.risk_per_trade = riskPerTrade
    # Phase 18: Full trading parameters
    if slAtr is not None:
        global_paper_trader.sl_atr = slAtr
    if tpAtr is not None:
        global_paper_trader.tp_atr = tpAtr
    if trailActivationAtr is not None:
        global_paper_trader.trail_activation_atr = trailActivationAtr
    if trailDistanceAtr is not None:
        global_paper_trader.trail_distance_atr = trailDistanceAtr
    if maxPositions is not None:
        global_paper_trader.max_positions = maxPositions
    # Algorithm sensitivity settings
    if zScoreThreshold is not None:
        global_paper_trader.z_score_threshold = zScoreThreshold
    if minConfidenceScore is not None:
        global_paper_trader.min_confidence_score = minConfidenceScore
    # Phase 50: Dynamic Min Score Range
    if minScoreLow is not None:
        global_paper_trader.min_score_low = minScoreLow
    if minScoreHigh is not None:
        global_paper_trader.min_score_high = minScoreHigh
    # Phase 36: Entry/Exit tightness settings
    if entryTightness is not None:
        global_paper_trader.entry_tightness = entryTightness
    if exitTightness is not None:
        global_paper_trader.exit_tightness = exitTightness
    if strategyMode is not None:
        old_mode = getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY)
        normalized_mode = str(strategyMode).upper()
        if normalized_mode not in (STRATEGY_MODE_LEGACY, STRATEGY_MODE_SMART_V2):
            return JSONResponse(
                {"success": False, "error": f"Invalid strategyMode: {strategyMode}. Use LEGACY or SMART_V2"},
                status_code=400
            )
        global_paper_trader.strategy_mode = normalized_mode
        if old_mode != normalized_mode and global_paper_trader.pending_orders:
            stale_count = len(global_paper_trader.pending_orders)
            global_paper_trader.pending_orders.clear()
            global_paper_trader.add_log(
                f"âš ï¸ SETTINGS_CHANGED_STRATEGY_MODE: {stale_count} pending order temizlendi ({old_mode}â†’{normalized_mode})"
            )
    
    # Phase 57: Kill Switch settings
    if killSwitchFirstReduction is not None:
        daily_kill_switch.first_reduction_pct = killSwitchFirstReduction
        logger.info(f"ðŸš¨ Kill Switch First Reduction updated: {killSwitchFirstReduction}%")
    if killSwitchFullClose is not None:
        daily_kill_switch.full_close_pct = killSwitchFullClose
        logger.info(f"ðŸš¨ Kill Switch Full Close updated: {killSwitchFullClose}%")
    
    # Phase 216: Leverage multiplier
    if leverageMultiplier is not None:
        clamped = max(0.3, min(3.0, leverageMultiplier))
        old_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        global_paper_trader.leverage_multiplier = clamped
        logger.info(f"âš¡ Leverage Multiplier updated: {old_mult:.1f}x â†’ {clamped:.1f}x")
        # Fix P1: Clear pending orders with stale leverage when multiplier changes
        if abs(old_mult - clamped) > 0.01 and global_paper_trader.pending_orders:
            stale_count = len(global_paper_trader.pending_orders)
            global_paper_trader.pending_orders.clear()
            global_paper_trader.add_log(f"âš ï¸ SETTINGS_CHANGED_LEVERAGE_MULTIPLIER: {stale_count} pending orders cleared (lev {old_mult:.1f}xâ†’{clamped:.1f}x)")
            logger.info(f"ðŸ—‘ï¸ Cleared {stale_count} pending orders due to leverage multiplier change")
    
    # Settings log throttle: skip noisy duplicate logs
    settings_log_message = (
        f"âš™ï¸ Ayarlar gÃ¼ncellendi: SL:{global_paper_trader.sl_atr} "
        f"TP:{global_paper_trader.tp_atr} Z:{global_paper_trader.z_score_threshold} "
        f"GiriÅŸ:{global_paper_trader.entry_tightness:.2f} Ã‡Ä±kÄ±ÅŸ:{global_paper_trader.exit_tightness:.2f} "
        f"Str:{getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY)} "
        f"LevM:{getattr(global_paper_trader, 'leverage_multiplier', 1.0):.2f} "
        f"KS:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}"
    )
    now_ms = int(datetime.now().timestamp() * 1000)
    throttle_ms = 90 * 1000
    last_sig = getattr(global_paper_trader, "_last_settings_log_signature", "")
    last_ts = int(getattr(global_paper_trader, "_last_settings_log_ts", 0) or 0)
    if settings_log_message != last_sig or (now_ms - last_ts) >= throttle_ms:
        global_paper_trader.add_log(settings_log_message)
        global_paper_trader._last_settings_log_signature = settings_log_message
        global_paper_trader._last_settings_log_ts = now_ms
    else:
        logger.debug("Settings log throttled (duplicate payload)")
    global_paper_trader.save_state()
    logger.info(f"Settings updated: MaxPositions:{global_paper_trader.max_positions} Z-Threshold:{global_paper_trader.z_score_threshold} KillSwitch:{daily_kill_switch.first_reduction_pct}/{daily_kill_switch.full_close_pct}")
    
    # ====== PHASE 37: Update existing positions' TP/SL based on new exit_tightness ======
    updated_positions = 0
    for pos in global_paper_trader.positions:
        try:
            entry_price = pos.get('entryPrice', 0)
            if entry_price <= 0:
                continue
            
            # Use stored ATR or estimate from entry price (2% is typical ATR)
            atr = pos.get('atr', entry_price * 0.02)
            side = pos.get('side', '')
            
            # Recalculate TP/SL with new exit_tightness
            adjusted_sl_atr = (global_paper_trader.sl_atr / 10) * global_paper_trader.exit_tightness
            adjusted_tp_atr = (global_paper_trader.tp_atr / 10) * global_paper_trader.exit_tightness
            adjusted_trail_activation_atr = global_paper_trader.trail_activation_atr * global_paper_trader.exit_tightness
            adjusted_trail_distance_atr = global_paper_trader.trail_distance_atr * global_paper_trader.exit_tightness
            
            if side == 'LONG':
                new_sl = max(entry_price * 0.01, entry_price - (atr * adjusted_sl_atr))
                new_tp = entry_price + (atr * adjusted_tp_atr)
                new_trail_activation = entry_price + (atr * adjusted_trail_activation_atr)
            else:  # SHORT
                new_sl = entry_price + (atr * adjusted_sl_atr)
                new_tp = max(entry_price * 0.01, entry_price - (atr * adjusted_tp_atr))
                new_trail_activation = max(entry_price * 0.01, entry_price - (atr * adjusted_trail_activation_atr))
            
            new_trail_distance = atr * adjusted_trail_distance_atr
            
            # Only update if not already in trailing mode (to preserve trailing stop progress)
            if not pos.get('isTrailingActive', False):
                pos['stopLoss'] = new_sl
                pos['trailingStop'] = new_sl
            
            pos['takeProfit'] = new_tp
            pos['trailActivation'] = new_trail_activation
            pos['trailDistance'] = new_trail_distance
            
            updated_positions += 1
            
        except Exception as e:
            logger.error(f"Error updating position {pos.get('symbol', '?')}: {e}")
    
    if updated_positions > 0:
        logger.info(f"ðŸ”„ Updated TP/SL for {updated_positions} existing positions based on new exit_tightness: {global_paper_trader.exit_tightness}")
        global_paper_trader.add_log(f"ðŸ”„ {updated_positions} pozisyonun TP/SL'si gÃ¼ncellendi (Exit: {global_paper_trader.exit_tightness})")
        global_paper_trader.save_state()
    
    return JSONResponse({
        "success": True,
        "symbol": global_paper_trader.symbol,
        "leverage": global_paper_trader.leverage,
        "riskPerTrade": global_paper_trader.risk_per_trade,
        "slAtr": global_paper_trader.sl_atr,
        "tpAtr": global_paper_trader.tp_atr,
        "trailActivationAtr": global_paper_trader.trail_activation_atr,
        "trailDistanceAtr": global_paper_trader.trail_distance_atr,
        "maxPositions": global_paper_trader.max_positions,
        "zScoreThreshold": global_paper_trader.z_score_threshold,
        "minConfidenceScore": global_paper_trader.min_confidence_score,
        "entryTightness": global_paper_trader.entry_tightness,
        "exitTightness": global_paper_trader.exit_tightness,
        "strategyMode": getattr(global_paper_trader, 'strategy_mode', STRATEGY_MODE_LEGACY),
        "killSwitchFirstReduction": daily_kill_switch.first_reduction_pct,
        "killSwitchFullClose": daily_kill_switch.full_close_pct,
        "updatedPositions": updated_positions
    })


# Phase 36: Market Order from Signal Card

# ============================================================================
# PHASE 193: NEW API ENDPOINTS (FreqAI, Hyperopt, StoplossGuard, WS Manager)
# ============================================================================

@app.get("/phase193/status")
async def phase193_status():
    """Get status of all Phase 193 modules."""
    return JSONResponse({
        "stoploss_guard": stoploss_frequency_guard.get_status(),
        "freqai": freqai_model.get_status() if freqai_model else {"enabled": False, "error": "not installed"},
        "hyperopt": hhq_hyperoptimizer.get_status() if hhq_hyperoptimizer else {"enabled": False, "error": "not installed"},
        "ws_manager": ccxt_ws_manager.get_status() if ccxt_ws_manager else {"enabled": False, "error": "not installed"},
        "pandas_ta": PANDAS_TA_AVAILABLE,
    })

@app.post("/phase193/stoploss-guard/settings")
async def phase193_sl_guard_settings(request: Request):
    """Update StoplossFrequencyGuard settings."""
    data = await request.json()
    stoploss_frequency_guard.update_settings(data)
    return JSONResponse(stoploss_frequency_guard.get_status())

@app.post("/phase193/freqai/retrain")
async def phase193_freqai_retrain():
    """Force FreqAI model retrain."""
    if not freqai_model:
        return JSONResponse({"error": "FreqAI not available"}, status_code=400)
    success = freqai_model.force_retrain()
    return JSONResponse({
        "success": success,
        "status": freqai_model.get_status()
    })

@app.post("/phase193/hyperopt/run")
async def phase193_hyperopt_run(request: Request):
    """Run hyperparameter optimization."""
    if not hhq_hyperoptimizer:
        return JSONResponse({"error": "Hyperopt not available"}, status_code=400)
    
    data = await request.json() if request.headers.get('content-type') == 'application/json' else {}
    n_trials = data.get('n_trials', 100)
    
    # Load trade data from paper trader if not already loaded
    if not hhq_hyperoptimizer.trade_data and 'global_paper_trader' in globals():
        hhq_hyperoptimizer.trade_data = list(global_paper_trader.trade_history)
    
    result = await hhq_hyperoptimizer.optimize(n_trials=n_trials)
    return JSONResponse(result)


@app.post("/paper-trading/market-order")
async def paper_trading_market_order(request: Request):
    """Open a market order from a signal card (manual entry)."""
    try:
        data = await request.json()
        symbol = data.get('symbol')
        side = data.get('side')  # LONG or SHORT
        price = float(data.get('price', 0))
        # Fix P0: Use signal leverage from UI (already includes multiplier)
        requested_lev = data.get('signalLeverage')
        
        if not symbol or not side or price <= 0:
            return JSONResponse({"success": False, "error": "Missing symbol, side, or price"}, status_code=400)
        
        # Check if we have room for more positions
        if len(global_paper_trader.positions) >= global_paper_trader.max_positions:
            return JSONResponse({"success": False, "error": f"Max positions ({global_paper_trader.max_positions}) reached"})
        
        # Phase 191: Paper market order engelle
        if not live_binance_trader.enabled:
            return JSONResponse({"success": False, "error": "Paper trading deaktif â€” sadece live"}, status_code=400)
        
        # Get ATR from analyzer if available
        atr = price * 0.02  # Default 2% of price as fallback ATR
        if symbol in multi_coin_scanner.analyzers:
            analyzer = multi_coin_scanner.analyzers[symbol]
            if hasattr(analyzer.opportunity, 'atr') and analyzer.opportunity.atr > 0:
                atr = analyzer.opportunity.atr
        
        # Calculate position sizing
        balance = global_paper_trader.balance
        risk_amount = balance * global_paper_trader.risk_per_trade
        
        # Fix P0: Leverage pipeline â€” priority: signalLeverage > base * multiplier
        base_lev = global_paper_trader.leverage
        user_mult = getattr(global_paper_trader, 'leverage_multiplier', 1.0)
        if requested_lev and requested_lev > 0:
            leverage = max(3, min(75, int(requested_lev)))
        else:
            leverage = max(3, min(75, int(base_lev * user_mult)))
        
        # LEV_PIPE log for full traceability
        logger.info(f"ðŸ”§ LEV_PIPE: signalLev={requested_lev} userMult={user_mult:.1f} baseLev={base_lev} â†’ orderLev={leverage}x | {side} {symbol}")
        
        # Fix P1: Set leverage on Binance â€” abort if real failure
        if live_binance_trader.enabled:
            set_ok = await live_binance_trader.set_leverage(symbol, leverage)
            if not set_ok:
                return JSONResponse({"success": False, "error": f"Binance leverage set failed for {symbol} â†’ {leverage}x"}, status_code=500)
        
        # SL/TP based on ATR
        sl_distance = atr * (global_paper_trader.sl_atr / 10)
        tp_distance = atr * (global_paper_trader.tp_atr / 10)
        
        if side == 'LONG':
            sl = price - sl_distance
            tp = price + tp_distance
        else:
            sl = price + sl_distance
            tp = price - tp_distance
        
        # Position size
        if sl_distance > 0:
            size = risk_amount / sl_distance
        else:
            size = (balance * 0.1) / price  # 10% of balance fallback
        
        size_usd = size * price
        
        # Create position
        position = {
            "id": f"manual_{int(datetime.now().timestamp() * 1000)}",
            "symbol": symbol,
            "side": side,
            "entryPrice": price,
            "currentPrice": price,
            "size": size,
            "sizeUsd": size_usd,
            "stopLoss": sl,
            "takeProfit": tp,
            "trailingStop": 0,
            "trailActivation": price + (atr * global_paper_trader.trail_activation_atr) if side == 'LONG' else price - (atr * global_paper_trader.trail_activation_atr),
            "trailDistance": atr * global_paper_trader.trail_distance_atr,
            "isTrailingActive": False,
            "unrealizedPnl": 0,
            "unrealizedPnlPercent": 0,
            "openTime": int(datetime.now().timestamp() * 1000),
            "leverage": leverage,
            # Phase 214: Failed Continuation Detector
            "fc_was_in_profit": False,
            "fc_failed_count": 0,
            "fc_max_profit_pct": 0.0,
            # Runtime trail telemetry (updated every tick)
            "effectiveExitTightness": global_paper_trader.exit_tightness,
            "runtimeTrailDistance": atr * global_paper_trader.trail_distance_atr,
            "runtimeTrailDistancePct": round((atr * global_paper_trader.trail_distance_atr / price * 100), 4) if price > 0 else 0.0,
            "runtimeTrailActivationMovePct": 0.0,
            "runtimeTrailActivationRoiPct": 0.0,
            "runtimeTrailThresholdMult": 1.0,
            "runtimeTrailLastUpdateTs": int(datetime.now().timestamp() * 1000),
        }
        
        global_paper_trader.positions.append(position)
        global_paper_trader.add_log(f"ðŸ›’ MARKET ORDER: {side} {symbol} @ ${price:.4f} | {leverage}x | SL: ${sl:.4f} | TP: ${tp:.4f}")
        global_paper_trader.save_state()
        
        logger.info(f"âœ… Market Order: {side} {symbol} @ {price} | finalLev={leverage}x")
        return JSONResponse({"success": True, "position": position})
        
    except Exception as e:
        logger.error(f"Market order error: {e}")
        return JSONResponse({"success": False, "error": str(e)}, status_code=500)


@app.post("/paper-trading/close/{position_id}")
async def paper_trading_close(position_id: str):
    """Close a specific position with real-time price."""
    try:
        # Find position by ID
        pos = next((p for p in global_paper_trader.positions if p['id'] == position_id), None)
        if not pos:
            logger.warning(f"Close position failed: position {position_id} not found. Active positions: {[p['id'] for p in global_paper_trader.positions]}")
            return JSONResponse({"success": False, "message": f"Pozisyon bulunamadÄ±: {position_id}"}, status_code=404)
        
        # Get current price - priority: 1) stored currentPrice 2) scanner opportunities 3) entryPrice fallback
        current_price = pos.get('currentPrice', 0)
        
        if not current_price or current_price <= 0:
            # Try to get from scanner opportunities
            symbol = pos.get('symbol', '')
            for opp in multi_coin_scanner.current_opportunities:
                if opp.get('symbol') == symbol:
                    current_price = opp.get('price', 0)
                    break
        
        if not current_price or current_price <= 0:
            # Final fallback to entry price
            current_price = pos.get('entryPrice', 0)
            logger.warning(f"Using entry price for close (no live price): {position_id}")
        
        if current_price <= 0:
            return JSONResponse({"success": False, "message": "GÃ¼ncel fiyat alÄ±namadÄ±"}, status_code=500)
        
        # Close the position
        success = global_paper_trader.close_position_by_id(position_id, current_price)
        if success:
            return JSONResponse({"success": True, "message": f"Pozisyon kapatÄ±ldÄ± @ ${current_price:.6f}"})
        else:
            logger.error(f"close_position_by_id returned False for {position_id}")
            return JSONResponse({"success": False, "message": "Pozisyon kapatÄ±lamadÄ±"}, status_code=500)
            
    except Exception as e:
        logger.error(f"Error closing position {position_id}: {e}")
        return JSONResponse({"success": False, "message": f"Hata: {str(e)}"}, status_code=500)


# ============================================================================
# PHASE 31: MULTI-COIN SCANNER WEBSOCKET ENDPOINT
# ============================================================================


def _safe_json_default(obj):
    """Fallback serializer for numpy/pandas types that json.dumps can't handle."""
    if isinstance(obj, (np.bool_,)):
        return bool(obj)
    if isinstance(obj, (np.integer,)):
        return int(obj)
    if isinstance(obj, (np.floating,)):
        return float(obj)
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")

@app.websocket("/ws/scanner")
async def scanner_websocket_endpoint(websocket: WebSocket):
    """
    PHASE 98: Simplified WebSocket endpoint using UI State Cache.
    
    Reads from pre-populated cache instead of making fresh Binance API calls.
    Cache is updated every 3 seconds by background_scanner_loop.
    
    Benefits:
    - Instant connection (~0ms vs 3+ minutes before)
    - No Binance API rate limit impact from UI connections
    - All clients see consistent data
    """
    global background_scanner_task
    await websocket.accept()
    logger.info("ðŸš€ Phase 98: Scanner WebSocket connected - using cache")

    # Auto-heal on client connect: dead task OR stale cache.
    task_alive = _is_scanner_task_alive()
    cache_age = int(max(0, datetime.now().timestamp() - ui_state_cache.last_update)) if ui_state_cache.last_update > 0 else 0
    if multi_coin_scanner.running and (not task_alive or cache_age > SCANNER_STALE_CACHE_SEC):
        reason = "ws_connect_dead_task" if not task_alive else f"ws_connect_stale_cache_{cache_age}s"
        await restart_background_scanner(reason=reason)
    
    full_state_interval = 2.0  # Full payload (opportunities + portfolio) cadence
    fast_tick_interval = 0.35  # Fast price ticks for active signals/positions
    last_full_state_sent = 0.0
    
    try:
        def build_warmup_state() -> dict:
            """Build non-empty fallback state while cache is warming up."""
            scanner_stats = multi_coin_scanner.get_scanner_stats() if 'multi_coin_scanner' in globals() else {}
            opps = ui_state_cache.opportunities or getattr(multi_coin_scanner, 'opportunities', []) or []
            min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
            long_count = sum(1 for o in opps if o.get('signalAction') == 'LONG' and o.get('signalScore', 0) >= min_score)
            short_count = sum(1 for o in opps if o.get('signalAction') == 'SHORT' and o.get('signalScore', 0) >= min_score)

            if live_binance_trader.enabled:
                positions = ui_state_cache.positions or global_paper_trader.positions
                balance = ui_state_cache.balance or (ui_state_cache.live_balance or {}).get('walletBalance', 0)
            else:
                positions = ui_state_cache.positions or global_paper_trader.positions
                balance = ui_state_cache.balance or global_paper_trader.balance

            trades = ui_state_cache.trades or global_paper_trader.trades

            return {
                "type": "scanner_update",
                "opportunities": opps,
                "stats": {
                    "totalCoins": scanner_stats.get('totalCoins', len(getattr(multi_coin_scanner, 'coins', []))),
                    "analyzedCoins": scanner_stats.get('analyzedCoins', len(getattr(multi_coin_scanner, 'analyzers', {}))),
                    "longSignals": long_count,
                    "shortSignals": short_count,
                    "activeSignals": long_count + short_count,
                    "lastUpdate": datetime.now().timestamp()
                },
                "portfolio": {
                    "balance": balance,
                    "positions": positions,
                    "trades": sorted(trades, key=lambda t: t.get('closeTime', 0), reverse=True),
                    "stats": {
                        **ui_state_cache.pnl_data,
                        "liveBalance": ui_state_cache.live_balance,
                        "winRate": 0,
                        "totalTrades": len(trades)
                    },
                    "logs": (ui_state_cache.logs or global_paper_trader.logs)[-100:],
                    "enabled": global_paper_trader.enabled
                },
                "tradingMode": "live" if live_binance_trader.enabled else "paper",
                "timestamp": datetime.now().timestamp(),
                "message": "Cache warming up (serving fallback scanner state)"
            }

        async def send_full_state():
            """Send scanner snapshot. Uses fallback state while cache initializes."""
            state = ui_state_cache.get_state() if ui_state_cache.is_ready() else build_warmup_state()
            await websocket.send_text(json.dumps(state, default=_safe_json_default))

        async def send_fast_price_tick():
            """Send lightweight fast price updates for active symbols only."""
            if not binance_ws_manager.tickers:
                return

            min_score = global_paper_trader.min_confidence_score if 'global_paper_trader' in globals() else 40
            source_opps = ui_state_cache.opportunities or getattr(multi_coin_scanner, 'opportunities', []) or []
            signal_symbols = set()
            for opp in source_opps:
                if opp.get('signalAction') != 'NONE' and opp.get('signalScore', 0) >= min_score:
                    sym = opp.get('symbol')
                    if sym:
                        signal_symbols.add(sym)

            source_positions = ui_state_cache.positions or global_paper_trader.positions
            position_symbols = set()
            for pos in source_positions:
                sym = pos.get('symbol')
                if sym:
                    position_symbols.add(sym)

            tracked_symbols = signal_symbols.union(position_symbols)
            if not tracked_symbols:
                return

            tickers = binance_ws_manager.get_tickers(list(tracked_symbols))
            if not tickers:
                return

            all_prices = {}
            signal_prices = {}
            position_prices = {}
            for sym, tick in tickers.items():
                px = float(tick.get('last', 0) or 0)
                if px <= 0:
                    continue
                all_prices[sym] = px
                if sym in signal_symbols:
                    signal_prices[sym] = px
                if sym in position_symbols:
                    position_prices[sym] = px

            if not all_prices:
                return

            await websocket.send_text(json.dumps({
                "type": "price_tick",
                "prices": all_prices,
                "signalPrices": signal_prices,
                "positionPrices": position_prices,
                "timestamp": datetime.now().timestamp()
            }, default=_safe_json_default))

        # INSTANT: Send cached state immediately (no API calls!)
        await send_full_state()
        last_full_state_sent = datetime.now().timestamp()
        if ui_state_cache.is_ready():
            logger.info(f"ðŸ“¦ Phase 98: Sent cached state instantly ({len(ui_state_cache.opportunities)} opportunities)")
        else:
            logger.info("â³ Phase 98: Cache not ready yet, sent empty state")
        
        # Stream fast ticks frequently + full state periodically.
        while True:
            await asyncio.sleep(fast_tick_interval)

            await send_fast_price_tick()

            now_ts = datetime.now().timestamp()
            if now_ts - last_full_state_sent >= full_state_interval:
                await send_full_state()
                last_full_state_sent = now_ts
            
    except WebSocketDisconnect:
        logger.info("Scanner WebSocket client disconnected")
    except Exception as e:
        if "close message" not in str(e).lower() and "disconnect" not in str(e).lower():
            logger.error(f"Scanner WebSocket error: {e}")
    finally:
        # Scanner continues running in background - we don't stop it here
        pass


@app.websocket("/ws/ui")
async def ui_websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for real-time UI updates.
    Broadcasts: signals, positions, prices, logs, kill switch events.
    """
    await ui_ws_manager.connect(websocket)
    
    try:
        # Phase 91: Send initial state with correct data source based on trading mode
        # Use Binance data for live mode, paper trader for paper mode
        
        if live_binance_trader.enabled:
            # Live mode: Get data from Binance
            try:
                initial_balance_data = await live_binance_trader.get_balance()
                initial_balance = initial_balance_data.get('walletBalance', 0)
                initial_live_balance = initial_balance_data
            except:
                initial_balance = 0
                initial_live_balance = None
            
            try:
                initial_positions = await live_binance_trader.get_positions()
            except:
                initial_positions = []
            
            # Get PnL data
            try:
                pnl_data = await live_binance_trader.get_pnl_from_binance()
            except:
                pnl_data = {'todayPnl': 0, 'todayPnlPercent': 0, 'totalPnl': 0, 'totalPnlPercent': 0}
            
            initial_state = {
                "balance": initial_balance,
                "positions": initial_positions,
                "pendingOrders": global_paper_trader.pending_orders,
                "enabled": global_paper_trader.enabled,
                "tradeCount": len(global_paper_trader.trades),
                "trades": global_paper_trader.trades,
                "opportunities": multi_coin_scanner.opportunities if multi_coin_scanner else [],
                # Phase 92: Include scanner stats with totalCoins
                "stats": {
                    "todayPnl": pnl_data.get('todayPnl', 0),
                    "todayPnlPercent": pnl_data.get('todayPnlPercent', 0),
                    "totalPnl": pnl_data.get('totalPnl', 0),
                    "totalPnlPercent": pnl_data.get('totalPnlPercent', 0),
                    "liveBalance": initial_live_balance,
                    # Scanner stats
                    "totalCoins": len(multi_coin_scanner.coins) if multi_coin_scanner and multi_coin_scanner.coins else 0,
                    "analyzedCoins": len(multi_coin_scanner.opportunities) if multi_coin_scanner else 0,
                    "longSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'LONG'),
                    "shortSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'SHORT')
                },
                "logs": global_paper_trader.logs[-100:] if hasattr(global_paper_trader, 'logs') else [],
                "tradingMode": "live"
            }
        else:
            # Paper mode: Use paper trader data
            pnl_data = global_paper_trader.get_today_pnl()
            initial_state = {
                "balance": global_paper_trader.balance,
                "positions": global_paper_trader.positions,
                "pendingOrders": global_paper_trader.pending_orders,
                "enabled": global_paper_trader.enabled,
                "tradeCount": len(global_paper_trader.trades),
                "trades": global_paper_trader.trades,
                "opportunities": multi_coin_scanner.opportunities if multi_coin_scanner else [],
                # Phase 92: Include scanner stats with totalCoins
                "stats": {
                    **global_paper_trader.stats,
                    **pnl_data,
                    # Scanner stats
                    "totalCoins": len(multi_coin_scanner.coins) if multi_coin_scanner and multi_coin_scanner.coins else 0,
                    "analyzedCoins": len(multi_coin_scanner.opportunities) if multi_coin_scanner else 0,
                    "longSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'LONG'),
                    "shortSignals": sum(1 for o in (multi_coin_scanner.opportunities or []) if o.get('signalAction') == 'SHORT')
                },
                "logs": global_paper_trader.logs[-100:] if hasattr(global_paper_trader, 'logs') else [],
                "tradingMode": "paper"
            }
        
        await websocket.send_json({"type": "INITIAL_STATE", "data": initial_state, "timestamp": int(datetime.now().timestamp() * 1000)})
        
        # Keep connection alive and handle incoming messages
        while True:
            try:
                # Wait for any message (ping/pong or commands)
                data = await asyncio.wait_for(websocket.receive_text(), timeout=30)
                
                # Handle ping
                if data == "ping":
                    await websocket.send_text("pong")
                    
            except asyncio.TimeoutError:
                # Send keepalive ping
                try:
                    await websocket.send_text("ping")
                except:
                    break
                    
    except WebSocketDisconnect:
        ui_ws_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"UI WebSocket error: {e}")
        ui_ws_manager.disconnect(websocket)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, symbol: str = None):
    """
    WebSocket endpoint for real-time data streaming.
    """
    await websocket.accept()
    
    # Phase 26 Fix: Prioritize Global Paper Trader Symbol
    # If symbol arg is "BTCUSDT" (default) or None, check if we have a persisted symbol
    active_symbol = symbol
    if not active_symbol or active_symbol == "BTCUSDT":
        if global_paper_trader.symbol and global_paper_trader.symbol != "SOLUSDT": # Avoid default if persisted is different
             active_symbol = global_paper_trader.symbol
        if not active_symbol:
             active_symbol = "BTCUSDT" # Ultimate fallback

    logger.info(f"Client connected. Active Symbol: {active_symbol} (Requested: {symbol}, Global: {global_paper_trader.symbol})")
    
    ccxt_symbol = active_symbol.replace("USDT", "/USDT")
    streamer = BinanceStreamer(ccxt_symbol)
    
    try:
        await streamer.connect()
        streamer.running = True
        streamer.paper_trader = global_paper_trader  # Phase 16: Use global instance
        
        # Phase 28: Load coin profile for dynamic optimization
        await streamer.update_coin_profile()
        
        # Fetch initial OHLCV for ATR (one-time REST call)
        try:
            ohlcv = await streamer.fetch_ohlcv()
            for candle in ohlcv:
                _, _, high, low, close, volume = candle
                streamer.update_price(close, high, low, volume)
        except Exception as e:
            logger.warning(f"Initial OHLCV fetch failed: {e}")
        
        # Wait for WebSocket stream to connect
        await asyncio.sleep(2)
        
        while streamer.running:
            try:
                # Use WebSocket stream data (no REST API calls = no rate limits!)
                ticker = streamer.ws_ticker
                spot_ticker = streamer.ws_spot_ticker
                order_book = streamer.ws_order_book
                
                if ticker and 'last' in ticker:
                    price = ticker['last']
                    high = ticker.get('high', price)
                    low = ticker.get('low', price)
                    volume = ticker.get('volume', 0)
                    streamer.update_price(price, high, low, volume)
                    
                    # Basis Calculation (Futures - Spot)
                    spot_price = spot_ticker.get('last', 0)
                    basis = 0.0
                    basis_pct = 0.0
                    if spot_price > 0:
                        basis = price - spot_price
                        basis_pct = (basis / spot_price) * 100
                    
                    metrics = streamer.get_metrics()
                    
                    # Format order book
                    bids = [
                        {"price": float(b[0]), "size": float(b[1]), "total": 0}
                        for b in order_book.get('bids', [])[:20]
                    ]
                    asks = [
                        {"price": float(a[0]), "size": float(a[1]), "total": 0}
                        for a in order_book.get('asks', [])[:20]
                    ]
                    
                    acc = 0
                    for b in bids:
                        acc += b['size']
                        b['total'] = acc
                    acc = 0
                    for a in asks:
                        acc += a['size']
                        a['total'] = acc
                    
                    imbalance = calculate_imbalance(
                        order_book.get('bids', []),
                        order_book.get('asks', [])
                    )
                    
                    
                    # Generate signal if conditions met
                    signal = None
                    try:
                        whale_z = streamer.whale_detector.get_zscore()
                        
                        # Check Breakout (Phase 11)
                        open_price = ticker.get('open', price)
                        vol_osc = metrics.get('vol_osc', 0)
                        breakout = streamer.pivot_analyzer.check_breakout(price, open_price, vol_osc)
                        
                        # Phase FIB: Update MTF BEFORE generate_signal (so OHLCV cache is fresh)
                        ws_fib_context = None
                        if FIB_ENABLED:
                            try:
                                await mtf_confirmation.update_coin_trend(active_symbol, streamer.exchange)
                                # Build fib_context from cached MTF data
                                trend_data = mtf_confirmation.coin_trends.get(active_symbol, {})
                                if trend_data:
                                    # Determine signal_side from z-score direction
                                    # P2 fix: use direction, not hardcoded Â±1.0 threshold
                                    z = metrics.get('zScore', 0)
                                    pre_side = 'LONG' if z < 0 else ('SHORT' if z > 0 else None)
                                    if pre_side:
                                        # P3 fix: get adx from trend_data (adx_4h), not metrics (has no adx)
                                        ws_adx = trend_data.get('adx_4h', 25)
                                        ws_fib_context = build_fib_context(
                                            signal_side=pre_side,
                                            price=price,
                                            atr=metrics['atr'],
                                            adx=ws_adx,
                                            hurst=metrics['hurst'],
                                            trend_data=trend_data
                                        )
                            except Exception as fib_err:
                                logger.debug(f"FIB context error: {fib_err}")
                        
                        # Phase 235 P2 FIX: Regime-aware params for WS parity with Scanner
                        _ws_market_regime = 'RANGING'
                        _ws_adx = 25.0
                        _ws_adx_trend = 'NEUTRAL'
                        _ws_coin_daily_trend = 'NEUTRAL'
                        _ws_ob_imbalance_trend = 0.0
                        _ws_funding_rate = 0.0
                        _ws_is_volume_spike = False
                        try:
                            _ws_market_regime = market_regime_detector.current_regime
                        except Exception:
                            pass
                        try:
                            trend_data_ws = mtf_confirmation.coin_trends.get(active_symbol, {})
                            _ws_adx = trend_data_ws.get('adx_4h', 25.0)
                            _ws_adx_trend = trend_data_ws.get('adx_trend_4h', 'NEUTRAL')
                            _ws_coin_daily_trend = trend_data_ws.get('daily_trend', 'NEUTRAL')
                        except Exception:
                            pass
                        try:
                            _ws_ob_imbalance_trend = obi_detector.obi_cache.get(active_symbol, {}).get('obi_trend', 0.0)
                        except Exception:
                            pass
                        try:
                            _ws_funding_rate = funding_oi_tracker.funding_rates.get(active_symbol, 0.0)
                        except Exception:
                            pass
                        try:
                            _ws_is_volume_spike = metrics.get('volumeRatio', 1.0) >= 2.0
                        except Exception:
                            pass
                        
                        signal = streamer.signal_generator.generate_signal(
                            hurst=metrics['hurst'],
                            zscore=metrics['zScore'],
                            imbalance=imbalance,
                            price=price,
                            atr=metrics['atr'],
                            vwap_zscore=metrics.get('vwap_zscore', 0),
                            htf_trend=getattr(streamer, 'last_htf_trend', "NEUTRAL"),
                            leverage=getattr(streamer.signal_generator, 'leverage', 10),
                            basis_pct=basis_pct,
                            whale_zscore=whale_z,
                            smc_data=trend_data_ws.get('smc_1h'),
                            breakout=breakout,
                            spread_pct=metrics.get('spreadPct', 0.05),
                            volatility_ratio=metrics.get('volatilityRatio', 1.0),
                            coin_profile=streamer.coin_profile,
                            fib_context=ws_fib_context,
                            # Phase 235 P2: Regime-aware params (Scanner parity)
                            market_regime=_ws_market_regime,
                            adx=_ws_adx,
                            adx_trend=_ws_adx_trend,
                            is_volume_spike=_ws_is_volume_spike,
                            coin_daily_trend=_ws_coin_daily_trend,
                            ob_imbalance_trend=_ws_ob_imbalance_trend,
                            funding_rate=_ws_funding_rate,
                        )
                        
                        # =====================================================
                        # PHASE 63: Cloud Scanner Parity - Real MTF Confirmation
                        # Uses same algorithm as Cloud Scanner for consistency
                        # =====================================================
                        if signal:
                            action = signal['action']
                            atr = metrics['atr']
                            hurst = metrics['hurst']
                            spread_pct = metrics.get('spreadPct', 0.05)
                            
                            # Phase 230B: Add coin data for BTC filter multi-factor override
                            # Source: ws_ticker has 'percentage' (24h change) and 'quoteVolume' (24h USD volume)
                            signal['priceChange24h'] = ticker.get('percentage', 0)
                            signal['volume24h'] = ticker.get('quoteVolume', 0)
                            
                            # Update MTF trends using real OHLCV data (Cloud Scanner parity)
                            # NOTE: If FIB_ENABLED, this was already called above â€” cache TTL prevents re-fetch
                            try:
                                await mtf_confirmation.update_coin_trend(active_symbol, streamer.exchange)
                            except Exception as mtf_update_err:
                                logger.warning(f"MTF trend update error: {mtf_update_err}")
                            
                            # Get MTF confirmation using Cloud Scanner's scoring system
                            mtf_result = mtf_confirmation.confirm_signal(active_symbol, action)
                            mtf_score = mtf_result.get('mtf_score', 0)
                            mtf_confirmed = mtf_result.get('confirmed', False)
                            score_modifier = mtf_result.get('score_modifier', 1.0)
                            
                            # Log MTF result (Cloud Scanner parity)
                            if score_modifier > 1.0:
                                logger.info(f"âœ… MTF BONUS: {action} {active_symbol} (skor: +{mtf_score}) - pozisyon +%{int((score_modifier-1)*100)} bÃ¼yÃ¼k")
                            elif score_modifier < 1.0 and mtf_confirmed:
                                logger.info(f"âš ï¸ MTF PENALTY: {action} {active_symbol} (skor: {mtf_score}) - pozisyon -%{int((1-score_modifier)*100)} kÃ¼Ã§Ã¼k")
                            
                            if not mtf_confirmed:
                                logger.info(f"ðŸš« MTF RED: {action} {active_symbol} (skor: {mtf_score}) - sinyal reddedildi")
                                signal = None
                            else:
                                # Add MTF size modifier to signal
                                signal['mtf_size_modifier'] = score_modifier
                                signal['mtf_score'] = mtf_score
                                
                                # =====================================================
                                # DYNAMIC LEVERAGE (Cloud Scanner Parity)
                                # Calculate leverage based on MTF + PRICE + SPREAD + VOLATILITY
                                # =====================================================
                                try:
                                    import math
                                    
                                    # Calculate TF count from scores (positive score = aligned)
                                    scores = mtf_result.get('scores', {'15m': 0, '1h': 0, '4h': 0, '1d': 0})
                                    tf_count = sum(1 for s in scores.values() if s > 0)
                                    
                                    # Base leverage from MTF agreement
                                    if tf_count >= 4:
                                        base_leverage = 100  # All 4 TFs aligned
                                    elif tf_count >= 3:
                                        base_leverage = 75   # 3 TFs aligned
                                    elif tf_count >= 2:
                                        base_leverage = 50   # 2 TFs aligned
                                    else:
                                        base_leverage = 25   # 0-1 TF aligned
                                    
                                    # PRICE FACTOR: Logarithmic reduction for low-price coins
                                    if price > 0:
                                        log_price = math.log10(max(price, 0.0001))
                                        price_factor = max(0.3, min(1.0, (log_price + 2) / 4))
                                    else:
                                        price_factor = 1.0
                                    
                                    # SPREAD FACTOR: High spread = lower leverage
                                    if spread_pct > 0:
                                        spread_factor = max(0.5, 1.0 - spread_pct * 2)
                                    else:
                                        spread_factor = 1.0
                                    
                                    # VOLATILITY FACTOR: High ATR = lower leverage
                                    volatility_pct = (atr / price * 100) if price > 0 and atr > 0 else 2.0
                                    if volatility_pct <= 2.0:
                                        volatility_factor = 1.0
                                    elif volatility_pct <= 4.0:
                                        volatility_factor = 0.8
                                    elif volatility_pct <= 6.0:
                                        volatility_factor = 0.6
                                    elif volatility_pct <= 10.0:
                                        volatility_factor = 0.4
                                    else:
                                        volatility_factor = 0.3
                                    
                                    # COMBINED LEVERAGE:
                                    # backend selector output (MTF+price+spread+volatility) Ã— user multiplier (Settings modal)
                                    base_dynamic_leverage = base_leverage * price_factor * spread_factor * volatility_factor
                                    user_lev_mult = (
                                        getattr(global_paper_trader, 'leverage_multiplier', 1.0)
                                        if 'global_paper_trader' in globals() else 1.0
                                    )
                                    dynamic_leverage = int(round(base_dynamic_leverage * user_lev_mult))
                                    dynamic_leverage = max(3, min(75, dynamic_leverage))
                                    
                                    signal['leverage'] = dynamic_leverage
                                    signal['leverage_includes_user_mult'] = True
                                    signal['leverage_user_mult'] = round(user_lev_mult, 2)
                                    signal['baseLeverage'] = max(3, min(75, int(round(base_dynamic_leverage))))
                                    signal['tf_count'] = tf_count
                                    signal['price_factor'] = round(price_factor, 2)
                                    signal['spread_factor'] = round(spread_factor, 2)
                                    signal['volatility_factor'] = round(volatility_factor, 2)
                                    signal['volatility_pct'] = round(volatility_pct, 2)
                                    
                                    # Log if any factor reduced leverage
                                    if price_factor < 0.9 or spread_factor < 0.9 or volatility_factor < 0.9 or user_lev_mult != 1.0:
                                        logger.info(
                                            f"ðŸ“Š Leverage: base={base_leverage}x Ã— price={price_factor:.2f} Ã— spread={spread_factor:.2f} Ã— vol={volatility_factor:.2f} Ã— user={user_lev_mult:.1f} "
                                            f"â†’ {dynamic_leverage}x | {active_symbol} @ ${price:.6f} (ATR:{volatility_pct:.1f}%)"
                                        )
                                    else:
                                        logger.info(f"ðŸ“Š Dynamic Leverage: {dynamic_leverage}x (TF:{tf_count}/3)")
                                except Exception as lev_err:
                                    logger.warning(f"Dynamic leverage error: {lev_err}")
                                    user_lev_mult = (
                                        getattr(global_paper_trader, 'leverage_multiplier', 1.0)
                                        if 'global_paper_trader' in globals() else 1.0
                                    )
                                    signal['leverage'] = max(3, min(75, int(round(25 * user_lev_mult))))
                                    signal['leverage_includes_user_mult'] = True
                                    signal['leverage_user_mult'] = round(user_lev_mult, 2)
                                
                                # =====================================================
                                # VOLUME PROFILE BOOST (Cloud Scanner Parity)
                                # Uses per-coin volume profiler
                                # =====================================================
                                try:
                                    # Get or create per-coin volume profiler
                                    if active_symbol not in coin_volume_profiles:
                                        coin_volume_profiles[active_symbol] = VolumeProfileAnalyzer()
                                    
                                    coin_vp = coin_volume_profiles[active_symbol]
                                    
                                    # Update volume profile if stale (every hour)
                                    if datetime.now().timestamp() - coin_vp.last_update > 3600:
                                        ohlcv_4h = await streamer.exchange.fetch_ohlcv(ccxt_symbol, '4h', limit=100)
                                        if ohlcv_4h:
                                            coin_vp.calculate_profile(ohlcv_4h)
                                            logger.debug(f"Updated VP for {active_symbol}: POC={coin_vp.poc:.6f}")
                                    
                                    # Get boost based on price proximity to key levels
                                    vp_boost = coin_vp.get_signal_boost(price, action)
                                    if vp_boost > 0:
                                        signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 + vp_boost)
                                        signal['vp_boost'] = vp_boost
                                        logger.info(f"ðŸ“ˆ VP BOOST: {active_symbol} +{vp_boost*100:.0f}% @ POC={coin_vp.poc:.6f}")
                                except Exception as vp_err:
                                    logger.warning(f"Volume Profile error: {vp_err}")
                                
                                # =====================================================
                                # DYNAMIC TRAIL PARAMETERS (Cloud Scanner Parity)
                                # Calculate trail_activation and trail_distance per-coin
                                # =====================================================
                                try:
                                    volatility_pct = signal.get('volatility_pct', (atr / price * 100) if price > 0 else 3.0)
                                    
                                    # Calculate dynamic trail params
                                    trail_activation_atr, trail_distance_atr = get_dynamic_trail_params(
                                        volatility_pct=volatility_pct,
                                        hurst=hurst,
                                        price=price,
                                        spread_pct=spread_pct,
                                        settings_activation=global_paper_trader.trail_activation_atr,  # Phase 231: Cap
                                        settings_distance=global_paper_trader.trail_distance_atr  # Phase 231: Cap
                                    )
                                    
                                    signal['dynamic_trail_activation'] = trail_activation_atr
                                    signal['dynamic_trail_distance'] = trail_distance_atr
                                    signal['hurst'] = hurst
                                    signal['spreadPct'] = spread_pct
                                    
                                    # Log if significantly different from defaults (1.5, 1.0)
                                    if abs(trail_activation_atr - 1.5) > 0.3 or abs(trail_distance_atr - 1.0) > 0.2:
                                        logger.info(f"ðŸŽ¯ Dynamic Trail: act={trail_activation_atr}x, dist={trail_distance_atr}x | {active_symbol} (vol:{volatility_pct:.1f}%, hurst:{hurst:.2f})")
                                except Exception as trail_err:
                                    logger.debug(f"Dynamic trail params error: {trail_err}")
                                
                                # =====================================================
                                # BTC CORRELATION FILTER
                                # =====================================================
                                try:
                                    await btc_filter.update_btc_state(streamer.exchange)
                                    btc_allowed, btc_penalty, btc_reason = btc_filter.should_allow_signal(
                                        active_symbol, signal['action'],
                                        coin_change_pct=signal.get('priceChange24h', 0),
                                        volume_24h=signal.get('volume24h', 0),
                                        zscore=signal.get('zscore', 0),
                                        spread_pct=signal.get('spreadPct', 0)
                                    )
                                    
                                    if not btc_allowed:
                                        logger.info(f"BTC FILTER BLOCKED: {btc_reason}")
                                        signal = None
                                    elif btc_penalty != 0:
                                        signal['sizeMultiplier'] = signal.get('sizeMultiplier', 1.0) * (1 - btc_penalty)
                                        if btc_penalty > 0:
                                            cap_lev, cap_size = get_btc_penalty_risk_caps(btc_penalty)
                                            if cap_lev:
                                                existing_cap = signal.get('overrideLeverageCap')
                                                signal['overrideLeverageCap'] = min(existing_cap, cap_lev) if existing_cap else cap_lev
                                                # Phase 238B: Leverage pipeline
                                                signal['leverageCapApplied'] = True
                                                signal['leverageCapValue'] = signal['overrideLeverageCap']
                                                signal['leverageCapReason'] = f"BTC_FILTER:{btc_reason.split(':')[0] if ':' in btc_reason else 'MODERATE'}"
                                            if cap_size:
                                                signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), cap_size)
                                        signal['btc_adjustment'] = btc_reason
                                        logger.info(f"BTC ADJUSTMENT: {btc_reason} | Size: {signal.get('sizeMultiplier', 1.0):.2f}x")
                                        # Phase 230B: Override risk caps
                                        if btc_filter.last_override:
                                            existing_cap = signal.get('overrideLeverageCap')
                                            signal['overrideLeverageCap'] = min(existing_cap, 3) if existing_cap else 3
                                            signal['sizeMultiplier'] = min(signal.get('sizeMultiplier', 1.0), 0.5)
                                            # Phase 238B: Leverage pipeline
                                            signal['leverageCapApplied'] = True
                                            signal['leverageCapValue'] = signal['overrideLeverageCap']
                                            signal['leverageCapReason'] = 'BTC_FILTER:EXTREME'
                                            logger.info(f"ðŸ’ª WS OVERRIDE CAPS: {active_symbol} | leverageâ‰¤3x, sizeâ‰¤0.5x")
                                except Exception as btc_err:
                                    logger.warning(f"BTC Filter error: {btc_err}")
                                
                                # Execute trade if signal still valid
                                if signal:
                                    trends = mtf_result.get('trends', {})
                                    logger.info(f"ðŸ¤– WS-Trade: {action} {active_symbol} @ ${price:.4f} | MTF:{mtf_score} | Lev:{signal.get('leverage', 50)}x | 15m:{trends.get('15m','?')}, 1h:{trends.get('1h','?')}, 4h:{trends.get('4h','?')}")
                                    
                                    try:
                                        if hasattr(streamer, 'paper_trader') and streamer.paper_trader:
                                            streamer.paper_trader.current_spread_pct = spread_pct
                                            streamer.paper_trader.on_signal(signal, price)
                                    except Exception as pt_err:
                                        logger.error(f"Paper Trading Error: {pt_err}")
                                    
                                    manager.last_signals[symbol] = signal
                                    logger.info(f"SIGNAL GENERATED: {signal['action']} @ {price}")

                    except Exception as e:
                        logger.error(f"Signal Generation Error: {e}")
                        # Ensure variables used below are at least defined if they fail
                        whale_z = 0
                        breakout = None
                    
                    # Use WhaleZ in metrics display if desired
                    metrics['whale_z'] = round(whale_z, 2)
                    
                    # Get pending liquidation
                    liquidation = streamer.pending_liquidation
                    streamer.pending_liquidation = None
                    
                    # Convert deques to lists for JSON serialization
                    active_supports = list(streamer.pivot_analyzer.supports)
                    active_resistances = list(streamer.pivot_analyzer.resistances)
                    
                    response = {
                        "type": "update",
                        "price": price,
                        "spotPrice": spot_price, # NEW
                        "basis": round(basis, 2), # NEW
                        "basisPercent": round(basis_pct, 4), # NEW
                        "metrics": metrics,
                        "orderBook": {
                            "bids": bids,
                            "asks": asks,
                            "imbalance": round(imbalance, 2)
                        },
                        "liquidation": liquidation,
                        "signal": signal,
                        "smc": { # NEW Phase 10
                            "fvgs": streamer.smc_analyzer.fvgs,
                            "structure": streamer.smc_analyzer.structure
                        },
                        "pivots": { # NEW Phase 11
                            "supports": active_supports,
                            "resistances": active_resistances,
                            "breakout": breakout
                        },
                        "portfolio": { # Phase 15: Cloud Portfolio
                            "balance": streamer.paper_trader.balance if hasattr(streamer, 'paper_trader') else 10000,
                            "positions": streamer.paper_trader.positions if hasattr(streamer, 'paper_trader') else [],
                            "stats": streamer.paper_trader.stats if hasattr(streamer, 'paper_trader') else {},
                            "equityCurve": streamer.paper_trader.equity_curve[-100:] if hasattr(streamer, 'paper_trader') else [],
                            # Phase 21: Live updates
                            "trades": streamer.paper_trader.trades[-20:] if hasattr(streamer, 'paper_trader') else [],
                            "logs": streamer.paper_trader.logs[-30:] if hasattr(streamer, 'paper_trader') else [],
                            "cloudSymbol": streamer.paper_trader.symbol if hasattr(streamer, 'paper_trader') else "UNKNOWN"
                        }
                    }
                    
                    await websocket.send_json(response)
                    
                await asyncio.sleep(1.0)  # Slow down main loop
                
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.error(f"Stream error: {e}")
                await asyncio.sleep(2)
                
    except WebSocketDisconnect:
        logger.info("Client disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await streamer.disconnect()


# ============================================================================
# BACKTEST ENGINE
# ============================================================================

from pydantic import BaseModel
from typing import List
import ccxt as ccxt_sync

class BacktestRequest(BaseModel):
    symbol: str = "BTCUSDT"
    timeframe: str = "1h"
    startDate: str = "2025-12-01"
    endDate: str = "2025-12-31"
    initialBalance: float = 10000
    leverage: int = 10
    riskPerTrade: float = 2

class BacktestTrade(BaseModel):
    id: str
    side: str
    entryPrice: float
    exitPrice: float
    entryTime: int
    exitTime: int
    pnl: float
    pnlPercent: float
    closeReason: str

class BacktestResult(BaseModel):
    trades: List[dict]
    equityCurve: List[dict]
    priceData: List[dict]
    stats: dict


def run_backtest_simulation(
    ohlcv_data: list,
    initial_balance: float,
    leverage: int,
    risk_per_trade: float
) -> tuple:
    """
    Run backtest simulation on historical OHLCV data.
    Returns (trades, equity_curve, stats)
    """
    trades = []
    equity_curve = []
    balance = initial_balance
    position = None
    pending_order = None
    
    # Data storage for calculations
    prices = []
    highs = []
    lows = []
    closes = []
    spreads = []
    
    peak_balance = initial_balance
    max_drawdown = 0
    
    for i, candle in enumerate(ohlcv_data):
        timestamp, open_p, high, low, close, volume = candle
        
        prices.append(close)
        highs.append(high)
        lows.append(low)
        closes.append(close)
        
        # 0. Check Pending Order (Limit Entry)
        if pending_order:
            # Expiry check (1 candle max wait ~ 1h, though user said 15m)
            # Since we only have 1H bars, if it doesn't fill in this candle (the one after signal), we cancel.
            if timestamp - pending_order['timestamp'] > 3600 * 2: # Give it 2 candles grace? No, strictly 1.
                 pending_order = None
            else:
                 # Try to fill
                 filled = False
                 if pending_order['side'] == 'LONG':
                     if low <= pending_order['entryPrice']:
                         filled = True
                 else: # SHORT
                     if high >= pending_order['entryPrice']:
                         filled = True
                 
                 if filled:
                     entry_price = pending_order['entryPrice']
                     risk_amt = balance * (risk_per_trade / 100)
                     size_usd = risk_amt * leverage * pending_order['sizeMultiplier']
                     size_token = size_usd / entry_price
                     
                     position = {
                        'side': pending_order['side'],
                        'entryPrice': entry_price,
                        'size': size_token,
                        'sizeUsd': size_usd,
                        'sl': pending_order['sl'],
                        'tp': pending_order['tp'],
                        'trailActivation': pending_order['trailActivation'],
                        'trailDistance': pending_order['trailDistance'],
                        'isTrailingActive': False,
                        'trailingStop': pending_order['sl'],
                        'entryTime': timestamp,
                        'slMoved': False, # For Breakeven Logic
                        'initialSL': pending_order['sl'],
                        'max_r': 0.0
                    }
                     pending_order = None # Consumed
        
        # Need at least 50 candles for calculations
        if len(prices) < 50:
            equity_curve.append({
                "time": timestamp,
                "balance": balance,
                "price": close
            })
            continue
        
        # Calculate spread
        ma = np.mean(prices[-20:])
        spread = close - ma
        spreads.append(spread)
        
        # Calculate metrics
        hurst = calculate_hurst(prices[-100:] if len(prices) >= 100 else prices)
        zscore = calculate_zscore(spreads) if len(spreads) >= 20 else 0
        atr = calculate_atr(highs[-30:], lows[-30:], closes[-30:])
        
        # Simulate order book imbalance (correlated with Z-Score for mean-reversion)
        # When Z-Score high (overbought), OB tends negative (selling pressure)
        np.random.seed(int(timestamp) % 10000)
        noise = np.random.uniform(-15, 15)
        imbalance = -zscore * 5 + noise  # Negative correlation with Z-Score
        imbalance = max(-40, min(40, imbalance))
        
        # Simulated Backtest Inputs for Parity
        # 1. VWAP Simulation
        # Since we have Volume in backtest data, we can calculate real VWAP
        # But our `prices` list doesn't store volume history in this simplified engine
        # So we'll use a simplified approximation or mock it.
        # Ideally we refactor engine to store volumes, but for now let's approximate:
        # If High Volume + Price Move -> VWAP confirms
        # For simulation parity, we'll use the Z-Score correlation method again
        # Negative correlation: Price High -> VWAP usually lags -> VWAP Z-Score High
        vwap_zscore = zscore * 0.8  # High correlation assumption
        
        # 2. HTF Trend Simulation
        # Taking 1H data, we can approximate 4H trend by looking at last 4 hours
        if len(prices) >= 4:
            p4 = prices[-4:]
            if p4[-1] > p4[0]: htf_trend = "BULLISH"
            else: htf_trend = "BEARISH"
        else:
            htf_trend = "NEUTRAL"
            
        # 3. Use REAL SignalGenerator (Parity)
        # We need to instantiate it once outside loop, but for now let's use a fresh one 
        # or better, pass one in. For simplicity in this function script:
        # We'll just instantiate. Note: state like 'last_signal_time' resets every loop if we do this
        # SO WE MUST instantiate outside loop.
        
        # ... Wait, we can't instantiate inside loop or state is lost.
        # Moving instantiation to top of function (done in next step logic if needed, 
        # but here we'll assume 'generator' is available or create a lightweight version)
        
        # Actually, let's just interpret the logic here to match EXACTLY or use the class.
        # Using the class is best.
        if 'generator' not in locals():
            generator = SignalGenerator()
            generator.min_signal_interval = 0 # Disable time check for backtest 1H candles
        
        # Phase 29: Simulate spread based on volatility
        # Higher volatility = higher spread (realistic simulation)
        volatility = atr / close * 100 if close > 0 else 1.0
        simulated_spread_pct = 0.02 + (volatility * 0.03)  # Base 0.02% + volatility adjustment
        simulated_spread_pct = min(0.5, simulated_spread_pct)  # Cap at 0.5%
        
        # Volatility ratio simulation
        volatility_ratio = volatility / 2.0 if volatility > 0 else 1.0  # Normalized to ~1.0
        
        # Create simulated coin profile for backtest
        # Phase 29: More aggressive parameters for DOGE backtest
        coin_profile = {
            'symbol': 'backtest',
            'optimal_threshold': 0.5,  # Very aggressive threshold for DOGE (Z > 0.5)
            'min_score': 40,  # Lower minimum for more signals in backtest
            'avg_atr_pct': volatility,
            'sl_atr': 2.0,
            'tp_atr': 3.0,
            'is_backtest': True  # Flag to skip adaptive threshold
        }
            
        signal_dict = generator.generate_signal(
            hurst=hurst,
            zscore=zscore,
            imbalance=imbalance,
            price=close,
            atr=atr,
            vwap_zscore=vwap_zscore,
            htf_trend=htf_trend,
            leverage=leverage,
            basis_pct=0.0,  # Backtest doesn't support Spot/Basis yet
            whale_zscore=0.0,  # Backtest doesn't support Whale Flow yet
            spread_pct=simulated_spread_pct,  # Phase 29: Spread simulation
            volatility_ratio=volatility_ratio,  # Phase 29: Volatility ratio
            coin_profile=coin_profile  # Phase 29: Coin profile
        )
        

        
        # Check existing position for SL/TP
        if position:
            if position['side'] == 'LONG':
                unrealized_pnl = (close - position['entryPrice']) * position['size']
                curr_pnl_pct = (unrealized_pnl / position['sizeUsd']) * 100 * leverage
                
                # 1. RESCUE MISSION (Stale Position)
                duration = timestamp - position['entryTime']
                if duration >= 3600 and unrealized_pnl < 0:
                     if high >= position['entryPrice']:
                         # Rescue!
                         exit_price = position['entryPrice']
                         pnl = 0
                         balance += pnl
                         trades.append({
                            'id': str(len(trades)), 'side': 'LONG', 'entryPrice': position['entryPrice'],
                            'exitPrice': exit_price, 'entryTime': position['entryTime'], 'exitTime': timestamp,
                            'pnl': 0, 'pnlPercent': 0, 'closeReason': 'RESCUE'
                         })
                         position = None
                         continue

                # 2. STEP TRAILING LOGIC (R-Based Risk Management)
                # Calculates R (Risk Unit) and trails Stop Loss based on profit milestones
                
                initial_risk = abs(position['entryPrice'] - position['initialSL'])
                if initial_risk == 0: initial_risk = position['entryPrice'] * 0.01 # Fallback to 1%

                # Calculate Max Price reached during this candle (Potential Max R)
                # Long: High, Short: Low
                if position['side'] == 'LONG':
                    # Check if SL hit first intra-candle?
                    # Worst case assumption: We check SL hit based on Low first (handled in Exits below)
                    # Here we update SL for NEXT candle based on High
                    current_r = (high - position['entryPrice']) / initial_risk
                else:
                    current_r = (position['entryPrice'] - low) / initial_risk

                # Update Max R Reached
                position['max_r'] = max(position.get('max_r', 0), current_r)
                
                # Apply Step Logic
                new_sl = position['sl']
                if position['side'] == 'LONG':
                    if position['max_r'] >= 4.0:
                        # Trail 2.5R locked (Trails 1.5R behind)
                        target_sl = position['entryPrice'] + (2.5 * initial_risk)
                        # Continuous trail above 4R: Entry + (MaxR - 1.5) * R
                        continuous_sl = position['entryPrice'] + (position['max_r'] - 1.5) * initial_risk
                        target_sl = max(target_sl, continuous_sl)
                        new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 3.0:
                         # Level 3: Lock 1.5R
                         target_sl = position['entryPrice'] + (1.5 * initial_risk)
                         new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 2.0:
                         # Level 2: Lock 0.5R
                         target_sl = position['entryPrice'] + (0.5 * initial_risk)
                         new_sl = max(new_sl, target_sl)
                    elif position['max_r'] >= 1.0:
                         # Level 1: Breakeven
                         new_sl = max(new_sl, position['entryPrice'])
                else: # SHORT
                    if position['max_r'] >= 4.0:
                        target_sl = position['entryPrice'] - (2.5 * initial_risk)
                        continuous_sl = position['entryPrice'] - (position['max_r'] - 1.5) * initial_risk
                        target_sl = min(target_sl, continuous_sl)
                        new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 3.0:
                         target_sl = position['entryPrice'] - (1.5 * initial_risk)
                         new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 2.0:
                         target_sl = position['entryPrice'] - (0.5 * initial_risk)
                         new_sl = min(new_sl, target_sl)
                    elif position['max_r'] >= 1.0:
                         new_sl = min(new_sl, position['entryPrice'])

                position['sl'] = new_sl
                # We disable 'trailingStop' logic from pending order to avoid conflict
                position['isTrailingActive'] = True # Mark as active so effective_sl uses this?
                # Actually below we use 'trailingStop' if 'isTrailingActive' is True.
                # Let's map 'sl' to 'trailingStop' seamlessly
                position['trailingStop'] = new_sl
                
                # Check exits
                effective_sl = position['trailingStop'] if position['isTrailingActive'] else position['sl']
                if low <= effective_sl:
                    exit_price = effective_sl
                    pnl = (exit_price - position['entryPrice']) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'LONG',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TRAILING' if position['isTrailingActive'] else 'SL'
                    })
                    position = None
                elif high >= position['tp']:
                    exit_price = position['tp']
                    pnl = (exit_price - position['entryPrice']) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'LONG',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TP'
                    })
                    position = None
                # Check scaling out (Simulated) - simplified for backtest
                
            else:  # SHORT
                unrealized_pnl = (position['entryPrice'] - close) * position['size']
                curr_pnl_pct = (unrealized_pnl / position['sizeUsd']) * 100 * leverage
                
                # 1. RESCUE MISSION
                duration = timestamp - position['entryTime']
                if duration >= 3600 and unrealized_pnl < 0:
                     if low <= position['entryPrice']:
                         exit_price = position['entryPrice']
                         pnl = 0
                         balance += pnl
                         trades.append({
                            'id': str(len(trades)), 'side': 'SHORT', 'entryPrice': position['entryPrice'],
                            'exitPrice': exit_price, 'entryTime': position['entryTime'], 'exitTime': timestamp,
                            'pnl': 0, 'pnlPercent': 0, 'closeReason': 'RESCUE'
                         })
                         position = None
                         continue

                # 2. BREAKEVEN
                if curr_pnl_pct > 0.5 and not position.get('slMoved', False):
                    position['sl'] = position['entryPrice']
                    position['slMoved'] = True

                if close <= position['trailActivation'] and not position['isTrailingActive']:
                    position['isTrailingActive'] = True
                    position['trailingStop'] = close + position['trailDistance']
                if position['isTrailingActive'] and close + position['trailDistance'] < position['trailingStop']:
                    position['trailingStop'] = close + position['trailDistance']
                
                effective_sl = position['trailingStop'] if position['isTrailingActive'] else position['sl']
                if high >= effective_sl:
                    exit_price = effective_sl
                    pnl = (position['entryPrice'] - exit_price) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'SHORT',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TRAILING' if position['isTrailingActive'] else 'SL'
                    })
                    position = None
                elif low <= position['tp']:
                    exit_price = position['tp']
                    pnl = (position['entryPrice'] - exit_price) * position['size']
                    balance += pnl
                    trades.append({
                        'id': str(len(trades)),
                        'side': 'SHORT',
                        'entryPrice': position['entryPrice'],
                        'exitPrice': exit_price,
                        'entryTime': position['entryTime'],
                        'exitTime': timestamp,
                        'pnl': round(pnl, 2),
                        'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
                        'closeReason': 'TP'
                    })
                    position = None
        
        # Open entry if no position
        # Open entry if no position
        elif signal_dict:
            # SignalGenerator returned a valid signal!
            action = signal_dict['action']
            
            # Create PENDING ORDER (Wait for Pullback Limit)
            # SignalGenerator now returns 'entryPrice' which is the Limit price
            limit_price = signal_dict.get('entryPrice', close) # Fallback to close if missing
            
            pending_order = {
                'side': action,
                'entryPrice': limit_price,
                'sl': signal_dict['sl'],
                'tp': signal_dict['tp'],
                'trailActivation': signal_dict['trailActivation'],
                'trailDistance': signal_dict['trailDistance'],
                'sizeMultiplier': signal_dict.get('sizeMultiplier', 1.0),
                'timestamp': timestamp # Signal time
            }
            # Position will be created in NEXT loop iteration if Limit fills
        

        
        # Update peak and drawdown
        if balance > peak_balance:
            peak_balance = balance
        current_dd = ((peak_balance - balance) / peak_balance) * 100
        if current_dd > max_drawdown:
            max_drawdown = current_dd
        
        equity_curve.append({
            "time": timestamp,
            "balance": round(balance, 2),
            "price": close
        })
    
    # Close any remaining position at last price
    if position and ohlcv_data:
        last_close = ohlcv_data[-1][4]
        last_time = ohlcv_data[-1][0]
        if position['side'] == 'LONG':
            pnl = (last_close - position['entryPrice']) * position['size']
        else:
            pnl = (position['entryPrice'] - last_close) * position['size']
        balance += pnl
        trades.append({
            'id': str(len(trades)),
            'side': position['side'],
            'entryPrice': position['entryPrice'],
            'exitPrice': last_close,
            'entryTime': position['entryTime'],
            'exitTime': last_time,
            'pnl': round(pnl, 2),
            'pnlPercent': round((pnl / position['sizeUsd']) * 100 * leverage, 2),
            'closeReason': 'END'
        })
    
    # Calculate stats
    winning_trades = [t for t in trades if t['pnl'] > 0]
    losing_trades = [t for t in trades if t['pnl'] <= 0]
    total_wins = sum(t['pnl'] for t in winning_trades)
    total_losses = abs(sum(t['pnl'] for t in losing_trades))
    
    stats = {
        'totalTrades': len(trades),
        'winningTrades': len(winning_trades),
        'losingTrades': len(losing_trades),
        'winRate': round((len(winning_trades) / len(trades)) * 100, 2) if trades else 0,
        'totalPnl': round(balance - initial_balance, 2),
        'totalPnlPercent': round(((balance - initial_balance) / initial_balance) * 100, 2),
        'maxDrawdown': round(max_drawdown, 2),
        'profitFactor': round(total_wins / total_losses, 2) if total_losses > 0 else 999,
        'avgWin': round(total_wins / len(winning_trades), 2) if winning_trades else 0,
        'avgLoss': round(total_losses / len(losing_trades), 2) if losing_trades else 0,
        'finalBalance': round(balance, 2)
    }
    
    return trades, equity_curve, stats


@app.post("/backtest")
async def run_backtest(request: BacktestRequest):
    """
    Run backtest on historical data.
    """
    logger.info(f"Starting backtest for {request.symbol} from {request.startDate} to {request.endDate}")
    
    try:
        # Use synchronous CCXT for fetching historical data
        exchange = ccxt_sync.binance({
            'enableRateLimit': True,
            'options': {'defaultType': 'future'}
        })
        
        # Parse dates
        start_ts = int(datetime.strptime(request.startDate, "%Y-%m-%d").timestamp() * 1000)
        end_ts = int(datetime.strptime(request.endDate, "%Y-%m-%d").timestamp() * 1000)
        
        logger.info(f"Backtest Date Range: {request.startDate} ({start_ts}) to {request.endDate} ({end_ts})")
        
        # Fetch OHLCV data
        symbol = request.symbol.replace("USDT", "/USDT")
        all_ohlcv = []
        current_ts = start_ts
        
        while current_ts < end_ts:
            logger.info(f"Fetching from {current_ts}...")
            ohlcv = exchange.fetch_ohlcv(symbol, request.timeframe, since=current_ts, limit=1000)
            if not ohlcv:
                logger.warning("No data returned from fetch_ohlcv")
                break
            
            logger.info(f"Fetched {len(ohlcv)} candles. First: {ohlcv[0][0]}, Last: {ohlcv[-1][0]}")
            all_ohlcv.extend(ohlcv)
            current_ts = ohlcv[-1][0] + 1
            if len(ohlcv) < 1000:
                break
        
        # Filter to date range
        all_ohlcv = [c for c in all_ohlcv if start_ts <= c[0] <= end_ts]
        
        logger.info(f"Total candles after filter: {len(all_ohlcv)}")
        
        # Run simulation
        trades, equity_curve, stats = run_backtest_simulation(
            all_ohlcv,
            request.initialBalance,
            request.leverage,
            request.riskPerTrade
        )
        
        # Format price data for chart
        price_data = [
            {
                "time": c[0],
                "open": c[1],
                "high": c[2],
                "low": c[3],
                "close": c[4],
                "volume": c[5]
            }
            for c in all_ohlcv[::max(1, len(all_ohlcv)//500)]  # Limit to 500 points
        ]
        
        logger.info(f"Backtest complete: {stats['totalTrades']} trades, {stats['winRate']}% win rate")
        
        return {
            "trades": trades,
            "equityCurve": equity_curve[::max(1, len(equity_curve)//500)],
            "priceData": price_data,
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"Backtest error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("Starting HHQ-1 Quant Backend v2.0...")
    logger.info("WebSocket endpoint: ws://localhost:8000/ws?symbol=BTCUSDT")
    logger.info("Backtest endpoint: POST http://localhost:8000/backtest")
    logger.info("Health check: http://localhost:8000/health")
    logger.info("Features: ATR, Liquidation Stream, 4-Layer Signal, Backtest")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
